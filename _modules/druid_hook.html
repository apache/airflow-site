

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>druid_hook &mdash; Airflow Documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="Airflow Documentation" href="../index.html"/>
        <link rel="up" title="Module code" href="index.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Airflow
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../project.html">Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ui.html">UI / Screenshots</a></li>
<li class="toctree-l1"><a class="reference internal" href="../concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../profiling.html">Data Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cli.html">Command Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scheduler.html">Scheduling &amp; Triggers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plugins.html">Plugins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../security.html">Security</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code.html">API Reference</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">Airflow</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
          <li><a href="index.html">Module code</a> &raquo;</li>
      
    <li>druid_hook</li>
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for druid_hook</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">from</span> <span class="nn">pydruid.client</span> <span class="kn">import</span> <span class="n">PyDruid</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="kn">from</span> <span class="nn">airflow.hooks.base_hook</span> <span class="kn">import</span> <span class="n">BaseHook</span>
<span class="kn">from</span> <span class="nn">airflow.exceptions</span> <span class="kn">import</span> <span class="n">AirflowException</span>

<span class="n">LOAD_CHECK_INTERVAL</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">DEFAULT_TARGET_PARTITION_SIZE</span> <span class="o">=</span> <span class="mi">5000000</span>

<span class="k">class</span> <span class="nc">AirflowDruidLoadException</span><span class="p">(</span><span class="n">AirflowException</span><span class="p">):</span>
    <span class="k">pass</span>


<div class="viewcode-block" id="DruidHook"><a class="viewcode-back" href="../code.html#airflow.hooks.DruidHook">[docs]</a><span class="k">class</span> <span class="nc">DruidHook</span><span class="p">(</span><span class="n">BaseHook</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Interact with druid.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">druid_query_conn_id</span><span class="o">=</span><span class="s1">&#39;druid_query_default&#39;</span><span class="p">,</span>
            <span class="n">druid_ingest_conn_id</span><span class="o">=</span><span class="s1">&#39;druid_ingest_default&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">druid_query_conn_id</span> <span class="o">=</span> <span class="n">druid_query_conn_id</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">druid_ingest_conn_id</span> <span class="o">=</span> <span class="n">druid_ingest_conn_id</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">header</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;content-type&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json&#39;</span><span class="p">}</span>

<div class="viewcode-block" id="DruidHook.get_conn"><a class="viewcode-back" href="../code.html#airflow.hooks.DruidHook.get_conn">[docs]</a>    <span class="k">def</span> <span class="nf">get_conn</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a druid connection object for query</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">conn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_connection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">druid_query_conn_id</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">PyDruid</span><span class="p">(</span>
            <span class="s2">&quot;http://{conn.host}:{conn.port}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="nb">locals</span><span class="p">()),</span>
            <span class="n">conn</span><span class="o">.</span><span class="n">extra_dejson</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;endpoint&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">))</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">ingest_post_url</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">conn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_connection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">druid_ingest_conn_id</span><span class="p">)</span>
        <span class="n">host</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">host</span>
        <span class="n">port</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">port</span>
        <span class="n">endpoint</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">extra_dejson</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;endpoint&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="s2">&quot;http://{host}:{port}/{endpoint}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="nb">locals</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_ingest_status_url</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task_id</span><span class="p">):</span>
        <span class="n">post_url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ingest_post_url</span>
        <span class="k">return</span> <span class="s2">&quot;{post_url}/{task_id}/status&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="nb">locals</span><span class="p">())</span>

<div class="viewcode-block" id="DruidHook.construct_ingest_query"><a class="viewcode-back" href="../code.html#airflow.hooks.DruidHook.construct_ingest_query">[docs]</a>    <span class="k">def</span> <span class="nf">construct_ingest_query</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">datasource</span><span class="p">,</span> <span class="n">static_path</span><span class="p">,</span> <span class="n">ts_dim</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">metric_spec</span><span class="p">,</span>
            <span class="n">intervals</span><span class="p">,</span> <span class="n">num_shards</span><span class="p">,</span> <span class="n">target_partition_size</span><span class="p">,</span> <span class="n">hadoop_dependency_coordinates</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Builds an ingest query for an HDFS TSV load.</span>

<span class="sd">        :param datasource: target datasource in druid</span>
<span class="sd">        :param columns: list of all columns in the TSV, in the right order</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># backward compatibilty for num_shards, but target_partition_size is the default setting</span>
        <span class="c1"># and overwrites the num_shards</span>
        <span class="k">if</span> <span class="n">target_partition_size</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">num_shards</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">target_partition_size</span> <span class="o">=</span> <span class="n">DEFAULT_TARGET_PARTITION_SIZE</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_shards</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

        <span class="n">metric_names</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">m</span><span class="p">[</span><span class="s1">&#39;fieldName&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metric_spec</span> <span class="k">if</span> <span class="n">m</span><span class="p">[</span><span class="s1">&#39;type&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;count&#39;</span><span class="p">]</span>
        <span class="n">dimensions</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">columns</span> <span class="k">if</span> <span class="n">c</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">metric_names</span> <span class="ow">and</span> <span class="n">c</span> <span class="o">!=</span> <span class="n">ts_dim</span><span class="p">]</span>
        <span class="n">ingest_query_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;index_hadoop&quot;</span><span class="p">,</span>
            <span class="s2">&quot;spec&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;dataSchema&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;metricsSpec&quot;</span><span class="p">:</span> <span class="n">metric_spec</span><span class="p">,</span>
                    <span class="s2">&quot;granularitySpec&quot;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;queryGranularity&quot;</span><span class="p">:</span> <span class="s2">&quot;NONE&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;intervals&quot;</span><span class="p">:</span> <span class="n">intervals</span><span class="p">,</span>
                        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;uniform&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;segmentGranularity&quot;</span><span class="p">:</span> <span class="s2">&quot;DAY&quot;</span><span class="p">,</span>
                    <span class="p">},</span>
                    <span class="s2">&quot;parser&quot;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;parseSpec&quot;</span><span class="p">:</span> <span class="p">{</span>
                            <span class="s2">&quot;columns&quot;</span><span class="p">:</span> <span class="n">columns</span><span class="p">,</span>
                            <span class="s2">&quot;dimensionsSpec&quot;</span><span class="p">:</span> <span class="p">{</span>
                                <span class="s2">&quot;dimensionExclusions&quot;</span><span class="p">:</span> <span class="p">[],</span>
                                <span class="s2">&quot;dimensions&quot;</span><span class="p">:</span> <span class="n">dimensions</span><span class="p">,</span>  <span class="c1"># list of names</span>
                                <span class="s2">&quot;spatialDimensions&quot;</span><span class="p">:</span> <span class="p">[]</span>
                            <span class="p">},</span>
                            <span class="s2">&quot;timestampSpec&quot;</span><span class="p">:</span> <span class="p">{</span>
                                <span class="s2">&quot;column&quot;</span><span class="p">:</span> <span class="n">ts_dim</span><span class="p">,</span>
                                <span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span>
                            <span class="p">},</span>
                            <span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;tsv&quot;</span>
                        <span class="p">}</span>
                    <span class="p">},</span>
                    <span class="s2">&quot;dataSource&quot;</span><span class="p">:</span> <span class="n">datasource</span>
                <span class="p">},</span>
                <span class="s2">&quot;tuningConfig&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;hadoop&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;jobProperties&quot;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;mapreduce.job.user.classpath.first&quot;</span><span class="p">:</span> <span class="s2">&quot;false&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;mapreduce.map.output.compress&quot;</span><span class="p">:</span> <span class="s2">&quot;false&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;mapreduce.output.fileoutputformat.compress&quot;</span><span class="p">:</span> <span class="s2">&quot;false&quot;</span><span class="p">,</span>
                    <span class="p">},</span>
                    <span class="s2">&quot;partitionsSpec&quot;</span> <span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;type&quot;</span> <span class="p">:</span> <span class="s2">&quot;hashed&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;targetPartitionSize&quot;</span> <span class="p">:</span> <span class="n">target_partition_size</span><span class="p">,</span>
                        <span class="s2">&quot;numShards&quot;</span> <span class="p">:</span> <span class="n">num_shards</span><span class="p">,</span>
                    <span class="p">},</span>
                <span class="p">},</span>
                <span class="s2">&quot;ioConfig&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;inputSpec&quot;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;paths&quot;</span><span class="p">:</span> <span class="n">static_path</span><span class="p">,</span>
                        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;static&quot;</span>
                    <span class="p">},</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;hadoop&quot;</span>
                <span class="p">}</span>
            <span class="p">}</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">hadoop_dependency_coordinates</span><span class="p">:</span>
            <span class="n">ingest_query_dict</span><span class="p">[</span>
                <span class="s1">&#39;hadoopDependencyCoordinates&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">hadoop_dependency_coordinates</span>

        <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">ingest_query_dict</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">send_ingest_query</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">datasource</span><span class="p">,</span> <span class="n">static_path</span><span class="p">,</span> <span class="n">ts_dim</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">metric_spec</span><span class="p">,</span>
            <span class="n">intervals</span><span class="p">,</span> <span class="n">num_shards</span><span class="p">,</span> <span class="n">target_partition_size</span><span class="p">,</span> <span class="n">hadoop_dependency_coordinates</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">construct_ingest_query</span><span class="p">(</span>
            <span class="n">datasource</span><span class="p">,</span> <span class="n">static_path</span><span class="p">,</span> <span class="n">ts_dim</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span>
            <span class="n">metric_spec</span><span class="p">,</span> <span class="n">intervals</span><span class="p">,</span> <span class="n">num_shards</span><span class="p">,</span> <span class="n">target_partition_size</span><span class="p">,</span> <span class="n">hadoop_dependency_coordinates</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ingest_post_url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">header</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">query</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ingest_post_url</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;task&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">d</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">AirflowDruidLoadException</span><span class="p">(</span>
                <span class="s2">&quot;[Error]: Ingesting data to druid failed.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;task&quot;</span><span class="p">]</span>

<div class="viewcode-block" id="DruidHook.load_from_hdfs"><a class="viewcode-back" href="../code.html#airflow.hooks.DruidHook.load_from_hdfs">[docs]</a>    <span class="k">def</span> <span class="nf">load_from_hdfs</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">datasource</span><span class="p">,</span> <span class="n">static_path</span><span class="p">,</span>  <span class="n">ts_dim</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span>
            <span class="n">intervals</span><span class="p">,</span> <span class="n">num_shards</span><span class="p">,</span> <span class="n">target_partition_size</span><span class="p">,</span> <span class="n">metric_spec</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">hadoop_dependency_coordinates</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        load data to druid from hdfs</span>
<span class="sd">        :params ts_dim: The column name to use as a timestamp</span>
<span class="sd">        :params metric_spec: A list of dictionaries</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">task_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">send_ingest_query</span><span class="p">(</span>
            <span class="n">datasource</span><span class="p">,</span> <span class="n">static_path</span><span class="p">,</span> <span class="n">ts_dim</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">metric_spec</span><span class="p">,</span>
            <span class="n">intervals</span><span class="p">,</span> <span class="n">num_shards</span><span class="p">,</span> <span class="n">target_partition_size</span><span class="p">,</span> <span class="n">hadoop_dependency_coordinates</span><span class="p">)</span>
        <span class="n">status_url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ingest_status_url</span><span class="p">(</span><span class="n">task_id</span><span class="p">)</span>
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">status_url</span><span class="p">)</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;status&#39;</span><span class="p">][</span><span class="s1">&#39;status&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;FAILED&#39;</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
                <span class="k">raise</span> <span class="n">AirflowDruidLoadException</span><span class="p">(</span>
                    <span class="s2">&quot;[Error]: Ingesting data to druid failed.&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;status&#39;</span><span class="p">][</span><span class="s1">&#39;status&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;SUCCESS&#39;</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">LOAD_CHECK_INTERVAL</span><span class="p">)</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>