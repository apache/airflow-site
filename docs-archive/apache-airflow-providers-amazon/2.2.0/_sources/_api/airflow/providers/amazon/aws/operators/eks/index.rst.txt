:mod:`airflow.providers.amazon.aws.operators.eks`
=================================================

.. py:module:: airflow.providers.amazon.aws.operators.eks

.. autoapi-nested-parse::

   This module contains Amazon EKS operators.



Module Contents
---------------

.. data:: CHECK_INTERVAL_SECONDS
   :annotation: = 15

   

.. data:: TIMEOUT_SECONDS
   

   

.. data:: DEFAULT_COMPUTE_TYPE
   :annotation: = nodegroup

   

.. data:: DEFAULT_CONN_ID
   :annotation: = aws_default

   

.. data:: DEFAULT_NAMESPACE_NAME
   :annotation: = default

   

.. data:: DEFAULT_NODEGROUP_NAME_SUFFIX
   :annotation: = -nodegroup

   

.. data:: DEFAULT_POD_NAME
   :annotation: = pod

   

.. py:class:: EKSCreateClusterOperator(cluster_name: str, cluster_role_arn: str, resources_vpc_config: Dict, nodegroup_name: Optional[str] = None, nodegroup_role_arn: Optional[str] = None, compute: Optional[str] = DEFAULT_COMPUTE_TYPE, aws_conn_id: str = DEFAULT_CONN_ID, region: Optional[str] = None, **kwargs)

   Bases: :class:`airflow.models.BaseOperator`

   Creates an Amazon EKS Cluster control plane.

   Optionally, can also create the supporting compute architecture:
   If argument 'compute' is provided with a value of 'nodegroup', will also attempt to create an Amazon
   EKS Managed Nodegroup for the cluster.  See EKSCreateNodegroupOperator documentation for requirements.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:EKSCreateClusterOperator`

   :param cluster_name: The unique name to give to your Amazon EKS Cluster. (templated)
   :type cluster_name: str
   :param cluster_role_arn: The Amazon Resource Name (ARN) of the IAM role that provides permissions for the
      Kubernetes control plane to make calls to AWS API operations on your behalf. (templated)
   :type cluster_role_arn: str
   :param resources_vpc_config: The VPC configuration used by the cluster control plane. (templated)
   :type resources_vpc_config: Dict
   :param compute: The type of compute architecture to generate along with the cluster. (templated)
       Defaults to 'nodegroup' to generate an EKS Managed Nodegroup.
   :type compute: str
   :param aws_conn_id: The Airflow connection used for AWS credentials. (templated)
        If this is None or empty then the default boto3 behaviour is used. If
        running Airflow in a distributed manner and aws_conn_id is None or
        empty, then the default boto3 configuration would be used (and must be
        maintained on each worker node).
   :type aws_conn_id: str
   :param region: Which AWS region the connection should use. (templated)
       If this is None or empty then the default boto3 behaviour is used.
   :type region: str

   If compute is assigned the value of ``nodegroup``, the following are required:

   :param nodegroup_name: The unique name to give your EKS Managed Nodegroup. (templated)
   :type nodegroup_name: str
   :param nodegroup_role_arn: The Amazon Resource Name (ARN) of the IAM role to associate
        with the EKS Managed Nodegroup. (templated)
   :type nodegroup_role_arn: str

   .. attribute:: template_fields
      :annotation: :Iterable[str] = ['cluster_name', 'cluster_role_arn', 'resources_vpc_config', 'nodegroup_name', 'nodegroup_role_arn', 'compute', 'aws_conn_id', 'region']

      

   
   .. method:: execute(self, context)




.. py:class:: EKSCreateNodegroupOperator(cluster_name: str, nodegroup_subnets: List[str], nodegroup_role_arn: str, nodegroup_name: Optional[str] = None, aws_conn_id: str = DEFAULT_CONN_ID, region: Optional[str] = None, **kwargs)

   Bases: :class:`airflow.models.BaseOperator`

   Creates am Amazon EKS Managed Nodegroup for an existing Amazon EKS Cluster.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:EKSCreateNodegroupOperator`

   :param cluster_name: The name of the Amazon EKS Cluster to create the managed nodegroup in. (templated)
   :type cluster_name: str
   :param nodegroup_name: The unique name to give your managed nodegroup. (templated)
   :type nodegroup_name: str
   :param nodegroup_subnets:
       The subnets to use for the Auto Scaling group that is created for the managed nodegroup. (templated)
   :type nodegroup_subnets: List[str]
   :param nodegroup_role_arn:
       The Amazon Resource Name (ARN) of the IAM role to associate with the managed nodegroup. (templated)
   :type nodegroup_role_arn: str
   :param aws_conn_id: The Airflow connection used for AWS credentials. (templated)
        If this is None or empty then the default boto3 behaviour is used. If
        running Airflow in a distributed manner and aws_conn_id is None or
        empty, then the default boto3 configuration would be used (and must be
        maintained on each worker node).
   :type aws_conn_id: str
       :param region: Which AWS region the connection should use. (templated)
       If this is None or empty then the default boto3 behaviour is used.
   :type region: str

   .. attribute:: template_fields
      :annotation: :Iterable[str] = ['cluster_name', 'nodegroup_subnets', 'nodegroup_role_arn', 'nodegroup_name', 'aws_conn_id', 'region']

      

   
   .. method:: execute(self, context)




.. py:class:: EKSDeleteClusterOperator(cluster_name: str, force_delete_compute: bool = False, aws_conn_id: str = DEFAULT_CONN_ID, region: Optional[str] = None, **kwargs)

   Bases: :class:`airflow.models.BaseOperator`

   Deletes the Amazon EKS Cluster control plane and all nodegroups attached to it.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:EKSDeleteClusterOperator`

   :param cluster_name: The name of the Amazon EKS Cluster to delete. (templated)
   :type cluster_name: str
   :param force_delete_compute: If True, will delete any attached resources. (templated)
        Defaults to False.
   :type force_delete_compute: bool
   :param aws_conn_id: The Airflow connection used for AWS credentials. (templated)
        If this is None or empty then the default boto3 behaviour is used. If
        running Airflow in a distributed manner and aws_conn_id is None or
        empty, then the default boto3 configuration would be used (and must be
        maintained on each worker node).
   :type aws_conn_id: str
   :param region: Which AWS region the connection should use. (templated)
       If this is None or empty then the default boto3 behaviour is used.
   :type region: str

   .. attribute:: template_fields
      :annotation: :Iterable[str] = ['cluster_name', 'force_delete_compute', 'aws_conn_id', 'region']

      

   
   .. method:: execute(self, context)




.. py:class:: EKSDeleteNodegroupOperator(cluster_name: str, nodegroup_name: str, aws_conn_id: str = DEFAULT_CONN_ID, region: Optional[str] = None, **kwargs)

   Bases: :class:`airflow.models.BaseOperator`

   Deletes an Amazon EKS Nodegroup from an Amazon EKS Cluster.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:EKSDeleteNodegroupOperator`

   :param cluster_name: The name of the Amazon EKS Cluster associated with your nodegroup. (templated)
   :type cluster_name: str
   :param nodegroup_name: The name of the nodegroup to delete. (templated)
   :type nodegroup_name: str
   :param aws_conn_id: The Airflow connection used for AWS credentials. (templated)
        If this is None or empty then the default boto3 behaviour is used.  If
        running Airflow in a distributed manner and aws_conn_id is None or
        empty, then the default boto3 configuration would be used (and must be
        maintained on each worker node).
   :type aws_conn_id: str
   :param region: Which AWS region the connection should use. (templated)
       If this is None or empty then the default boto3 behaviour is used.
   :type region: str

   .. attribute:: template_fields
      :annotation: :Iterable[str] = ['cluster_name', 'nodegroup_name', 'aws_conn_id', 'region']

      

   
   .. method:: execute(self, context)




.. py:class:: EKSPodOperator(cluster_name: str, in_cluster: bool = False, namespace: str = DEFAULT_NAMESPACE_NAME, pod_context: str = DEFAULT_CONTEXT_NAME, pod_name: str = DEFAULT_POD_NAME, pod_username: str = DEFAULT_POD_USERNAME, aws_conn_id: str = DEFAULT_CONN_ID, region: Optional[str] = None, **kwargs)

   Bases: :class:`airflow.providers.cncf.kubernetes.operators.kubernetes_pod.KubernetesPodOperator`

   Executes a task in a Kubernetes pod on the specified Amazon EKS Cluster.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:EKSPodOperator`

   :param cluster_name: The name of the Amazon EKS Cluster to execute the task on. (templated)
   :type cluster_name: str
   :param cluster_role_arn: The Amazon Resource Name (ARN) of the IAM role that provides permissions
      for the Kubernetes control plane to make calls to AWS API operations on your behalf. (templated)
   :type cluster_role_arn: str
   :param in_cluster: If True, look for config inside the cluster; if False look for a local file path.
   :type in_cluster: bool
   :param namespace: The namespace in which to execute the pod. (templated)
   :type namespace: str
   :param pod_context: The security context to use while executing the pod. (templated)
   :type pod_context: str
   :param pod_name: The unique name to give the pod. (templated)
   :type pod_name: str
   :param pod_username: The username to use while executing the pod. (templated)
   :type pod_username: str
   :param aws_profile: The named profile containing the credentials for the AWS CLI tool to use.
   :param aws_profile: str
   :param region: Which AWS region the connection should use. (templated)
       If this is None or empty then the default boto3 behaviour is used.
   :type region: str
   :param aws_conn_id: The Airflow connection used for AWS credentials. (templated)
        If this is None or empty then the default boto3 behaviour is used. If
        running Airflow in a distributed manner and aws_conn_id is None or
        empty, then the default boto3 configuration would be used (and must be
        maintained on each worker node).
   :type aws_conn_id: str

   .. attribute:: template_fields
      :annotation: :Iterable[str]

      

   
   .. method:: execute(self, context)




