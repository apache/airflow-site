:py:mod:`airflow.providers.amazon.aws.transfers.s3_to_dynamodb`
===============================================================

.. py:module:: airflow.providers.amazon.aws.transfers.s3_to_dynamodb


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.amazon.aws.transfers.s3_to_dynamodb.AttributeDefinition
   airflow.providers.amazon.aws.transfers.s3_to_dynamodb.KeySchema
   airflow.providers.amazon.aws.transfers.s3_to_dynamodb.S3ToDynamoDBOperator




.. py:class:: AttributeDefinition


   Bases: :py:obj:`TypedDict`

   Attribute Definition Type.

   .. py:attribute:: AttributeName
      :type: str

      

   .. py:attribute:: AttributeType
      :type: Literal[S, N, B]

      


.. py:class:: KeySchema


   Bases: :py:obj:`TypedDict`

   Key Schema Type.

   .. py:attribute:: AttributeName
      :type: str

      

   .. py:attribute:: KeyType
      :type: Literal[HASH, RANGE]

      


.. py:class:: S3ToDynamoDBOperator(*, s3_bucket, s3_key, dynamodb_table_name, dynamodb_key_schema, dynamodb_attributes = None, dynamodb_tmp_table_prefix = 'tmp', delete_on_error = False, use_existing_table = False, input_format = 'DYNAMODB_JSON', billing_mode = 'PAY_PER_REQUEST', import_table_kwargs = None, import_table_creation_kwargs = None, wait_for_completion = True, check_interval = 30, max_attempts = 240, aws_conn_id = 'aws_default', **kwargs)


   Bases: :py:obj:`airflow.models.BaseOperator`

   Load Data from S3 into a DynamoDB.

   Data stored in S3 can be uploaded to a new or existing DynamoDB. Supported file formats CSV, DynamoDB JSON and
   Amazon ION.


   :param s3_bucket: The S3 bucket that is imported
   :param s3_key: Key prefix that imports single or multiple objects from S3
   :param dynamodb_table_name: Name of the table that shall be created
   :param dynamodb_key_schema: Primary key and sort key. Each element represents one primary key
       attribute. AttributeName is the name of the attribute. KeyType is the role for the attribute. Valid values
       HASH or RANGE
   :param dynamodb_attributes: Name of the attributes of a table. AttributeName is the name for the attribute
       AttributeType is the data type for the attribute. Valid values for AttributeType are
       S - attribute is of type String
       N - attribute is of type Number
       B - attribute is of type Binary
   :param dynamodb_tmp_table_prefix: Prefix for the temporary DynamoDB table
   :param delete_on_error: If set, the new DynamoDB table will be deleted in case of import errors
   :param use_existing_table: Whether to import to an existing non new DynamoDB table. If set to
       true data is loaded first into a temporary DynamoDB table (using the AWS ImportTable Service),
       then retrieved as chunks into memory and loaded into the target table. If set to false, a new
       DynamoDB table will be created and S3 data is bulk loaded by the AWS ImportTable Service.
   :param input_format: The format for the imported data. Valid values for InputFormat are CSV, DYNAMODB_JSON
       or ION
   :param billing_mode: Billing mode for the table. Valid values are PROVISIONED or PAY_PER_REQUEST
   :param on_demand_throughput: Extra options for maximum number of read and write units
   :param import_table_kwargs: Any additional optional import table parameters to pass, such as ClientToken,
       InputCompressionType, or InputFormatOptions. See:
       https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb/client/import_table.html
   :param import_table_creation_kwargs: Any additional optional import table creation parameters to pass, such as
       ProvisionedThroughput, SSESpecification, or GlobalSecondaryIndexes. See:
       https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb/client/import_table.html
   :param wait_for_completion: Whether to wait for cluster to stop
   :param check_interval: Time in seconds to wait between status checks
   :param max_attempts: Maximum number of attempts to check for job completion
   :param aws_conn_id: The reference to the AWS connection details

   .. py:property:: tmp_table_name

      Temporary table name.


   .. py:attribute:: template_fields
      :type: Sequence[str]
      :value: ('s3_bucket', 's3_key', 'dynamodb_table_name', 'dynamodb_key_schema', 'dynamodb_attributes',...

      

   .. py:attribute:: ui_color
      :value: '#e2e8f0'

      

   .. py:method:: execute(context)

      Execute S3 to DynamoDB Job from Airflow.

      :param context: The current context of the task instance
      :return: The Amazon resource number (ARN)



