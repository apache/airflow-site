:py:mod:`airflow.providers.amazon.aws.operators.appflow`
========================================================

.. py:module:: airflow.providers.amazon.aws.operators.appflow


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.amazon.aws.operators.appflow.AppflowBaseOperator
   airflow.providers.amazon.aws.operators.appflow.AppflowRunOperator
   airflow.providers.amazon.aws.operators.appflow.AppflowRunFullOperator
   airflow.providers.amazon.aws.operators.appflow.AppflowRunBeforeOperator
   airflow.providers.amazon.aws.operators.appflow.AppflowRunAfterOperator
   airflow.providers.amazon.aws.operators.appflow.AppflowRunDailyOperator
   airflow.providers.amazon.aws.operators.appflow.AppflowRecordsShortCircuitOperator




Attributes
~~~~~~~~~~

.. autoapisummary::

   airflow.providers.amazon.aws.operators.appflow.SUPPORTED_SOURCES
   airflow.providers.amazon.aws.operators.appflow.MANDATORY_FILTER_DATE_MSG
   airflow.providers.amazon.aws.operators.appflow.NOT_SUPPORTED_SOURCE_MSG


.. py:data:: SUPPORTED_SOURCES

   

.. py:data:: MANDATORY_FILTER_DATE_MSG
   :value: 'The filter_date argument is mandatory for {entity}!'

   

.. py:data:: NOT_SUPPORTED_SOURCE_MSG
   :value: 'Source {source} is not supported for {entity}!'

   

.. py:class:: AppflowBaseOperator(flow_name, flow_update, source = None, source_field = None, filter_date = None, poll_interval = 20, max_attempts = 60, wait_for_completion = True, **kwargs)


   Bases: :py:obj:`airflow.providers.amazon.aws.operators.base_aws.AwsBaseOperator`\ [\ :py:obj:`airflow.providers.amazon.aws.hooks.appflow.AppflowHook`\ ]

   Amazon AppFlow Base Operator class (not supposed to be used directly in DAGs).

   :param source: The source name (Supported: salesforce, zendesk)
   :param flow_name: The flow name
   :param flow_update: A boolean to enable/disable a flow update before the run
   :param source_field: The field name to apply filters
   :param filter_date: The date value (or template) to be used in filters.
   :param poll_interval: how often in seconds to check the query status
   :param max_attempts: how many times to check for status before timing out
   :param wait_for_completion: whether to wait for the run to end to return
   :param aws_conn_id: The Airflow connection used for AWS credentials.
       If this is ``None`` or empty then the default boto3 behaviour is used. If
       running Airflow in a distributed manner and aws_conn_id is None or
       empty, then default boto3 configuration would be used (and must be
       maintained on each worker node).
   :param region_name: AWS region_name. If not specified then the default boto3 behaviour is used.
   :param verify: Whether or not to verify SSL certificates. See:
       https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html
   :param botocore_config: Configuration dictionary (key-values) for botocore client. See:
       https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html

   .. py:attribute:: aws_hook_class

      

   .. py:attribute:: ui_color
      :value: '#2bccbd'

      

   .. py:attribute:: template_fields

      

   .. py:attribute:: UPDATE_PROPAGATION_TIME
      :type: int
      :value: 15

      

   .. py:method:: execute(context)

      Derive when creating an operator.

      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



.. py:class:: AppflowRunOperator(flow_name, poll_interval = 20, wait_for_completion = True, **kwargs)


   Bases: :py:obj:`AppflowBaseOperator`

   Execute an AppFlow run as is.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:AppflowRunOperator`

   :param flow_name: The flow name
   :param poll_interval: how often in seconds to check the query status
   :param aws_conn_id: The Airflow connection used for AWS credentials.
       If this is None or empty then the default boto3 behaviour is used. If
       running Airflow in a distributed manner and aws_conn_id is None or
       empty, then default boto3 configuration would be used (and must be
       maintained on each worker node).
   :param region: aws region to use
   :param wait_for_completion: whether to wait for the run to end to return


.. py:class:: AppflowRunFullOperator(source, flow_name, poll_interval = 20, wait_for_completion = True, **kwargs)


   Bases: :py:obj:`AppflowBaseOperator`

   Execute an AppFlow full run removing any filter.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:AppflowRunFullOperator`

   :param source: The source name (Supported: salesforce, zendesk)
   :param flow_name: The flow name
   :param poll_interval: how often in seconds to check the query status
   :param wait_for_completion: whether to wait for the run to end to return


.. py:class:: AppflowRunBeforeOperator(source, flow_name, source_field, filter_date, poll_interval = 20, wait_for_completion = True, **kwargs)


   Bases: :py:obj:`AppflowBaseOperator`

   Execute an AppFlow run after updating the filters to select only previous data.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:AppflowRunBeforeOperator`

   :param source: The source name (Supported: salesforce)
   :param flow_name: The flow name
   :param source_field: The field name to apply filters
   :param filter_date: The date value (or template) to be used in filters.
   :param poll_interval: how often in seconds to check the query status
   :param aws_conn_id: The Airflow connection used for AWS credentials.
       If this is None or empty then the default boto3 behaviour is used. If
       running Airflow in a distributed manner and aws_conn_id is None or
       empty, then default boto3 configuration would be used (and must be
       maintained on each worker node).
   :param region: aws region to use
   :param wait_for_completion: whether to wait for the run to end to return


.. py:class:: AppflowRunAfterOperator(source, flow_name, source_field, filter_date, poll_interval = 20, wait_for_completion = True, **kwargs)


   Bases: :py:obj:`AppflowBaseOperator`

   Execute an AppFlow run after updating the filters to select only future data.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:AppflowRunAfterOperator`

   :param source: The source name (Supported: salesforce, zendesk)
   :param flow_name: The flow name
   :param source_field: The field name to apply filters
   :param filter_date: The date value (or template) to be used in filters.
   :param poll_interval: how often in seconds to check the query status
   :param wait_for_completion: whether to wait for the run to end to return


.. py:class:: AppflowRunDailyOperator(source, flow_name, source_field, filter_date, poll_interval = 20, wait_for_completion = True, **kwargs)


   Bases: :py:obj:`AppflowBaseOperator`

   Execute an AppFlow run after updating the filters to select only a single day.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:AppflowRunDailyOperator`

   :param source: The source name (Supported: salesforce)
   :param flow_name: The flow name
   :param source_field: The field name to apply filters
   :param filter_date: The date value (or template) to be used in filters.
   :param poll_interval: how often in seconds to check the query status
   :param wait_for_completion: whether to wait for the run to end to return


.. py:class:: AppflowRecordsShortCircuitOperator(*, flow_name, appflow_run_task_id, ignore_downstream_trigger_rules = True, aws_conn_id = 'aws_default', region_name = None, verify = None, botocore_config = None, **kwargs)


   Bases: :py:obj:`airflow.operators.python.ShortCircuitOperator`, :py:obj:`airflow.providers.amazon.aws.utils.mixins.AwsBaseHookMixin`\ [\ :py:obj:`airflow.providers.amazon.aws.hooks.appflow.AppflowHook`\ ]

   Short-circuit in case of an empty AppFlow's run.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:AppflowRecordsShortCircuitOperator`

   :param flow_name: The flow name
   :param appflow_run_task_id: Run task ID from where this operator should extract the execution ID
   :param ignore_downstream_trigger_rules: Ignore downstream trigger rules
   :param aws_conn_id: The Airflow connection used for AWS credentials.
       If this is ``None`` or empty then the default boto3 behaviour is used. If
       running Airflow in a distributed manner and aws_conn_id is None or
       empty, then default boto3 configuration would be used (and must be
       maintained on each worker node).
   :param region_name: AWS region_name. If not specified then the default boto3 behaviour is used.
   :param verify: Whether or not to verify SSL certificates. See:
       https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html
   :param botocore_config: Configuration dictionary (key-values) for botocore client. See:
       https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html

   .. py:attribute:: aws_hook_class

      

   .. py:attribute:: template_fields

      

   .. py:attribute:: ui_color
      :value: '#33ffec'

      


