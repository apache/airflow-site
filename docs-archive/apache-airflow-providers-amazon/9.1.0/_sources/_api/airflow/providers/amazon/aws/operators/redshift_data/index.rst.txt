:py:mod:`airflow.providers.amazon.aws.operators.redshift_data`
==============================================================

.. py:module:: airflow.providers.amazon.aws.operators.redshift_data


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.amazon.aws.operators.redshift_data.RedshiftDataOperator




.. py:class:: RedshiftDataOperator(sql, database = None, cluster_identifier = None, db_user = None, parameters = None, secret_arn = None, statement_name = None, with_event = False, wait_for_completion = True, poll_interval = 10, return_sql_result = False, workgroup_name = None, deferrable = conf.getboolean('operators', 'default_deferrable', fallback=False), session_id = None, session_keep_alive_seconds = None, **kwargs)


   Bases: :py:obj:`airflow.providers.amazon.aws.operators.base_aws.AwsBaseOperator`\ [\ :py:obj:`airflow.providers.amazon.aws.hooks.redshift_data.RedshiftDataHook`\ ]

   Executes SQL Statements against an Amazon Redshift cluster using Redshift Data.

   ... see also::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:RedshiftDataOperator`

   :param database: the name of the database
   :param sql: the SQL statement or list of  SQL statement to run
   :param cluster_identifier: unique identifier of a cluster
   :param db_user: the database username
   :param parameters: the parameters for the SQL statement
   :param secret_arn: the name or ARN of the secret that enables db access
   :param statement_name: the name of the SQL statement
   :param with_event: indicates whether to send an event to EventBridge
   :param wait_for_completion: indicates whether to wait for a result, if True wait, if False don't wait
   :param poll_interval: how often in seconds to check the query status
   :param return_sql_result: if True will return the result of an SQL statement,
       if False (default) will return statement ID
   :param workgroup_name: name of the Redshift Serverless workgroup. Mutually exclusive with
       `cluster_identifier`. Specify this parameter to query Redshift Serverless. More info
       https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-serverless.html
   :param session_id: the session identifier of the query
   :param session_keep_alive_seconds: duration in seconds to keep the session alive after the query
       finishes. The maximum time a session can keep alive is 24 hours
   :param aws_conn_id: The Airflow connection used for AWS credentials.
       If this is ``None`` or empty then the default boto3 behaviour is used. If
       running Airflow in a distributed manner and aws_conn_id is None or
       empty, then default boto3 configuration would be used (and must be
       maintained on each worker node).
   :param region_name: AWS region_name. If not specified then the default boto3 behaviour is used.
   :param verify: Whether to verify SSL certificates. See:
       https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html
   :param botocore_config: Configuration dictionary (key-values) for botocore client. See:
       https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html

   .. py:attribute:: aws_hook_class

      

   .. py:attribute:: template_fields

      

   .. py:attribute:: template_ext
      :value: ('.sql',)

      

   .. py:attribute:: template_fields_renderers

      

   .. py:method:: execute(context)

      Execute a statement against Amazon Redshift.


   .. py:method:: execute_complete(context, event = None)


   .. py:method:: get_sql_results(statement_id, return_sql_result)

      Retrieve either the result of the SQL query, or the statement ID(s).

      :param statement_id: Statement ID of the running queries
      :param return_sql_result: Boolean, true if results should be returned


   .. py:method:: on_kill()

      Cancel the submitted redshift query.



