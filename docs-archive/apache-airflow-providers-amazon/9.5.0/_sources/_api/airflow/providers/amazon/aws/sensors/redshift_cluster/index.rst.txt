airflow.providers.amazon.aws.sensors.redshift_cluster
=====================================================

.. py:module:: airflow.providers.amazon.aws.sensors.redshift_cluster


Classes
-------

.. autoapisummary::

   airflow.providers.amazon.aws.sensors.redshift_cluster.RedshiftClusterSensor


Module Contents
---------------

.. py:class:: RedshiftClusterSensor(*, cluster_identifier, target_status = 'available', aws_conn_id = 'aws_default', deferrable = conf.getboolean('operators', 'default_deferrable', fallback=False), **kwargs)

   Bases: :py:obj:`airflow.sensors.base.BaseSensorOperator`


   Waits for a Redshift cluster to reach a specific status.

   .. seealso::
       For more information on how to use this sensor, take a look at the guide:
       :ref:`howto/sensor:RedshiftClusterSensor`

   :param cluster_identifier: The identifier for the cluster being pinged.
   :param target_status: The cluster status desired.
   :param deferrable: Run operator in the deferrable mode.


   .. py:attribute:: template_fields
      :type:  collections.abc.Sequence[str]
      :value: ('cluster_identifier', 'target_status')



   .. py:attribute:: cluster_identifier


   .. py:attribute:: target_status
      :value: 'available'



   .. py:attribute:: aws_conn_id
      :value: 'aws_default'



   .. py:attribute:: deferrable
      :value: True



   .. py:method:: poke(context)

      Override when deriving this class.



   .. py:method:: execute(context)

      Derive when creating an operator.

      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



   .. py:method:: execute_complete(context, event = None)


   .. py:property:: hook
      :type: airflow.providers.amazon.aws.hooks.redshift_cluster.RedshiftHook



