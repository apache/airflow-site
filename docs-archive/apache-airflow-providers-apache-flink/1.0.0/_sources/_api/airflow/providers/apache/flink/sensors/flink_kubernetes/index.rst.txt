:py:mod:`airflow.providers.apache.flink.sensors.flink_kubernetes`
=================================================================

.. py:module:: airflow.providers.apache.flink.sensors.flink_kubernetes


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.apache.flink.sensors.flink_kubernetes.FlinkKubernetesSensor




.. py:class:: FlinkKubernetesSensor(*, application_name, attach_log = False, namespace = None, kubernetes_conn_id = 'kubernetes_default', api_group = 'flink.apache.org', api_version = 'v1beta1', plural = 'flinkdeployments', **kwargs)

   Bases: :py:obj:`airflow.sensors.base.BaseSensorOperator`

   Checks flinkDeployment object in kubernetes cluster:

   .. seealso::
       For more detail about Flink Deployment Object have a look at the reference:
       https://nightlies.apache.org/flink/flink-kubernetes-operator-docs-main/docs/custom-resource/reference/#flinkdeployment

   :param application_name: flink Application resource name
   :param namespace: the kubernetes namespace where the flinkDeployment reside in
   :param kubernetes_conn_id: The :ref:`kubernetes connection<howto/connection:kubernetes>`
       to Kubernetes cluster
   :param attach_log: determines whether logs for driver pod should be appended to the sensor log
   :param api_group: kubernetes api group of flinkDeployment
   :param api_version: kubernetes api version of flinkDeployment
   :param plural: kubernetes api custom object plural

   .. py:attribute:: template_fields
      :type: Sequence[str]
      :value: ('application_name', 'namespace')

      

   .. py:attribute:: FAILURE_STATES
      :value: ('MISSING', 'ERROR')

      

   .. py:attribute:: SUCCESS_STATES
      :value: ('READY',)

      

   .. py:method:: poke(context)

      Function defined by the sensors while deriving this class should override.



