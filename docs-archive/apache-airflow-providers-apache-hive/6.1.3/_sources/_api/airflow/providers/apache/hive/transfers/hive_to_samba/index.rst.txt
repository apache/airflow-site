:py:mod:`airflow.providers.apache.hive.transfers.hive_to_samba`
===============================================================

.. py:module:: airflow.providers.apache.hive.transfers.hive_to_samba

.. autoapi-nested-parse::

   This module contains an operator to move data from Hive to Samba.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.apache.hive.transfers.hive_to_samba.HiveToSambaOperator




.. py:class:: HiveToSambaOperator(*, hql, destination_filepath, samba_conn_id = 'samba_default', hiveserver2_conn_id = 'hiveserver2_default', **kwargs)


   Bases: :py:obj:`airflow.models.BaseOperator`

   Execute hql code in a specific Hive database and load the results as a csv to a Samba location.

   :param hql: the hql to be exported. (templated)
   :param destination_filepath: the file path to where the file will be pushed onto samba
   :param samba_conn_id: reference to the samba destination
   :param hiveserver2_conn_id: Reference to the
       :ref: `Hive Server2 thrift service connection id <howto/connection:hiveserver2>`.

   .. py:attribute:: template_fields
      :type: Sequence[str]
      :value: ('hql', 'destination_filepath')

      

   .. py:attribute:: template_ext
      :type: Sequence[str]
      :value: ('.hql', '.sql')

      

   .. py:attribute:: template_fields_renderers

      

   .. py:method:: execute(context)

      This is the main method to derive when creating an operator.

      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



