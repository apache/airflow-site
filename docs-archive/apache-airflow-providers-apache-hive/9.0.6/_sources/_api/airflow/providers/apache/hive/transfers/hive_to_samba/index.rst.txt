airflow.providers.apache.hive.transfers.hive_to_samba
=====================================================

.. py:module:: airflow.providers.apache.hive.transfers.hive_to_samba

.. autoapi-nested-parse::

   This module contains an operator to move data from Hive to Samba.



Classes
-------

.. autoapisummary::

   airflow.providers.apache.hive.transfers.hive_to_samba.HiveToSambaOperator


Module Contents
---------------

.. py:class:: HiveToSambaOperator(*, hql, destination_filepath, samba_conn_id = 'samba_default', hiveserver2_conn_id = 'hiveserver2_default', **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`


   Execute hql code in a specific Hive database and load the results as a csv to a Samba location.

   :param hql: the hql to be exported. (templated)
   :param destination_filepath: the file path to where the file will be pushed onto samba
   :param samba_conn_id: reference to the samba destination
   :param hiveserver2_conn_id: Reference to the
       :ref: `Hive Server2 thrift service connection id <howto/connection:hiveserver2>`.


   .. py:attribute:: template_fields
      :type:  collections.abc.Sequence[str]
      :value: ('hql', 'destination_filepath')



   .. py:attribute:: template_ext
      :type:  collections.abc.Sequence[str]
      :value: ('.hql', '.sql')



   .. py:attribute:: template_fields_renderers


   .. py:attribute:: hiveserver2_conn_id
      :value: 'hiveserver2_default'



   .. py:attribute:: samba_conn_id
      :value: 'samba_default'



   .. py:attribute:: destination_filepath


   .. py:attribute:: hql


   .. py:method:: execute(context)

      Derive when creating an operator.

      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



