:py:mod:`airflow.providers.apache.kylin.operators.kylin_cube`
=============================================================

.. py:module:: airflow.providers.apache.kylin.operators.kylin_cube


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.apache.kylin.operators.kylin_cube.KylinCubeOperator




.. py:class:: KylinCubeOperator(*, kylin_conn_id = 'kylin_default', project = None, cube = None, dsn = None, command = None, start_time = None, end_time = None, offset_start = None, offset_end = None, segment_name = None, is_track_job = False, interval = 60, timeout = 60 * 60 * 24, eager_error_status=('ERROR', 'DISCARDED', 'KILLED', 'SUICIDAL', 'STOPPED'), **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   This operator is used to submit request about kylin build/refresh/merge,
   and can track job status . so users can easier to build kylin job

   For more detail information in
   `Apache Kylin <http://kylin.apache.org/>`_

   :param kylin_conn_id: The connection id as configured in Airflow administration.
   :param project: kylin project name, this param will overwrite the project in kylin_conn_id:
   :param cube: kylin cube name
   :param dsn: (dsn , dsn url of kylin connection ,which will overwrite kylin_conn_id.
       for example: kylin://ADMIN:KYLIN@sandbox/learn_kylin?timeout=60&is_debug=1)
   :param command: (kylin command include 'build', 'merge', 'refresh', 'delete',
       'build_streaming', 'merge_streaming', 'refresh_streaming', 'disable', 'enable',
       'purge', 'clone', 'drop'.
       build - use /kylin/api/cubes/{cubeName}/build rest api,and buildType is 'BUILD',
       and you should give start_time and end_time
       refresh - use build rest api,and buildType is 'REFRESH'
       merge - use build rest api,and buildType is 'MERGE'
       build_streaming - use /kylin/api/cubes/{cubeName}/build2 rest api,and buildType is 'BUILD'
       and you should give offset_start and offset_end
       refresh_streaming - use build2 rest api,and buildType is 'REFRESH'
       merge_streaming - use build2 rest api,and buildType is 'MERGE'
       delete - delete segment, and you should give segment_name value
       disable - disable cube
       enable - enable cube
       purge - purge cube
       clone - clone cube,new cube name is {cube_name}_clone
       drop - drop cube)
   :param start_time: build segment start time
   :param end_time: build segment end time
   :param offset_start: streaming build segment start time
   :param offset_end: streaming build segment end time
   :param segment_name: segment name
   :param is_track_job: (whether to track job status. if value is True,will track job until
       job status is in("FINISHED", "ERROR", "DISCARDED", "KILLED", "SUICIDAL",
       "STOPPED") or timeout)
   :param interval: track job status,default value is 60s
   :param timeout: timeout value,default value is 1 day,60 * 60 * 24 s
   :param eager_error_status: (jobs error status,if job status in this list ,this task will be error.
       default value is tuple(["ERROR", "DISCARDED", "KILLED", "SUICIDAL", "STOPPED"]))

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['project', 'cube', 'dsn', 'command', 'start_time', 'end_time', 'segment_name', 'offset_start',...

      

   .. py:attribute:: ui_color
      :annotation: = #E79C46

      

   .. py:attribute:: build_command
      

      

   .. py:attribute:: jobs_end_status
      

      

   .. py:method:: execute(context)

      This is the main method to derive when creating an operator.
      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



