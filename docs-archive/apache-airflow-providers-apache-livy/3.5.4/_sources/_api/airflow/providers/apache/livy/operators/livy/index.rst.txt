:py:mod:`airflow.providers.apache.livy.operators.livy`
======================================================

.. py:module:: airflow.providers.apache.livy.operators.livy

.. autoapi-nested-parse::

   This module contains the Apache Livy operator.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.apache.livy.operators.livy.LivyOperator




.. py:class:: LivyOperator(*, file, class_name = None, args = None, conf = None, jars = None, py_files = None, files = None, driver_memory = None, driver_cores = None, executor_memory = None, executor_cores = None, num_executors = None, archives = None, queue = None, name = None, proxy_user = None, livy_conn_id = 'livy_default', livy_conn_auth_type = None, polling_interval = 0, extra_options = None, extra_headers = None, retry_args = None, deferrable = conf.getboolean('operators', 'default_deferrable', fallback=False), **kwargs)


   Bases: :py:obj:`airflow.models.BaseOperator`

   Wraps the Apache Livy batch REST API, allowing to submit a Spark application to the underlying cluster.

   :param file: path of the file containing the application to execute (required). (templated)
   :param class_name: name of the application Java/Spark main class. (templated)
   :param args: application command line arguments. (templated)
   :param jars: jars to be used in this sessions. (templated)
   :param py_files: python files to be used in this session. (templated)
   :param files: files to be used in this session. (templated)
   :param driver_memory: amount of memory to use for the driver process. (templated)
   :param driver_cores: number of cores to use for the driver process. (templated)
   :param executor_memory: amount of memory to use per executor process. (templated)
   :param executor_cores: number of cores to use for each executor. (templated)
   :param num_executors: number of executors to launch for this session. (templated)
   :param archives: archives to be used in this session. (templated)
   :param queue: name of the YARN queue to which the application is submitted. (templated)
   :param name: name of this session. (templated)
   :param conf: Spark configuration properties. (templated)
   :param proxy_user: user to impersonate when running the job. (templated)
   :param livy_conn_id: reference to a pre-defined Livy Connection.
   :param livy_conn_auth_type: The auth type for the Livy Connection.
   :param polling_interval: time in seconds between polling for job completion. Don't poll for values >=0
   :param extra_options: A dictionary of options, where key is string and value
       depends on the option that's being modified.
   :param extra_headers: A dictionary of headers passed to the HTTP request to livy.
   :param retry_args: Arguments which define the retry behaviour.
   :param deferrable: Run operator in the deferrable mode
           See Tenacity documentation at https://github.com/jd/tenacity

   .. py:attribute:: template_fields
      :type: Sequence[str]
      :value: ('spark_params',)

      

   .. py:attribute:: template_fields_renderers

      

   .. py:method:: get_hook()

      Get valid hook.

      :return: hook


   .. py:method:: execute(context)

      Derive when creating an operator.

      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.


   .. py:method:: poll_for_termination(batch_id)

      Pool Livy for batch termination.

      :param batch_id: id of the batch session to monitor.


   .. py:method:: on_kill()

      Override this method to clean up subprocesses when a task instance gets killed.

      Any use of the threading, subprocess or multiprocessing module within an
      operator needs to be cleaned up, or it will leave ghost processes behind.


   .. py:method:: kill()

      Delete the current batch session.


   .. py:method:: execute_complete(context, event)

      Execute when the trigger fires - returns immediately.

      Relies on trigger to throw an exception, otherwise it assumes execution was successful.



