Search.setIndex({"docnames": ["_api/airflow/providers/databricks/hooks/databricks/index", "_api/airflow/providers/databricks/hooks/databricks_base/index", "_api/airflow/providers/databricks/hooks/databricks_sql/index", "_api/airflow/providers/databricks/hooks/index", "_api/airflow/providers/databricks/index", "_api/airflow/providers/databricks/operators/databricks/index", "_api/airflow/providers/databricks/operators/databricks_repos/index", "_api/airflow/providers/databricks/operators/databricks_sql/index", "_api/airflow/providers/databricks/operators/databricks_workflow/index", "_api/airflow/providers/databricks/operators/index", "_api/airflow/providers/databricks/plugins/databricks_workflow/index", "_api/airflow/providers/databricks/plugins/index", "_api/airflow/providers/databricks/sensors/databricks_partition/index", "_api/airflow/providers/databricks/sensors/databricks_sql/index", "_api/airflow/providers/databricks/sensors/index", "_api/airflow/providers/databricks/triggers/databricks/index", "_api/airflow/providers/databricks/triggers/index", "_api/airflow/providers/databricks/utils/databricks/index", "_api/airflow/providers/databricks/utils/index", "_api/tests/system/providers/databricks/example_databricks/index", "_api/tests/system/providers/databricks/example_databricks_repos/index", "_api/tests/system/providers/databricks/example_databricks_sensors/index", "_api/tests/system/providers/databricks/example_databricks_sql/index", "_api/tests/system/providers/databricks/example_databricks_workflow/index", "_api/tests/system/providers/databricks/index", "changelog", "commits", "connections/databricks", "index", "installing-providers-from-sources", "operators/copy_into", "operators/index", "operators/jobs_create", "operators/notebook", "operators/repos_create", "operators/repos_delete", "operators/repos_update", "operators/run_now", "operators/sql", "operators/submit_run", "operators/task", "operators/workflow", "plugins/index", "plugins/workflow", "security"], "filenames": ["_api/airflow/providers/databricks/hooks/databricks/index.rst", "_api/airflow/providers/databricks/hooks/databricks_base/index.rst", "_api/airflow/providers/databricks/hooks/databricks_sql/index.rst", "_api/airflow/providers/databricks/hooks/index.rst", "_api/airflow/providers/databricks/index.rst", "_api/airflow/providers/databricks/operators/databricks/index.rst", "_api/airflow/providers/databricks/operators/databricks_repos/index.rst", "_api/airflow/providers/databricks/operators/databricks_sql/index.rst", "_api/airflow/providers/databricks/operators/databricks_workflow/index.rst", "_api/airflow/providers/databricks/operators/index.rst", "_api/airflow/providers/databricks/plugins/databricks_workflow/index.rst", "_api/airflow/providers/databricks/plugins/index.rst", "_api/airflow/providers/databricks/sensors/databricks_partition/index.rst", "_api/airflow/providers/databricks/sensors/databricks_sql/index.rst", "_api/airflow/providers/databricks/sensors/index.rst", "_api/airflow/providers/databricks/triggers/databricks/index.rst", "_api/airflow/providers/databricks/triggers/index.rst", "_api/airflow/providers/databricks/utils/databricks/index.rst", "_api/airflow/providers/databricks/utils/index.rst", "_api/tests/system/providers/databricks/example_databricks/index.rst", "_api/tests/system/providers/databricks/example_databricks_repos/index.rst", "_api/tests/system/providers/databricks/example_databricks_sensors/index.rst", "_api/tests/system/providers/databricks/example_databricks_sql/index.rst", "_api/tests/system/providers/databricks/example_databricks_workflow/index.rst", "_api/tests/system/providers/databricks/index.rst", "changelog.rst", "commits.rst", "connections/databricks.rst", "index.rst", "installing-providers-from-sources.rst", "operators/copy_into.rst", "operators/index.rst", "operators/jobs_create.rst", "operators/notebook.rst", "operators/repos_create.rst", "operators/repos_delete.rst", "operators/repos_update.rst", "operators/run_now.rst", "operators/sql.rst", "operators/submit_run.rst", "operators/task.rst", "operators/workflow.rst", "plugins/index.rst", "plugins/workflow.rst", "security.rst"], "titles": ["<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.hooks.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.hooks.databricks_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.hooks.databricks_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.hooks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators.databricks_repos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators.databricks_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators.databricks_workflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.plugins.databricks_workflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.plugins</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.sensors.databricks_partition</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.sensors.databricks_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.sensors</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.triggers.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.triggers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.utils.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks.example_databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks.example_databricks_repos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks.example_databricks_sensors</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks.example_databricks_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks.example_databricks_workflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks</span></code>", "Changelog", "Package apache-airflow-providers-databricks", "Databricks Connection", "<code class=\"docutils literal notranslate\"><span class=\"pre\">apache-airflow-providers-databricks</span></code>", "Installing from sources", "DatabricksCopyIntoOperator", "Databricks Operators", "DatabricksCreateJobsOperator", "DatabricksNotebookOperator", "DatabricksReposCreateOperator", "DatabricksReposDeleteOperator", "DatabricksReposUpdateOperator", "DatabricksRunNowOperator", "DatabricksSqlOperator", "DatabricksSubmitRunOperator", "DatabricksTaskOperator", "DatabricksWorkflowTaskGroup", "Databricks Plugins", "DatabricksWorkflowPlugin", "Releasing security patches"], "terms": {"thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "enabl": [0, 1, 26, 27], "submit": [0, 1, 5, 8, 26, 39], "run": [0, 1, 2, 5, 8, 10, 12, 13, 15, 19, 22, 25, 26, 27, 29, 32, 37, 38, 39, 43], "job": [0, 1, 5, 8, 10, 19, 25, 26, 32, 33, 36, 37, 39, 41, 43], "platform": [0, 1], "intern": [0, 1, 2, 7, 12, 13, 27], "oper": [0, 1, 4, 10, 12, 25, 26, 27, 40, 43], "talk": [0, 1], "api": [0, 1, 2, 5, 6, 15, 19, 25, 26, 27, 32, 34, 35, 36, 37, 39], "2": [0, 1, 2, 5, 6, 28, 32, 34, 35, 36, 37, 38, 39], "1": [0, 1, 5, 6, 8, 28, 32, 33, 37, 38, 39], "now": [0, 5, 7, 25, 26, 37], "endpoint": [0, 1, 2, 5, 6, 7, 25, 26, 27, 30, 32, 34, 35, 36, 37, 39], "http": [0, 1, 2, 5, 6, 7, 12, 13, 19, 25, 26, 27, 29, 30, 33, 34, 38, 41], "doc": [0, 5, 6, 19, 25, 26], "com": [0, 5, 6, 19, 20, 25, 29, 34, 35, 36, 39], "dev": [0, 5, 6, 26], "tool": [0, 5, 6, 26], "latest": [0, 5, 6, 19, 25, 26, 36, 44], "html": [0, 5, 6, 19], "jobsrunnow": [0, 5], "_": [0, 41], "get_cluster_endpoint": 0, "get": [0, 2, 5, 7, 13, 25, 26, 29, 32, 39, 44], "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "cluster": [0, 2, 5, 7, 8, 12, 13, 19, 27, 30, 38, 39], "sourc": [0, 1, 2, 4, 5, 6, 7, 8, 10, 12, 13, 15, 17, 19, 20, 21, 22, 23, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41], "restart_cluster_endpoint": 0, "post": [0, 6], "restart": 0, "start_cluster_endpoint": 0, "start": 0, "terminate_cluster_endpoint": 0, "delet": [0, 6, 25, 26], "create_endpoint": 0, "creat": [0, 5, 6, 7, 8, 13, 19, 22, 25, 26, 29, 32, 38, 41], "reset_endpoint": 0, "reset": [0, 5, 25, 26, 32], "update_endpoint": 0, "updat": [0, 5, 6, 25, 26, 32, 41], "run_now_endpoint": 0, "submit_run_endpoint": 0, "get_run_endpoint": 0, "cancel_run_endpoint": 0, "cancel": [0, 5, 25, 26], "delete_run_endpoint": 0, "repair_run_endpoint": 0, "repair": [0, 5, 10, 25, 26, 43], "output_runs_job_endpoint": 0, "output": [0, 7, 22, 25, 26], "cancel_all_runs_endpoint": 0, "all": [0, 2, 5, 7, 8, 10, 12, 13, 17, 25, 26, 27, 28, 32, 37, 38, 41, 43, 44], "install_libs_endpoint": 0, "librari": [0, 1, 5, 39, 40, 41], "instal": [0, 5, 8, 25, 26, 43, 44], "uninstall_libs_endpoint": 0, "uninstal": [0, 26], "list_jobs_endpoint": 0, "list": [0, 2, 5, 7, 8, 10, 12, 13, 25, 26, 34, 38], "list_pipelines_endpoint": 0, "pipelin": [0, 5, 25, 26, 39], "workspace_get_status_endpoint": 0, "workspac": [0, 5, 19, 27, 33, 38, 40, 41, 43], "statu": [0, 25, 26], "spark_versions_endpoint": 0, "spark": [0, 2, 5, 7, 8, 12, 13, 19, 26, 27, 39], "version": [0, 2, 5, 7, 12, 13, 25, 26, 28, 29, 37, 39, 41, 44], "runlifecyclest": 0, "base": [0, 1, 2, 5, 6, 7, 8, 10, 12, 13, 15, 25, 26, 38], "enum": 0, "life": 0, "cycl": 0, "state": [0, 5, 19, 25, 26], "concept": [0, 26], "see": [0, 5, 6, 10, 17, 25, 26, 27, 28, 34], "more": [0, 5, 6, 7, 8, 10, 19, 25, 26, 27, 37, 39], "inform": [0, 5, 7, 8, 10, 15, 19, 25, 26, 44], "azur": [0, 25, 26, 27], "listrun": 0, "life_cycle_st": 0, "block": [0, 25, 26], "internal_error": 0, "pend": 0, "queu": [0, 25, 26], "skip": [0, 25, 26], "termin": [0, 5], "waiting_for_retri": 0, "runstat": [0, 5, 19], "result_st": [0, 19], "state_messag": [0, 5], "arg": [0, 5, 26], "kwarg": [0, 2, 5, 6, 7, 8, 12, 13], "util": [0, 4, 6, 8, 10, 37, 39, 43], "properti": [0, 8], "is_termin": 0, "bool": [0, 2, 5, 6, 7, 34], "true": [0, 2, 5, 7, 8, 17, 27, 30], "current": [0, 2, 5, 10, 32, 39], "i": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44], "is_success": 0, "result": [0, 2, 5, 12, 13, 15, 25, 26], "success": [0, 19], "run_life_cycle_st": [0, 25, 26], "__eq__": 0, "other": [0, 5, 25, 26, 30, 37, 38, 41], "return": [0, 1, 2, 5, 6, 7, 10, 12, 13, 15, 25, 26, 32], "self": [0, 5, 10, 17, 29], "valu": [0, 5, 6, 7, 10, 17, 22, 25, 26, 27, 38, 39], "__repr__": 0, "repr": 0, "to_json": 0, "classmethod": [0, 10], "from_json": 0, "data": [0, 7, 22, 25, 26], "clusterst": [0, 25, 26], "is_run": 0, "cluster_life_cycle_st": 0, "resiz": 0, "error": [0, 8, 25, 26, 32, 39], "unknown": [0, 1, 29], "databrickshook": [0, 25, 26], "databricks_conn_id": [0, 1, 2, 5, 6, 7, 8, 12, 13, 15, 23, 25, 26, 30, 34, 35, 36, 38, 40, 41], "basedatabrickshook": [0, 1, 2], "default_conn_nam": [0, 1, 2, 7, 12, 13], "timeout_second": [0, 1, 5, 32, 39], "180": [0, 1], "retry_limit": [0, 1, 15], "3": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "retry_delai": [0, 1, 15], "retry_arg": [0, 1, 15], "none": [0, 1, 2, 5, 6, 7, 8, 10, 12, 13, 15, 29], "caller": [0, 1, 2, 5, 15], "databricks_bas": [0, 2, 3, 4], "interact": [0, 1, 2, 38], "paramet": [0, 1, 2, 5, 6, 7, 8, 10, 12, 13, 15, 25, 26, 27, 30, 34, 35, 36, 37, 38, 41], "str": [0, 1, 2, 5, 6, 7, 8, 10, 12, 13, 15, 26, 34, 35, 36], "refer": [0, 1, 2, 5, 6, 7, 12, 13, 15, 19, 25, 26, 39], "connect": [0, 1, 2, 5, 6, 7, 8, 12, 13, 15, 25, 26, 34, 35, 36, 38], "int": [0, 1, 5, 6, 7, 8, 15, 38], "The": [0, 1, 2, 5, 8, 10, 15, 17, 19, 22, 25, 27, 28, 29, 30, 32, 37, 38, 39, 43, 44], "amount": [0, 1, 5, 6, 34, 35, 36], "time": [0, 1, 5, 6, 8, 15, 25, 26, 34, 35, 36, 38, 39, 41], "second": [0, 1, 5, 6, 15, 19, 22, 32, 34, 35, 36, 39, 41], "request": [0, 1, 2, 5, 7, 10, 12, 13, 26, 27, 28], "wait": [0, 1, 5, 6, 15, 34, 35, 36, 38], "befor": [0, 1, 2, 5, 25, 26, 36], "out": [0, 1, 6, 25, 26, 44], "number": [0, 1, 5, 6, 7, 8, 15, 26, 34, 35, 36], "retri": [0, 1, 5, 6, 15, 25, 26, 34, 35, 36, 41], "case": [0, 1, 5, 6, 15, 25, 39, 44], "servic": [0, 1, 15, 25, 26, 27], "outag": [0, 1, 15], "float": [0, 1, 5, 6], "between": [0, 1, 5, 6, 15, 34, 35, 36], "might": [0, 1, 5, 6, 28, 44], "point": [0, 1, 5, 6, 26], "dict": [0, 1, 2, 5, 7, 8, 10, 12, 13, 15, 17, 25, 26], "ani": [0, 1, 2, 5, 7, 8, 10, 12, 13, 15, 25, 29], "an": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "option": [0, 1, 2, 5, 6, 7, 12, 13, 15, 25, 26, 27, 30, 34, 37, 38], "dictionari": [0, 1, 2, 5, 6, 7, 8, 10, 12, 13, 15, 27], "argument": [0, 1, 5, 15, 25, 26, 27, 32], "pass": [0, 1, 2, 5, 7, 8, 15, 22, 26, 32, 37, 39, 41], "tenac": [0, 1, 5, 15], "hook_nam": [0, 2], "create_job": 0, "json": [0, 5, 7, 17, 25, 26, 27, 30, 37], "call": [0, 1, 2, 5, 15, 25, 26, 32, 37, 39], "us": [0, 2, 5, 6, 7, 8, 10, 12, 13, 15, 19, 22, 23, 25, 26, 27, 28, 29, 33, 41, 43, 44], "bodi": [0, 26], "job_id": [0, 5, 8, 25, 26, 32, 37], "type": [0, 5, 7, 10, 15, 17, 25, 26, 27, 32, 37, 38, 39], "reset_job": 0, "new_set": [0, 5], "update_job": 0, "id": [0, 5, 6, 7, 8, 10, 12, 13, 15, 25, 26, 29, 35, 36, 37, 38, 39], "run_now": [0, 32], "run_id": [0, 5, 8, 10, 15], "submit_run": 0, "list_job": [0, 25, 26], "limit": [0, 38], "25": [0, 26], "expand_task": 0, "fals": [0, 2, 5, 6, 15, 17, 33], "job_nam": [0, 5, 37], "page_token": [0, 25], "include_user_nam": 0, "batch": [0, 26], "size": 0, "retriev": [0, 5, 10, 25, 26], "whether": [0, 2, 5], "includ": [0, 25, 26, 28, 32, 39, 43, 44], "task": [0, 5, 8, 10, 15, 19, 22, 25, 26, 32, 33, 37, 38, 39, 40, 41, 43], "detail": [0, 5, 25, 26, 29], "respons": [0, 25, 26], "name": [0, 1, 2, 5, 6, 7, 8, 10, 12, 13, 25, 26, 27, 30, 34, 35, 36, 37, 38, 41], "search": [0, 25, 26], "page": [0, 15, 26, 29], "token": [0, 1, 5, 6, 25, 26, 27], "first": [0, 5, 7, 19, 22, 25, 26, 32, 37, 39], "A": [0, 5, 8, 10], "find_job_id_by_nam": 0, "find": 0, "its": [0, 6, 25, 34, 36, 38, 43], "ar": [0, 5, 7, 8, 10, 15, 25, 26, 27, 28, 29, 30, 32, 37, 38, 39, 41, 43, 44], "multipl": [0, 32, 37, 39], "same": [0, 5, 6, 7, 25, 32, 37, 39], "rais": [0, 8, 25, 26], "airflowexcept": 0, "look": [0, 5, 7, 8, 10], "up": [0, 5, 26], "wa": [0, 2, 5, 10, 15, 25, 32], "found": [0, 30, 37, 38, 44], "list_pipelin": 0, "batch_siz": 0, "pipeline_nam": [0, 39], "notebook_path": [0, 5, 32, 33, 39, 40, 41], "delta": [0, 5, 22, 39], "live": [0, 5, 39], "tabl": [0, 2, 5, 7, 12, 22, 30, 38, 39], "cannot": [0, 5, 25, 26], "combin": 0, "path": [0, 2, 5, 6, 7, 12, 13, 15, 19, 22, 25, 26, 27, 30, 34, 38, 39], "notebook": [0, 5, 8, 19, 25, 26, 39, 41], "find_pipeline_id_by_nam": 0, "pipeline_id": [0, 5, 39], "guid": [0, 5, 7, 8, 10, 26, 29], "string": [0, 2, 7, 12, 13, 17, 25, 26, 30, 34, 35, 36, 38], "get_run_page_url": 0, "run_page_url": [0, 5, 15], "url": [0, 6, 15, 25, 26, 27, 34], "async": [0, 1, 15, 25, 26], "a_get_run_page_url": 0, "get_job_id": 0, "from": [0, 5, 6, 7, 10, 13, 17, 22, 25, 26, 27, 28, 30, 34, 44], "given": [0, 5, 6, 7, 10, 34, 36, 38], "get_run_st": 0, "pleas": [0, 5, 25, 29], "note": [0, 2, 5, 10, 26, 27, 32, 37, 39], "method": [0, 5, 8, 25, 26, 27], "failur": [0, 5], "unless": [0, 2], "you": [0, 5, 25, 27, 28, 29, 32, 34, 35, 36, 37, 39, 41, 44], "have": [0, 5, 17, 19, 25, 26, 27, 38, 44], "xcom": [0, 5, 25, 26, 32], "pickl": 0, "can": [0, 5, 6, 7, 17, 25, 27, 28, 29, 32, 34, 37, 38, 39, 40, 41, 44], "done": [0, 44], "follow": [0, 5, 25, 26, 27, 29, 30, 32, 34, 35, 36, 37, 38, 39, 44], "environ": [0, 27, 43], "variabl": [0, 27], "airflow__core__enable_xcom_pickl": 0, "If": [0, 2, 5, 6, 7, 8, 12, 13, 15, 25, 27, 29, 32, 34, 39, 41], "do": [0, 8, 25, 26, 29, 38, 39, 41], "want": [0, 15, 25, 29, 44], "get_run_state_str": 0, "describ": [0, 2, 7, 12, 13, 29, 37], "get_run_state_lifecycl": 0, "get_run_state_result": 0, "get_run_state_messag": 0, "individu": [0, 7, 26, 43], "compon": [0, 27], "a_get_run_st": 0, "get_run": 0, "a_get_run": 0, "represent": [0, 5], "lifecycl": 0, "messag": [0, 5], "get_run_output": 0, "a_get_run_output": 0, "cancel_run": 0, "cancel_all_run": 0, "activ": [0, 27], "asynchron": [0, 15], "canon": 0, "identifi": 0, "delete_run": 0, "non": [0, 17, 26], "repair_run": [0, 5, 15, 25, 26, 37], "re": [0, 15, 26, 27], "one": [0, 5, 17, 25, 26, 29, 32, 37, 38, 39], "get_latest_repair_id": 0, "exist": [0, 5, 6, 8, 28, 32, 34, 35, 36, 37, 38, 39, 41], "els": [0, 25, 26], "get_cluster_st": 0, "cluster_id": 0, "a_get_cluster_st": 0, "restart_clust": 0, "contain": [0, 5, 6, 7, 8, 10, 12, 13, 17, 27, 29, 30], "specif": [0, 5, 7, 8, 26, 27, 38, 39, 41], "start_clust": 0, "terminate_clust": 0, "function": [0, 2, 13, 25, 26, 37, 39], "arrai": [0, 5, 39], "update_repo": [0, 36], "repo_id": [0, 6, 35, 36], "repo": [0, 6, 20, 25, 26, 33, 41], "payload": [0, 5, 26, 32, 37, 39], "metadata": [0, 1, 5, 8], "delete_repo": [0, 35], "create_repo": [0, 34], "get_repo_by_path": 0, "obtain": [0, 27], "repositori": [0, 5, 6, 34], "doesn": 0, "t": [0, 2, 6, 7, 25, 26, 27, 34, 35, 36, 37, 41], "update_job_permiss": 0, "permiss": [0, 5, 25, 26, 27], "test_connect": [0, 25, 26], "test": [0, 25, 26, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 44], "ui": [0, 5, 32, 43], "6": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "10": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "dev0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "experiment": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "featur": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44], "azure_metadata_service_token_url": 1, "169": 1, "254": 1, "ident": [1, 25, 26, 27], "oauth2": 1, "azure_metadata_service_instance_url": 1, "instanc": [1, 5, 10, 25, 26], "token_refresh_lead_tim": 1, "120": 1, "azure_management_endpoint": 1, "manag": [1, 8, 25, 26, 27, 29], "core": [1, 26, 30], "window": [1, 30], "net": [1, 30], "default_databricks_scop": 1, "2ff814a6": 1, "3304": 1, "4ab8": 1, "85cb": 1, "cd0e6f879c1d": 1, "oidc_token_service_url": 1, "oidc": 1, "v1": 1, "basehook": 1, "conn_name_attr": 1, "databricks_default": [1, 5, 6, 21, 27, 38], "conn_typ": 1, "extra_paramet": 1, "host": [1, 5, 6, 25, 26, 27], "use_azure_managed_ident": [1, 27], "azure_ad_endpoint": [1, 27], "azure_resource_id": [1, 27], "databricks_conn": [1, 40], "get_conn": [1, 2], "user_agent_head": 1, "user_agent_valu": 1, "__aenter__": 1, "__aexit__": 1, "err": 1, "bearerauth": 1, "aiohttp": [1, 25, 26, 28], "basicauth": [1, 25, 26], "onli": [1, 2, 5, 7, 17, 25, 27, 30, 37, 38, 43, 44], "ship": 1, "bearer": [1, 27], "auth": [1, 25, 26, 27], "we": [1, 5, 6, 17, 19, 25, 26, 34, 38, 41, 44], "need": [1, 5, 15, 25, 26, 27, 28, 34, 35, 36, 39], "subclass": 1, "encod": [1, 27], "credenti": [1, 7, 27], "list_sql_endpoints_endpoint": 2, "sql": [2, 7, 12, 13, 22, 25, 26, 27, 28, 30, 38], "databrickssqlhook": [2, 7, 12, 13, 25, 26], "http_path": [2, 7, 12, 13, 27, 30, 38], "sql_endpoint_nam": [2, 7, 30, 38], "session_configur": [2, 7, 12, 13, 27], "http_header": [2, 7, 12, 13], "catalog": [2, 7, 12, 13, 38], "schema": [2, 7, 12, 13, 38], "return_tupl": [2, 25, 26], "common": [2, 5, 6, 7, 25, 26, 28], "dbapihook": [2, 12, 13, 25, 26], "specifi": [2, 5, 6, 7, 12, 13, 22, 25, 26, 27, 28, 30, 34, 37, 38, 41], "should": [2, 5, 6, 7, 12, 13, 15, 25, 26, 27, 29, 38, 39, 43, 44], "either": [2, 5, 7, 12, 13, 15, 27, 35, 36, 37, 39], "": [2, 5, 6, 7, 12, 13, 25, 26, 27, 29, 32, 34, 38, 39, 43], "extra": [2, 5, 6, 7, 12, 13, 25, 26, 27, 28], "must": [2, 5, 6, 7, 8, 12, 13, 17, 27, 34, 38, 39], "abov": [2, 7, 29], "session": [2, 7, 10, 12, 13, 25, 26, 27], "default": [2, 5, 6, 7, 8, 12, 13, 15, 26, 38, 44], "could": [2, 7, 12, 13, 27, 30, 38], "tupl": [2, 7, 12, 13, 15, 25, 26], "k": [2, 7, 12, 13], "v": [2, 7, 12, 13, 38], "pair": [2, 5, 7, 12, 13], "set": [2, 5, 7, 12, 13, 19, 25, 26, 27], "header": [2, 7, 12, 13, 26, 27, 30], "everi": [2, 5, 7, 12, 13, 15], "initi": [2, 7, 12, 13, 25, 26, 32, 39], "requir": [2, 5, 6, 7, 12, 13, 25, 26, 27, 30, 34, 35, 36, 37, 38, 41, 44], "dbr": [2, 7], "9": [2, 7, 12, 13, 28, 39], "namedtupl": [2, 25, 26], "object": [2, 5, 7, 10, 13, 25, 26, 27, 39], "instead": [2, 5, 25, 26, 27, 39], "row": [2, 7, 25, 26], "In": [2, 5, 15, 19, 32, 37, 39], "futur": 2, "releas": [2, 25, 26, 28, 36], "becom": 2, "ensur": [2, 25, 26, 43], "backward": 2, "compat": [2, 25, 26], "dure": [2, 5, 25, 26, 32, 39], "transit": 2, "phase": 2, "flag": [2, 27], "also": [2, 5, 7, 25, 29, 32, 39, 43], "remov": [2, 25, 26, 29], "addit": [2, 7, 12, 13, 37], "connector": [2, 7, 12, 13, 25, 26, 27, 28], "iter": [2, 13], "autocommit": 2, "map": [2, 5, 10, 27], "handler": [2, 12, 13], "split_stat": 2, "return_last": 2, "callabl": [2, 12, 13], "command": [2, 5, 7, 26, 30, 39], "statement": [2, 7, 13, 22, 25, 26], "them": [2, 25, 26, 28], "execut": [2, 5, 6, 7, 13, 19, 25, 26, 32, 36, 39, 41], "sequenti": [2, 19], "what": 2, "queri": [2, 7, 13, 25, 26, 38, 41], "commit": [2, 26], "so": [2, 25, 26, 32, 38, 44], "ha": [2, 19, 25], "effect": [2, 37, 39], "render": [2, 5, 6, 7], "which": [2, 5, 7, 8, 10, 19, 22, 25, 26, 27, 39, 44], "each": [2, 5, 8, 32, 37, 38, 39, 43], "split": 2, "singl": [2, 7, 8, 10, 15, 39, 41, 43], "separ": [2, 26, 44], "last": 2, "after": [2, 25, 26, 32], "express": [2, 7, 25, 26], "abstract": 2, "bulk_dump": 2, "tmp_file": 2, "dump": 2, "databas": [2, 7], "tab": 2, "delimit": 2, "file": [2, 5, 7, 22, 25, 26, 29, 30, 39], "target": 2, "bulk_load": 2, "load": [2, 22, 26, 30], "databricks_sql": [3, 4, 9, 14, 25, 26], "hook": [4, 5, 7, 13, 25, 26, 27], "databricks_repo": [4, 9], "databricks_workflow": [4, 9, 11], "plugin": [4, 26, 43], "sensor": [4, 25, 26], "databricks_partit": [4, 14], "trigger": [4, 5, 25, 26, 37], "__version__": [4, 26], "defer_method_nam": 5, "execute_complet": [5, 25, 26], "xcom_run_id_kei": 5, "xcom_job_id_kei": 5, "xcom_run_page_url_kei": 5, "is_repair_reason_match_exist": 5, "run_stat": 5, "check": [5, 6, 12, 25, 26, 29, 32, 38, 39], "reason": [5, 17, 25, 26, 44], "match": [5, 7, 25, 26, 29, 41], "being": [5, 15], "handl": [5, 15, 25, 26], "otherwis": [5, 25], "update_job_for_repair": 5, "partial": 5, "fail": [5, 10, 17, 25, 26, 43], "databricksjobrunlink": [5, 25, 26], "model": [5, 6, 7, 10, 44], "baseoperatorlink": [5, 10], "construct": [5, 7, 10], "link": [5, 10, 25, 26, 29, 43], "monitor": [5, 10, 33, 40, 41, 43], "get_link": [5, 10], "ti_kei": [5, 10], "extern": [5, 10, 38], "system": [5, 10, 27, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41], "old": [5, 10, 26], "signatur": [5, 10, 26, 28, 29], "dttm": [5, 10], "datetim": [5, 10], "That": [5, 10, 25], "still": [5, 10, 25], "support": [5, 7, 10, 25, 26, 27, 28, 30, 32, 34, 38, 39], "runtim": [5, 10, 12, 13, 25, 26], "deprec": [5, 10, 25, 26], "baseoper": [5, 6, 7, 10, 25, 26], "associ": [5, 10], "taskinstancekei": [5, 10, 26], "taskinst": [5, 10, 25, 26], "databrickscreatejobsoper": [5, 25, 26, 31], "descript": [5, 25, 26, 32], "tag": [5, 6, 32, 34, 36], "job_clust": [5, 8, 32, 41], "email_notif": [5, 32, 41], "webhook_notif": [5, 32], "notification_set": [5, 32], "schedul": [5, 32], "max_concurrent_run": [5, 8, 32], "git_sourc": [5, 25, 26, 32, 39], "access_control_list": [5, 32], "polling_period_second": [5, 15], "30": [5, 15, 26], "databricks_retry_limit": [5, 6, 34, 35, 36], "databricks_retry_delai": [5, 6, 34, 35, 36], "databricks_retry_arg": 5, "directli": [5, 32, 37, 39], "e": [5, 15, 27], "etc": 5, "merg": [5, 32, 39], "thei": [5, 15, 17, 32, 38, 39], "conflict": [5, 32, 39, 41], "take": [5, 7, 8, 10, 32, 37, 39], "preced": [5, 32, 39], "overrid": [5, 8, 25, 26, 32, 39], "top": [5, 28, 29, 32, 37, 39], "level": [5, 8, 25, 26, 32, 37, 39, 41, 43], "kei": [5, 6, 10, 29, 32, 39], "templat": [5, 6, 7, 12, 13, 25, 26], "For": [5, 7, 8, 10, 19, 26, 27, 28, 29, 37, 38], "about": [5, 19, 26, 29, 44], "jinja": [5, 6, 7, 25, 26], "jobtaskset": 5, "share": [5, 32, 33, 40, 41], "reus": [5, 27], "jobclust": 5, "jobemailnotif": 5, "webhooknotif": 5, "notif": [5, 25, 26], "timeout": [5, 38], "appli": [5, 25, 26], "cronschedul": 5, "maximum": [5, 8], "allow": [5, 25, 26, 27, 37, 39, 43], "concurr": [5, 8], "remot": 5, "gitsourc": 5, "accesscontrolrequestforus": 5, "accesscontrolrequestforgroup": 5, "accesscontrolrequestforserviceprincip": 5, "order": [5, 26, 28], "acl": [5, 25, 26], "consid": [5, 27], "control": [5, 7, 15, 32, 39, 41], "rate": [5, 15], "poll": [5, 15], "By": [5, 6, 15, 29], "backend": [5, 6, 26, 34, 35, 36], "unreach": [5, 6, 34, 35, 36], "Its": [5, 6], "greater": [5, 6], "than": [5, 6, 32], "equal": [5, 6], "template_field": [5, 6, 7, 12, 13, 25, 26], "sequenc": [5, 6, 7, 12, 13, 25, 26], "ui_color": 5, "1cb1c2": 5, "ui_fgcolor": 5, "fff": 5, "context": [5, 6, 7, 8, 10, 12, 13, 15, 26], "deriv": [5, 6, 7, 25, 26], "when": [5, 6, 7, 15, 17, 25, 26, 27, 28, 32, 39, 41, 44], "get_template_context": [5, 6, 7], "databrickssubmitrunoper": [5, 19, 25, 26, 31], "spark_jar_task": [5, 39], "notebook_task": [5, 32, 39, 40, 41], "spark_python_task": [5, 39], "spark_submit_task": [5, 39], "pipeline_task": [5, 25, 26, 39], "dbt_task": [5, 39], "new_clust": [5, 32, 33, 39], "existing_cluster_id": [5, 33, 39], "run_nam": [5, 39], "do_xcom_push": [5, 25, 26], "idempotency_token": [5, 37], "wait_for_termin": [5, 25, 26], "deferr": [5, 25, 26, 37, 39], "conf": 5, "getboolean": 5, "default_deferr": [5, 25, 26], "fallback": 5, "jobsrunssubmit": 5, "There": [5, 25, 27, 29, 32, 37, 38, 39, 41], "three": [5, 32, 39], "wai": [5, 27, 32, 37, 38, 39], "instanti": [5, 15, 32, 37, 39], "how": [5, 7, 8, 10, 26, 29], "runsubmittaskset": 5, "100": [5, 33], "item": 5, "main": [5, 25, 26, 29, 39, 44], "jar": [5, 8, 19, 39], "actual": [5, 34], "OR": 5, "field": [5, 6, 17, 25, 26, 27], "jobssparkjartask": 5, "jobsnotebooktask": 5, "python": [5, 8, 25, 26, 28, 29, 39], "jobssparkpythontask": 5, "jobssparksubmittask": 5, "least": [5, 25, 34], "jobspipelinetask": 5, "dbt": [5, 25, 26, 39], "spec": [5, 39], "new": [5, 19, 25, 26, 32, 37, 39, 44], "except": [5, 6, 17, 25, 26, 34, 37, 44], "jobsclusterspecnewclust": 5, "managedlibrarieslibrari": 5, "task_id": [5, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41], "superclass": 5, "guarante": 5, "idempot": 5, "alreadi": [5, 6, 29, 34, 41], "doe": [5, 17, 25, 41, 43], "most": [5, 29], "64": 5, "charact": [5, 26], "repres": [5, 25, 26, 38], "access": [5, 27, 38], "consist": [5, 25], "subject": [5, 26], "user_nam": 5, "user": [5, 6, 20, 23, 25, 26, 27, 29, 34, 35, 36, 38, 39, 41, 43], "group_nam": 5, "group": [5, 8, 10, 41], "permission_level": 5, "document": [5, 7, 25, 26, 27, 30, 34, 37, 38], "mean": 5, "To": [5, 6, 29, 34, 35, 36, 41], "authent": [5, 6, 7, 25, 26], "leav": [5, 6, 27], "empti": [5, 6, 25, 26, 27], "push": [5, 25], "git": [5, 6, 34, 36], "mode": [5, 25, 26], "template_ext": [5, 7, 12, 13, 25, 26], "tpl": 5, "operator_extra_link": [5, 10], "on_kil": 5, "clean": [5, 26], "subprocess": 5, "kill": 5, "thread": 5, "multiprocess": 5, "within": [5, 10, 25, 26, 32, 40, 41, 43], "ghost": 5, "process": [5, 15, 25, 26], "behind": 5, "event": [5, 15, 17, 25, 26, 38], "databrickssubmitrundeferrableoper": [5, 31], "databricksrunnowoper": [5, 25, 26, 31], "notebook_param": [5, 8, 37, 41], "python_param": [5, 8, 37], "jar_param": [5, 8, 37], "spark_submit_param": [5, 8, 37], "python_named_param": 5, "databricks_repair_reason_new_set": 5, "cancel_previous_run": [5, 25, 26, 37], "two": [5, 19, 37], "typic": [5, 32, 37, 39], "our": [5, 26, 32, 37, 39], "through": [5, 32, 37, 39], "exampl": [5, 12, 19, 22, 23, 26, 27, 28, 29, 37], "42": 5, "dry": 5, "oldest": 5, "1457570074236": 5, "notebook_run": [5, 39], "anoth": [5, 15, 37, 39], "accomplish": [5, 32, 37, 39], "thing": [5, 32, 37, 38, 39], "exactli": [5, 32, 37, 38, 39], "your": [5, 25, 41, 43], "code": [5, 7, 25, 26, 29, 36, 41], "would": 5, "like": [5, 15, 34, 35, 36], "dougla": 5, "adam": 5, "org": [5, 29, 33, 41], "apach": [5, 25, 29], "sparkpi": 5, "where": [5, 39, 44], "both": [5, 19, 27, 32, 39], "AND": [5, 32, 39], "togeth": [5, 7, 32, 39], "python_named_paramet": [5, 37], "It": [5, 29, 37, 38, 39], "mutual": 5, "exclus": 5, "g": [5, 15, 27], "john": 5, "ag": 5, "35": 5, "dbutil": 5, "widget": 5, "upon": 5, "conjunct": 5, "exce": 5, "000": 5, "byte": 5, "line": [5, 26], "overwrit": 5, "wheel": [5, 28], "script": [5, 26, 29], "per": [5, 25, 26], "noth": 5, "databricksrunnowdeferrableoper": [5, 25, 26, 31], "databrickstaskbaseoper": 5, "job_cluster_kei": [5, 32, 40, 41], "5": [5, 28], "workflow_run_metadata": 5, "abc": [5, 12, 38], "workflow": [5, 8, 10, 40, 43], "log": [5, 10, 25, 26], "notebook_packag": [5, 8, 33, 41], "param": [5, 25, 26, 39], "expect": 5, "conn_id": [5, 8], "monitor_databricks_job": 5, "defer": [5, 15, 25, 26], "launch": [5, 10, 33, 40, 41, 43], "databricksnotebookoper": [5, 23, 25, 26, 31, 41], "part": [5, 40], "databricksworkflowtaskgroup": [5, 8, 23, 25, 26, 31, 40], "advantag": [5, 41], "cheaper": 5, "locat": [5, 7, 30], "local": [5, 29], "defin": [5, 8, 25, 26, 27, 41], "visit": 5, "jobscreat": 5, "databrickstaskoper": [5, 25, 26, 31, 41], "task_config": [5, 40, 41], "configur": [5, 7, 30, 38, 43], "databricksreposcreateoper": [6, 31], "git_url": [6, 34], "git_provid": [6, 34], "branch": [6, 34, 36, 44], "repo_path": [6, 20, 34, 35, 36], "ignore_existing_repo": [6, 34], "guess": [6, 34], "format": [6, 7, 22, 25, 26, 30, 38], "folder": [6, 26, 29], "directori": [6, 27, 29, 34], "checkout": [6, 34], "don": [6, 25, 26, 34], "throw": [6, 17, 34, 37], "__git_providers__": 6, "__aws_code_commit_regexp__": 6, "__repos_path_regexp__": 6, "static": [6, 26], "__detect_repo_provider__": 6, "databricksreposupdateoper": [6, 31], "patch": [6, 26], "omit": 6, "databricksreposdeleteoper": [6, 31], "databrickssqloper": [7, 22, 25, 26, 27, 31], "output_path": [7, 38], "output_format": [7, 38], "csv": 7, "csv_param": 7, "client_paramet": [7, 12, 13], "sqlexecutequeryoper": [7, 25, 26], "recogn": 7, "end": [7, 26], "write": 7, "select": [7, 22, 29], "possibl": [7, 26, 41], "jsonl": [7, 38], "dictwrit": 7, "template_fields_render": [7, 12, 13], "conn_id_field": 7, "get_db_hook": 7, "copy_into_approved_format": 7, "avro": [7, 30], "orc": [7, 30], "parquet": [7, 30], "text": [7, 30], "binaryfil": [7, 30], "databrickscopyintooper": [7, 22, 25, 26, 31], "table_nam": [7, 12, 30, 38], "file_loc": [7, 22, 30], "file_format": [7, 30], "pattern": 7, "expression_list": 7, "storage_credenti": 7, "encrypt": 7, "format_opt": [7, 30], "force_copi": [7, 30], "copy_opt": 7, "valid": [7, 17, 25, 26, 29], "copi": [7, 30], "INTO": [7, 30], "piec": 7, "import": [7, 25, 26, 29], "regex": 7, "against": [7, 38], "uniti": 7, "storag": 7, "destin": 7, "forc": 7, "integ": [7, 34, 35, 36], "n": 7, "right": 7, "workflowrunmetadata": 8, "existing_clust": 8, "extra_job_param": [8, 41], "task_group": [8, 10, 23, 41], "taskgroup": [8, 10], "produc": [8, 41], "those": [8, 28, 29], "elig": 8, "_convert_to_databricks_workflow_task": 8, "pars": 8, "definit": [8, 19, 41], "These": 8, "packag": [8, 25, 27, 33, 40, 41], "under": [8, 32], "And": 8, "is_databrick": 8, "__exit__": 8, "_type": 8, "_valu": 8, "_tb": 8, "exit": 8, "add": [8, 25, 26, 27], "_createdatabricksworkflowoper": 8, "repair_wait_attempt": 10, "repair_wait_delai": 10, "airflow_app": 10, "get_auth_decor": 10, "get_databricks_task_id": 10, "group_id": [10, 23, 41], "task_map": 10, "logger": [10, 26], "get_launch_task_id": 10, "parent": [10, 25, 26], "recurs": 10, "inspect": 10, "get_task_inst": 10, "new_sess": 10, "get_xcom_result": 10, "workflowjobrunlink": 10, "logging_mixin": 10, "loggingmixin": 10, "workflowjobrepairallfailedlink": 10, "send": 10, "get_task_group_children": 10, "children": 10, "get_tasks_to_run": 10, "workflowjobrepairsingletasklink": 10, "repairdatabrickstask": 10, "www": [10, 25, 26], "view": [10, 25, 26, 43], "airflowbaseview": 10, "default_view": 10, "dag_id": [10, 19, 20, 21, 22], "repair_databricks_view": 10, "repair_databricks_packag": 10, "databricksworkflowplugin": [10, 25, 26, 42], "plugins_manag": 10, "airflowplugin": 10, "appbuilder_view": 10, "databrickspartitionsensor": [12, 25, 26, 31], "sql_warehouse_nam": [12, 13, 38], "partit": [12, 38], "partition_oper": [12, 38], "fetch_all_handl": [12, 13], "basesensoroper": [12, 13], "detect": [12, 25, 26, 32, 39, 43], "presenc": [12, 38], "warehous": [12, 13, 38], "below": [12, 13, 28, 29], "purpos": [12, 13, 41], "date": [12, 38], "2023": [12, 26, 38], "01": [12, 26, 38], "03": [12, 26, 38], "def": [12, 38], "comparison": [12, 38], "poke": [12, 13, 38], "databrickssqlsensor": [13, 25, 26, 31], "databricksexecutiontrigg": [15, 17], "basetrigg": 15, "logic": 15, "commun": 15, "serial": [15, 25, 26], "reconstruct": 15, "keyword": 15, "yield": [15, 25, 26], "whenev": [15, 41], "fire": 15, "off": 15, "finish": [15, 38], "thu": 15, "immedi": 15, "resum": 15, "veri": 15, "quickli": 15, "mai": [15, 26, 27, 39], "workload": 15, "move": [15, 25, 26], "multi": [15, 25, 26], "assum": 15, "persist": 15, "reli": [15, 25, 32], "cleanup": [15, 26], "longer": 15, "normalise_json_cont": 17, "json_path": 17, "normal": [17, 26], "numer": 17, "boolean": [17, 25, 26, 27], "why": [17, 29], "becaus": [17, 19, 32, 39, 41], "render_templ": 17, "convert": [17, 25, 26], "understand": 17, "validate_trigger_ev": 17, "correct": [17, 25, 26, 29], "receiv": [17, 44], "dag": [19, 22, 23, 25, 26, 40], "upload": 19, "dbf": [19, 39], "downstream": [19, 38], "depend": [19, 25, 26, 37, 44], "NOT": 19, "until": [19, 38], "complet": [19, 25], "successfulli": 19, "env_id": [19, 20, 21, 22], "example_databricks_oper": 19, "query_id": [19, 23, 40, 41], "warehouse_id": [19, 23, 40, 41], "test_run": [19, 20, 21, 22, 23], "default_arg": [20, 26], "example_databricks_repos_oper": 20, "domain": [20, 34, 35, 36], "demo": [20, 34, 35, 36], "connection_id": [21, 22, 30, 38], "insert": [22, 38], "third": [22, 32], "store": [22, 38], "fourth": 22, "written": 22, "final": [22, 25, 26], "example_databricks_sql_oper": 22, "my_connect": 22, "execution_timeout": [23, 41], "databricks_notification_email": [23, 41], "job_cluster_spec": [23, 41], "example_databrick": [24, 32, 33, 39, 40], "example_databricks_repo": [24, 34, 35, 36], "example_databricks_sensor": [24, 38], "example_databricks_sql": [24, 30, 38], "example_databricks_workflow": [24, 41], "airflow": [25, 27, 29, 33, 34, 35, 36, 37, 39, 40, 43, 44], "provid": [25, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 43, 44], "databrick": [25, 29, 30, 32, 37, 38, 39, 43], "feat": [25, 26], "appropri": [25, 26], "41412": [25, 26], "has_access": [25, 26], "min": [25, 26], "41747": [25, 26], "soft_fail": [25, 26], "41710": [25, 26], "avail": [25, 29, 33, 39], "explain": 25, "polici": [25, 44], "bump": [25, 26], "minimum": [25, 26, 28], "41396": [25, 26], "revert": [25, 26], "some": [25, 26], "ad": [25, 26, 27], "around": 25, "40724": [25, 26], "databricksplugin": [25, 26], "redirect": [25, 26], "url_for": [25, 26], "41040": [25, 26], "40864": [25, 26], "pr": [25, 26], "40471": [25, 26], "41050": [25, 26], "make": [25, 26], "40332": [25, 26], "40013": [25, 26], "39771": [25, 26], "40178": [25, 26], "implement": [25, 26], "lowest": [25, 26], "direct": [25, 26], "resolut": [25, 26], "39946": [25, 26], "lower": [25, 26], "info": [25, 26], "debug": [25, 26], "reduc": [25, 26], "verbos": [25, 26], "39941": [25, 26], "panda": [25, 26, 28], "12": [25, 26, 29, 32, 33, 39], "40272": [25, 26], "39295": [25, 26], "39354": [25, 26], "faster": [25, 26], "airflow_vers": [25, 26], "39552": [25, 26], "simplifi": [25, 26], "39497": [25, 26], "better": [25, 26], "39742": [25, 26], "39178": [25, 26], "39175": [25, 26], "39110": [25, 26], "39240": [25, 26], "38702": [25, 26], "38619": [25, 26], "38962": [25, 26], "remain": [25, 26], "d401": [25, 26], "37434": [25, 26], "38741": [25, 26], "slash": [25, 26], "38918": [25, 26], "typo": [25, 26], "latest_repair_id": 25, "39050": [25, 26], "refactor": [25, 26], "redund": [25, 26], "38397": [25, 26], "renam": [25, 26], "compli": [25, 26], "38052": [25, 26], "work": [25, 26, 27, 43], "37025": [25, 26], "avoid": [25, 26], "cve": [25, 26], "2024": [25, 26], "23829": [25, 26], "23334": [25, 26], "37110": [25, 26], "switch": [25, 26, 27], "class": [25, 26, 28, 30, 38, 39], "decor": [25, 26], "36876": [25, 26], "rid": [25, 26], "pytest": [25, 26], "httpx": [25, 26], "37334": [25, 26], "36601": [25, 26], "36827": [25, 26], "column": [25, 26], "attribut": [25, 26], "36949": [25, 26], "36862": [25, 26], "structur": [25, 26, 41], "dbapi": [25, 26], "36205": 25, "fetchon": [25, 26], "odbchook": [25, 26], "36161": [25, 26], "36017": [25, 26], "36248": [25, 26], "snippet": [25, 26], "docstr": [25, 26], "via": [25, 26, 28, 29, 34, 35, 36, 37, 38, 39, 41], "ruff": [25, 26], "36262": [25, 26], "been": 25, "broken": [25, 26], "pyodbc": [25, 26], "serializ": [25, 26], "make_serializ": [25, 26], "32319": [25, 26], "offset": [25, 26], "favor": 25, "pagin": [25, 26], "similarli": 25, "34926": [25, 26], "35156": [25, 26], "34643": [25, 26], "respect": [25, 26, 38], "34544": [25, 26], "34517": [25, 26], "decod": [25, 26], "f": [25, 26, 41], "34518": [25, 26], "34728": [25, 26], "httpbasicauth": [25, 26], "34590": [25, 26], "33472": [25, 26], "deploy": [25, 26, 43], "33886": [25, 26], "accept": [25, 26, 38], "32903": [25, 26], "replac": [25, 26], "concaten": [25, 26], "unpack": [25, 26], "33933": [25, 26], "improv": [25, 26], "modul": [25, 26], "33754": [25, 26], "liter": [25, 26], "33761": [25, 26], "33752": [25, 26], "exclud": [25, 26], "due": [25, 26], "properli": [25, 43], "declar": 25, "urllib3": 25, "github": [25, 26, 34], "issu": 25, "190": 25, "princip": [25, 26, 27], "oauth": [25, 26, 27], "33005": [25, 26], "py": [25, 26, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41], "32340": [25, 26], "33519": [25, 26], "duplic": [25, 26], "sort": [25, 26], "33675": [25, 26], "condit": [25, 26], "len": [25, 26], "33569": [25, 26], "smaller": [25, 26], "33234": [25, 26], "conn": [25, 26], "30784": [25, 26], "32806": [25, 26], "miss": [25, 26], "32689": [25, 26], "accur": [25, 26], "31846": [25, 26], "modifi": [25, 26, 41], "32253": [25, 26], "config": [25, 26], "31712": [25, 26], "drop": [25, 26, 29, 38], "loop": [25, 26], "stop": [25, 26], "31985": [25, 26], "annot": [25, 26], "31888": [25, 26], "31780": [25, 26], "relat": [25, 26, 27, 38], "again": [25, 26], "31898": [25, 26], "31899": [25, 26], "31703": [25, 26], "30963": [25, 26], "31136": [25, 26], "31038": [25, 26], "databr": [25, 26], "30744": [25, 26], "30786": [25, 26], "30980": [25, 26], "30917": [25, 26], "30761": [25, 26], "inact": [25, 26], "30646": [25, 26], "30477": [25, 26], "taskflow": [25, 26], "29840": [25, 26], "conform": 25, "semant": 25, "kind": 25, "previous": 25, "pre": [25, 26], "cursor": 25, "just": 25, "last_descript": 25, "suitabl": 25, "gener": [25, 26, 27, 38], "lineag": 25, "analysi": 25, "had": 25, "custom": [25, 43], "behaviour": [25, 26], "adapt": 25, "standard": [25, 26, 33], "approach": [25, 32, 39], "howev": [25, 43], "unchang": 25, "continu": 25, "without": 25, "introduc": [25, 26, 37, 39], "27854": [25, 26], "27888": [25, 26], "27868": [25, 26], "27912": [25, 26], "databricskssqloper": 25, "27196": [25, 26], "urlpars": [25, 26], "urlsplit": [25, 26], "27389": [25, 26], "25717": [25, 26], "27446": [25, 26], "25623": [25, 26], "bound": [25, 26], "25789": [25, 26], "26628": [25, 26], "agent": [25, 26], "25873": [25, 26], "25578": [25, 26], "25260": [25, 26], "telemetri": [25, 26], "25115": [25, 26], "unifi": [25, 26], "23971": [25, 26], "25114": [25, 26], "deep_string_coerc": [25, 26], "25394": [25, 26], "correctli": [25, 26], "25427": [25, 26], "x": [25, 26, 32, 33, 39], "25674": [25, 26], "24945": [25, 26], "24617": [25, 26], "24836": [25, 26], "functool": [25, 26], "cached_properti": [25, 26], "24582": [25, 26], "19736": [25, 26], "23620": [25, 26], "23622": [25, 26], "23641": [25, 26], "unboundlocalerror": [25, 26], "23815": [25, 26], "dbsql": [25, 26], "further": [25, 26], "23199": [25, 26], "22422": [25, 26], "22541": [25, 26], "22886": [25, 26], "22885": [25, 26], "hoc": [25, 26], "22571": [25, 26], "22278": [25, 26], "mistakenli": 25, "install_requir": 25, "22382": 25, "22076": [25, 26], "429": [25, 26], "well": [25, 26, 29, 40], "21852": [25, 26], "22221": [25, 26], "show": [25, 26], "21709": [25, 26], "21663": [25, 26], "18925": [25, 26], "21530": [25, 26], "21363": [25, 26], "januari": [25, 26], "2022": [25, 26], "delai": [25, 26], "21439": [25, 26], "21494": [25, 26], "20536": [25, 26], "20526": [25, 26], "attr": [25, 26], "20540": [25, 26], "verif": [25, 26], "20550": [25, 26], "19723": [25, 26], "sp": [25, 26], "cloud": [25, 26, 27], "19722": [25, 26], "pat": [25, 26, 27], "password": [25, 26, 27], "19585": [25, 26], "19544": [25, 26], "19412": [25, 26], "aad": [25, 26, 27], "19335": [25, 26], "19443": [25, 26], "db": [25, 26], "__init__": [25, 26], "20180": [25, 26], "fixup": [25, 26], "19099": [25, 26], "expir": [25, 26], "20036": [25, 26], "18339": [25, 26], "optimis": 25, "auto": [25, 26], "apply_default": [25, 26], "15667": [25, 26], "upgrad": [25, 26, 44], "automat": [25, 26, 43], "manual": 25, "migrat": [25, 26], "readm": [25, 26], "chang": [26, 44], "high": 26, "changelog": 26, "08": 26, "365b42f5a1": 26, "8765039214": 26, "27": [26, 28], "1613e9ec1c": 26, "19": 26, "75fb7acbac": 26, "prepar": [26, 44], "aug": 26, "2nd": 26, "wave": 26, "41559": 26, "fcbff15bda": 26, "d23881c648": 26, "1st": 26, "41230": 26, "4535e08b86": 26, "07": [26, 41], "dd10f472c5": 26, "26": 26, "fix": [26, 44], "cfe1d53ed0": 26, "fded2d8969": 26, "13": 26, "dd6ee34775": 26, "11": [26, 29, 33, 39], "40153": 26, "40714": 26, "22ec726063": 26, "09": 26, "09a7bd1d58": 26, "juli": 26, "40644": 26, "4fb2140f39": 26, "02": 26, "a62bd83188": 26, "06": 26, "enforc": 26, "pydocstyl": 26, "rule": [26, 44], "d213": 26, "40448": 26, "de5c751cff": 26, "22": 26, "bug": [26, 44], "6e5ae26382": 26, "june": 26, "40273": 26, "81c331e29a": 26, "17": 26, "a1f9b7de28": 26, "14": [26, 28], "68bd42a7ff": 26, "04": 26, "c0f27094ab": 26, "f0ea079594": 26, "05": 26, "2ecf7fa07d": 26, "34500f3a2f": 26, "3rd": 26, "39738": 26, "f18e6340d8": 26, "21": 26, "1e4663f34c": 26, "2b1a2f8d56": 26, "reappli": 26, "39554": 26, "2c05187b07": 26, "73918925ed": 26, "2d103e115c": 26, "fe4605a10": 26, "39328": 26, "42dbccaac2": 26, "7683344c9c": 26, "ead9b00f7c": 26, "04ac0c1b32": 26, "23": 26, "paramat": 26, "16": 26, "13df6569d6": 26, "rc3": 26, "april": 26, "38995": 26, "39054": 26, "66df296a6e": 26, "629545bea2": 26, "f9dcc82fb6": 26, "rc2": 26, "4a669fb1a9": 26, "5fa80b6aea": 26, "rc1": 26, "38863": 26, "6f21f7dc9b": 26, "4e6d3fa4cf": 26, "39b684d91a": 26, "c74947a69d": 26, "b5b972a106": 26, "18": [26, 33, 41], "yank": 26, "38262": 26, "0a74928894": 26, "38240": 26, "aa75fbb2b8": 26, "restor": 26, "38207": 26, "4742fc0ea5": 26, "15": 26, "8fc984873a": 26, "38070": 26, "83316b8158": 26, "march": 26, "37876": 26, "14d9bff3ad": 26, "24": 26, "37665": 26, "5a0be392e6": 26, "comment": 26, "37488": 26, "e346253760": 26, "bfb054e9e8": 26, "februari": 26, "37326": 26, "78294c24e2": 26, "0c4210af62": 26, "31": 26, "6d748c923b": 26, "dec2662190": 26, "cead3da4a6": 26, "round": 26, "jan": 26, "37019": 26, "0b680c9492": 26, "logger_nam": 26, "36675": 26, "37015": 26, "c0f7601391": 26, "347373986c": 26, "2b4da0101f": 26, "36945": 26, "13b0930bf4": 26, "574102fd29": 26, "c439ab87c4": 26, "build": [26, 29], "hatchl": 26, "36537": 26, "6bd450da1e": 26, "f7b663d9af": 26, "mypi": 26, "full": [26, 32, 39], "ci": 26, "36638": 26, "19ebcac239": 26, "36640": 26, "6937ae7647": 26, "speed": 26, "autocomplet": 26, "breez": 26, "36499": 26, "77b563bfc5": 26, "break": [26, 44], "36382": 26, "b15d5578da": 26, "decemb": 26, "36380": 26, "f5883d6e7b": 26, "36373": 26, "5fe5d31a46": 26, "322aa649": 26, "e9ba37bb58": 26, "64931b1a65": 26, "36190": 26, "36010f6d0e": 26, "999b70178a": 26, "36112": 26, "d0918d77ee": 26, "0b23d5601c": 26, "novemb": 26, "35836": 26, "99534e47f3": 26, "reproduc": 26, "35693": 26, "064fc2b775": 26, "99df205f42": 26, "35686": 26, "1b059c57d6": 26, "35537": 26, "10bac853d2": 26, "28": 26, "d1c58d86de": 26, "octob": 26, "35233": 26, "3592ff4046": 26, "35187": 26, "a8784e3c35": 26, "dd7ba3cae1": 26, "292": 26, "35053": 26, "7a93b19138": 26, "daskexecutor": 26, "inclus": 26, "34935": 26, "e9987d5059": 26, "34916": 26, "946b539f0d": 26, "0c8e30e43b": 26, "7ebf4220c9": 26, "usag": [26, 30, 32, 34, 35, 36, 38, 39], "34320": 26, "a1ef232230": 26, "f26fa6d602": 26, "3813ed69c7": 26, "966c2bce9f": 26, "dfec053371": 26, "21990ed894": 26, "34201": 26, "c45617c4d5": 26, "55976af32": 26, "concatin": 26, "f7a005db8c": 26, "9d8c77e447": 26, "b11525702c": 26, "c90eec9365": 26, "c077d19060": 26, "33730": 26, "dc47c460dc": 26, "4154cc04ce": 26, "2dbb963324": 26, "1cdd82391e": 26, "a91ee7ac2f": 26, "20": 26, "8bf53dd554": 26, "5f8f25b34c": 26, "ecldud": 26, "33311": 26, "b5a4d36383": 26, "33291": 26, "9736143468": 26, "29": 26, "d06b7af69a": 26, "32875": 26, "58e21c66fd": 26, "6313e52932": 26, "60c49ab2df": 26, "225e3041d2": 26, "32381": 26, "3878fe6fab": 26, "spuriou": 26, "32373": 26, "cb4927a018": 26, "32298": 26, "f8593503cb": 26, "6b4350e89c": 26, "d1aa509bbd": 26, "d205": 26, "32243": 26, "09d4718d3a": 26, "32125": 26, "79bcc2e668": 26, "32001": 26, "8b146152d6": 26, "32015": 26, "69bc90b824": 26, "66299338eb": 26, "7b096483fa": 26, "049c6184b7": 26, "9276310a43": 26, "31681": 26, "86b5ba2802": 26, "dc5bf3fd02": 26, "discover": 26, "yaml": 26, "31576": 26, "a59076eae": 26, "d400": 26, "31427": 26, "9fa75aaf7a": 26, "45548b9451": 26, "31416": 26, "abea189022": 26, "31393": 26, "f5aed58d9f": 26, "circular": 26, "caus": 26, "31379": 26, "d9ff55cf6d": 26, "31252": 26, "fdc7a31aeb": 26, "edd7133a13": 26, "3df0be0f6f": 26, "ac46902154": 26, "31033": 26, "0a30706aa7": 26, "airflowproviderdeprecationwarn": 26, "30975": 26, "eef5bc7f16": 26, "autom": 26, "30994": 26, "a7eb32a5b2": 26, "9409446097": 26, "cli": 26, "cmd": 26, "30822": 26, "ecb9a9ea78": 26, "9bebf85e24": 26, "7d02277ae1": 26, "e46ce78b66": 26, "adhoc": 26, "30787": 26, "37cf0506b5": 26, "1e311cf036": 26, "d23a3bbed8": 26, "mechan": 26, "suspend": 26, "30422": 26, "55dbf1ff1f": 26, "30378": 26, "c3867781e0": 26, "29950": 26, "c405ecb63": 26, "25bdbc8e67": 26, "27937": 26, "db5375bea7": 26, "2e20e9f7eb": 26, "relas": 26, "27774": 26, "80c327bd3b": 26, "ea306c9462": 26, "a343bba1e3": 26, "12c3c39d1a": 26, "27613": 26, "00af5c007": 26, "eb06c65556": 26, "9ab1a6a3e7": 26, "style": 26, "26872": 26, "78b8ea2f22": 26, "2a34dc9e84": 26, "27205": 26, "ecd4d6654f": 26, "f8db64c35c": 26, "septemb": 26, "26731": 26, "89e44c46ad": 26, "06acf40a43": 26, "pep": 26, "563": 26, "postpon": 26, "evalu": 26, "26289": 26, "5066844513": 26, "period": 26, "batch02": 26, "25268": 26, "25a9c6a905": 26, "9535ec0bba": 26, "ca9229b6f": 26, "7d0525a55b": 26, "rc4": 26, "25720": 26, "4d32f61fd0": 26, "e5ac6c7cfb": 26, "august": 26, "25618": 26, "52f2f5bfa8": 26, "0255a0a5e7": 26, "679a85325a": 26, "82f842ffc5": 26, "24599": 26, "54a8c4fd2a": 26, "7438707747": 26, "df00436569": 26, "2f70daf5ac": 26, "d2459a241b": 26, "25030": 26, "8dfe7bf5ff": 26, "acaa0635c8": 26, "lazi": 26, "interpol": 26, "24910": 26, "46bbfdade0": 26, "96b01a8012": 26, "bad": 26, "codebas": 26, "24841": 26, "0de31bd73a": 26, "insid": [26, 27], "24672": 26, "510a6bab45": 26, "24702": 26, "ed37c3a0e8": 26, "9c59831ee7": 26, "dcdcf3a2b8": 26, "24307": 26, "717a7588bc": 26, "doubl": 26, "24292": 26, "aeabe994b3": 26, "24231": 26, "027b707d21": 26, "explanatori": 26, "contributor": [26, 27], "24229": 26, "ddf9013098": 26, "aip": 26, "47": 26, "design": [26, 38], "22442": 26, "24203": 26, "acf89510cd": 26, "92ddcf4ac6": 26, "flake8": 26, "implicit": 26, "concat": 26, "23873": 26, "6150d28323": 26, "cf5a78e91c": 26, "d0a5b3a4f2": 26, "75c60923e0": 26, "23631": 26, "428a439953": 26, "23591": 26, "a58506b2a6": 26, "address": 26, "review": 26, "6a3d6cc32b": 26, "7b3bf4e435": 26, "f02b0b6b40": 26, "8b6b0848a3": 26, "brees": 26, "pull": 26, "verifi": [26, 28], "imag": 26, "23104": 26, "40831144be": 26, "22979": 26, "7be57eb256": 26, "aa8c08db38": 26, "6933022e94": 26, "22884": 26, "56ab82ed7a": 26, "mid": 26, "22819": 26, "1b12c93ed3": 26, "95169d1d07": 26, "352d7f72dd": 26, "c063fc688c": 26, "black": 26, "precommit": 26, "22521": 26, "d7dbfb7e26": 26, "bugfix": [26, 44], "22383": 26, "cc920963a6": 26, "16adc035b1": 26, "classifi": 26, "22226": 26, "12e9e2c695": 26, "af9d85ccd8": 26, "4014194320": 26, "f5b96315fe": 26, "feb": 26, "22056": 26, "62bf1276f6": 26, "27d19e7626": 26, "a1845c68f9": 26, "7cca82495b": 26, "0a2d0d1ecb": 26, "d94fa37830": 26, "6c3a67d4fc": 26, "2021": [26, 29], "21257": 26, "602abe8394": 26, "sphinx": 26, "autoapi": 26, "typehint": 26, "20951": 26, "f77417eb0d": 26, "k8": 26, "pypi": [26, 28, 33, 40, 41, 44], "20614": 26, "97496ba2b4": 26, "20523": 26, "0bf424f37f": 26, "20598": 26, "d56e7b56bb": 26, "friendli": 26, "20571": 26, "a0821235fb": 26, "everywher": 26, "20565": 26, "c5c18c54fa": 26, "d3b3161f0d": 26, "58afc19377": 26, "e7659d08b0": 26, "cad39274d9": 26, "20265": 26, "820bfed515": 26, "20205": 26, "66f94f95c2": 26, "545ca59ba9": 26, "unhid": 26, "entri": 26, "20128": 26, "637db1a0ba": 26, "20086": 26, "728e94a47": 26, "19835": 26, "4925b37b66": 26, "853576d901": 26, "19882": 26, "11998848a4": 26, "56bdfe7a84": 26, "244627e3da": 26, "0a4a8bdb94": 26, "8ae878953b": 26, "28b51fb7bd": 26, "3a0c455855": 26, "d9567eb106": 26, "19321": 26, "f5ad26dcdd": 26, "840ea3efb9": 26, "18613": 26, "ef037e7021": 26, "start_dat": 26, "misc": 26, "18597": 26, "0b7b13372f": 26, "0a68588479": 26, "17890": 26, "be75dcd39c": 26, "meta": 26, "76ed2a49c6": 26, "lazili": 26, "17682": 26, "87f408b1e7": 26, "17116": 26, "b916b75079": 26, "17015": 26, "866a601b76": 26, "pylint": 26, "toolchain": 26, "16682": 26, "bbc627a3da": 26, "16501": 26, "cbf8001d76": 26, "synchron": 26, "buggfix": 26, "16464": 26, "1fba5402bb": 26, "16405": 26, "9c94b72d44": 26, "16294": 26, "37681bca00": 26, "807ad32ce5": 26, "pip": [26, 28, 29], "15576": 26, "df143aee8d": 26, "rework": 26, "15444": 26, "49cae1f052": 26, "15410": 26, "68e4c4dcb0": 26, "backport": 26, "14886": 26, "88bdcfa0df": 26, "14013": 26, "ac2f72c98d": 26, "13767": 26, "a9ac2b040b": 26, "flynt": 26, "13732": 26, "3fd5ef3555": 26, "logo": 26, "integr": [26, 27], "13717": 26, "295d66f914": 26, "2020": 26, "grammar": 26, "warn": [26, 29], "13380": 26, "6cf76d7ac0": 26, "13148": 26, "32971a1a2d": 26, "12955": 26, "b40dffa085": 26, "rema": 26, "12917": 26, "9b39f24780": 26, "dynam": 26, "form": 26, "12558": 26, "bd90136aaf": 26, "12681": 26, "c34ef853c8": 26, "12444": 26, "0080354502": 26, "0b2": 26, "12449": 26, "7ca0b6f121": 26, "markdownlint": 26, "md003": 26, "head": 26, "12427": 26, "12438": 26, "ae7cb4a1e2": 26, "wrong": 26, "hash": 26, "12390": 26, "6889a333cf": 26, "ref": 26, "12366": 26, "7825e8f590": 26, "12304": 26, "b027223132": 26, "12316": 26, "85a18e13d9": 26, "project": [26, 39], "cross": 26, "12212": 26, "59eb5de78c": 26, "come": 26, "0beta1": 26, "12206": 26, "b2a28d1590": 26, "12082": 26, "7e0d08e1f0": 26, "12175": 26, "4e8f9cc8d0": 26, "formmatt": 26, "9550": 26, "8c42cf1b00": 26, "pyupgrad": 26, "11447": 26, "5a439e84eb": 26, "2a1": 26, "11855": 26, "872b1566a1": 26, "setup": [26, 38], "11826": 26, "349b0811c3": 26, "d200": 26, "11688": 26, "16e7129719": 26, "11487": 26, "0a0e1af800": 26, "markdown": 26, "toc": 26, "11249": 26, "ca4238eb4d": 26, "month": 26, "11242": 26, "5220e4c384": 26, "11238": 26, "54353f8745": 26, "increas": 26, "coverag": 26, "five": 26, "differ": [26, 27, 29], "11170": 26, "966a06d96b": 26, "fetch": 26, "suppli": [26, 38], "10762": 26, "9549274d11": 26, "8b1": 26, "10818": 26, "fdd9b6f65b": 26, "10543": 26, "bfefcce0c9": 26, "rest": [26, 32, 39], "10462": 26, "3696c34c28": 26, "word": 26, "10528": 26, "2f2d8dbfaf": 26, "noinspect": 26, "nativ": 26, "intellij": 26, "10525": 26, "ee7ca128a1": 26, "refernc": 26, "10483": 26, "cdec301254": 26, "10205": 26, "7d24b088cd": 26, "example_dag": 26, "9985": 26, "e13a14c873": 26, "whitespac": 26, "9458": 26, "d0e7db4024": 26, "fresh": 26, "9408": 26, "12af6a0800": 26, "23rc1": 26, "9404": 26, "c7e5bce57f": 26, "candid": 26, "9370": 26, "f6bd817a3a": 26, "transfer": 26, "9320": 26, "0b0e4f7a4c": 26, "9026": 26, "00642a46d0": 26, "wrongli": 26, "8994": 26, "f1073381ed": 26, "8846": 26, "375d1ca229": 26, "8898": 26, "12c5e5d8a": 26, "8891": 26, "f3521fb0e3": 26, "regener": 26, "8886": 26, "92585ca4cb": 26, "8807": 26, "649935e8c": 26, "8472": 26, "_do_api_cal": 26, "8473": 26, "16903ba3a6": 26, "8474": 26, "8475": 26, "5648dfbc30": 26, "super": 26, "amazon": 26, "cloudant": 26, "7827": 26, "3320e432a1": 26, "6817": 26, "keep": [26, 41], "face": 26, "untouch": 26, "7517": 26, "4d03e33c11": 26, "explicit": 26, "md": 26, "squash": 26, "rebas": 26, "7456": 26, "97a429f9d0": 26, "6714": 26, "magic": 26, "utf": 26, "7338": 26, "83c037873f": 26, "6674": [26, 29], "accord": 26, "7287": 26, "c42a375e79": 26, "6644": 26, "7265": 26, "sever": 27, "person": 27, "recommend": [27, 29, 41], "login": 27, "usernam": 27, "account": [27, 30, 43], "discourag": 27, "secret": 27, "outsid": [27, 41, 43], "owner": [27, 29], "vm": 27, "assign": 27, "sent": 27, "basic": 27, "plan": 27, "httpoper": 27, "aw": 27, "secur": 27, "necessari": 27, "service_principal_oauth": 27, "client": 27, "azure_tenant_id": 27, "tenant": 27, "resourc": 27, "isn": [27, 35, 36, 37], "special": [27, 38], "govcloud": 27, "china": 27, "germani": 27, "protocol": 27, "microsoftonlin": 27, "de": 27, "uri": [27, 30], "syntax": 27, "export": 27, "airflow_conn_databricks_default": 27, "yourtoken": 27, "8": [28, 33, 39], "4": 28, "mergedeep": 28, "python_vers": 28, "pyarrow": 28, "checksum": [28, 29], "site": 28, "sdist": [28, 29], "asc": [28, 29], "sha512": [28, 29], "download": 29, "offici": 29, "choos": 29, "down": 29, "left": 29, "whl": 29, "origin": 29, "softwar": 29, "foundat": 29, "pgp": 29, "essenti": 29, "sha": 29, "gpg": 29, "relev": [29, 43], "distribut": 29, "mirror": 29, "pgpk": 29, "ka": 29, "binari": 29, "pgpv": 29, "tar": 29, "gz": 29, "made": 29, "sat": 29, "sep": 29, "49": 29, "54": 29, "bst": 29, "rsa": 29, "cde15c6e4d3a8ec4ecf4ba4b6674e08ad7de406f": 29, "issuer": 29, "kaxilnaik": 29, "good": [29, 44], "kaxil": 29, "naik": 29, "aka": 29, "gmail": 29, "certifi": 29, "trust": 29, "indic": 29, "belong": 29, "primari": 29, "fingerprint": 29, "cde1": 29, "5c6e": 29, "4d3a": 29, "8ec4": 29, "ecf4": 29, "ba4b": 29, "e08a": 29, "d7de": 29, "406f": 29, "worri": 29, "certif": 29, "sign": 29, "server": 29, "previou": 29, "step": 29, "know": 29, "sum": 29, "shasum": 29, "512": 29, "diff": 29, "bin": [29, 33], "bash": 29, "package_vers": 29, "package_nam": 29, "provider_download_dir": 29, "mktemp": 29, "d": [29, 41], "dep": 29, "dest": 29, "curl": 29, "apache_airflow_providers_databrick": 29, "py3": 29, "l": 29, "o": 29, "echo": 29, "la": 29, "onc": 29, "instruct": [29, 44], "chapter": 29, "temporari": 29, "One": [30, 38], "copy_into": 30, "import_csv": 30, "my_tabl": 30, "abfss": 30, "df": 30, "my": 30, "past": 32, "rememb": 32, "repeat": 32, "rather": 32, "ones": 32, "fall": 32, "With": [32, 39, 41], "over": [32, 39], "underli": [32, 39], "harder": [32, 39], "lack": [32, 39], "task_kei": 32, "spark_vers": [32, 33, 39], "7": 32, "scala2": [32, 33, 39], "node_type_id": [32, 33, 39], "i3": [32, 33], "xlarg": [32, 33, 39], "num_work": [32, 33, 39], "jobs_create_json": 32, "jobs_create_nam": 32, "return_valu": 32, "ti": 32, "xcom_pul": 32, "new_cluster_spec": 33, "cluster_nam": 33, "aws_attribut": [33, 39], "first_on_demand": 33, "spot_with_fallback": 33, "zone_id": 33, "u": 33, "east": 33, "2b": 33, "spot_bid_price_perc": 33, "ebs_volume_count": 33, "spark_env_var": 33, "pyspark_python": 33, "python3": 33, "enable_elastic_disk": 33, "data_security_mod": 33, "legacy_single_user_standard": 33, "runtime_engin": 33, "notebook_1": [33, 40, 41], "simplejson": [33, 40, 41], "simpl": [33, 38, 41], "faker": [33, 40, 41], "notebook_2": [33, 41], "input": [34, 35, 36], "user_email": [34, 35, 36], "repo_nam": [34, 35, 36], "decim": [34, 35, 36], "usual": 36, "worker": [37, 39], "extens": 38, "new_lin": 38, "select_data": 38, "my_airflow_t": 38, "select_into_fil": 38, "select_data_into_fil": 38, "tmp": 38, "perform": 38, "create_and_populate_t": 38, "create_fil": 38, "create_and_populate_from_fil": 38, "starter": 38, "sql_sensor": 38, "hive_metastor": 38, "sql_sensor_task": 38, "temp": 38, "sample_table_3": 38, "60": 38, "someth": 38, "occur": 38, "happen": 38, "succe": 38, "arriv": 38, "interv": 38, "poke_interv": 38, "rang": 38, "partition_nam": 38, "partition_valu": 38, "partition_sensor": 38, "partition_sensor_task": 38, "sample_table_2": 38, "db3": 39, "preparedata": 39, "here": [39, 41], "invok": 39, "r3": 39, "on_demand": 39, "notebook_task_param": 39, "main_class_nam": 39, "processdata": 39, "lib": 39, "etl": 39, "standalon": 40, "task_operator_nb_1": [40, 41], "nb_1": [40, 41], "shared_job_clust": [40, 41], "task_operator_sql_queri": 40, "sql_queri": [40, 41], "sql_task": [40, 41], "75": 41, "cost": 41, "reduct": 41, "40": 41, "dbu": 41, "comput": 41, "compar": 41, "few": 41, "author": 41, "interfac": 41, "web": 41, "price": 41, "begin": 41, "test_workflow_": 41, "pin": 41, "index": 41, "on_start": 41, "workflow_notebook_1": 41, "timedelta": 41, "600": 41, "workflow_notebook_2": 41, "foo": 41, "bar": 41, "dag_nam": 41, "minim": 41, "enhanc": 43, "addition": 43, "offer": 43, "At": 43, "henc": 43, "ideal": 43, "prevent": 43, "embed": 43, "independ": 44, "itself": 44, "vulner": 44, "publish": 44, "develop": 44, "alwai": 44, "next": 44, "strict": 44, "semver": 44, "scope": 44, "major": 44, "minor": 44, "patchlevel": 44, "critic": 44, "band": 44, "stakehold": 44, "decid": 44, "cherri": 44, "pick": 44, "older": 44, "mix": 44, "govern": 44, "interest": 44, "parti": 44}, "objects": {"airflow.providers": [[4, 0, 0, "-", "databricks"]], "airflow.providers.databricks": [[4, 1, 1, "", "__version__"], [3, 0, 0, "-", "hooks"], [9, 0, 0, "-", "operators"], [11, 0, 0, "-", "plugins"], [14, 0, 0, "-", "sensors"], [16, 0, 0, "-", "triggers"], [18, 0, 0, "-", "utils"]], "airflow.providers.databricks.hooks": [[0, 0, 0, "-", "databricks"], [1, 0, 0, "-", "databricks_base"], [2, 0, 0, "-", "databricks_sql"]], "airflow.providers.databricks.hooks.databricks": [[0, 1, 1, "", "CANCEL_ALL_RUNS_ENDPOINT"], [0, 1, 1, "", "CANCEL_RUN_ENDPOINT"], [0, 1, 1, "", "CREATE_ENDPOINT"], [0, 2, 1, "", "ClusterState"], [0, 1, 1, "", "DELETE_RUN_ENDPOINT"], [0, 2, 1, "", "DatabricksHook"], [0, 1, 1, "", "GET_CLUSTER_ENDPOINT"], [0, 1, 1, "", "GET_RUN_ENDPOINT"], [0, 1, 1, "", "INSTALL_LIBS_ENDPOINT"], [0, 1, 1, "", "LIST_JOBS_ENDPOINT"], [0, 1, 1, "", "LIST_PIPELINES_ENDPOINT"], [0, 1, 1, "", "OUTPUT_RUNS_JOB_ENDPOINT"], [0, 1, 1, "", "REPAIR_RUN_ENDPOINT"], [0, 1, 1, "", "RESET_ENDPOINT"], [0, 1, 1, "", "RESTART_CLUSTER_ENDPOINT"], [0, 1, 1, "", "RUN_NOW_ENDPOINT"], [0, 2, 1, "", "RunLifeCycleState"], [0, 2, 1, "", "RunState"], [0, 1, 1, "", "SPARK_VERSIONS_ENDPOINT"], [0, 1, 1, "", "START_CLUSTER_ENDPOINT"], [0, 1, 1, "", "SUBMIT_RUN_ENDPOINT"], [0, 1, 1, "", "TERMINATE_CLUSTER_ENDPOINT"], [0, 1, 1, "", "UNINSTALL_LIBS_ENDPOINT"], [0, 1, 1, "", "UPDATE_ENDPOINT"], [0, 1, 1, "", "WORKSPACE_GET_STATUS_ENDPOINT"]], "airflow.providers.databricks.hooks.databricks.ClusterState": [[0, 3, 1, "", "CLUSTER_LIFE_CYCLE_STATES"], [0, 4, 1, "", "__eq__"], [0, 4, 1, "", "__repr__"], [0, 4, 1, "", "from_json"], [0, 5, 1, "", "is_running"], [0, 5, 1, "", "is_terminal"], [0, 4, 1, "", "to_json"]], "airflow.providers.databricks.hooks.databricks.DatabricksHook": [[0, 4, 1, "", "a_get_cluster_state"], [0, 4, 1, "", "a_get_run"], [0, 4, 1, "", "a_get_run_output"], [0, 4, 1, "", "a_get_run_page_url"], [0, 4, 1, "", "a_get_run_state"], [0, 4, 1, "", "cancel_all_runs"], [0, 4, 1, "", "cancel_run"], [0, 4, 1, "", "create_job"], [0, 4, 1, "", "create_repo"], [0, 4, 1, "", "delete_repo"], [0, 4, 1, "", "delete_run"], [0, 4, 1, "", "find_job_id_by_name"], [0, 4, 1, "", "find_pipeline_id_by_name"], [0, 4, 1, "", "get_cluster_state"], [0, 4, 1, "", "get_job_id"], [0, 4, 1, "", "get_latest_repair_id"], [0, 4, 1, "", "get_repo_by_path"], [0, 4, 1, "", "get_run"], [0, 4, 1, "", "get_run_output"], [0, 4, 1, "", "get_run_page_url"], [0, 4, 1, "", "get_run_state"], [0, 4, 1, "", "get_run_state_lifecycle"], [0, 4, 1, "", "get_run_state_message"], [0, 4, 1, "", "get_run_state_result"], [0, 4, 1, "", "get_run_state_str"], [0, 3, 1, "", "hook_name"], [0, 4, 1, "", "install"], [0, 4, 1, "", "list_jobs"], [0, 4, 1, "", "list_pipelines"], [0, 4, 1, "", "repair_run"], [0, 4, 1, "", "reset_job"], [0, 4, 1, "", "restart_cluster"], [0, 4, 1, "", "run_now"], [0, 4, 1, "", "start_cluster"], [0, 4, 1, "", "submit_run"], [0, 4, 1, "", "terminate_cluster"], [0, 4, 1, "", "test_connection"], [0, 4, 1, "", "uninstall"], [0, 4, 1, "", "update_job"], [0, 4, 1, "", "update_job_permission"], [0, 4, 1, "", "update_repo"]], "airflow.providers.databricks.hooks.databricks.RunLifeCycleState": [[0, 3, 1, "", "BLOCKED"], [0, 3, 1, "", "INTERNAL_ERROR"], [0, 3, 1, "", "PENDING"], [0, 3, 1, "", "QUEUED"], [0, 3, 1, "", "RUNNING"], [0, 3, 1, "", "SKIPPED"], [0, 3, 1, "", "TERMINATED"], [0, 3, 1, "", "TERMINATING"], [0, 3, 1, "", "WAITING_FOR_RETRY"]], "airflow.providers.databricks.hooks.databricks.RunState": [[0, 3, 1, "", "RUN_LIFE_CYCLE_STATES"], [0, 4, 1, "", "__eq__"], [0, 4, 1, "", "__repr__"], [0, 4, 1, "", "from_json"], [0, 5, 1, "", "is_successful"], [0, 5, 1, "", "is_terminal"], [0, 4, 1, "", "to_json"]], "airflow.providers.databricks.hooks.databricks_base": [[1, 1, 1, "", "AZURE_MANAGEMENT_ENDPOINT"], [1, 1, 1, "", "AZURE_METADATA_SERVICE_INSTANCE_URL"], [1, 1, 1, "", "AZURE_METADATA_SERVICE_TOKEN_URL"], [1, 2, 1, "", "BaseDatabricksHook"], [1, 2, 1, "", "BearerAuth"], [1, 1, 1, "", "DEFAULT_DATABRICKS_SCOPE"], [1, 1, 1, "", "OIDC_TOKEN_SERVICE_URL"], [1, 1, 1, "", "TOKEN_REFRESH_LEAD_TIME"]], "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook": [[1, 4, 1, "", "__aenter__"], [1, 4, 1, "", "__aexit__"], [1, 3, 1, "", "conn_name_attr"], [1, 3, 1, "", "conn_type"], [1, 4, 1, "", "databricks_conn"], [1, 3, 1, "", "default_conn_name"], [1, 3, 1, "", "extra_parameters"], [1, 4, 1, "", "get_conn"], [1, 4, 1, "", "host"], [1, 4, 1, "", "user_agent_header"], [1, 4, 1, "", "user_agent_value"]], "airflow.providers.databricks.hooks.databricks_base.BearerAuth": [[1, 4, 1, "", "encode"]], "airflow.providers.databricks.hooks.databricks_sql": [[2, 2, 1, "", "DatabricksSqlHook"], [2, 1, 1, "", "LIST_SQL_ENDPOINTS_ENDPOINT"], [2, 1, 1, "", "T"]], "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook": [[2, 4, 1, "", "bulk_dump"], [2, 4, 1, "", "bulk_load"], [2, 4, 1, "", "get_conn"], [2, 3, 1, "", "hook_name"], [2, 4, 1, "", "run"]], "airflow.providers.databricks.operators": [[5, 0, 0, "-", "databricks"], [6, 0, 0, "-", "databricks_repos"], [7, 0, 0, "-", "databricks_sql"], [8, 0, 0, "-", "databricks_workflow"]], "airflow.providers.databricks.operators.databricks": [[5, 1, 1, "", "DEFER_METHOD_NAME"], [5, 2, 1, "", "DatabricksCreateJobsOperator"], [5, 2, 1, "", "DatabricksJobRunLink"], [5, 2, 1, "", "DatabricksNotebookOperator"], [5, 2, 1, "", "DatabricksRunNowDeferrableOperator"], [5, 2, 1, "", "DatabricksRunNowOperator"], [5, 2, 1, "", "DatabricksSubmitRunDeferrableOperator"], [5, 2, 1, "", "DatabricksSubmitRunOperator"], [5, 2, 1, "", "DatabricksTaskBaseOperator"], [5, 2, 1, "", "DatabricksTaskOperator"], [5, 1, 1, "", "XCOM_JOB_ID_KEY"], [5, 1, 1, "", "XCOM_RUN_ID_KEY"], [5, 1, 1, "", "XCOM_RUN_PAGE_URL_KEY"], [5, 6, 1, "", "is_repair_reason_match_exist"], [5, 6, 1, "", "update_job_for_repair"]], "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator": [[5, 4, 1, "", "execute"], [5, 3, 1, "", "template_fields"], [5, 3, 1, "", "ui_color"], [5, 3, 1, "", "ui_fgcolor"]], "airflow.providers.databricks.operators.databricks.DatabricksJobRunLink": [[5, 4, 1, "", "get_link"], [5, 3, 1, "", "name"]], "airflow.providers.databricks.operators.databricks.DatabricksNotebookOperator": [[5, 3, 1, "", "CALLER"], [5, 3, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator": [[5, 4, 1, "", "execute"], [5, 4, 1, "", "execute_complete"], [5, 4, 1, "", "on_kill"], [5, 3, 1, "", "operator_extra_links"], [5, 3, 1, "", "template_ext"], [5, 3, 1, "", "template_fields"], [5, 3, 1, "", "ui_color"], [5, 3, 1, "", "ui_fgcolor"]], "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunDeferrableOperator": [[5, 4, 1, "", "execute"]], "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator": [[5, 4, 1, "", "execute"], [5, 4, 1, "", "execute_complete"], [5, 4, 1, "", "on_kill"], [5, 3, 1, "", "operator_extra_links"], [5, 3, 1, "", "template_ext"], [5, 3, 1, "", "template_fields"], [5, 3, 1, "", "ui_color"], [5, 3, 1, "", "ui_fgcolor"]], "airflow.providers.databricks.operators.databricks.DatabricksTaskBaseOperator": [[5, 4, 1, "", "execute"], [5, 4, 1, "", "execute_complete"], [5, 4, 1, "", "monitor_databricks_job"]], "airflow.providers.databricks.operators.databricks.DatabricksTaskOperator": [[5, 3, 1, "", "CALLER"], [5, 3, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_repos": [[6, 2, 1, "", "DatabricksReposCreateOperator"], [6, 2, 1, "", "DatabricksReposDeleteOperator"], [6, 2, 1, "", "DatabricksReposUpdateOperator"]], "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator": [[6, 3, 1, "", "__aws_code_commit_regexp__"], [6, 4, 1, "", "__detect_repo_provider__"], [6, 3, 1, "", "__git_providers__"], [6, 3, 1, "", "__repos_path_regexp__"], [6, 4, 1, "", "execute"], [6, 3, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_repos.DatabricksReposDeleteOperator": [[6, 4, 1, "", "execute"], [6, 3, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_repos.DatabricksReposUpdateOperator": [[6, 4, 1, "", "execute"], [6, 3, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_sql": [[7, 1, 1, "", "COPY_INTO_APPROVED_FORMATS"], [7, 2, 1, "", "DatabricksCopyIntoOperator"], [7, 2, 1, "", "DatabricksSqlOperator"]], "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator": [[7, 4, 1, "", "execute"], [7, 3, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator": [[7, 3, 1, "", "conn_id_field"], [7, 4, 1, "", "get_db_hook"], [7, 3, 1, "", "template_ext"], [7, 3, 1, "", "template_fields"], [7, 3, 1, "", "template_fields_renderers"]], "airflow.providers.databricks.operators.databricks_workflow": [[8, 2, 1, "", "DatabricksWorkflowTaskGroup"], [8, 2, 1, "", "WorkflowRunMetadata"]], "airflow.providers.databricks.operators.databricks_workflow.DatabricksWorkflowTaskGroup": [[8, 4, 1, "", "__exit__"], [8, 3, 1, "", "is_databricks"]], "airflow.providers.databricks.operators.databricks_workflow.WorkflowRunMetadata": [[8, 3, 1, "", "conn_id"], [8, 3, 1, "", "job_id"], [8, 3, 1, "", "run_id"]], "airflow.providers.databricks.plugins": [[10, 0, 0, "-", "databricks_workflow"]], "airflow.providers.databricks.plugins.databricks_workflow": [[10, 2, 1, "", "DatabricksWorkflowPlugin"], [10, 1, 1, "", "REPAIR_WAIT_ATTEMPTS"], [10, 1, 1, "", "REPAIR_WAIT_DELAY"], [10, 2, 1, "", "RepairDatabricksTasks"], [10, 2, 1, "", "WorkflowJobRepairAllFailedLink"], [10, 2, 1, "", "WorkflowJobRepairSingleTaskLink"], [10, 2, 1, "", "WorkflowJobRunLink"], [10, 1, 1, "", "airflow_app"], [10, 6, 1, "", "get_auth_decorator"], [10, 6, 1, "", "get_databricks_task_ids"], [10, 6, 1, "", "get_launch_task_id"], [10, 6, 1, "", "get_task_instance"], [10, 6, 1, "", "get_xcom_result"], [10, 1, 1, "", "repair_databricks_package"], [10, 1, 1, "", "repair_databricks_view"]], "airflow.providers.databricks.plugins.databricks_workflow.DatabricksWorkflowPlugin": [[10, 3, 1, "", "appbuilder_views"], [10, 3, 1, "", "name"], [10, 3, 1, "", "operator_extra_links"]], "airflow.providers.databricks.plugins.databricks_workflow.RepairDatabricksTasks": [[10, 3, 1, "", "default_view"], [10, 4, 1, "", "repair"]], "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairAllFailedLink": [[10, 4, 1, "", "get_link"], [10, 4, 1, "", "get_task_group_children"], [10, 4, 1, "", "get_tasks_to_run"], [10, 3, 1, "", "name"]], "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairSingleTaskLink": [[10, 4, 1, "", "get_link"], [10, 3, 1, "", "name"]], "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRunLink": [[10, 4, 1, "", "get_link"], [10, 3, 1, "", "name"]], "airflow.providers.databricks.sensors": [[12, 0, 0, "-", "databricks_partition"], [13, 0, 0, "-", "databricks_sql"]], "airflow.providers.databricks.sensors.databricks_partition": [[12, 2, 1, "", "DatabricksPartitionSensor"]], "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor": [[12, 4, 1, "", "poke"], [12, 3, 1, "", "template_ext"], [12, 3, 1, "", "template_fields"], [12, 3, 1, "", "template_fields_renderers"]], "airflow.providers.databricks.sensors.databricks_sql": [[13, 2, 1, "", "DatabricksSqlSensor"]], "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor": [[13, 4, 1, "", "hook"], [13, 4, 1, "", "poke"], [13, 3, 1, "", "template_ext"], [13, 3, 1, "", "template_fields"], [13, 3, 1, "", "template_fields_renderers"]], "airflow.providers.databricks.triggers": [[15, 0, 0, "-", "databricks"]], "airflow.providers.databricks.triggers.databricks": [[15, 2, 1, "", "DatabricksExecutionTrigger"]], "airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger": [[15, 4, 1, "", "run"], [15, 4, 1, "", "serialize"]], "airflow.providers.databricks.utils": [[17, 0, 0, "-", "databricks"]], "airflow.providers.databricks.utils.databricks": [[17, 6, 1, "", "normalise_json_content"], [17, 6, 1, "", "validate_trigger_event"]], "tests.system.providers": [[24, 0, 0, "-", "databricks"]], "tests.system.providers.databricks": [[19, 0, 0, "-", "example_databricks"], [20, 0, 0, "-", "example_databricks_repos"], [21, 0, 0, "-", "example_databricks_sensors"], [22, 0, 0, "-", "example_databricks_sql"], [23, 0, 0, "-", "example_databricks_workflow"]], "tests.system.providers.databricks.example_databricks": [[19, 1, 1, "", "DAG_ID"], [19, 1, 1, "", "ENV_ID"], [19, 1, 1, "", "QUERY_ID"], [19, 1, 1, "", "WAREHOUSE_ID"], [19, 1, 1, "", "job"], [19, 1, 1, "", "test_run"]], "tests.system.providers.databricks.example_databricks_repos": [[20, 1, 1, "", "DAG_ID"], [20, 1, 1, "", "ENV_ID"], [20, 1, 1, "", "default_args"], [20, 1, 1, "", "repo_path"], [20, 1, 1, "", "test_run"]], "tests.system.providers.databricks.example_databricks_sensors": [[21, 1, 1, "", "DAG_ID"], [21, 1, 1, "", "ENV_ID"], [21, 1, 1, "", "connection_id"], [21, 1, 1, "", "test_run"]], "tests.system.providers.databricks.example_databricks_sql": [[22, 1, 1, "", "DAG_ID"], [22, 1, 1, "", "ENV_ID"], [22, 1, 1, "", "connection_id"], [22, 1, 1, "", "test_run"]], "tests.system.providers.databricks.example_databricks_workflow": [[23, 1, 1, "", "DATABRICKS_CONN_ID"], [23, 1, 1, "", "DATABRICKS_NOTIFICATION_EMAIL"], [23, 1, 1, "", "EXECUTION_TIMEOUT"], [23, 1, 1, "", "GROUP_ID"], [23, 1, 1, "", "QUERY_ID"], [23, 1, 1, "", "USER"], [23, 1, 1, "", "WAREHOUSE_ID"], [23, 1, 1, "", "dag"], [23, 1, 1, "", "job_cluster_spec"], [23, 1, 1, "", "task_group"], [23, 1, 1, "", "test_run"]]}, "objtypes": {"0": "py:module", "1": "py:data", "2": "py:class", "3": "py:attribute", "4": "py:method", "5": "py:property", "6": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "data", "Python data"], "2": ["py", "class", "Python class"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "method", "Python method"], "5": ["py", "property", "Python property"], "6": ["py", "function", "Python function"]}, "titleterms": {"airflow": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 26, 28, 41], "provid": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 41], "databrick": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 31, 33, 34, 35, 36, 40, 41, 42], "hook": [0, 1, 2, 3], "modul": [0, 1, 2, 5, 6, 7, 8, 10, 12, 13, 15, 17, 19, 20, 21, 22, 23], "content": [0, 1, 2, 4, 5, 6, 7, 8, 10, 12, 13, 15, 17, 19, 20, 21, 22, 23], "class": [0, 1, 2, 5, 6, 7, 8, 10, 12, 13, 15], "attribut": [0, 1, 2, 5, 7, 10], "databricks_bas": 1, "databricks_sql": [2, 7, 13], "submodul": [3, 9, 11, 14, 16, 18, 24], "subpackag": 4, "packag": [4, 26, 28, 29], "oper": [5, 6, 7, 8, 9, 30, 31, 32, 34, 35, 36, 37, 38, 39], "function": [5, 10, 17], "databricks_repo": 6, "databricks_workflow": [8, 10], "plugin": [10, 11, 42], "sensor": [12, 13, 14, 38], "databricks_partit": 12, "trigger": [15, 16, 41], "util": [17, 18], "test": [19, 20, 21, 22, 23, 24], "system": [19, 20, 21, 22, 23, 24], "example_databrick": 19, "example_databricks_repo": 20, "example_databricks_sensor": 21, "example_databricks_sql": 22, "example_databricks_workflow": 23, "changelog": 25, "6": [25, 26], "10": [25, 26], "0": [25, 26], "featur": [25, 43], "misc": 25, "9": [25, 26], "8": [25, 26], "bug": 25, "fix": 25, "7": [25, 26], "5": [25, 26], "4": [25, 26], "3": [25, 26], "2": [25, 26], "1": [25, 26], "break": 25, "chang": 25, "yank": 25, "apach": [26, 28], "connect": 27, "authent": 27, "default": 27, "id": 27, "configur": 27, "instal": [28, 29], "requir": 28, "cross": 28, "depend": 28, "download": 28, "offici": 28, "from": [29, 38, 41], "sourc": 29, "releas": [29, 44], "integr": 29, "verifi": 29, "pypi": 29, "databrickscopyintooper": 30, "us": [30, 32, 34, 35, 36, 37, 38, 39, 40], "exampl": [30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43], "import": 30, "csv": 30, "data": [30, 38], "databrickscreatejobsoper": 32, "specifi": [32, 35, 36, 39], "paramet": [32, 39], "json": [32, 39], "name": [32, 39], "pair": 32, "databricksrunnowoper": [32, 37], "databricksnotebookoper": 33, "run": [33, 40, 41], "notebook": [33, 40], "new": 33, "cluster": 33, "an": 33, "exist": 33, "databricksreposcreateoper": 34, "creat": 34, "repo": [34, 35, 36], "databricksreposdeleteoper": 35, "delet": 35, "path": [35, 36], "databricksreposupdateoper": 36, "updat": 36, "databricksrunnowdeferrableoper": 37, "databrickssqloper": 38, "select": 38, "file": 38, "execut": 38, "multipl": 38, "statement": 38, "databrickssqlsensor": 38, "databrickspartitionsensor": 38, "databrickssubmitrunoper": 39, "databrickssubmitrundeferrableoper": 39, "databrickstaskoper": 40, "sql": 40, "queri": 40, "databricksworkflowtaskgroup": 41, "what": 41, "dag": 41, "look": 41, "like": 41, "The": 41, "follow": 41, "imag": 41, "displai": 41, "result": 41, "workflow": 41, "ui": 41, "base": 41, "abov": 41, "correspond": 41, "i": 41, "depict": 41, "below": 41, "databricksworkflowplugin": 43, "overview": 43, "note": 43, "usag": 43, "secur": 44, "patch": 44}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"airflow.providers.databricks.hooks.databricks": [[0, "module-airflow.providers.databricks.hooks.databricks"]], "Module Contents": [[0, "module-contents"], [1, "module-contents"], [2, "module-contents"], [5, "module-contents"], [6, "module-contents"], [7, "module-contents"], [8, "module-contents"], [10, "module-contents"], [12, "module-contents"], [13, "module-contents"], [15, "module-contents"], [17, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"]], "Classes": [[0, "classes"], [1, "classes"], [2, "classes"], [5, "classes"], [6, "classes"], [7, "classes"], [8, "classes"], [10, "classes"], [12, "classes"], [13, "classes"], [15, "classes"]], "Attributes": [[0, "attributes"], [1, "attributes"], [2, "attributes"], [5, "attributes"], [7, "attributes"], [10, "attributes"]], "airflow.providers.databricks.hooks.databricks_base": [[1, "module-airflow.providers.databricks.hooks.databricks_base"]], "airflow.providers.databricks.hooks.databricks_sql": [[2, "module-airflow.providers.databricks.hooks.databricks_sql"]], "airflow.providers.databricks.hooks": [[3, "module-airflow.providers.databricks.hooks"]], "Submodules": [[3, "submodules"], [9, "submodules"], [11, "submodules"], [14, "submodules"], [16, "submodules"], [18, "submodules"], [24, "submodules"]], "airflow.providers.databricks": [[4, "module-airflow.providers.databricks"]], "Subpackages": [[4, "subpackages"]], "Package Contents": [[4, "package-contents"]], "airflow.providers.databricks.operators.databricks": [[5, "module-airflow.providers.databricks.operators.databricks"]], "Functions": [[5, "functions"], [10, "functions"], [17, "functions"]], "airflow.providers.databricks.operators.databricks_repos": [[6, "module-airflow.providers.databricks.operators.databricks_repos"]], "airflow.providers.databricks.operators.databricks_sql": [[7, "module-airflow.providers.databricks.operators.databricks_sql"]], "airflow.providers.databricks.operators.databricks_workflow": [[8, "module-airflow.providers.databricks.operators.databricks_workflow"]], "airflow.providers.databricks.operators": [[9, "module-airflow.providers.databricks.operators"]], "airflow.providers.databricks.plugins.databricks_workflow": [[10, "module-airflow.providers.databricks.plugins.databricks_workflow"]], "airflow.providers.databricks.plugins": [[11, "module-airflow.providers.databricks.plugins"]], "airflow.providers.databricks.sensors.databricks_partition": [[12, "module-airflow.providers.databricks.sensors.databricks_partition"]], "airflow.providers.databricks.sensors.databricks_sql": [[13, "module-airflow.providers.databricks.sensors.databricks_sql"]], "airflow.providers.databricks.sensors": [[14, "module-airflow.providers.databricks.sensors"]], "airflow.providers.databricks.triggers.databricks": [[15, "module-airflow.providers.databricks.triggers.databricks"]], "airflow.providers.databricks.triggers": [[16, "module-airflow.providers.databricks.triggers"]], "airflow.providers.databricks.utils.databricks": [[17, "module-airflow.providers.databricks.utils.databricks"]], "airflow.providers.databricks.utils": [[18, "module-airflow.providers.databricks.utils"]], "tests.system.providers.databricks.example_databricks": [[19, "module-tests.system.providers.databricks.example_databricks"]], "tests.system.providers.databricks.example_databricks_repos": [[20, "module-tests.system.providers.databricks.example_databricks_repos"]], "tests.system.providers.databricks.example_databricks_sensors": [[21, "module-tests.system.providers.databricks.example_databricks_sensors"]], "tests.system.providers.databricks.example_databricks_sql": [[22, "module-tests.system.providers.databricks.example_databricks_sql"]], "tests.system.providers.databricks.example_databricks_workflow": [[23, "module-tests.system.providers.databricks.example_databricks_workflow"]], "tests.system.providers.databricks": [[24, "module-tests.system.providers.databricks"]], "Changelog": [[25, "changelog"]], "6.10.0": [[25, "id1"], [26, "id1"]], "Features": [[25, "features"], [25, "id5"], [25, "id8"], [25, "id11"], [25, "id15"], [25, "id20"], [25, "id23"], [25, "id27"], [25, "id30"], [25, "id40"], [25, "id43"], [25, "id47"], [25, "id50"], [25, "id61"], [25, "id66"], [25, "id69"], [25, "id78"], [25, "id80"], [25, "id84"], [25, "id87"], [25, "id92"], [25, "id95"], [25, "id97"], [25, "id101"], [25, "id104"], [25, "id107"], [25, "id111"], [25, "id113"], [43, "features"]], "Misc": [[25, "misc"], [25, "id3"], [25, "id6"], [25, "id13"], [25, "id17"], [25, "id21"], [25, "id25"], [25, "id28"], [25, "id35"], [25, "id36"], [25, "id45"], [25, "id48"], [25, "id51"], [25, "id53"], [25, "id56"], [25, "id59"], [25, "id63"], [25, "id67"], [25, "id77"], [25, "id81"], [25, "id99"], [25, "id105"], [25, "id109"], [25, "id118"]], "6.9.0": [[25, "id2"], [26, "id3"]], "6.8.0": [[25, "id4"], [26, "id4"]], "Bug Fixes": [[25, "bug-fixes"], [25, "id9"], [25, "id12"], [25, "id16"], [25, "id24"], [25, "id31"], [25, "id34"], [25, "id44"], [25, "id55"], [25, "id58"], [25, "id62"], [25, "id71"], [25, "id74"], [25, "id82"], [25, "id85"], [25, "id88"], [25, "id93"], [25, "id98"], [25, "id102"], [25, "id108"], [25, "id114"], [25, "id116"]], "6.7.0": [[25, "id7"], [26, "id5"]], "6.6.0": [[25, "id10"], [26, "id6"]], "6.5.0": [[25, "id14"], [26, "id7"]], "6.4.0": [[25, "id18"], [26, "id8"]], "6.3.0": [[25, "id22"], [26, "id9"]], "6.2.0": [[25, "id26"], [26, "id10"]], "6.1.0": [[25, "id29"], [26, "id11"]], "6.0.0": [[25, "id32"], [26, "id12"]], "Breaking changes": [[25, "breaking-changes"], [25, "id38"], [25, "id73"], [25, "id90"], [25, "id120"]], "5.0.1 (YANKED)": [[25, "yanked"]], "5.0.0": [[25, "id37"], [26, "id14"]], "4.7.0": [[25, "id39"], [26, "id15"]], "4.6.0": [[25, "id41"], [26, "id16"]], "4.5.0": [[25, "id46"], [26, "id17"]], "4.4.0": [[25, "id49"], [26, "id18"]], "4.3.3": [[25, "id52"], [26, "id19"]], "4.3.2": [[25, "id54"], [26, "id21"]], "4.3.1": [[25, "id57"], [26, "id22"]], "4.3.0": [[25, "id60"], [26, "id23"]], "4.2.0": [[25, "id64"], [26, "id24"]], "4.1.0": [[25, "id68"], [26, "id26"]], "4.0.1": [[25, "id70"], [26, "id27"]], "4.0.0": [[25, "id72"], [26, "id28"]], "3.4.0 (YANKED)": [[25, "id75"]], "3.3.0": [[25, "id79"], [26, "id30"]], "3.2.0": [[25, "id83"], [26, "id32"]], "3.1.0": [[25, "id86"], [26, "id34"]], "3.0.0": [[25, "id89"], [26, "id35"]], "2.7.0": [[25, "id94"], [26, "id36"]], "2.6.0": [[25, "id96"], [26, "id37"]], "2.5.0": [[25, "id100"], [26, "id38"]], "2.4.0": [[25, "id103"], [26, "id39"]], "2.3.0": [[25, "id106"], [26, "id41"]], "2.2.0": [[25, "id110"], [26, "id42"]], "2.1.0": [[25, "id112"], [26, "id43"]], "2.0.2": [[25, "id115"], [26, "id44"]], "2.0.1": [[25, "id117"], [26, "id45"]], "2.0.0": [[25, "id119"], [26, "id46"]], "1.0.1": [[25, "id121"], [26, "id47"]], "1.0.0": [[25, "id122"], [26, "id48"]], "Package apache-airflow-providers-databricks": [[26, "package-apache-airflow-providers-databricks"]], "5.0.1": [[26, "id13"]], "3.4.0": [[26, "id29"]], "Databricks Connection": [[27, "databricks-connection"]], "Authenticating to Databricks": [[27, "authenticating-to-databricks"]], "Default Connection IDs": [[27, "default-connection-ids"]], "Configuring the Connection": [[27, "configuring-the-connection"]], "apache-airflow-providers-databricks": [[28, "apache-airflow-providers-databricks"]], "apache-airflow-providers-databricks package": [[28, "apache-airflow-providers-databricks-package"]], "Provider package": [[28, "provider-package"]], "Installation": [[28, "installation"]], "Requirements": [[28, "requirements"]], "Cross provider package dependencies": [[28, "cross-provider-package-dependencies"]], "Downloading official packages": [[28, "downloading-official-packages"]], "Installing from sources": [[29, "installing-from-sources"]], "Released packages": [[29, "released-packages"]], "Release integrity": [[29, "release-integrity"]], "Verifying PyPI releases": [[29, "verifying-pypi-releases"]], "DatabricksCopyIntoOperator": [[30, "databrickscopyintooperator"]], "Using the Operator": [[30, "using-the-operator"], [32, "using-the-operator"], [34, "using-the-operator"], [35, "using-the-operator"], [36, "using-the-operator"], [37, "using-the-operator"], [38, "using-the-operator"], [39, "using-the-operator"]], "Examples": [[30, "examples"], [32, "examples"], [33, "examples"], [34, "examples"], [35, "examples"], [36, "examples"], [38, "examples"], [38, "id1"], [38, "id3"], [39, "examples"], [40, "examples"], [41, "examples"], [43, "examples"]], "Importing CSV data": [[30, "importing-csv-data"]], "Databricks Operators": [[31, "databricks-operators"]], "DatabricksCreateJobsOperator": [[32, "databrickscreatejobsoperator"]], "Specifying parameters as JSON": [[32, "specifying-parameters-as-json"], [39, "specifying-parameters-as-json"]], "Using named parameters": [[32, "using-named-parameters"], [39, "using-named-parameters"]], "Pairing with DatabricksRunNowOperator": [[32, "pairing-with-databricksrunnowoperator"]], "DatabricksNotebookOperator": [[33, "databricksnotebookoperator"]], "Running a notebook in Databricks on a new cluster": [[33, "running-a-notebook-in-databricks-on-a-new-cluster"]], "Running a notebook in Databricks on an existing cluster": [[33, "running-a-notebook-in-databricks-on-an-existing-cluster"]], "DatabricksReposCreateOperator": [[34, "databricksreposcreateoperator"]], "Create a Databricks Repo": [[34, "create-a-databricks-repo"]], "DatabricksReposDeleteOperator": [[35, "databricksreposdeleteoperator"]], "Deleting Databricks Repo by specifying path": [[35, "deleting-databricks-repo-by-specifying-path"]], "DatabricksReposUpdateOperator": [[36, "databricksreposupdateoperator"]], "Updating Databricks Repo by specifying path": [[36, "updating-databricks-repo-by-specifying-path"]], "DatabricksRunNowOperator": [[37, "databricksrunnowoperator"]], "DatabricksRunNowDeferrableOperator": [[37, "databricksrunnowdeferrableoperator"]], "DatabricksSqlOperator": [[38, "databrickssqloperator"]], "Selecting data": [[38, "selecting-data"]], "Selecting data into a file": [[38, "selecting-data-into-a-file"]], "Executing multiple statements": [[38, "executing-multiple-statements"]], "Executing multiple statements from a file": [[38, "executing-multiple-statements-from-a-file"]], "DatabricksSqlSensor": [[38, "databrickssqlsensor"]], "Using the Sensor": [[38, "using-the-sensor"], [38, "id2"]], "DatabricksPartitionSensor": [[38, "databrickspartitionsensor"]], "DatabricksSubmitRunOperator": [[39, "databrickssubmitrunoperator"]], "DatabricksSubmitRunDeferrableOperator": [[39, "databrickssubmitrundeferrableoperator"]], "DatabricksTaskOperator": [[40, "databrickstaskoperator"]], "Running a notebook in Databricks using DatabricksTaskOperator": [[40, "running-a-notebook-in-databricks-using-databrickstaskoperator"]], "Running a SQL query in Databricks using DatabricksTaskOperator": [[40, "running-a-sql-query-in-databricks-using-databrickstaskoperator"]], "DatabricksWorkflowTaskGroup": [[41, "databricksworkflowtaskgroup"]], "Example of what a DAG looks like with a DatabricksWorkflowTaskGroup": [[41, "example-of-what-a-dag-looks-like-with-a-databricksworkflowtaskgroup"]], "The following image displays the resulting Databricks Workflow in the Airflow UI (based on the above example provided)": [[41, "the-following-image-displays-the-resulting-databricks-workflow-in-the-airflow-ui-based-on-the-above-example-provided"]], "The corresponding Databricks Workflow  in the Databricks UI for the run triggered from the Airflow DAG is depicted below": [[41, "the-corresponding-databricks-workflow-in-the-databricks-ui-for-the-run-triggered-from-the-airflow-dag-is-depicted-below"]], "Databricks Plugins": [[42, "databricks-plugins"]], "DatabricksWorkflowPlugin": [[43, "databricksworkflowplugin"]], "Overview": [[43, "overview"]], "Notes": [[43, "notes"]], "Usage": [[43, "usage"]], "Releasing security patches": [[44, "releasing-security-patches"]]}, "indexentries": {"blocked (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.BLOCKED"]], "cancel_all_runs_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.CANCEL_ALL_RUNS_ENDPOINT"]], "cancel_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.CANCEL_RUN_ENDPOINT"]], "cluster_life_cycle_states (airflow.providers.databricks.hooks.databricks.clusterstate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.CLUSTER_LIFE_CYCLE_STATES"]], "create_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.CREATE_ENDPOINT"]], "clusterstate (class in airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState"]], "delete_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.DELETE_RUN_ENDPOINT"]], "databrickshook (class in airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook"]], "get_cluster_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.GET_CLUSTER_ENDPOINT"]], "get_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.GET_RUN_ENDPOINT"]], "install_libs_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.INSTALL_LIBS_ENDPOINT"]], "internal_error (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.INTERNAL_ERROR"]], "list_jobs_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.LIST_JOBS_ENDPOINT"]], "list_pipelines_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.LIST_PIPELINES_ENDPOINT"]], "output_runs_job_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.OUTPUT_RUNS_JOB_ENDPOINT"]], "pending (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.PENDING"]], "queued (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.QUEUED"]], "repair_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.REPAIR_RUN_ENDPOINT"]], "reset_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.RESET_ENDPOINT"]], "restart_cluster_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.RESTART_CLUSTER_ENDPOINT"]], "running (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.RUNNING"]], "run_life_cycle_states (airflow.providers.databricks.hooks.databricks.runstate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.RUN_LIFE_CYCLE_STATES"]], "run_now_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.RUN_NOW_ENDPOINT"]], "runlifecyclestate (class in airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState"]], "runstate (class in airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.RunState"]], "skipped (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.SKIPPED"]], "spark_versions_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.SPARK_VERSIONS_ENDPOINT"]], "start_cluster_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.START_CLUSTER_ENDPOINT"]], "submit_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.SUBMIT_RUN_ENDPOINT"]], "terminated (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.TERMINATED"]], "terminate_cluster_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.TERMINATE_CLUSTER_ENDPOINT"]], "terminating (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.TERMINATING"]], "uninstall_libs_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.UNINSTALL_LIBS_ENDPOINT"]], "update_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.UPDATE_ENDPOINT"]], "waiting_for_retry (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.WAITING_FOR_RETRY"]], "workspace_get_status_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.WORKSPACE_GET_STATUS_ENDPOINT"]], "__eq__() (airflow.providers.databricks.hooks.databricks.clusterstate method)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.__eq__"]], "__eq__() (airflow.providers.databricks.hooks.databricks.runstate method)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.__eq__"]], "__repr__() (airflow.providers.databricks.hooks.databricks.clusterstate method)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.__repr__"]], "__repr__() (airflow.providers.databricks.hooks.databricks.runstate method)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.__repr__"]], "a_get_cluster_state() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_cluster_state"]], "a_get_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_run"]], "a_get_run_output() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_run_output"]], "a_get_run_page_url() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_run_page_url"]], "a_get_run_state() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_run_state"]], "airflow.providers.databricks.hooks.databricks": [[0, "module-airflow.providers.databricks.hooks.databricks"]], "cancel_all_runs() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.cancel_all_runs"]], "cancel_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.cancel_run"]], "create_job() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.create_job"]], "create_repo() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.create_repo"]], "delete_repo() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.delete_repo"]], "delete_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.delete_run"]], "find_job_id_by_name() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.find_job_id_by_name"]], "find_pipeline_id_by_name() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.find_pipeline_id_by_name"]], "from_json() (airflow.providers.databricks.hooks.databricks.clusterstate class method)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.from_json"]], "from_json() (airflow.providers.databricks.hooks.databricks.runstate class method)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.from_json"]], "get_cluster_state() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_cluster_state"]], "get_job_id() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_job_id"]], "get_latest_repair_id() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_latest_repair_id"]], "get_repo_by_path() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_repo_by_path"]], "get_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run"]], "get_run_output() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_output"]], "get_run_page_url() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_page_url"]], "get_run_state() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state"]], "get_run_state_lifecycle() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state_lifecycle"]], "get_run_state_message() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state_message"]], "get_run_state_result() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state_result"]], "get_run_state_str() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state_str"]], "hook_name (airflow.providers.databricks.hooks.databricks.databrickshook attribute)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.hook_name"]], "install() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.install"]], "is_running (airflow.providers.databricks.hooks.databricks.clusterstate property)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.is_running"]], "is_successful (airflow.providers.databricks.hooks.databricks.runstate property)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.is_successful"]], "is_terminal (airflow.providers.databricks.hooks.databricks.clusterstate property)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.is_terminal"]], "is_terminal (airflow.providers.databricks.hooks.databricks.runstate property)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.is_terminal"]], "list_jobs() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.list_jobs"]], "list_pipelines() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.list_pipelines"]], "module": [[0, "module-airflow.providers.databricks.hooks.databricks"], [1, "module-airflow.providers.databricks.hooks.databricks_base"], [2, "module-airflow.providers.databricks.hooks.databricks_sql"], [3, "module-airflow.providers.databricks.hooks"], [4, "module-airflow.providers.databricks"], [5, "module-airflow.providers.databricks.operators.databricks"], [6, "module-airflow.providers.databricks.operators.databricks_repos"], [7, "module-airflow.providers.databricks.operators.databricks_sql"], [8, "module-airflow.providers.databricks.operators.databricks_workflow"], [9, "module-airflow.providers.databricks.operators"], [10, "module-airflow.providers.databricks.plugins.databricks_workflow"], [11, "module-airflow.providers.databricks.plugins"], [12, "module-airflow.providers.databricks.sensors.databricks_partition"], [13, "module-airflow.providers.databricks.sensors.databricks_sql"], [14, "module-airflow.providers.databricks.sensors"], [15, "module-airflow.providers.databricks.triggers.databricks"], [16, "module-airflow.providers.databricks.triggers"], [17, "module-airflow.providers.databricks.utils.databricks"], [18, "module-airflow.providers.databricks.utils"], [19, "module-tests.system.providers.databricks.example_databricks"], [20, "module-tests.system.providers.databricks.example_databricks_repos"], [21, "module-tests.system.providers.databricks.example_databricks_sensors"], [22, "module-tests.system.providers.databricks.example_databricks_sql"], [23, "module-tests.system.providers.databricks.example_databricks_workflow"], [24, "module-tests.system.providers.databricks"]], "repair_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.repair_run"]], "reset_job() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.reset_job"]], "restart_cluster() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.restart_cluster"]], "run_now() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.run_now"]], "start_cluster() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.start_cluster"]], "submit_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.submit_run"]], "terminate_cluster() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.terminate_cluster"]], "test_connection() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.test_connection"]], "to_json() (airflow.providers.databricks.hooks.databricks.clusterstate method)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.to_json"]], "to_json() (airflow.providers.databricks.hooks.databricks.runstate method)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.to_json"]], "uninstall() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.uninstall"]], "update_job() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.update_job"]], "update_job_permission() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.update_job_permission"]], "update_repo() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.update_repo"]], "azure_management_endpoint (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.AZURE_MANAGEMENT_ENDPOINT"]], "azure_metadata_service_instance_url (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.AZURE_METADATA_SERVICE_INSTANCE_URL"]], "azure_metadata_service_token_url (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.AZURE_METADATA_SERVICE_TOKEN_URL"]], "basedatabrickshook (class in airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook"]], "bearerauth (class in airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.BearerAuth"]], "default_databricks_scope (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.DEFAULT_DATABRICKS_SCOPE"]], "oidc_token_service_url (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.OIDC_TOKEN_SERVICE_URL"]], "token_refresh_lead_time (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.TOKEN_REFRESH_LEAD_TIME"]], "__aenter__() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.__aenter__"]], "__aexit__() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.__aexit__"]], "airflow.providers.databricks.hooks.databricks_base": [[1, "module-airflow.providers.databricks.hooks.databricks_base"]], "conn_name_attr (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook attribute)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.conn_name_attr"]], "conn_type (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook attribute)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.conn_type"]], "databricks_conn() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.databricks_conn"]], "default_conn_name (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook attribute)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.default_conn_name"]], "encode() (airflow.providers.databricks.hooks.databricks_base.bearerauth method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BearerAuth.encode"]], "extra_parameters (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook attribute)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.extra_parameters"]], "get_conn() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.get_conn"]], "host() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.host"]], "user_agent_header() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.user_agent_header"]], "user_agent_value() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.user_agent_value"]], "databrickssqlhook (class in airflow.providers.databricks.hooks.databricks_sql)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook"]], "list_sql_endpoints_endpoint (in module airflow.providers.databricks.hooks.databricks_sql)": [[2, "airflow.providers.databricks.hooks.databricks_sql.LIST_SQL_ENDPOINTS_ENDPOINT"]], "t (in module airflow.providers.databricks.hooks.databricks_sql)": [[2, "airflow.providers.databricks.hooks.databricks_sql.T"]], "airflow.providers.databricks.hooks.databricks_sql": [[2, "module-airflow.providers.databricks.hooks.databricks_sql"]], "bulk_dump() (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook method)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.bulk_dump"]], "bulk_load() (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook method)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.bulk_load"]], "get_conn() (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook method)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.get_conn"]], "hook_name (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook attribute)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.hook_name"]], "run() (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook method)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.run"]], "airflow.providers.databricks.hooks": [[3, "module-airflow.providers.databricks.hooks"]], "__version__ (in module airflow.providers.databricks)": [[4, "airflow.providers.databricks.__version__"]], "airflow.providers.databricks": [[4, "module-airflow.providers.databricks"]], "caller (airflow.providers.databricks.operators.databricks.databricksnotebookoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksNotebookOperator.CALLER"]], "caller (airflow.providers.databricks.operators.databricks.databrickstaskoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksTaskOperator.CALLER"]], "defer_method_name (in module airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DEFER_METHOD_NAME"]], "databrickscreatejobsoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator"]], "databricksjobrunlink (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksJobRunLink"]], "databricksnotebookoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksNotebookOperator"]], "databricksrunnowdeferrableoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowDeferrableOperator"]], "databricksrunnowoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator"]], "databrickssubmitrundeferrableoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunDeferrableOperator"]], "databrickssubmitrunoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"]], "databrickstaskbaseoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksTaskBaseOperator"]], "databrickstaskoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksTaskOperator"]], "xcom_job_id_key (in module airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.XCOM_JOB_ID_KEY"]], "xcom_run_id_key (in module airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.XCOM_RUN_ID_KEY"]], "xcom_run_page_url_key (in module airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.XCOM_RUN_PAGE_URL_KEY"]], "airflow.providers.databricks.operators.databricks": [[5, "module-airflow.providers.databricks.operators.databricks"]], "execute() (airflow.providers.databricks.operators.databricks.databrickscreatejobsoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks.databricksrunnowoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks.databrickssubmitrundeferrableoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunDeferrableOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks.databrickstaskbaseoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksTaskBaseOperator.execute"]], "execute_complete() (airflow.providers.databricks.operators.databricks.databricksrunnowoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.execute_complete"]], "execute_complete() (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.execute_complete"]], "execute_complete() (airflow.providers.databricks.operators.databricks.databrickstaskbaseoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksTaskBaseOperator.execute_complete"]], "get_link() (airflow.providers.databricks.operators.databricks.databricksjobrunlink method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksJobRunLink.get_link"]], "is_repair_reason_match_exist() (in module airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.is_repair_reason_match_exist"]], "monitor_databricks_job() (airflow.providers.databricks.operators.databricks.databrickstaskbaseoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksTaskBaseOperator.monitor_databricks_job"]], "name (airflow.providers.databricks.operators.databricks.databricksjobrunlink attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksJobRunLink.name"]], "on_kill() (airflow.providers.databricks.operators.databricks.databricksrunnowoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.on_kill"]], "on_kill() (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.on_kill"]], "operator_extra_links (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.operator_extra_links"]], "operator_extra_links (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.operator_extra_links"]], "template_ext (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.template_ext"]], "template_ext (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.template_ext"]], "template_fields (airflow.providers.databricks.operators.databricks.databrickscreatejobsoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks.databricksnotebookoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksNotebookOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks.databrickstaskoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksTaskOperator.template_fields"]], "ui_color (airflow.providers.databricks.operators.databricks.databrickscreatejobsoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator.ui_color"]], "ui_color (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.ui_color"]], "ui_color (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.ui_color"]], "ui_fgcolor (airflow.providers.databricks.operators.databricks.databrickscreatejobsoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator.ui_fgcolor"]], "ui_fgcolor (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.ui_fgcolor"]], "ui_fgcolor (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.ui_fgcolor"]], "update_job_for_repair() (in module airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.update_job_for_repair"]], "databricksreposcreateoperator (class in airflow.providers.databricks.operators.databricks_repos)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator"]], "databricksreposdeleteoperator (class in airflow.providers.databricks.operators.databricks_repos)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposDeleteOperator"]], "databricksreposupdateoperator (class in airflow.providers.databricks.operators.databricks_repos)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposUpdateOperator"]], "__aws_code_commit_regexp__ (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.__aws_code_commit_regexp__"]], "__detect_repo_provider__() (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator static method)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.__detect_repo_provider__"]], "__git_providers__ (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.__git_providers__"]], "__repos_path_regexp__ (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.__repos_path_regexp__"]], "airflow.providers.databricks.operators.databricks_repos": [[6, "module-airflow.providers.databricks.operators.databricks_repos"]], "execute() (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator method)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks_repos.databricksreposdeleteoperator method)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposDeleteOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks_repos.databricksreposupdateoperator method)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposUpdateOperator.execute"]], "template_fields (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks_repos.databricksreposdeleteoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposDeleteOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks_repos.databricksreposupdateoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposUpdateOperator.template_fields"]], "copy_into_approved_formats (in module airflow.providers.databricks.operators.databricks_sql)": [[7, "airflow.providers.databricks.operators.databricks_sql.COPY_INTO_APPROVED_FORMATS"]], "databrickscopyintooperator (class in airflow.providers.databricks.operators.databricks_sql)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator"]], "databrickssqloperator (class in airflow.providers.databricks.operators.databricks_sql)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator"]], "airflow.providers.databricks.operators.databricks_sql": [[7, "module-airflow.providers.databricks.operators.databricks_sql"]], "conn_id_field (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.conn_id_field"]], "execute() (airflow.providers.databricks.operators.databricks_sql.databrickscopyintooperator method)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator.execute"]], "get_db_hook() (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator method)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.get_db_hook"]], "template_ext (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.template_ext"]], "template_fields (airflow.providers.databricks.operators.databricks_sql.databrickscopyintooperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.template_fields"]], "template_fields_renderers (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.template_fields_renderers"]], "databricksworkflowtaskgroup (class in airflow.providers.databricks.operators.databricks_workflow)": [[8, "airflow.providers.databricks.operators.databricks_workflow.DatabricksWorkflowTaskGroup"]], "workflowrunmetadata (class in airflow.providers.databricks.operators.databricks_workflow)": [[8, "airflow.providers.databricks.operators.databricks_workflow.WorkflowRunMetadata"]], "__exit__() (airflow.providers.databricks.operators.databricks_workflow.databricksworkflowtaskgroup method)": [[8, "airflow.providers.databricks.operators.databricks_workflow.DatabricksWorkflowTaskGroup.__exit__"]], "airflow.providers.databricks.operators.databricks_workflow": [[8, "module-airflow.providers.databricks.operators.databricks_workflow"]], "conn_id (airflow.providers.databricks.operators.databricks_workflow.workflowrunmetadata attribute)": [[8, "airflow.providers.databricks.operators.databricks_workflow.WorkflowRunMetadata.conn_id"]], "is_databricks (airflow.providers.databricks.operators.databricks_workflow.databricksworkflowtaskgroup attribute)": [[8, "airflow.providers.databricks.operators.databricks_workflow.DatabricksWorkflowTaskGroup.is_databricks"]], "job_id (airflow.providers.databricks.operators.databricks_workflow.workflowrunmetadata attribute)": [[8, "airflow.providers.databricks.operators.databricks_workflow.WorkflowRunMetadata.job_id"]], "run_id (airflow.providers.databricks.operators.databricks_workflow.workflowrunmetadata attribute)": [[8, "airflow.providers.databricks.operators.databricks_workflow.WorkflowRunMetadata.run_id"]], "airflow.providers.databricks.operators": [[9, "module-airflow.providers.databricks.operators"]], "databricksworkflowplugin (class in airflow.providers.databricks.plugins.databricks_workflow)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.DatabricksWorkflowPlugin"]], "repair_wait_attempts (in module airflow.providers.databricks.plugins.databricks_workflow)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.REPAIR_WAIT_ATTEMPTS"]], "repair_wait_delay (in module airflow.providers.databricks.plugins.databricks_workflow)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.REPAIR_WAIT_DELAY"]], "repairdatabrickstasks (class in airflow.providers.databricks.plugins.databricks_workflow)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.RepairDatabricksTasks"]], "workflowjobrepairallfailedlink (class in airflow.providers.databricks.plugins.databricks_workflow)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairAllFailedLink"]], "workflowjobrepairsingletasklink (class in airflow.providers.databricks.plugins.databricks_workflow)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairSingleTaskLink"]], "workflowjobrunlink (class in airflow.providers.databricks.plugins.databricks_workflow)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRunLink"]], "airflow.providers.databricks.plugins.databricks_workflow": [[10, "module-airflow.providers.databricks.plugins.databricks_workflow"]], "airflow_app (in module airflow.providers.databricks.plugins.databricks_workflow)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.airflow_app"]], "appbuilder_views (airflow.providers.databricks.plugins.databricks_workflow.databricksworkflowplugin attribute)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.DatabricksWorkflowPlugin.appbuilder_views"]], "default_view (airflow.providers.databricks.plugins.databricks_workflow.repairdatabrickstasks attribute)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.RepairDatabricksTasks.default_view"]], "get_auth_decorator() (in module airflow.providers.databricks.plugins.databricks_workflow)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.get_auth_decorator"]], "get_databricks_task_ids() (in module airflow.providers.databricks.plugins.databricks_workflow)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.get_databricks_task_ids"]], "get_launch_task_id() (in module airflow.providers.databricks.plugins.databricks_workflow)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.get_launch_task_id"]], "get_link() (airflow.providers.databricks.plugins.databricks_workflow.workflowjobrepairallfailedlink method)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairAllFailedLink.get_link"]], "get_link() (airflow.providers.databricks.plugins.databricks_workflow.workflowjobrepairsingletasklink method)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairSingleTaskLink.get_link"]], "get_link() (airflow.providers.databricks.plugins.databricks_workflow.workflowjobrunlink method)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRunLink.get_link"]], "get_task_group_children() (airflow.providers.databricks.plugins.databricks_workflow.workflowjobrepairallfailedlink class method)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairAllFailedLink.get_task_group_children"]], "get_task_instance() (in module airflow.providers.databricks.plugins.databricks_workflow)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.get_task_instance"]], "get_tasks_to_run() (airflow.providers.databricks.plugins.databricks_workflow.workflowjobrepairallfailedlink method)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairAllFailedLink.get_tasks_to_run"]], "get_xcom_result() (in module airflow.providers.databricks.plugins.databricks_workflow)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.get_xcom_result"]], "name (airflow.providers.databricks.plugins.databricks_workflow.databricksworkflowplugin attribute)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.DatabricksWorkflowPlugin.name"]], "name (airflow.providers.databricks.plugins.databricks_workflow.workflowjobrepairallfailedlink attribute)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairAllFailedLink.name"]], "name (airflow.providers.databricks.plugins.databricks_workflow.workflowjobrepairsingletasklink attribute)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairSingleTaskLink.name"]], "name (airflow.providers.databricks.plugins.databricks_workflow.workflowjobrunlink attribute)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRunLink.name"]], "operator_extra_links (airflow.providers.databricks.plugins.databricks_workflow.databricksworkflowplugin attribute)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.DatabricksWorkflowPlugin.operator_extra_links"]], "repair() (airflow.providers.databricks.plugins.databricks_workflow.repairdatabrickstasks method)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.RepairDatabricksTasks.repair"]], "repair_databricks_package (in module airflow.providers.databricks.plugins.databricks_workflow)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.repair_databricks_package"]], "repair_databricks_view (in module airflow.providers.databricks.plugins.databricks_workflow)": [[10, "airflow.providers.databricks.plugins.databricks_workflow.repair_databricks_view"]], "airflow.providers.databricks.plugins": [[11, "module-airflow.providers.databricks.plugins"]], "databrickspartitionsensor (class in airflow.providers.databricks.sensors.databricks_partition)": [[12, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor"]], "airflow.providers.databricks.sensors.databricks_partition": [[12, "module-airflow.providers.databricks.sensors.databricks_partition"]], "poke() (airflow.providers.databricks.sensors.databricks_partition.databrickspartitionsensor method)": [[12, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor.poke"]], "template_ext (airflow.providers.databricks.sensors.databricks_partition.databrickspartitionsensor attribute)": [[12, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor.template_ext"]], "template_fields (airflow.providers.databricks.sensors.databricks_partition.databrickspartitionsensor attribute)": [[12, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor.template_fields"]], "template_fields_renderers (airflow.providers.databricks.sensors.databricks_partition.databrickspartitionsensor attribute)": [[12, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor.template_fields_renderers"]], "databrickssqlsensor (class in airflow.providers.databricks.sensors.databricks_sql)": [[13, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor"]], "airflow.providers.databricks.sensors.databricks_sql": [[13, "module-airflow.providers.databricks.sensors.databricks_sql"]], "hook() (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor method)": [[13, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.hook"]], "poke() (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor method)": [[13, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.poke"]], "template_ext (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor attribute)": [[13, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.template_ext"]], "template_fields (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor attribute)": [[13, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.template_fields"]], "template_fields_renderers (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor attribute)": [[13, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.template_fields_renderers"]], "airflow.providers.databricks.sensors": [[14, "module-airflow.providers.databricks.sensors"]], "databricksexecutiontrigger (class in airflow.providers.databricks.triggers.databricks)": [[15, "airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger"]], "airflow.providers.databricks.triggers.databricks": [[15, "module-airflow.providers.databricks.triggers.databricks"]], "run() (airflow.providers.databricks.triggers.databricks.databricksexecutiontrigger method)": [[15, "airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger.run"]], "serialize() (airflow.providers.databricks.triggers.databricks.databricksexecutiontrigger method)": [[15, "airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger.serialize"]], "airflow.providers.databricks.triggers": [[16, "module-airflow.providers.databricks.triggers"]], "airflow.providers.databricks.utils.databricks": [[17, "module-airflow.providers.databricks.utils.databricks"]], "normalise_json_content() (in module airflow.providers.databricks.utils.databricks)": [[17, "airflow.providers.databricks.utils.databricks.normalise_json_content"]], "validate_trigger_event() (in module airflow.providers.databricks.utils.databricks)": [[17, "airflow.providers.databricks.utils.databricks.validate_trigger_event"]], "airflow.providers.databricks.utils": [[18, "module-airflow.providers.databricks.utils"]], "dag_id (in module tests.system.providers.databricks.example_databricks)": [[19, "tests.system.providers.databricks.example_databricks.DAG_ID"]], "env_id (in module tests.system.providers.databricks.example_databricks)": [[19, "tests.system.providers.databricks.example_databricks.ENV_ID"]], "query_id (in module tests.system.providers.databricks.example_databricks)": [[19, "tests.system.providers.databricks.example_databricks.QUERY_ID"]], "warehouse_id (in module tests.system.providers.databricks.example_databricks)": [[19, "tests.system.providers.databricks.example_databricks.WAREHOUSE_ID"]], "job (in module tests.system.providers.databricks.example_databricks)": [[19, "tests.system.providers.databricks.example_databricks.job"]], "test_run (in module tests.system.providers.databricks.example_databricks)": [[19, "tests.system.providers.databricks.example_databricks.test_run"]], "tests.system.providers.databricks.example_databricks": [[19, "module-tests.system.providers.databricks.example_databricks"]], "dag_id (in module tests.system.providers.databricks.example_databricks_repos)": [[20, "tests.system.providers.databricks.example_databricks_repos.DAG_ID"]], "env_id (in module tests.system.providers.databricks.example_databricks_repos)": [[20, "tests.system.providers.databricks.example_databricks_repos.ENV_ID"]], "default_args (in module tests.system.providers.databricks.example_databricks_repos)": [[20, "tests.system.providers.databricks.example_databricks_repos.default_args"]], "repo_path (in module tests.system.providers.databricks.example_databricks_repos)": [[20, "tests.system.providers.databricks.example_databricks_repos.repo_path"]], "test_run (in module tests.system.providers.databricks.example_databricks_repos)": [[20, "tests.system.providers.databricks.example_databricks_repos.test_run"]], "tests.system.providers.databricks.example_databricks_repos": [[20, "module-tests.system.providers.databricks.example_databricks_repos"]], "dag_id (in module tests.system.providers.databricks.example_databricks_sensors)": [[21, "tests.system.providers.databricks.example_databricks_sensors.DAG_ID"]], "env_id (in module tests.system.providers.databricks.example_databricks_sensors)": [[21, "tests.system.providers.databricks.example_databricks_sensors.ENV_ID"]], "connection_id (in module tests.system.providers.databricks.example_databricks_sensors)": [[21, "tests.system.providers.databricks.example_databricks_sensors.connection_id"]], "test_run (in module tests.system.providers.databricks.example_databricks_sensors)": [[21, "tests.system.providers.databricks.example_databricks_sensors.test_run"]], "tests.system.providers.databricks.example_databricks_sensors": [[21, "module-tests.system.providers.databricks.example_databricks_sensors"]], "dag_id (in module tests.system.providers.databricks.example_databricks_sql)": [[22, "tests.system.providers.databricks.example_databricks_sql.DAG_ID"]], "env_id (in module tests.system.providers.databricks.example_databricks_sql)": [[22, "tests.system.providers.databricks.example_databricks_sql.ENV_ID"]], "connection_id (in module tests.system.providers.databricks.example_databricks_sql)": [[22, "tests.system.providers.databricks.example_databricks_sql.connection_id"]], "test_run (in module tests.system.providers.databricks.example_databricks_sql)": [[22, "tests.system.providers.databricks.example_databricks_sql.test_run"]], "tests.system.providers.databricks.example_databricks_sql": [[22, "module-tests.system.providers.databricks.example_databricks_sql"]], "databricks_conn_id (in module tests.system.providers.databricks.example_databricks_workflow)": [[23, "tests.system.providers.databricks.example_databricks_workflow.DATABRICKS_CONN_ID"]], "databricks_notification_email (in module tests.system.providers.databricks.example_databricks_workflow)": [[23, "tests.system.providers.databricks.example_databricks_workflow.DATABRICKS_NOTIFICATION_EMAIL"]], "execution_timeout (in module tests.system.providers.databricks.example_databricks_workflow)": [[23, "tests.system.providers.databricks.example_databricks_workflow.EXECUTION_TIMEOUT"]], "group_id (in module tests.system.providers.databricks.example_databricks_workflow)": [[23, "tests.system.providers.databricks.example_databricks_workflow.GROUP_ID"]], "query_id (in module tests.system.providers.databricks.example_databricks_workflow)": [[23, "tests.system.providers.databricks.example_databricks_workflow.QUERY_ID"]], "user (in module tests.system.providers.databricks.example_databricks_workflow)": [[23, "tests.system.providers.databricks.example_databricks_workflow.USER"]], "warehouse_id (in module tests.system.providers.databricks.example_databricks_workflow)": [[23, "tests.system.providers.databricks.example_databricks_workflow.WAREHOUSE_ID"]], "dag (in module tests.system.providers.databricks.example_databricks_workflow)": [[23, "tests.system.providers.databricks.example_databricks_workflow.dag"]], "job_cluster_spec (in module tests.system.providers.databricks.example_databricks_workflow)": [[23, "tests.system.providers.databricks.example_databricks_workflow.job_cluster_spec"]], "task_group (in module tests.system.providers.databricks.example_databricks_workflow)": [[23, "tests.system.providers.databricks.example_databricks_workflow.task_group"]], "test_run (in module tests.system.providers.databricks.example_databricks_workflow)": [[23, "tests.system.providers.databricks.example_databricks_workflow.test_run"]], "tests.system.providers.databricks.example_databricks_workflow": [[23, "module-tests.system.providers.databricks.example_databricks_workflow"]], "tests.system.providers.databricks": [[24, "module-tests.system.providers.databricks"]]}})