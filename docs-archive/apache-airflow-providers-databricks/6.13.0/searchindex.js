Search.setIndex({"docnames": ["_api/airflow/providers/databricks/exceptions/index", "_api/airflow/providers/databricks/hooks/databricks/index", "_api/airflow/providers/databricks/hooks/databricks_base/index", "_api/airflow/providers/databricks/hooks/databricks_sql/index", "_api/airflow/providers/databricks/hooks/index", "_api/airflow/providers/databricks/index", "_api/airflow/providers/databricks/operators/databricks/index", "_api/airflow/providers/databricks/operators/databricks_repos/index", "_api/airflow/providers/databricks/operators/databricks_sql/index", "_api/airflow/providers/databricks/operators/databricks_workflow/index", "_api/airflow/providers/databricks/operators/index", "_api/airflow/providers/databricks/plugins/databricks_workflow/index", "_api/airflow/providers/databricks/plugins/index", "_api/airflow/providers/databricks/sensors/databricks_partition/index", "_api/airflow/providers/databricks/sensors/databricks_sql/index", "_api/airflow/providers/databricks/sensors/index", "_api/airflow/providers/databricks/triggers/databricks/index", "_api/airflow/providers/databricks/triggers/index", "_api/airflow/providers/databricks/utils/databricks/index", "_api/airflow/providers/databricks/utils/index", "_api/tests/system/databricks/example_databricks/index", "_api/tests/system/databricks/example_databricks_repos/index", "_api/tests/system/databricks/example_databricks_sensors/index", "_api/tests/system/databricks/example_databricks_sql/index", "_api/tests/system/databricks/example_databricks_workflow/index", "_api/tests/system/databricks/index", "changelog", "commits", "connections/databricks", "index", "installing-providers-from-sources", "operators/copy_into", "operators/index", "operators/jobs_create", "operators/notebook", "operators/repos_create", "operators/repos_delete", "operators/repos_update", "operators/run_now", "operators/sql", "operators/submit_run", "operators/task", "operators/workflow", "plugins/index", "plugins/workflow", "security"], "filenames": ["_api/airflow/providers/databricks/exceptions/index.rst", "_api/airflow/providers/databricks/hooks/databricks/index.rst", "_api/airflow/providers/databricks/hooks/databricks_base/index.rst", "_api/airflow/providers/databricks/hooks/databricks_sql/index.rst", "_api/airflow/providers/databricks/hooks/index.rst", "_api/airflow/providers/databricks/index.rst", "_api/airflow/providers/databricks/operators/databricks/index.rst", "_api/airflow/providers/databricks/operators/databricks_repos/index.rst", "_api/airflow/providers/databricks/operators/databricks_sql/index.rst", "_api/airflow/providers/databricks/operators/databricks_workflow/index.rst", "_api/airflow/providers/databricks/operators/index.rst", "_api/airflow/providers/databricks/plugins/databricks_workflow/index.rst", "_api/airflow/providers/databricks/plugins/index.rst", "_api/airflow/providers/databricks/sensors/databricks_partition/index.rst", "_api/airflow/providers/databricks/sensors/databricks_sql/index.rst", "_api/airflow/providers/databricks/sensors/index.rst", "_api/airflow/providers/databricks/triggers/databricks/index.rst", "_api/airflow/providers/databricks/triggers/index.rst", "_api/airflow/providers/databricks/utils/databricks/index.rst", "_api/airflow/providers/databricks/utils/index.rst", "_api/tests/system/databricks/example_databricks/index.rst", "_api/tests/system/databricks/example_databricks_repos/index.rst", "_api/tests/system/databricks/example_databricks_sensors/index.rst", "_api/tests/system/databricks/example_databricks_sql/index.rst", "_api/tests/system/databricks/example_databricks_workflow/index.rst", "_api/tests/system/databricks/index.rst", "changelog.rst", "commits.rst", "connections/databricks.rst", "index.rst", "installing-providers-from-sources.rst", "operators/copy_into.rst", "operators/index.rst", "operators/jobs_create.rst", "operators/notebook.rst", "operators/repos_create.rst", "operators/repos_delete.rst", "operators/repos_update.rst", "operators/run_now.rst", "operators/sql.rst", "operators/submit_run.rst", "operators/task.rst", "operators/workflow.rst", "plugins/index.rst", "plugins/workflow.rst", "security.rst"], "titles": ["<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.exceptions</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.hooks.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.hooks.databricks_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.hooks.databricks_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.hooks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators.databricks_repos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators.databricks_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators.databricks_workflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.plugins.databricks_workflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.plugins</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.sensors.databricks_partition</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.sensors.databricks_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.sensors</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.triggers.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.triggers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.utils.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.databricks.example_databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.databricks.example_databricks_repos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.databricks.example_databricks_sensors</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.databricks.example_databricks_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.databricks.example_databricks_workflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.databricks</span></code>", "Changelog", "Package apache-airflow-providers-databricks", "Databricks Connection", "<code class=\"docutils literal notranslate\"><span class=\"pre\">apache-airflow-providers-databricks</span></code>", "Installing from sources", "DatabricksCopyIntoOperator", "Databricks Operators", "DatabricksCreateJobsOperator", "DatabricksNotebookOperator", "DatabricksReposCreateOperator", "DatabricksReposDeleteOperator", "DatabricksReposUpdateOperator", "DatabricksRunNowOperator", "DatabricksSqlOperator", "DatabricksSubmitRunOperator", "DatabricksTaskOperator", "DatabricksWorkflowTaskGroup", "Databricks Plugins", "DatabricksWorkflowPlugin", "Releasing security patches"], "terms": {"us": [0, 1, 3, 6, 7, 8, 9, 11, 13, 14, 16, 20, 23, 24, 26, 27, 28, 29, 30, 34, 42, 44, 45], "databrickssqlexecutionerror": 0, "sourc": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 13, 14, 16, 18, 20, 21, 22, 23, 24, 27, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42], "base": [0, 1, 2, 3, 6, 7, 8, 9, 11, 13, 14, 16, 26, 27, 39], "airflowexcept": [0, 1], "rais": [0, 1, 3, 9, 26, 27], "when": [0, 6, 7, 8, 16, 18, 26, 27, 28, 29, 33, 40, 42, 45], "i": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45], "an": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], "error": [0, 1, 9, 26, 27, 33, 40], "sql": [0, 3, 8, 13, 14, 23, 26, 27, 28, 29, 31, 39], "execut": [0, 3, 6, 7, 8, 14, 20, 26, 27, 33, 37, 40, 42], "databrickssqlexecutiontimeout": 0, "time": [0, 1, 2, 3, 6, 7, 9, 16, 26, 27, 35, 36, 37, 39, 40, 42], "out": [0, 1, 2, 7, 26, 27, 45], "6": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], "13": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], "3": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], "dev0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], "experiment": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], "featur": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45], "enabl": [1, 2, 26, 27, 28], "submit": [1, 2, 6, 9, 27, 40], "run": [1, 2, 3, 6, 9, 11, 13, 14, 16, 20, 23, 26, 27, 28, 30, 33, 38, 39, 40, 44], "job": [1, 2, 6, 9, 11, 20, 26, 27, 33, 34, 37, 38, 40, 42, 44], "platform": [1, 2], "intern": [1, 2, 3, 8, 13, 14, 28], "oper": [1, 2, 5, 11, 13, 26, 27, 28, 41, 44], "talk": [1, 2], "api": [1, 2, 3, 6, 7, 16, 20, 26, 27, 28, 33, 35, 36, 37, 38, 40], "2": [1, 2, 3, 6, 7, 29, 33, 35, 36, 37, 38, 39, 40], "1": [1, 2, 6, 7, 9, 29, 33, 34, 38, 39, 40], "now": [1, 6, 8, 26, 27, 38], "endpoint": [1, 2, 3, 6, 7, 8, 26, 27, 28, 31, 33, 35, 36, 37, 38, 40], "http": [1, 2, 3, 6, 7, 8, 13, 14, 20, 26, 27, 28, 30, 31, 34, 35, 39, 42], "doc": [1, 6, 7, 20, 26, 27], "com": [1, 6, 7, 20, 21, 26, 30, 35, 36, 37, 40], "dev": [1, 6, 7, 27], "tool": [1, 6, 7, 27], "latest": [1, 6, 7, 20, 26, 27, 37, 45], "html": [1, 6, 7, 20], "jobsrunnow": [1, 6], "_": [1, 42], "get_cluster_endpoint": 1, "get": [1, 3, 6, 8, 14, 26, 27, 30, 33, 40, 45], "cluster": [1, 3, 6, 8, 9, 13, 14, 20, 28, 31, 39, 40], "restart_cluster_endpoint": 1, "post": [1, 7], "restart": 1, "start_cluster_endpoint": 1, "start": [1, 27], "terminate_cluster_endpoint": 1, "delet": [1, 7, 26, 27], "create_endpoint": 1, "creat": [1, 6, 7, 8, 9, 14, 20, 23, 26, 27, 30, 33, 39, 42], "reset_endpoint": 1, "reset": [1, 6, 26, 27, 33], "update_endpoint": 1, "updat": [1, 6, 7, 26, 27, 33, 42], "run_now_endpoint": 1, "submit_run_endpoint": 1, "get_run_endpoint": 1, "cancel_run_endpoint": 1, "cancel": [1, 6, 26, 27], "delete_run_endpoint": 1, "repair_run_endpoint": 1, "repair": [1, 6, 11, 26, 27, 44], "output_runs_job_endpoint": 1, "output": [1, 8, 23, 26, 27], "cancel_all_runs_endpoint": 1, "all": [1, 3, 6, 8, 9, 11, 13, 14, 18, 26, 27, 28, 29, 33, 38, 39, 42, 44, 45], "install_libs_endpoint": 1, "librari": [1, 2, 6, 40, 41, 42], "instal": [1, 6, 9, 26, 27, 44, 45], "uninstall_libs_endpoint": 1, "uninstal": [1, 27], "list_jobs_endpoint": 1, "list": [1, 3, 6, 8, 9, 11, 13, 14, 26, 27, 35, 39], "list_pipelines_endpoint": 1, "pipelin": [1, 6, 26, 27, 40], "workspace_get_status_endpoint": 1, "workspac": [1, 6, 20, 27, 28, 34, 39, 41, 42, 44], "statu": [1, 26, 27], "spark_versions_endpoint": 1, "spark": [1, 3, 6, 8, 9, 13, 14, 20, 27, 28, 40], "version": [1, 3, 6, 8, 13, 14, 26, 27, 29, 30, 38, 40, 42, 45], "runlifecyclest": 1, "enum": 1, "life": 1, "cycl": 1, "state": [1, 6, 20, 26, 27], "concept": [1, 27], "see": [1, 6, 7, 11, 18, 26, 27, 28, 29, 35], "more": [1, 6, 7, 8, 9, 11, 20, 26, 27, 28, 38, 40], "inform": [1, 6, 8, 9, 11, 16, 20, 26, 27, 45], "azur": [1, 26, 27, 28], "listrun": 1, "life_cycle_st": 1, "block": [1, 26, 27], "internal_error": 1, "pend": 1, "queu": [1, 26, 27], "skip": [1, 26, 27], "termin": [1, 6], "waiting_for_retri": 1, "runstat": [1, 6, 20], "result_st": [1, 20], "state_messag": [1, 6], "arg": [1, 6, 27], "kwarg": [1, 3, 6, 7, 8, 9, 13, 14], "util": [1, 5, 7, 9, 11, 38, 40, 44], "properti": [1, 9, 26, 27], "is_termin": 1, "bool": [1, 3, 6, 7, 8, 35], "true": [1, 3, 6, 8, 9, 18, 28, 31], "current": [1, 3, 6, 11, 33, 40], "is_success": 1, "result": [1, 3, 6, 13, 14, 16, 26, 27], "success": [1, 20], "run_life_cycle_st": [1, 26, 27], "__eq__": 1, "other": [1, 6, 26, 27, 31, 38, 39, 42], "return": [1, 2, 3, 6, 7, 8, 11, 13, 14, 16, 26, 27, 33], "self": [1, 6, 11, 18, 30], "valu": [1, 6, 7, 8, 11, 18, 23, 26, 27, 28, 39, 40], "__repr__": 1, "repr": 1, "to_json": 1, "classmethod": [1, 11], "from_json": 1, "data": [1, 8, 23, 26, 27], "clusterst": [1, 26, 27], "is_run": 1, "cluster_life_cycle_st": 1, "resiz": 1, "unknown": [1, 2, 30], "databrickshook": [1, 26, 27], "databricks_conn_id": [1, 2, 3, 6, 7, 8, 9, 13, 14, 16, 24, 26, 27, 31, 35, 36, 37, 39, 41, 42], "basedatabrickshook": [1, 2, 3], "default_conn_nam": [1, 2, 3, 8, 13, 14], "timeout_second": [1, 2, 6, 33, 40], "180": [1, 2], "retry_limit": [1, 2, 16], "retry_delai": [1, 2, 16], "retry_arg": [1, 2, 16], "none": [1, 2, 3, 6, 7, 8, 9, 11, 13, 14, 16, 30], "caller": [1, 2, 3, 6, 16], "databricks_bas": [1, 3, 4, 5], "interact": [1, 2, 3, 39], "paramet": [1, 2, 3, 6, 7, 8, 9, 11, 13, 14, 16, 26, 27, 28, 31, 35, 36, 37, 38, 39, 42], "str": [1, 2, 3, 6, 7, 8, 9, 11, 13, 14, 16, 27, 35, 36, 37], "refer": [1, 2, 3, 6, 7, 8, 13, 14, 16, 20, 26, 27, 40], "connect": [1, 2, 3, 6, 7, 8, 9, 13, 14, 16, 26, 27, 35, 36, 37, 39], "int": [1, 2, 6, 7, 8, 9, 16, 39], "The": [1, 2, 3, 6, 9, 11, 16, 18, 20, 23, 26, 28, 29, 30, 31, 33, 38, 39, 40, 44, 45], "amount": [1, 2, 6, 7, 35, 36, 37], "second": [1, 2, 6, 7, 16, 20, 23, 33, 35, 36, 37, 40, 42], "request": [1, 2, 3, 6, 8, 11, 13, 14, 26, 27, 28, 29], "wait": [1, 2, 6, 7, 16, 35, 36, 37, 39], "befor": [1, 2, 3, 6, 26, 27, 37], "number": [1, 2, 6, 7, 8, 9, 16, 27, 35, 36, 37], "retri": [1, 2, 6, 7, 16, 26, 27, 35, 36, 37, 42], "case": [1, 2, 6, 7, 16, 26, 40, 45], "servic": [1, 2, 16, 26, 27, 28], "outag": [1, 2, 16], "float": [1, 2, 6, 7], "between": [1, 2, 6, 7, 16, 35, 36, 37], "might": [1, 2, 6, 7, 29, 45], "point": [1, 2, 6, 7, 27], "dict": [1, 2, 3, 6, 8, 9, 11, 13, 14, 16, 18, 26, 27], "ani": [1, 2, 3, 6, 8, 9, 11, 13, 14, 16, 26, 30], "option": [1, 2, 3, 6, 7, 8, 13, 14, 16, 26, 27, 28, 31, 35, 38, 39], "dictionari": [1, 2, 3, 6, 7, 8, 9, 11, 13, 14, 16, 28], "argument": [1, 2, 6, 16, 26, 27, 28, 33], "pass": [1, 2, 3, 6, 8, 9, 16, 23, 27, 33, 38, 40, 42], "tenac": [1, 2, 6, 16], "hook_nam": [1, 3], "create_job": 1, "json": [1, 6, 8, 18, 26, 27, 28, 31, 38], "call": [1, 2, 3, 6, 16, 26, 27, 33, 38, 40], "bodi": [1, 27], "job_id": [1, 6, 9, 26, 27, 33, 38], "type": [1, 6, 8, 11, 16, 18, 26, 27, 28, 33, 38, 39, 40], "reset_job": 1, "new_set": [1, 6], "update_job": 1, "id": [1, 6, 7, 8, 9, 11, 13, 14, 16, 26, 27, 30, 36, 37, 38, 39, 40], "run_now": [1, 33], "run_id": [1, 6, 9, 11, 16], "submit_run": 1, "list_job": [1, 26, 27], "limit": [1, 39], "25": [1, 27], "expand_task": 1, "fals": [1, 3, 6, 7, 16, 18, 34], "job_nam": [1, 6, 38], "page_token": [1, 26], "include_user_nam": 1, "batch": [1, 27], "size": 1, "retriev": [1, 6, 11, 26, 27, 28], "whether": [1, 3, 6], "includ": [1, 26, 27, 29, 33, 40, 44, 45], "task": [1, 3, 6, 8, 9, 11, 16, 20, 23, 26, 27, 33, 34, 38, 39, 40, 41, 42, 44], "detail": [1, 6, 26, 27, 30], "respons": [1, 26, 27], "name": [1, 2, 3, 6, 7, 8, 9, 11, 13, 14, 26, 27, 28, 31, 35, 36, 37, 38, 39, 42], "search": [1, 26, 27], "page": [1, 16, 27, 30], "token": [1, 2, 6, 7, 26, 27, 28], "first": [1, 6, 8, 20, 23, 26, 27, 33, 38, 40], "A": [1, 6, 9, 11], "find_job_id_by_nam": 1, "find": 1, "its": [1, 7, 26, 35, 37, 39, 44], "ar": [1, 6, 8, 9, 11, 16, 26, 27, 28, 29, 30, 31, 33, 38, 39, 40, 42, 44, 45], "multipl": [1, 33, 38, 40], "same": [1, 6, 7, 8, 26, 33, 38, 40], "look": [1, 6, 8, 9, 11], "up": [1, 6, 8, 27], "wa": [1, 3, 6, 11, 16, 26, 33], "found": [1, 31, 38, 39, 45], "list_pipelin": 1, "batch_siz": 1, "pipeline_nam": [1, 40], "notebook_path": [1, 6, 33, 34, 40, 41, 42], "delta": [1, 6, 23, 40], "live": [1, 6, 40], "tabl": [1, 3, 6, 8, 13, 23, 31, 39, 40], "cannot": [1, 6, 26, 27], "combin": [1, 6], "path": [1, 3, 6, 7, 8, 13, 14, 16, 20, 23, 26, 27, 28, 31, 35, 39, 40], "notebook": [1, 6, 9, 20, 26, 27, 40, 42], "find_pipeline_id_by_nam": 1, "pipeline_id": [1, 6, 40], "guid": [1, 6, 8, 9, 11, 27, 30], "string": [1, 3, 8, 13, 14, 18, 26, 27, 31, 35, 36, 37, 39], "get_run_page_url": 1, "run_page_url": [1, 6, 16], "url": [1, 7, 16, 26, 27, 28, 35], "async": [1, 2, 16, 26, 27], "a_get_run_page_url": 1, "get_job_id": 1, "from": [1, 6, 7, 8, 11, 14, 18, 23, 26, 27, 28, 29, 31, 35, 45], "given": [1, 6, 7, 8, 11, 35, 37, 39], "get_run_st": 1, "pleas": [1, 6, 26, 30], "note": [1, 3, 6, 11, 27, 28, 33, 38, 40], "method": [1, 6, 8, 9, 26, 27, 28], "failur": [1, 6], "unless": [1, 3], "you": [1, 6, 26, 28, 29, 30, 33, 35, 36, 37, 38, 40, 42, 45], "have": [1, 6, 18, 20, 26, 27, 28, 39, 45], "xcom": [1, 6, 26, 27, 33], "pickl": 1, "can": [1, 6, 7, 8, 18, 26, 28, 29, 30, 33, 35, 38, 39, 40, 41, 42, 45], "done": [1, 45], "follow": [1, 6, 26, 27, 28, 30, 31, 33, 35, 36, 37, 38, 39, 40, 45], "environ": [1, 28, 44], "variabl": [1, 28], "airflow__core__enable_xcom_pickl": 1, "If": [1, 3, 6, 7, 8, 9, 13, 14, 16, 26, 28, 30, 33, 35, 40, 42], "do": [1, 9, 26, 27, 30, 39, 40, 42], "want": [1, 16, 26, 30, 45], "get_run_state_str": 1, "describ": [1, 3, 8, 13, 14, 30, 38], "get_run_state_lifecycl": 1, "get_run_state_result": 1, "get_run_state_messag": 1, "individu": [1, 8, 27, 44], "compon": [1, 28], "a_get_run_st": 1, "get_run": 1, "a_get_run": 1, "represent": [1, 6], "lifecycl": 1, "messag": [1, 6], "get_run_output": 1, "a_get_run_output": 1, "cancel_run": 1, "cancel_all_run": 1, "activ": [1, 28], "asynchron": [1, 16], "canon": 1, "identifi": 1, "delete_run": 1, "non": [1, 18, 27], "repair_run": [1, 6, 16, 26, 27, 38], "re": [1, 16, 27, 28], "one": [1, 6, 18, 26, 27, 30, 33, 38, 39, 40], "get_latest_repair_id": 1, "exist": [1, 6, 7, 9, 29, 33, 35, 36, 37, 38, 39, 40, 42], "els": [1, 26, 27], "get_cluster_st": 1, "cluster_id": 1, "a_get_cluster_st": 1, "restart_clust": 1, "contain": [1, 6, 7, 8, 9, 11, 13, 14, 18, 28, 30, 31], "specif": [1, 6, 8, 9, 27, 28, 39, 40, 42], "start_clust": 1, "terminate_clust": 1, "function": [1, 14, 26, 27, 38, 40], "arrai": [1, 6, 40], "update_repo": [1, 37], "repo_id": [1, 7, 36, 37], "repo": [1, 7, 21, 26, 27, 34, 42], "payload": [1, 6, 27, 33, 38, 40], "metadata": [1, 2, 6, 9], "delete_repo": [1, 36], "create_repo": [1, 35], "get_repo_by_path": 1, "obtain": [1, 28], "repositori": [1, 6, 7, 27, 35], "doesn": 1, "t": [1, 3, 7, 8, 26, 27, 28, 35, 36, 37, 38, 42], "update_job_permiss": 1, "permiss": [1, 6, 26, 27, 28], "test_connect": [1, 26, 27], "test": [1, 26, 27, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 45], "ui": [1, 6, 33, 44], "azure_metadata_service_token_url": 2, "169": 2, "254": 2, "ident": [2, 26, 27, 28], "oauth2": 2, "azure_metadata_service_instance_url": 2, "instanc": [2, 3, 6, 8, 11, 26, 27], "token_refresh_lead_tim": 2, "120": 2, "azure_management_endpoint": 2, "manag": [2, 9, 26, 27, 28, 30], "core": [2, 27, 31], "window": [2, 31], "net": [2, 31], "default_databricks_scop": 2, "2ff814a6": 2, "3304": 2, "4ab8": 2, "85cb": 2, "cd0e6f879c1d": 2, "oidc_token_service_url": 2, "oidc": 2, "v1": 2, "default_azure_credential_setting_kei": 2, "use_default_azure_credenti": [2, 28], "basehook": 2, "conn_name_attr": 2, "databricks_default": [2, 6, 7, 22, 28, 39], "conn_typ": 2, "extra_paramet": 2, "databricks_conn": [2, 41], "get_conn": [2, 3], "user_agent_head": 2, "user_agent_valu": 2, "host": [2, 6, 7, 26, 27, 28], "__aenter__": 2, "__aexit__": 2, "err": 2, "bearerauth": 2, "aiohttp": [2, 26, 27, 29], "basicauth": [2, 26, 27], "onli": [2, 3, 6, 8, 18, 26, 28, 31, 38, 39, 44, 45], "ship": 2, "bearer": [2, 28], "auth": [2, 26, 27, 28], "we": [2, 6, 7, 18, 20, 26, 27, 35, 39, 42, 45], "need": [2, 6, 8, 16, 26, 27, 28, 29, 35, 36, 37, 40], "subclass": 2, "encod": [2, 28], "credenti": [2, 8, 28], "list_sql_endpoints_endpoint": 3, "create_timeout_thread": 3, "cur": 3, "execution_timeout": [3, 24, 42], "databrickssqlhook": [3, 8, 13, 14, 26, 27], "http_path": [3, 8, 13, 14, 28, 31, 39], "sql_endpoint_nam": [3, 8, 31, 39], "session_configur": [3, 8, 13, 14, 28], "http_header": [3, 8, 13, 14], "catalog": [3, 8, 13, 14, 39], "schema": [3, 8, 13, 14, 39], "return_tupl": [3, 26, 27], "common": [3, 6, 7, 8, 26, 27, 29], "dbapihook": [3, 13, 14, 26, 27], "specifi": [3, 6, 7, 8, 13, 14, 23, 26, 27, 28, 29, 31, 35, 38, 39, 42], "should": [3, 6, 7, 8, 13, 14, 16, 26, 27, 28, 30, 39, 40, 44, 45], "either": [3, 6, 8, 13, 14, 16, 28, 36, 37, 38, 40], "": [3, 6, 7, 8, 13, 14, 26, 27, 28, 30, 33, 35, 39, 40, 44], "extra": [3, 6, 7, 8, 13, 14, 26, 27, 28, 29], "must": [3, 6, 7, 8, 9, 13, 14, 18, 28, 35, 39, 40], "abov": [3, 8, 30], "session": [3, 8, 11, 13, 14, 26, 27, 28], "default": [3, 6, 7, 8, 9, 13, 14, 16, 27, 39, 45], "could": [3, 8, 13, 14, 28, 31, 39], "tupl": [3, 8, 13, 14, 16, 26, 27], "k": [3, 8, 13, 14], "v": [3, 8, 13, 14, 39], "pair": [3, 6, 8, 13, 14], "set": [3, 6, 8, 13, 14, 20, 26, 27, 28], "header": [3, 8, 13, 14, 27, 28, 31], "everi": [3, 6, 8, 13, 14, 16], "initi": [3, 8, 13, 14, 26, 27, 33, 40], "requir": [3, 6, 7, 8, 13, 14, 26, 27, 28, 31, 35, 36, 37, 38, 39, 42, 45], "dbr": [3, 8], "9": [3, 8, 13, 14, 29, 40], "namedtupl": [3, 26, 27], "object": [3, 6, 8, 11, 14, 26, 27, 28, 40], "instead": [3, 6, 26, 27, 28, 40], "row": [3, 8, 26, 27], "In": [3, 6, 16, 20, 33, 38, 40], "futur": 3, "releas": [3, 26, 27, 29, 37], "becom": 3, "ensur": [3, 26, 27, 44], "backward": 3, "compat": [3, 26, 27], "dure": [3, 6, 26, 27, 33, 40], "transit": 3, "phase": 3, "flag": [3, 28], "also": [3, 6, 8, 26, 30, 33, 40, 44], "remov": [3, 26, 27, 30], "addit": [3, 8, 13, 14, 38], "connector": [3, 8, 13, 14, 26, 27, 28, 29], "iter": [3, 14], "autocommit": 3, "map": [3, 6, 11, 28], "handler": [3, 13, 14], "split_stat": 3, "return_last": 3, "datetim": [3, 6, 11], "timedelta": [3, 42], "callabl": [3, 13, 14], "command": [3, 6, 8, 27, 31, 40], "statement": [3, 8, 14, 23, 26, 27], "them": [3, 26, 27, 29], "sequenti": [3, 20], "what": 3, "queri": [3, 8, 14, 26, 27, 39, 42], "commit": [3, 27], "so": [3, 26, 27, 33, 39, 45], "ha": [3, 20, 26], "effect": [3, 38, 40], "render": [3, 6, 7, 8], "which": [3, 6, 8, 9, 11, 20, 23, 26, 27, 28, 40, 45], "each": [3, 6, 9, 33, 38, 39, 40, 44], "split": [3, 27], "singl": [3, 8, 9, 11, 16, 40, 42, 44], "separ": [3, 27, 45], "last": 3, "after": [3, 26, 27, 33], "max": 3, "allow": [3, 6, 26, 27, 28, 38, 40, 44], "goe": 3, "beyond": 3, "fail": [3, 6, 11, 18, 26, 27, 44], "express": [3, 8, 26, 27], "abstract": 3, "bulk_dump": 3, "tmp_file": 3, "dump": 3, "databas": [3, 8], "tab": 3, "delimit": 3, "file": [3, 6, 8, 23, 26, 27, 30, 31, 40], "target": 3, "bulk_load": 3, "load": [3, 23, 27, 31], "databricks_sql": [4, 5, 10, 15, 26, 27], "hook": [5, 6, 8, 14, 26, 27, 28], "databricks_repo": [5, 10], "databricks_workflow": [5, 10, 12], "plugin": [5, 27, 44], "sensor": [5, 26, 27], "databricks_partit": [5, 15], "trigger": [5, 6, 26, 27, 38], "except": [5, 6, 7, 18, 26, 27, 35, 38, 45], "__version__": [5, 27], "defer_method_nam": 6, "execute_complet": [6, 26, 27], "xcom_run_id_kei": 6, "xcom_job_id_kei": 6, "xcom_run_page_url_kei": 6, "is_repair_reason_match_exist": 6, "run_stat": 6, "check": [6, 7, 13, 26, 27, 30, 33, 39, 40], "reason": [6, 18, 26, 27, 45], "match": [6, 8, 26, 27, 30, 42], "being": [6, 16], "handl": [6, 16, 26, 27], "otherwis": [6, 26], "update_job_for_repair": 6, "partial": 6, "databricksjobrunlink": [6, 26, 27], "model": [6, 7, 8, 11, 45], "baseoperatorlink": [6, 11], "construct": [6, 8, 11], "link": [6, 11, 26, 27, 30, 44], "monitor": [6, 11, 34, 41, 42, 44], "get_link": [6, 11], "ti_kei": [6, 11], "extern": [6, 11, 39], "system": [6, 11, 28, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42], "old": [6, 11, 27], "signatur": [6, 11, 27, 29, 30], "dttm": [6, 11], "That": [6, 11, 26], "still": [6, 11, 26], "support": [6, 8, 11, 26, 27, 28, 29, 31, 33, 35, 39, 40], "runtim": [6, 11, 13, 14, 26, 27], "deprec": [6, 11, 26, 27], "baseoper": [6, 7, 8, 11, 26, 27], "associ": [6, 11], "taskinstancekei": [6, 11, 27], "taskinst": [6, 11, 26, 27], "databrickscreatejobsoper": [6, 26, 27, 32], "descript": [6, 26, 27, 33], "tag": [6, 7, 33, 35, 37], "job_clust": [6, 9, 33, 42], "email_notif": [6, 33, 42], "webhook_notif": [6, 33], "notification_set": [6, 33], "schedul": [6, 33], "max_concurrent_run": [6, 9, 33], "git_sourc": [6, 26, 27, 33, 40], "access_control_list": [6, 33], "polling_period_second": [6, 16], "30": [6, 16, 27], "databricks_retry_limit": [6, 7, 35, 36, 37], "databricks_retry_delai": [6, 7, 35, 36, 37], "databricks_retry_arg": 6, "directli": [6, 33, 38, 40], "e": [6, 16, 28], "etc": 6, "merg": [6, 33, 40], "thei": [6, 16, 18, 33, 39, 40], "conflict": [6, 33, 40, 42], "take": [6, 8, 9, 11, 33, 38, 40], "preced": [6, 33, 40], "overrid": [6, 8, 9, 26, 27, 33, 40], "top": [6, 29, 30, 33, 38, 40], "level": [6, 9, 26, 27, 33, 38, 40, 42, 44], "kei": [6, 7, 11, 30, 33, 40], "templat": [6, 7, 8, 13, 14, 26, 27], "For": [6, 8, 9, 11, 20, 27, 28, 29, 30, 38, 39], "about": [6, 20, 27, 30, 45], "jinja": [6, 7, 8, 26, 27], "jobtaskset": 6, "share": [6, 33, 34, 41, 42], "reus": [6, 28], "jobclust": 6, "jobemailnotif": 6, "webhooknotif": 6, "notif": [6, 26, 27], "timeout": [6, 39], "appli": [6, 26, 27], "cronschedul": 6, "maximum": [6, 9], "concurr": [6, 9], "remot": 6, "gitsourc": 6, "accesscontrolrequestforus": 6, "accesscontrolrequestforgroup": 6, "accesscontrolrequestforserviceprincip": 6, "order": [6, 27, 29], "acl": [6, 26, 27], "consid": [6, 28], "control": [6, 8, 16, 33, 40, 42], "rate": [6, 16], "poll": [6, 16], "By": [6, 7, 16, 30], "backend": [6, 7, 27, 35, 36, 37], "unreach": [6, 7, 35, 36, 37], "Its": [6, 7], "greater": [6, 7], "than": [6, 7, 33], "equal": [6, 7], "template_field": [6, 7, 8, 13, 14, 26, 27], "sequenc": [6, 7, 8, 13, 14, 26, 27], "ui_color": 6, "1cb1c2": 6, "ui_fgcolor": 6, "fff": 6, "context": [6, 7, 8, 9, 11, 13, 14, 16, 27], "deriv": [6, 7, 8, 26, 27], "get_template_context": [6, 7, 8], "databrickssubmitrunoper": [6, 20, 26, 27, 32], "spark_jar_task": [6, 40], "notebook_task": [6, 33, 40, 41, 42], "spark_python_task": [6, 40], "spark_submit_task": [6, 40], "pipeline_task": [6, 26, 27, 40], "dbt_task": [6, 40], "new_clust": [6, 33, 34, 40], "existing_cluster_id": [6, 34, 40], "run_nam": [6, 40], "do_xcom_push": [6, 26, 27], "idempotency_token": [6, 38], "wait_for_termin": [6, 26, 27], "deferr": [6, 26, 27, 38, 40], "conf": 6, "getboolean": 6, "default_deferr": [6, 26, 27], "fallback": 6, "jobsrunssubmit": 6, "There": [6, 26, 28, 30, 33, 38, 39, 40, 42], "three": [6, 33, 40], "wai": [6, 28, 33, 38, 39, 40], "instanti": [6, 16, 33, 38, 40], "how": [6, 8, 9, 11, 27, 30], "runsubmittaskset": 6, "100": [6, 26, 27, 34], "item": 6, "main": [6, 26, 27, 30, 40, 45], "jar": [6, 9, 20, 40], "actual": [6, 35], "OR": 6, "field": [6, 7, 18, 26, 27, 28], "jobssparkjartask": 6, "jobsnotebooktask": 6, "python": [6, 9, 26, 27, 29, 30, 40], "jobssparkpythontask": 6, "jobssparksubmittask": 6, "least": [6, 26, 35], "jobspipelinetask": 6, "dbt": [6, 26, 27, 40], "spec": [6, 40], "new": [6, 20, 26, 27, 33, 38, 40, 45], "jobsclusterspecnewclust": 6, "managedlibrarieslibrari": 6, "task_id": [6, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42], "superclass": 6, "guarante": 6, "idempot": 6, "alreadi": [6, 7, 30, 35, 42], "doe": [6, 18, 26, 42, 44], "most": [6, 30], "64": 6, "charact": [6, 27], "repres": [6, 26, 27, 39], "access": [6, 28, 39], "consist": [6, 26], "subject": [6, 27], "user_nam": 6, "user": [6, 7, 21, 24, 26, 27, 28, 30, 35, 36, 37, 39, 40, 42, 44], "group_nam": 6, "group": [6, 9, 11, 42], "permission_level": 6, "document": [6, 8, 26, 27, 28, 31, 35, 38, 39], "mean": 6, "To": [6, 7, 30, 35, 36, 37, 42], "authent": [6, 7, 8, 26, 27], "leav": [6, 7, 8, 28], "empti": [6, 7, 26, 27, 28], "push": [6, 26], "git": [6, 7, 35, 37], "mode": [6, 26, 27], "template_ext": [6, 8, 13, 14, 26, 27], "tpl": 6, "operator_extra_link": [6, 11], "on_kil": [6, 8, 26, 27], "clean": [6, 8, 27], "subprocess": [6, 8], "kill": [6, 8], "thread": [6, 8], "multiprocess": [6, 8], "within": [6, 8, 11, 26, 27, 28, 33, 41, 42, 44], "ghost": [6, 8], "process": [6, 8, 16, 26, 27], "behind": [6, 8], "event": [6, 16, 18, 26, 27, 39], "databrickssubmitrundeferrableoper": [6, 32], "databricksrunnowoper": [6, 26, 27, 32], "job_paramet": [6, 26, 27], "dbt_command": [6, 26, 27], "notebook_param": [6, 9, 38, 42], "python_param": [6, 9, 38], "jar_param": [6, 9, 38], "spark_submit_param": [6, 9, 38], "python_named_param": 6, "databricks_repair_reason_new_set": 6, "cancel_previous_run": [6, 26, 27, 38], "two": [6, 20, 38], "typic": [6, 33, 38, 40], "our": [6, 27, 33, 38, 40], "through": [6, 33, 38, 40], "exampl": [6, 13, 20, 23, 24, 27, 28, 29, 30, 38], "42": 6, "dry": 6, "oldest": 6, "1457570074236": 6, "notebook_run": [6, 40], "anoth": [6, 16, 38, 40], "accomplish": [6, 33, 38, 40], "thing": [6, 33, 38, 39, 40], "exactli": [6, 33, 38, 39, 40], "your": [6, 26, 42, 44], "code": [6, 8, 26, 27, 30, 37, 42], "would": 6, "like": [6, 16, 35, 36, 37], "dep": [6, 30], "seed": 6, "dougla": 6, "adam": 6, "org": [6, 30, 34, 42], "apach": [6, 26, 30], "sparkpi": 6, "where": [6, 40, 45], "both": [6, 20, 28, 33, 40], "AND": [6, 33, 40], "togeth": [6, 8, 28, 33, 40], "python_named_paramet": [6, 38], "It": [6, 30, 38, 39, 40], "mutual": 6, "exclus": 6, "augment": 6, "accept": [6, 26, 27, 39], "supersed": 6, "en": 6, "workflow": [6, 9, 11, 26, 27, 41, 44], "add": [6, 9, 26, 27, 28], "line": [6, 27], "interfac": [6, 42], "g": [6, 16, 28], "john": 6, "ag": 6, "35": 6, "dbutil": 6, "widget": 6, "upon": 6, "conjunct": 6, "exce": 6, "10": [6, 16, 40], "000": 6, "byte": 6, "overwrit": 6, "wheel": [6, 29], "script": [6, 27, 30], "per": [6, 26, 27], "noth": 6, "databricksrunnowdeferrableoper": [6, 26, 27, 32], "databrickstaskbaseoper": 6, "job_cluster_kei": [6, 33, 41, 42], "5": [6, 29], "workflow_run_metadata": 6, "abc": [6, 13, 39], "log": [6, 11, 26, 27], "notebook_packag": [6, 9, 34, 42], "param": [6, 26, 27, 40], "expect": 6, "conn_id": [6, 9], "monitor_databricks_job": 6, "defer": [6, 16, 26, 27], "launch": [6, 11, 34, 41, 42, 44], "databricksnotebookoper": [6, 24, 26, 27, 32, 42], "part": [6, 41], "databricksworkflowtaskgroup": [6, 9, 24, 26, 27, 32, 41], "advantag": [6, 42], "cheaper": 6, "locat": [6, 8, 31], "local": [6, 30], "defin": [6, 9, 26, 27, 28, 42], "visit": 6, "jobscreat": 6, "databrickstaskoper": [6, 26, 27, 32, 42], "task_config": [6, 41, 42], "configur": [6, 8, 27, 31, 39, 44], "databricksreposcreateoper": [7, 32], "git_url": [7, 35], "git_provid": [7, 35], "branch": [7, 27, 35, 37, 45], "repo_path": [7, 21, 35, 36, 37], "ignore_existing_repo": [7, 35], "guess": [7, 35], "format": [7, 8, 23, 26, 27, 31, 39], "folder": [7, 27, 30], "directori": [7, 28, 30, 35], "checkout": [7, 35], "don": [7, 26, 27, 35], "throw": [7, 18, 35, 38], "__git_providers__": 7, "__aws_code_commit_regexp__": 7, "__repos_path_regexp__": 7, "static": [7, 27], "__detect_repo_provider__": 7, "databricksreposupdateoper": [7, 32], "patch": [7, 27], "omit": 7, "databricksreposdeleteoper": [7, 32], "databrickssqloper": [8, 23, 26, 27, 28, 32], "output_path": [8, 39], "output_format": [8, 39], "csv": 8, "csv_param": 8, "client_paramet": [8, 13, 14], "sqlexecutequeryoper": [8, 26, 27], "recogn": 8, "end": [8, 27], "write": 8, "select": [8, 23, 30], "possibl": [8, 27, 42], "jsonl": [8, 39], "dictwrit": 8, "template_fields_render": [8, 13, 14], "classvar": 8, "conn_id_field": 8, "get_db_hook": 8, "copy_into_approved_format": 8, "avro": [8, 31], "orc": [8, 31], "parquet": [8, 31], "text": [8, 31], "binaryfil": [8, 31], "databrickscopyintooper": [8, 23, 26, 27, 32], "table_nam": [8, 13, 31, 39], "file_loc": [8, 23, 31], "file_format": [8, 31], "pattern": 8, "expression_list": 8, "storage_credenti": 8, "encrypt": 8, "format_opt": [8, 31], "force_copi": [8, 31], "copy_opt": 8, "valid": [8, 18, 26, 27, 30], "copi": [8, 31], "INTO": [8, 31], "piec": 8, "import": [8, 26, 27, 30], "regex": 8, "against": [8, 39], "uniti": 8, "storag": 8, "destin": 8, "forc": 8, "integ": [8, 35, 36, 37], "n": 8, "right": 8, "workflowrunmetadata": 9, "existing_clust": 9, "extra_job_param": [9, 42], "task_group": [9, 11, 24, 42], "taskgroup": [9, 11], "produc": [9, 42], "those": [9, 29, 30], "elig": 9, "_convert_to_databricks_workflow_task": 9, "pars": 9, "definit": [9, 20, 27, 42], "These": 9, "packag": [9, 26, 28, 34, 41, 42], "under": [9, 33], "And": 9, "is_databrick": 9, "__exit__": 9, "_type": 9, "_valu": 9, "_tb": 9, "exit": 9, "_createdatabricksworkflowoper": 9, "repair_wait_attempt": 11, "repair_wait_delai": 11, "airflow_app": 11, "get_auth_decor": 11, "get_databricks_task_id": 11, "group_id": [11, 24, 42], "task_map": 11, "logger": [11, 27], "get_launch_task_id": 11, "parent": [11, 26, 27], "recurs": 11, "inspect": 11, "get_task_inst": 11, "new_sess": 11, "get_xcom_result": 11, "workflowjobrunlink": 11, "logging_mixin": 11, "loggingmixin": 11, "workflowjobrepairallfailedlink": 11, "send": 11, "get_task_group_children": 11, "children": 11, "get_tasks_to_run": 11, "workflowjobrepairsingletasklink": 11, "repairdatabrickstask": 11, "www": [11, 26, 27], "view": [11, 26, 27, 44], "airflowbaseview": 11, "default_view": 11, "dag_id": [11, 20, 21, 22, 23], "repair_databricks_view": 11, "repair_databricks_packag": 11, "databricksworkflowplugin": [11, 26, 27, 43], "plugins_manag": 11, "airflowplugin": 11, "appbuilder_view": 11, "databrickspartitionsensor": [13, 26, 27, 32], "sql_warehouse_nam": [13, 14, 39], "partit": [13, 39], "partition_oper": [13, 39], "fetch_all_handl": [13, 14], "basesensoroper": [13, 14], "detect": [13, 26, 27, 33, 40, 44], "presenc": [13, 39], "warehous": [13, 14, 39], "below": [13, 14, 29, 30], "purpos": [13, 14, 42], "date": [13, 39], "2023": [13, 27, 39], "01": [13, 27, 39], "03": [13, 27, 39], "def": [13, 39], "comparison": [13, 27, 39], "poke": [13, 14, 39], "databrickssqlsensor": [14, 26, 27, 32], "databricksexecutiontrigg": [16, 18], "basetrigg": 16, "logic": 16, "commun": 16, "serial": [16, 26, 27], "reconstruct": 16, "keyword": 16, "yield": [16, 26, 27], "whenev": [16, 42], "fire": 16, "off": 16, "finish": [16, 39], "thu": 16, "immedi": 16, "resum": 16, "veri": 16, "quickli": 16, "mai": [16, 27, 28, 40], "workload": [16, 26, 27, 28], "move": [16, 26, 27], "multi": [16, 26, 27], "assum": 16, "persist": 16, "reli": [16, 26, 33], "cleanup": [16, 27], "longer": 16, "normalise_json_cont": 18, "json_path": 18, "normal": [18, 27], "numer": 18, "boolean": [18, 26, 27, 28], "why": [18, 30], "becaus": [18, 20, 33, 40, 42], "render_templ": 18, "convert": [18, 26, 27], "understand": 18, "validate_trigger_ev": 18, "correct": [18, 26, 27, 30], "receiv": [18, 45], "dag": [20, 23, 24, 26, 27, 41], "upload": 20, "dbf": [20, 40], "downstream": [20, 39], "depend": [20, 26, 27, 38, 45], "NOT": 20, "until": [20, 39], "complet": [20, 26], "successfulli": 20, "env_id": [20, 21, 22, 23], "example_databricks_oper": 20, "query_id": [20, 24, 41, 42], "warehouse_id": [20, 24, 41, 42], "test_run": [20, 21, 22, 23, 24], "default_arg": [21, 27], "example_databricks_repos_oper": 21, "domain": [21, 35, 36, 37], "demo": [21, 35, 36, 37], "connection_id": [22, 23, 31, 39], "insert": [23, 39], "third": [23, 33], "store": [23, 39], "fourth": 23, "written": 23, "final": [23, 26, 27], "example_databricks_sql_oper": 23, "my_connect": 23, "databricks_notification_email": [24, 42], "job_cluster_spec": [24, 42], "example_databrick": [25, 33, 34, 40, 41], "example_databricks_repo": [25, 35, 36, 37], "example_databricks_sensor": [25, 39], "example_databricks_sql": [25, 31, 39], "example_databricks_workflow": [25, 42], "airflow": [26, 28, 30, 34, 35, 36, 37, 38, 40, 41, 44, 45], "provid": [26, 30, 35, 36, 37, 40, 44, 45], "databrick": [26, 30, 31, 33, 38, 39, 40, 44], "42668": [26, 27], "ad": [26, 27, 28], "43895": [26, 27], "41639": [26, 27], "semicolon": [26, 27], "strip": [26, 27], "prestohook": [26, 27], "trinohook": [26, 27], "41916": [26, 27], "timeouterror": [26, 27], "retryabl": [26, 27], "43137": [26, 27], "clientconnectorerror": [26, 27], "43091": [26, 27], "work": [26, 27, 28, 44], "clientrespons": [26, 27], "43333": [26, 27], "respect": [26, 27, 39], "42618": [26, 27], "42115": [26, 27], "warn": [26, 27, 30], "task_kei": [26, 27, 33], "42813": [26, 27], "debug": [26, 27], "print": [26, 27], "42662": [26, 27], "feat": [26, 27], "appropri": [26, 27], "41412": [26, 27], "has_access": [26, 27], "min": [26, 27], "41747": [26, 27], "soft_fail": [26, 27], "41710": [26, 27], "avail": [26, 30, 34, 40], "explain": 26, "polici": [26, 45], "bump": [26, 27], "minimum": [26, 27, 29], "41396": [26, 27], "revert": [26, 27], "some": [26, 27], "around": 26, "40724": [26, 27], "databricksplugin": [26, 27], "redirect": [26, 27], "url_for": [26, 27], "41040": [26, 27], "40864": [26, 27], "pr": [26, 27], "40471": [26, 27], "41050": [26, 27], "make": [26, 27], "40332": [26, 27], "40013": [26, 27], "39771": [26, 27], "40178": [26, 27], "implement": [26, 27], "lowest": [26, 27], "direct": [26, 27], "resolut": [26, 27], "39946": [26, 27], "lower": [26, 27], "info": [26, 27], "reduc": [26, 27], "verbos": [26, 27], "39941": [26, 27], "panda": [26, 27, 29], "40272": [26, 27], "39295": [26, 27], "39354": [26, 27], "faster": [26, 27], "airflow_vers": [26, 27], "39552": [26, 27], "simplifi": [26, 27], "39497": [26, 27], "better": [26, 27], "39742": [26, 27], "39178": [26, 27], "39175": [26, 27], "39110": [26, 27], "39240": [26, 27], "38702": [26, 27], "38619": [26, 27], "38962": [26, 27], "remain": [26, 27], "d401": [26, 27], "37434": [26, 27], "38741": [26, 27], "slash": [26, 27], "38918": [26, 27], "typo": [26, 27], "latest_repair_id": 26, "39050": [26, 27], "refactor": [26, 27], "redund": [26, 27], "38397": [26, 27], "renam": [26, 27], "compli": [26, 27], "38052": [26, 27], "37025": [26, 27], "avoid": [26, 27], "cve": [26, 27], "2024": [26, 27], "23829": [26, 27], "23334": [26, 27], "37110": [26, 27], "switch": [26, 27, 28], "class": [26, 27, 28, 29, 31, 39, 40], "decor": [26, 27], "36876": [26, 27], "rid": [26, 27], "pytest": [26, 27], "httpx": [26, 27], "37334": [26, 27], "36601": [26, 27], "36827": [26, 27], "column": [26, 27], "attribut": [26, 27], "36949": [26, 27], "36862": [26, 27], "structur": [26, 27, 42], "dbapi": [26, 27], "36205": 26, "fetchon": [26, 27], "odbchook": [26, 27], "36161": [26, 27], "36017": [26, 27], "36248": [26, 27], "snippet": [26, 27], "docstr": [26, 27], "via": [26, 27, 29, 30, 35, 36, 37, 38, 39, 40, 42], "ruff": [26, 27], "36262": [26, 27], "been": 26, "broken": [26, 27], "pyodbc": [26, 27], "serializ": [26, 27], "make_serializ": [26, 27], "32319": [26, 27], "offset": [26, 27], "favor": 26, "pagin": [26, 27], "similarli": 26, "34926": [26, 27], "35156": [26, 27], "34643": [26, 27], "34544": [26, 27], "34517": [26, 27], "decod": [26, 27], "f": [26, 27, 42], "34518": [26, 27], "34728": [26, 27], "httpbasicauth": [26, 27], "34590": [26, 27], "33472": [26, 27], "deploy": [26, 27, 44], "33886": [26, 27], "32903": [26, 27], "replac": [26, 27], "concaten": [26, 27], "unpack": [26, 27], "33933": [26, 27], "improv": [26, 27], "modul": [26, 27], "33754": [26, 27], "liter": [26, 27], "33761": [26, 27], "33752": [26, 27], "exclud": [26, 27], "due": [26, 27], "properli": [26, 44], "declar": 26, "urllib3": 26, "github": [26, 27, 35], "issu": 26, "190": 26, "princip": [26, 27, 28], "oauth": [26, 27, 28], "33005": [26, 27], "py": [26, 27, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42], "32340": [26, 27], "33519": [26, 27], "duplic": [26, 27], "sort": [26, 27], "33675": [26, 27], "condit": [26, 27], "len": [26, 27], "33569": [26, 27], "smaller": [26, 27], "33234": [26, 27], "conn": [26, 27], "30784": [26, 27], "32806": [26, 27], "miss": [26, 27], "32689": [26, 27], "accur": [26, 27], "31846": [26, 27], "modifi": [26, 27, 42], "32253": [26, 27], "config": [26, 27], "31712": [26, 27], "drop": [26, 27, 30, 39], "loop": [26, 27], "stop": [26, 27], "31985": [26, 27], "annot": [26, 27], "31888": [26, 27], "31780": [26, 27], "relat": [26, 27, 28, 39], "again": [26, 27], "31898": [26, 27], "31899": [26, 27], "31703": [26, 27], "30963": [26, 27], "31136": [26, 27], "31038": [26, 27], "databr": [26, 27], "30744": [26, 27], "30786": [26, 27], "30980": [26, 27], "30917": [26, 27], "30761": [26, 27], "inact": [26, 27], "30646": [26, 27], "30477": [26, 27], "taskflow": [26, 27], "29840": [26, 27], "conform": 26, "semant": 26, "kind": 26, "previous": 26, "pre": [26, 27], "cursor": 26, "just": 26, "last_descript": 26, "suitabl": 26, "gener": [26, 27, 28, 39], "lineag": 26, "analysi": 26, "had": 26, "custom": [26, 44], "behaviour": [26, 27], "adapt": 26, "standard": [26, 27, 34], "approach": [26, 33, 40], "howev": [26, 44], "unchang": 26, "continu": 26, "without": 26, "introduc": [26, 27, 38, 40], "27854": [26, 27], "27888": [26, 27], "27868": [26, 27], "27912": [26, 27], "databricskssqloper": 26, "27196": [26, 27], "urlpars": [26, 27], "urlsplit": [26, 27], "27389": [26, 27], "25717": [26, 27], "27446": [26, 27], "25623": [26, 27], "bound": [26, 27], "25789": [26, 27], "26628": [26, 27], "agent": [26, 27], "25873": [26, 27], "25578": [26, 27], "25260": [26, 27], "telemetri": [26, 27], "25115": [26, 27], "unifi": [26, 27], "23971": [26, 27], "25114": [26, 27], "deep_string_coerc": [26, 27], "25394": [26, 27], "correctli": [26, 27], "25427": [26, 27], "x": [26, 27, 33, 34, 40], "25674": [26, 27], "24945": [26, 27], "24617": [26, 27], "24836": [26, 27], "functool": [26, 27], "cached_properti": [26, 27], "24582": [26, 27], "19736": [26, 27], "23620": [26, 27], "23622": [26, 27], "23641": [26, 27], "unboundlocalerror": [26, 27], "23815": [26, 27], "dbsql": [26, 27], "further": [26, 27], "23199": [26, 27], "22422": [26, 27], "22541": [26, 27], "22886": [26, 27], "22885": [26, 27], "hoc": [26, 27], "22571": [26, 27], "22278": [26, 27], "mistakenli": 26, "install_requir": 26, "22382": 26, "22076": [26, 27], "429": [26, 27], "well": [26, 27, 30, 41], "21852": [26, 27], "22221": [26, 27], "show": [26, 27], "21709": [26, 27], "21663": [26, 27], "18925": [26, 27], "21530": [26, 27], "21363": [26, 27], "januari": [26, 27], "2022": [26, 27], "delai": [26, 27], "21439": [26, 27], "21494": [26, 27], "20536": [26, 27], "20526": [26, 27], "attr": [26, 27], "20540": [26, 27], "verif": [26, 27], "20550": [26, 27], "19723": [26, 27], "sp": [26, 27], "cloud": [26, 27, 28], "19722": [26, 27], "pat": [26, 27, 28], "password": [26, 27, 28], "19585": [26, 27], "19544": [26, 27], "19412": [26, 27], "aad": [26, 27, 28], "19335": [26, 27], "19443": [26, 27], "db": [26, 27], "__init__": [26, 27], "20180": [26, 27], "fixup": [26, 27], "19099": [26, 27], "expir": [26, 27], "20036": [26, 27], "18339": [26, 27], "optimis": 26, "auto": [26, 27], "apply_default": [26, 27], "15667": [26, 27], "upgrad": [26, 27, 45], "automat": [26, 27, 44], "manual": 26, "migrat": [26, 27], "readm": [26, 27], "chang": [27, 45], "high": 27, "changelog": 27, "e7194dff6a": 27, "aa2a937e5c": 27, "e7b493712d": 27, "a0a3b8a50f": 27, "06": 27, "d8c7d28411": 27, "port": 27, "sdk": 27, "43076": 27, "27": [27, 29], "78ff0a9970": 27, "prepar": [27, 45], "oct": 27, "2nd": 27, "wave": 27, "43409": 27, "7e56dac75c": 27, "fix": [27, 45], "8e9db955f6": 27, "21": 27, "0de5587894": 27, "18": [27, 34, 42], "3ca80dd9a4": 27, "17": 27, "857ca4c06c": 27, "09": 27, "tree": 27, "uv": 27, "project": [27, 40], "42505": 27, "2bb8628463": 27, "1st": 27, "adhoc": 27, "42862": 27, "c377e7fceb": 27, "08": 27, "5d51beee35": 27, "9b90d2f216": 27, "7628d47d04": 27, "sep": [27, 30], "42387": 27, "365b42f5a1": 27, "8765039214": 27, "1613e9ec1c": 27, "19": 27, "75fb7acbac": 27, "aug": 27, "41559": 27, "fcbff15bda": 27, "d23881c648": 27, "41230": 27, "4535e08b86": 27, "07": [27, 42], "dd10f472c5": 27, "26": 27, "cfe1d53ed0": 27, "fded2d8969": 27, "dd6ee34775": 27, "40153": 27, "40714": 27, "22ec726063": 27, "09a7bd1d58": 27, "juli": 27, "40644": 27, "4fb2140f39": 27, "02": 27, "a62bd83188": 27, "enforc": 27, "pydocstyl": 27, "rule": [27, 45], "d213": 27, "40448": 27, "de5c751cff": 27, "22": 27, "bug": [27, 45], "6e5ae26382": 27, "june": 27, "40273": 27, "81c331e29a": 27, "a1f9b7de28": 27, "14": [27, 29], "68bd42a7ff": 27, "04": 27, "c0f27094ab": 27, "5aa43e2a03": 27, "05": 27, "31": 27, "checklist": 27, "39965": 27, "f0ea079594": 27, "2ecf7fa07d": 27, "34500f3a2f": 27, "3rd": 27, "39738": 27, "f18e6340d8": 27, "1e4663f34c": 27, "2b1a2f8d56": 27, "reappli": 27, "39554": 27, "2c05187b07": 27, "73918925ed": 27, "2d103e115c": 27, "fe4605a10": 27, "39328": 27, "42dbccaac2": 27, "7683344c9c": 27, "ead9b00f7c": 27, "04ac0c1b32": 27, "23": 27, "paramat": 27, "16": 27, "13df6569d6": 27, "rc3": 27, "april": 27, "38995": 27, "39054": 27, "66df296a6e": 27, "629545bea2": 27, "f9dcc82fb6": 27, "rc2": 27, "4a669fb1a9": 27, "5fa80b6aea": 27, "rc1": 27, "38863": 27, "6f21f7dc9b": 27, "4e6d3fa4cf": 27, "39b684d91a": 27, "c74947a69d": 27, "b5b972a106": 27, "yank": 27, "38262": 27, "0a74928894": 27, "38240": 27, "aa75fbb2b8": 27, "restor": 27, "38207": 27, "4742fc0ea5": 27, "15": 27, "8fc984873a": 27, "38070": 27, "83316b8158": 27, "march": 27, "37876": 27, "14d9bff3ad": 27, "24": 27, "37665": 27, "5a0be392e6": 27, "comment": 27, "37488": 27, "e346253760": 27, "bfb054e9e8": 27, "februari": 27, "37326": 27, "78294c24e2": 27, "0c4210af62": 27, "6d748c923b": 27, "dec2662190": 27, "cead3da4a6": 27, "round": 27, "jan": 27, "37019": 27, "0b680c9492": 27, "logger_nam": 27, "36675": 27, "37015": 27, "c0f7601391": 27, "347373986c": 27, "2b4da0101f": 27, "36945": 27, "13b0930bf4": 27, "574102fd29": 27, "c439ab87c4": 27, "build": [27, 30], "hatchl": 27, "36537": 27, "6bd450da1e": 27, "f7b663d9af": 27, "mypi": 27, "full": [27, 33, 40], "ci": 27, "36638": 27, "19ebcac239": 27, "36640": 27, "6937ae7647": 27, "speed": 27, "autocomplet": 27, "breez": 27, "36499": 27, "77b563bfc5": 27, "break": [27, 45], "36382": 27, "b15d5578da": 27, "decemb": 27, "36380": 27, "f5883d6e7b": 27, "36373": 27, "5fe5d31a46": 27, "322aa649": 27, "e9ba37bb58": 27, "64931b1a65": 27, "36190": 27, "36010f6d0e": 27, "999b70178a": 27, "36112": 27, "d0918d77ee": 27, "0b23d5601c": 27, "novemb": 27, "35836": 27, "99534e47f3": 27, "reproduc": 27, "35693": 27, "064fc2b775": 27, "99df205f42": 27, "35686": 27, "1b059c57d6": 27, "35537": 27, "706878ec35": 27, "35436": 27, "052e26ad47": 27, "secur": [27, 28], "rst": 27, "35435": 27, "70b3bd3fb9": 27, "httpoper": [27, 28], "modular": 27, "34669": 27, "10bac853d2": 27, "28": 27, "d1c58d86de": 27, "octob": 27, "35233": 27, "3592ff4046": 27, "35187": 27, "a8784e3c35": 27, "dd7ba3cae1": 27, "292": 27, "35053": 27, "7a93b19138": 27, "daskexecutor": 27, "inclus": 27, "34935": 27, "e9987d5059": 27, "34916": 27, "946b539f0d": 27, "0c8e30e43b": 27, "7ebf4220c9": 27, "usag": [27, 31, 33, 35, 36, 37, 39, 40], "34320": 27, "a1ef232230": 27, "f26fa6d602": 27, "3813ed69c7": 27, "966c2bce9f": 27, "dfec053371": 27, "21990ed894": 27, "34201": 27, "c45617c4d5": 27, "55976af32": 27, "concatin": 27, "f7a005db8c": 27, "9d8c77e447": 27, "b11525702c": 27, "c90eec9365": 27, "c077d19060": 27, "33730": 27, "dc47c460dc": 27, "4154cc04ce": 27, "2dbb963324": 27, "1cdd82391e": 27, "a91ee7ac2f": 27, "20": [27, 29], "8bf53dd554": 27, "5f8f25b34c": 27, "ecldud": 27, "33311": 27, "b5a4d36383": 27, "33291": 27, "9736143468": 27, "29": 27, "d06b7af69a": 27, "32875": 27, "58e21c66fd": 27, "6313e52932": 27, "73b90c48b1": 27, "contribut": 27, "32604": 27, "60c49ab2df": 27, "225e3041d2": 27, "32381": 27, "3878fe6fab": 27, "spuriou": 27, "32373": 27, "cb4927a018": 27, "32298": 27, "f8593503cb": 27, "6b4350e89c": 27, "d1aa509bbd": 27, "d205": 27, "32243": 27, "09d4718d3a": 27, "32125": 27, "79bcc2e668": 27, "32001": 27, "8b146152d6": 27, "32015": 27, "69bc90b824": 27, "66299338eb": 27, "7b096483fa": 27, "049c6184b7": 27, "9276310a43": 27, "31681": 27, "86b5ba2802": 27, "dc5bf3fd02": 27, "discover": 27, "yaml": 27, "31576": 27, "a59076eae": 27, "d400": 27, "31427": 27, "9fa75aaf7a": 27, "45548b9451": 27, "31416": 27, "abea189022": 27, "31393": 27, "f5aed58d9f": 27, "circular": 27, "caus": 27, "31379": 27, "7ebda3898d": 27, "index": [27, 42], "31343": 27, "d9ff55cf6d": 27, "31252": 27, "fdc7a31aeb": 27, "edd7133a13": 27, "3df0be0f6f": 27, "ac46902154": 27, "31033": 27, "0a30706aa7": 27, "airflowproviderdeprecationwarn": 27, "30975": 27, "eef5bc7f16": 27, "autom": 27, "30994": 27, "a7eb32a5b2": 27, "9409446097": 27, "cli": 27, "cmd": 27, "30822": 27, "ecb9a9ea78": 27, "9bebf85e24": 27, "7d02277ae1": 27, "e46ce78b66": 27, "30787": 27, "37cf0506b5": 27, "1e311cf036": 27, "d23a3bbed8": 27, "mechan": 27, "suspend": 27, "30422": 27, "55dbf1ff1f": 27, "30378": 27, "c3867781e0": 27, "29950": 27, "c405ecb63": 27, "2b92c3c74d": 27, "28754": 27, "c8e348dcb0": 27, "28090": 27, "25bdbc8e67": 27, "27937": 27, "db5375bea7": 27, "2e20e9f7eb": 27, "relas": 27, "27774": 27, "80c327bd3b": 27, "ea306c9462": 27, "a343bba1e3": 27, "12c3c39d1a": 27, "27613": 27, "00af5c007": 27, "eb06c65556": 27, "9ab1a6a3e7": 27, "style": 27, "26872": 27, "c8b2737ab1": 27, "27269": 27, "78b8ea2f22": 27, "2a34dc9e84": 27, "27205": 27, "ecd4d6654f": 27, "f8db64c35c": 27, "septemb": 27, "26731": 27, "89e44c46ad": 27, "06acf40a43": 27, "pep": 27, "563": 27, "postpon": 27, "evalu": 27, "26289": 27, "5066844513": 27, "period": 27, "batch02": 27, "25268": 27, "25a9c6a905": 27, "9535ec0bba": 27, "ca9229b6f": 27, "7d0525a55b": 27, "rc4": 27, "25720": 27, "4d32f61fd0": 27, "e5ac6c7cfb": 27, "august": 27, "25618": 27, "52f2f5bfa8": 27, "0255a0a5e7": 27, "679a85325a": 27, "6ef15840d5": 27, "recommend": [27, 28, 30, 42], "login": [27, 28], "25435": 27, "82f842ffc5": 27, "24599": 27, "54a8c4fd2a": 27, "7438707747": 27, "df00436569": 27, "2f70daf5ac": 27, "d2459a241b": 27, "25030": 27, "8dfe7bf5ff": 27, "acaa0635c8": 27, "lazi": 27, "interpol": 27, "24910": 27, "46bbfdade0": 27, "96b01a8012": 27, "bad": 27, "codebas": 27, "24841": 27, "0de31bd73a": 27, "insid": [27, 28], "24672": 27, "510a6bab45": 27, "24702": 27, "ed37c3a0e8": 27, "9c59831ee7": 27, "08b675cf66": 27, "24386": 27, "dcdcf3a2b8": 27, "24307": 27, "717a7588bc": 27, "doubl": 27, "24292": 27, "aeabe994b3": 27, "24231": 27, "027b707d21": 27, "explanatori": 27, "contributor": [27, 28], "24229": 27, "ddf9013098": 27, "aip": 27, "47": 27, "design": [27, 39], "22442": 27, "24203": 27, "acf89510cd": 27, "92ddcf4ac6": 27, "flake8": 27, "implicit": 27, "concat": 27, "23873": 27, "6150d28323": 27, "cf5a78e91c": 27, "d0a5b3a4f2": 27, "75c60923e0": 27, "23631": 27, "428a439953": 27, "23591": 27, "a58506b2a6": 27, "address": 27, "review": 27, "6a3d6cc32b": 27, "7b3bf4e435": 27, "f02b0b6b40": 27, "8b6b0848a3": 27, "brees": 27, "pull": 27, "verifi": [27, 29], "imag": 27, "23104": 27, "40831144be": 27, "22979": 27, "7be57eb256": 27, "aa8c08db38": 27, "6933022e94": 27, "22884": 27, "56ab82ed7a": 27, "mid": 27, "22819": 27, "1b12c93ed3": 27, "95169d1d07": 27, "352d7f72dd": 27, "c063fc688c": 27, "black": 27, "precommit": 27, "22521": 27, "d7dbfb7e26": 27, "bugfix": [27, 45], "22383": 27, "cc920963a6": 27, "16adc035b1": 27, "classifi": 27, "22226": 27, "12e9e2c695": 27, "af9d85ccd8": 27, "4014194320": 27, "f5b96315fe": 27, "feb": 27, "22056": 27, "62bf1276f6": 27, "d9017a0005": 27, "21886": 27, "27d19e7626": 27, "a1845c68f9": 27, "7cca82495b": 27, "0a2d0d1ecb": 27, "d94fa37830": 27, "6c3a67d4fc": 27, "2021": [27, 30], "21257": 27, "602abe8394": 27, "sphinx": 27, "autoapi": 27, "typehint": 27, "20951": 27, "f77417eb0d": 27, "k8": 27, "pypi": [27, 29, 34, 41, 42, 45], "20614": 27, "97496ba2b4": 27, "20523": 27, "0bf424f37f": 27, "20598": 27, "d56e7b56bb": 27, "friendli": 27, "20571": 27, "a0821235fb": 27, "everywher": 27, "20565": 27, "c5c18c54fa": 27, "d3b3161f0d": 27, "58afc19377": 27, "e7659d08b0": 27, "cad39274d9": 27, "20265": 27, "820bfed515": 27, "20205": 27, "66f94f95c2": 27, "545ca59ba9": 27, "unhid": 27, "entri": 27, "20128": 27, "637db1a0ba": 27, "20086": 27, "728e94a47": 27, "19835": 27, "4925b37b66": 27, "43de625d42": 27, "capit": 27, "abbrevi": 27, "19908": 27, "853576d901": 27, "19882": 27, "11998848a4": 27, "56bdfe7a84": 27, "244627e3da": 27, "0a4a8bdb94": 27, "8ae878953b": 27, "28b51fb7bd": 27, "3a0c455855": 27, "d9567eb106": 27, "19321": 27, "f5ad26dcdd": 27, "840ea3efb9": 27, "18613": 27, "ef037e7021": 27, "start_dat": 27, "misc": 27, "18597": 27, "0b7b13372f": 27, "1cb456cba1": 27, "offici": [27, 30], "download": [27, 30], "18187": 27, "046f02e5a7": 27, "misspel": 27, "18121": 27, "0a68588479": 27, "17890": 27, "be75dcd39c": 27, "meta": 27, "76ed2a49c6": 27, "lazili": 27, "17682": 27, "87f408b1e7": 27, "17116": 27, "b916b75079": 27, "17015": 27, "866a601b76": 27, "pylint": 27, "toolchain": 27, "16682": 27, "bbc627a3da": 27, "16501": 27, "cbf8001d76": 27, "synchron": 27, "buggfix": 27, "16464": 27, "1fba5402bb": 27, "16405": 27, "9c94b72d44": 27, "16294": 27, "1e647029e4": 27, "16149": 27, "37681bca00": 27, "807ad32ce5": 27, "pip": [27, 29, 30], "15576": 27, "df143aee8d": 27, "rework": 27, "15444": 27, "49cae1f052": 27, "15410": 27, "68e4c4dcb0": 27, "backport": 27, "14886": 27, "88bdcfa0df": 27, "14013": 27, "ac2f72c98d": 27, "13767": 27, "a9ac2b040b": 27, "flynt": 27, "13732": 27, "3fd5ef3555": 27, "logo": 27, "integr": [27, 28], "13717": 27, "295d66f914": 27, "2020": 27, "grammar": 27, "13380": 27, "6cf76d7ac0": 27, "13148": 27, "f6448b4e48": 27, "13064": 27, "32971a1a2d": 27, "12955": 27, "b40dffa085": 27, "rema": 27, "12917": 27, "9b39f24780": 27, "dynam": 27, "form": 27, "12558": 27, "bd90136aaf": 27, "12681": 27, "f2569de7d1": 27, "12528": 27, "c34ef853c8": 27, "12444": 27, "0080354502": 27, "0b2": 27, "12449": 27, "7ca0b6f121": 27, "markdownlint": 27, "md003": 27, "head": 27, "12427": 27, "12438": 27, "ae7cb4a1e2": 27, "wrong": 27, "hash": 27, "12390": 27, "6889a333cf": 27, "ref": 27, "12366": 27, "7825e8f590": 27, "12304": 27, "b027223132": 27, "12316": 27, "85a18e13d9": 27, "cross": 27, "12212": 27, "59eb5de78c": 27, "come": 27, "0beta1": 27, "12206": 27, "b2a28d1590": 27, "12082": 27, "7e0d08e1f0": 27, "12175": 27, "4e8f9cc8d0": 27, "formmatt": 27, "9550": 27, "8c42cf1b00": 27, "pyupgrad": 27, "11447": 27, "5a439e84eb": 27, "2a1": 27, "11855": 27, "872b1566a1": 27, "setup": [27, 39], "11826": 27, "349b0811c3": 27, "d200": 27, "11688": 27, "16e7129719": 27, "11487": 27, "0a0e1af800": 27, "markdown": 27, "toc": 27, "11249": 27, "ca4238eb4d": 27, "month": 27, "11242": 27, "5220e4c384": 27, "11238": 27, "54353f8745": 27, "increas": 27, "coverag": 27, "five": 27, "differ": [27, 28, 30], "11170": 27, "966a06d96b": 27, "fetch": 27, "suppli": [27, 39], "10762": 27, "9549274d11": 27, "8b1": 27, "10818": 27, "fdd9b6f65b": 27, "10543": 27, "bfefcce0c9": 27, "rest": [27, 33, 40], "10462": 27, "3696c34c28": 27, "word": 27, "10528": 27, "2f2d8dbfaf": 27, "noinspect": 27, "nativ": 27, "intellij": 27, "10525": 27, "ee7ca128a1": 27, "refernc": 27, "10483": 27, "cdec301254": 27, "10205": 27, "7d24b088cd": 27, "example_dag": 27, "9985": 27, "e13a14c873": 27, "whitespac": 27, "9458": 27, "d0e7db4024": 27, "fresh": 27, "9408": 27, "12af6a0800": 27, "23rc1": 27, "9404": 27, "c7e5bce57f": 27, "candid": 27, "9370": 27, "f6bd817a3a": 27, "transfer": 27, "9320": 27, "0b0e4f7a4c": 27, "9026": 27, "00642a46d0": 27, "wrongli": 27, "8994": 27, "f1073381ed": 27, "8846": 27, "375d1ca229": 27, "8898": 27, "12c5e5d8a": 27, "8891": 27, "f3521fb0e3": 27, "regener": 27, "8886": 27, "92585ca4cb": 27, "8807": 27, "649935e8c": 27, "8472": 27, "_do_api_cal": 27, "8473": 27, "16903ba3a6": 27, "8474": 27, "8475": 27, "5648dfbc30": 27, "super": 27, "amazon": 27, "cloudant": 27, "7827": 27, "3320e432a1": 27, "6817": 27, "keep": [27, 42], "face": 27, "untouch": 27, "7517": 27, "4d03e33c11": 27, "explicit": 27, "md": 27, "squash": 27, "rebas": 27, "7456": 27, "97a429f9d0": 27, "6714": 27, "magic": 27, "utf": 27, "7338": 27, "83c037873f": 27, "6674": [27, 30], "accord": 27, "7287": 27, "c42a375e79": 27, "6644": 27, "7265": 27, "sever": 28, "person": 28, "usernam": 28, "account": [28, 31, 44], "discourag": 28, "secret": 28, "outsid": [28, 42, 44], "owner": [28, 30], "vm": 28, "assign": 28, "sent": 28, "basic": 28, "plan": 28, "aw": 28, "necessari": 28, "service_principal_oauth": 28, "client": 28, "azure_tenant_id": 28, "tenant": 28, "azure_resource_id": 28, "resourc": 28, "isn": [28, 36, 37, 38], "azure_ad_endpoint": 28, "special": [28, 39], "govcloud": 28, "china": 28, "germani": 28, "protocol": 28, "microsoftonlin": 28, "de": 28, "use_azure_managed_ident": 28, "defaultazurecredenti": 28, "kubernet": 28, "uri": [28, 31], "syntax": 28, "export": 28, "airflow_conn_databricks_default": 28, "yourtoken": 28, "8": [29, 34, 40], "4": 29, "mergedeep": 29, "python_vers": 29, "pyarrow": 29, "checksum": [29, 30], "site": 29, "sdist": [29, 30], "asc": [29, 30], "sha512": [29, 30], "choos": 30, "down": 30, "left": 30, "whl": 30, "origin": 30, "softwar": 30, "foundat": 30, "pgp": 30, "essenti": 30, "sha": 30, "gpg": 30, "relev": [30, 44], "distribut": 30, "mirror": 30, "pgpk": 30, "ka": 30, "binari": 30, "pgpv": 30, "tar": 30, "gz": 30, "made": 30, "sat": 30, "11": [30, 34, 40], "12": [30, 33, 34, 40], "49": 30, "54": 30, "bst": 30, "rsa": 30, "cde15c6e4d3a8ec4ecf4ba4b6674e08ad7de406f": 30, "issuer": 30, "kaxilnaik": 30, "good": [30, 45], "kaxil": 30, "naik": 30, "aka": 30, "gmail": 30, "certifi": 30, "trust": 30, "indic": 30, "belong": 30, "primari": 30, "fingerprint": 30, "cde1": 30, "5c6e": 30, "4d3a": 30, "8ec4": 30, "ecf4": 30, "ba4b": 30, "e08a": 30, "d7de": 30, "406f": 30, "worri": 30, "certif": 30, "sign": 30, "server": 30, "previou": 30, "step": 30, "know": 30, "sum": 30, "shasum": 30, "512": 30, "diff": 30, "bin": [30, 34], "bash": 30, "package_vers": 30, "package_nam": 30, "provider_download_dir": 30, "mktemp": 30, "d": [30, 42], "dest": 30, "curl": 30, "apache_airflow_providers_databrick": 30, "py3": 30, "l": 30, "o": 30, "echo": 30, "la": 30, "onc": 30, "instruct": [30, 45], "chapter": 30, "temporari": 30, "One": [31, 39], "copy_into": 31, "import_csv": 31, "my_tabl": 31, "abfss": 31, "df": 31, "my": 31, "past": 33, "rememb": 33, "repeat": 33, "rather": 33, "ones": 33, "fall": 33, "With": [33, 40, 42], "over": [33, 40], "underli": [33, 40], "harder": [33, 40], "lack": [33, 40], "spark_vers": [33, 34, 40], "7": 33, "scala2": [33, 34, 40], "node_type_id": [33, 34, 40], "i3": [33, 34], "xlarg": [33, 34, 40], "num_work": [33, 34, 40], "jobs_create_json": 33, "jobs_create_nam": 33, "return_valu": 33, "ti": 33, "xcom_pul": 33, "new_cluster_spec": 34, "cluster_nam": 34, "aws_attribut": [34, 40], "first_on_demand": 34, "spot_with_fallback": 34, "zone_id": 34, "u": 34, "east": 34, "2b": 34, "spot_bid_price_perc": 34, "ebs_volume_count": 34, "spark_env_var": 34, "pyspark_python": 34, "python3": 34, "enable_elastic_disk": 34, "data_security_mod": 34, "legacy_single_user_standard": 34, "runtime_engin": 34, "notebook_1": [34, 41, 42], "simplejson": [34, 41, 42], "simpl": [34, 39, 42], "faker": [34, 41, 42], "notebook_2": [34, 42], "input": [35, 36, 37], "user_email": [35, 36, 37], "repo_nam": [35, 36, 37], "decim": [35, 36, 37], "usual": 37, "worker": [38, 40], "extens": 39, "new_lin": 39, "select_data": 39, "my_airflow_t": 39, "select_into_fil": 39, "select_data_into_fil": 39, "tmp": 39, "perform": 39, "create_and_populate_t": 39, "create_fil": 39, "create_and_populate_from_fil": 39, "starter": 39, "sql_sensor": 39, "hive_metastor": 39, "sql_sensor_task": 39, "temp": 39, "sample_table_3": 39, "60": 39, "someth": 39, "occur": 39, "happen": 39, "succe": 39, "arriv": 39, "interv": 39, "poke_interv": 39, "rang": 39, "partition_nam": 39, "partition_valu": 39, "partition_sensor": 39, "partition_sensor_task": 39, "sample_table_2": 39, "db3": 40, "preparedata": 40, "here": [40, 42], "invok": 40, "r3": 40, "on_demand": 40, "notebook_task_param": 40, "main_class_nam": 40, "processdata": 40, "lib": 40, "etl": 40, "standalon": 41, "task_operator_nb_1": [41, 42], "nb_1": [41, 42], "shared_job_clust": [41, 42], "task_operator_sql_queri": 41, "sql_queri": [41, 42], "sql_task": [41, 42], "75": 42, "cost": 42, "reduct": 42, "40": 42, "dbu": 42, "comput": 42, "compar": 42, "few": 42, "author": 42, "web": 42, "price": 42, "begin": 42, "test_workflow_": 42, "pin": 42, "on_start": 42, "workflow_notebook_1": 42, "600": 42, "workflow_notebook_2": 42, "foo": 42, "bar": 42, "dag_nam": 42, "minim": 42, "enhanc": 44, "addition": 44, "offer": 44, "At": 44, "henc": 44, "ideal": 44, "prevent": 44, "embed": 44, "independ": 45, "itself": 45, "vulner": 45, "publish": 45, "develop": 45, "alwai": 45, "next": 45, "strict": 45, "semver": 45, "scope": 45, "major": 45, "minor": 45, "patchlevel": 45, "critic": 45, "band": 45, "stakehold": 45, "decid": 45, "cherri": 45, "pick": 45, "older": 45, "mix": 45, "govern": 45, "interest": 45, "parti": 45}, "objects": {"airflow.providers": [[5, 0, 0, "-", "databricks"]], "airflow.providers.databricks": [[5, 1, 1, "", "__version__"], [0, 0, 0, "-", "exceptions"], [4, 0, 0, "-", "hooks"], [10, 0, 0, "-", "operators"], [12, 0, 0, "-", "plugins"], [15, 0, 0, "-", "sensors"], [17, 0, 0, "-", "triggers"], [19, 0, 0, "-", "utils"]], "airflow.providers.databricks.exceptions": [[0, 2, 1, "", "DatabricksSqlExecutionError"], [0, 2, 1, "", "DatabricksSqlExecutionTimeout"]], "airflow.providers.databricks.hooks": [[1, 0, 0, "-", "databricks"], [2, 0, 0, "-", "databricks_base"], [3, 0, 0, "-", "databricks_sql"]], "airflow.providers.databricks.hooks.databricks": [[1, 1, 1, "", "CANCEL_ALL_RUNS_ENDPOINT"], [1, 1, 1, "", "CANCEL_RUN_ENDPOINT"], [1, 1, 1, "", "CREATE_ENDPOINT"], [1, 3, 1, "", "ClusterState"], [1, 1, 1, "", "DELETE_RUN_ENDPOINT"], [1, 3, 1, "", "DatabricksHook"], [1, 1, 1, "", "GET_CLUSTER_ENDPOINT"], [1, 1, 1, "", "GET_RUN_ENDPOINT"], [1, 1, 1, "", "INSTALL_LIBS_ENDPOINT"], [1, 1, 1, "", "LIST_JOBS_ENDPOINT"], [1, 1, 1, "", "LIST_PIPELINES_ENDPOINT"], [1, 1, 1, "", "OUTPUT_RUNS_JOB_ENDPOINT"], [1, 1, 1, "", "REPAIR_RUN_ENDPOINT"], [1, 1, 1, "", "RESET_ENDPOINT"], [1, 1, 1, "", "RESTART_CLUSTER_ENDPOINT"], [1, 1, 1, "", "RUN_NOW_ENDPOINT"], [1, 3, 1, "", "RunLifeCycleState"], [1, 3, 1, "", "RunState"], [1, 1, 1, "", "SPARK_VERSIONS_ENDPOINT"], [1, 1, 1, "", "START_CLUSTER_ENDPOINT"], [1, 1, 1, "", "SUBMIT_RUN_ENDPOINT"], [1, 1, 1, "", "TERMINATE_CLUSTER_ENDPOINT"], [1, 1, 1, "", "UNINSTALL_LIBS_ENDPOINT"], [1, 1, 1, "", "UPDATE_ENDPOINT"], [1, 1, 1, "", "WORKSPACE_GET_STATUS_ENDPOINT"]], "airflow.providers.databricks.hooks.databricks.ClusterState": [[1, 4, 1, "", "CLUSTER_LIFE_CYCLE_STATES"], [1, 5, 1, "", "__eq__"], [1, 5, 1, "", "__repr__"], [1, 5, 1, "", "from_json"], [1, 6, 1, "", "is_running"], [1, 6, 1, "", "is_terminal"], [1, 5, 1, "", "to_json"]], "airflow.providers.databricks.hooks.databricks.DatabricksHook": [[1, 5, 1, "", "a_get_cluster_state"], [1, 5, 1, "", "a_get_run"], [1, 5, 1, "", "a_get_run_output"], [1, 5, 1, "", "a_get_run_page_url"], [1, 5, 1, "", "a_get_run_state"], [1, 5, 1, "", "cancel_all_runs"], [1, 5, 1, "", "cancel_run"], [1, 5, 1, "", "create_job"], [1, 5, 1, "", "create_repo"], [1, 5, 1, "", "delete_repo"], [1, 5, 1, "", "delete_run"], [1, 5, 1, "", "find_job_id_by_name"], [1, 5, 1, "", "find_pipeline_id_by_name"], [1, 5, 1, "", "get_cluster_state"], [1, 5, 1, "", "get_job_id"], [1, 5, 1, "", "get_latest_repair_id"], [1, 5, 1, "", "get_repo_by_path"], [1, 5, 1, "", "get_run"], [1, 5, 1, "", "get_run_output"], [1, 5, 1, "", "get_run_page_url"], [1, 5, 1, "", "get_run_state"], [1, 5, 1, "", "get_run_state_lifecycle"], [1, 5, 1, "", "get_run_state_message"], [1, 5, 1, "", "get_run_state_result"], [1, 5, 1, "", "get_run_state_str"], [1, 4, 1, "", "hook_name"], [1, 5, 1, "", "install"], [1, 5, 1, "", "list_jobs"], [1, 5, 1, "", "list_pipelines"], [1, 5, 1, "", "repair_run"], [1, 5, 1, "", "reset_job"], [1, 5, 1, "", "restart_cluster"], [1, 5, 1, "", "run_now"], [1, 5, 1, "", "start_cluster"], [1, 5, 1, "", "submit_run"], [1, 5, 1, "", "terminate_cluster"], [1, 5, 1, "", "test_connection"], [1, 5, 1, "", "uninstall"], [1, 5, 1, "", "update_job"], [1, 5, 1, "", "update_job_permission"], [1, 5, 1, "", "update_repo"]], "airflow.providers.databricks.hooks.databricks.RunLifeCycleState": [[1, 4, 1, "", "BLOCKED"], [1, 4, 1, "", "INTERNAL_ERROR"], [1, 4, 1, "", "PENDING"], [1, 4, 1, "", "QUEUED"], [1, 4, 1, "", "RUNNING"], [1, 4, 1, "", "SKIPPED"], [1, 4, 1, "", "TERMINATED"], [1, 4, 1, "", "TERMINATING"], [1, 4, 1, "", "WAITING_FOR_RETRY"]], "airflow.providers.databricks.hooks.databricks.RunState": [[1, 4, 1, "", "RUN_LIFE_CYCLE_STATES"], [1, 5, 1, "", "__eq__"], [1, 5, 1, "", "__repr__"], [1, 5, 1, "", "from_json"], [1, 6, 1, "", "is_successful"], [1, 6, 1, "", "is_terminal"], [1, 5, 1, "", "to_json"]], "airflow.providers.databricks.hooks.databricks_base": [[2, 1, 1, "", "AZURE_MANAGEMENT_ENDPOINT"], [2, 1, 1, "", "AZURE_METADATA_SERVICE_INSTANCE_URL"], [2, 1, 1, "", "AZURE_METADATA_SERVICE_TOKEN_URL"], [2, 3, 1, "", "BaseDatabricksHook"], [2, 3, 1, "", "BearerAuth"], [2, 1, 1, "", "DEFAULT_AZURE_CREDENTIAL_SETTING_KEY"], [2, 1, 1, "", "DEFAULT_DATABRICKS_SCOPE"], [2, 1, 1, "", "OIDC_TOKEN_SERVICE_URL"], [2, 1, 1, "", "TOKEN_REFRESH_LEAD_TIME"]], "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook": [[2, 5, 1, "", "__aenter__"], [2, 5, 1, "", "__aexit__"], [2, 4, 1, "", "conn_name_attr"], [2, 4, 1, "", "conn_type"], [2, 5, 1, "", "databricks_conn"], [2, 4, 1, "", "default_conn_name"], [2, 4, 1, "", "extra_parameters"], [2, 5, 1, "", "get_conn"], [2, 5, 1, "", "host"], [2, 5, 1, "", "user_agent_header"], [2, 5, 1, "", "user_agent_value"]], "airflow.providers.databricks.hooks.databricks_base.BearerAuth": [[2, 5, 1, "", "encode"]], "airflow.providers.databricks.hooks.databricks_sql": [[3, 3, 1, "", "DatabricksSqlHook"], [3, 1, 1, "", "LIST_SQL_ENDPOINTS_ENDPOINT"], [3, 1, 1, "", "T"], [3, 7, 1, "", "create_timeout_thread"]], "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook": [[3, 5, 1, "", "bulk_dump"], [3, 5, 1, "", "bulk_load"], [3, 5, 1, "", "get_conn"], [3, 4, 1, "", "hook_name"], [3, 5, 1, "", "run"]], "airflow.providers.databricks.operators": [[6, 0, 0, "-", "databricks"], [7, 0, 0, "-", "databricks_repos"], [8, 0, 0, "-", "databricks_sql"], [9, 0, 0, "-", "databricks_workflow"]], "airflow.providers.databricks.operators.databricks": [[6, 1, 1, "", "DEFER_METHOD_NAME"], [6, 3, 1, "", "DatabricksCreateJobsOperator"], [6, 3, 1, "", "DatabricksJobRunLink"], [6, 3, 1, "", "DatabricksNotebookOperator"], [6, 3, 1, "", "DatabricksRunNowDeferrableOperator"], [6, 3, 1, "", "DatabricksRunNowOperator"], [6, 3, 1, "", "DatabricksSubmitRunDeferrableOperator"], [6, 3, 1, "", "DatabricksSubmitRunOperator"], [6, 3, 1, "", "DatabricksTaskBaseOperator"], [6, 3, 1, "", "DatabricksTaskOperator"], [6, 1, 1, "", "XCOM_JOB_ID_KEY"], [6, 1, 1, "", "XCOM_RUN_ID_KEY"], [6, 1, 1, "", "XCOM_RUN_PAGE_URL_KEY"], [6, 7, 1, "", "is_repair_reason_match_exist"], [6, 7, 1, "", "update_job_for_repair"]], "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator": [[6, 5, 1, "", "execute"], [6, 4, 1, "", "template_fields"], [6, 4, 1, "", "ui_color"], [6, 4, 1, "", "ui_fgcolor"]], "airflow.providers.databricks.operators.databricks.DatabricksJobRunLink": [[6, 5, 1, "", "get_link"], [6, 4, 1, "", "name"]], "airflow.providers.databricks.operators.databricks.DatabricksNotebookOperator": [[6, 4, 1, "", "CALLER"], [6, 4, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator": [[6, 5, 1, "", "execute"], [6, 5, 1, "", "execute_complete"], [6, 5, 1, "", "on_kill"], [6, 4, 1, "", "operator_extra_links"], [6, 4, 1, "", "template_ext"], [6, 4, 1, "", "template_fields"], [6, 4, 1, "", "ui_color"], [6, 4, 1, "", "ui_fgcolor"]], "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunDeferrableOperator": [[6, 5, 1, "", "execute"]], "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator": [[6, 5, 1, "", "execute"], [6, 5, 1, "", "execute_complete"], [6, 5, 1, "", "on_kill"], [6, 4, 1, "", "operator_extra_links"], [6, 4, 1, "", "template_ext"], [6, 4, 1, "", "template_fields"], [6, 4, 1, "", "ui_color"], [6, 4, 1, "", "ui_fgcolor"]], "airflow.providers.databricks.operators.databricks.DatabricksTaskBaseOperator": [[6, 5, 1, "", "execute"], [6, 5, 1, "", "execute_complete"], [6, 5, 1, "", "monitor_databricks_job"]], "airflow.providers.databricks.operators.databricks.DatabricksTaskOperator": [[6, 4, 1, "", "CALLER"], [6, 4, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_repos": [[7, 3, 1, "", "DatabricksReposCreateOperator"], [7, 3, 1, "", "DatabricksReposDeleteOperator"], [7, 3, 1, "", "DatabricksReposUpdateOperator"]], "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator": [[7, 4, 1, "", "__aws_code_commit_regexp__"], [7, 5, 1, "", "__detect_repo_provider__"], [7, 4, 1, "", "__git_providers__"], [7, 4, 1, "", "__repos_path_regexp__"], [7, 5, 1, "", "execute"], [7, 4, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_repos.DatabricksReposDeleteOperator": [[7, 5, 1, "", "execute"], [7, 4, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_repos.DatabricksReposUpdateOperator": [[7, 5, 1, "", "execute"], [7, 4, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_sql": [[8, 1, 1, "", "COPY_INTO_APPROVED_FORMATS"], [8, 3, 1, "", "DatabricksCopyIntoOperator"], [8, 3, 1, "", "DatabricksSqlOperator"]], "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator": [[8, 5, 1, "", "execute"], [8, 5, 1, "", "on_kill"], [8, 4, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator": [[8, 4, 1, "", "conn_id_field"], [8, 5, 1, "", "get_db_hook"], [8, 4, 1, "", "template_ext"], [8, 4, 1, "", "template_fields"], [8, 4, 1, "", "template_fields_renderers"]], "airflow.providers.databricks.operators.databricks_workflow": [[9, 3, 1, "", "DatabricksWorkflowTaskGroup"], [9, 3, 1, "", "WorkflowRunMetadata"]], "airflow.providers.databricks.operators.databricks_workflow.DatabricksWorkflowTaskGroup": [[9, 5, 1, "", "__exit__"], [9, 4, 1, "", "is_databricks"]], "airflow.providers.databricks.operators.databricks_workflow.WorkflowRunMetadata": [[9, 4, 1, "", "conn_id"], [9, 4, 1, "", "job_id"], [9, 4, 1, "", "run_id"]], "airflow.providers.databricks.plugins": [[11, 0, 0, "-", "databricks_workflow"]], "airflow.providers.databricks.plugins.databricks_workflow": [[11, 3, 1, "", "DatabricksWorkflowPlugin"], [11, 1, 1, "", "REPAIR_WAIT_ATTEMPTS"], [11, 1, 1, "", "REPAIR_WAIT_DELAY"], [11, 3, 1, "", "RepairDatabricksTasks"], [11, 3, 1, "", "WorkflowJobRepairAllFailedLink"], [11, 3, 1, "", "WorkflowJobRepairSingleTaskLink"], [11, 3, 1, "", "WorkflowJobRunLink"], [11, 1, 1, "", "airflow_app"], [11, 7, 1, "", "get_auth_decorator"], [11, 7, 1, "", "get_databricks_task_ids"], [11, 7, 1, "", "get_launch_task_id"], [11, 7, 1, "", "get_task_instance"], [11, 7, 1, "", "get_xcom_result"], [11, 1, 1, "", "repair_databricks_package"], [11, 1, 1, "", "repair_databricks_view"]], "airflow.providers.databricks.plugins.databricks_workflow.DatabricksWorkflowPlugin": [[11, 4, 1, "", "appbuilder_views"], [11, 4, 1, "", "name"], [11, 4, 1, "", "operator_extra_links"]], "airflow.providers.databricks.plugins.databricks_workflow.RepairDatabricksTasks": [[11, 4, 1, "", "default_view"], [11, 5, 1, "", "repair"]], "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairAllFailedLink": [[11, 5, 1, "", "get_link"], [11, 5, 1, "", "get_task_group_children"], [11, 5, 1, "", "get_tasks_to_run"], [11, 4, 1, "", "name"]], "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairSingleTaskLink": [[11, 5, 1, "", "get_link"], [11, 4, 1, "", "name"]], "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRunLink": [[11, 5, 1, "", "get_link"], [11, 4, 1, "", "name"]], "airflow.providers.databricks.sensors": [[13, 0, 0, "-", "databricks_partition"], [14, 0, 0, "-", "databricks_sql"]], "airflow.providers.databricks.sensors.databricks_partition": [[13, 3, 1, "", "DatabricksPartitionSensor"]], "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor": [[13, 5, 1, "", "poke"], [13, 4, 1, "", "template_ext"], [13, 4, 1, "", "template_fields"], [13, 4, 1, "", "template_fields_renderers"]], "airflow.providers.databricks.sensors.databricks_sql": [[14, 3, 1, "", "DatabricksSqlSensor"]], "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor": [[14, 5, 1, "", "hook"], [14, 5, 1, "", "poke"], [14, 4, 1, "", "template_ext"], [14, 4, 1, "", "template_fields"], [14, 4, 1, "", "template_fields_renderers"]], "airflow.providers.databricks.triggers": [[16, 0, 0, "-", "databricks"]], "airflow.providers.databricks.triggers.databricks": [[16, 3, 1, "", "DatabricksExecutionTrigger"]], "airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger": [[16, 5, 1, "", "run"], [16, 5, 1, "", "serialize"]], "airflow.providers.databricks.utils": [[18, 0, 0, "-", "databricks"]], "airflow.providers.databricks.utils.databricks": [[18, 7, 1, "", "normalise_json_content"], [18, 7, 1, "", "validate_trigger_event"]], "tests.system": [[25, 0, 0, "-", "databricks"]], "tests.system.databricks": [[20, 0, 0, "-", "example_databricks"], [21, 0, 0, "-", "example_databricks_repos"], [22, 0, 0, "-", "example_databricks_sensors"], [23, 0, 0, "-", "example_databricks_sql"], [24, 0, 0, "-", "example_databricks_workflow"]], "tests.system.databricks.example_databricks": [[20, 1, 1, "", "DAG_ID"], [20, 1, 1, "", "ENV_ID"], [20, 1, 1, "", "QUERY_ID"], [20, 1, 1, "", "WAREHOUSE_ID"], [20, 1, 1, "", "job"], [20, 1, 1, "", "test_run"]], "tests.system.databricks.example_databricks_repos": [[21, 1, 1, "", "DAG_ID"], [21, 1, 1, "", "ENV_ID"], [21, 1, 1, "", "default_args"], [21, 1, 1, "", "repo_path"], [21, 1, 1, "", "test_run"]], "tests.system.databricks.example_databricks_sensors": [[22, 1, 1, "", "DAG_ID"], [22, 1, 1, "", "ENV_ID"], [22, 1, 1, "", "connection_id"], [22, 1, 1, "", "test_run"]], "tests.system.databricks.example_databricks_sql": [[23, 1, 1, "", "DAG_ID"], [23, 1, 1, "", "ENV_ID"], [23, 1, 1, "", "connection_id"], [23, 1, 1, "", "test_run"]], "tests.system.databricks.example_databricks_workflow": [[24, 1, 1, "", "DATABRICKS_CONN_ID"], [24, 1, 1, "", "DATABRICKS_NOTIFICATION_EMAIL"], [24, 1, 1, "", "EXECUTION_TIMEOUT"], [24, 1, 1, "", "GROUP_ID"], [24, 1, 1, "", "QUERY_ID"], [24, 1, 1, "", "USER"], [24, 1, 1, "", "WAREHOUSE_ID"], [24, 1, 1, "", "dag"], [24, 1, 1, "", "job_cluster_spec"], [24, 1, 1, "", "task_group"], [24, 1, 1, "", "test_run"]]}, "objtypes": {"0": "py:module", "1": "py:data", "2": "py:exception", "3": "py:class", "4": "py:attribute", "5": "py:method", "6": "py:property", "7": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "data", "Python data"], "2": ["py", "exception", "Python exception"], "3": ["py", "class", "Python class"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "method", "Python method"], "6": ["py", "property", "Python property"], "7": ["py", "function", "Python function"]}, "titleterms": {"airflow": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 27, 29, 42], "provid": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 27, 29, 42], "databrick": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 34, 35, 36, 37, 41, 42, 43], "except": 0, "modul": [0, 1, 2, 3, 6, 7, 8, 9, 11, 13, 14, 16, 18, 20, 21, 22, 23, 24], "content": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 13, 14, 16, 18, 20, 21, 22, 23, 24], "hook": [1, 2, 3, 4], "class": [1, 2, 3, 6, 7, 8, 9, 11, 13, 14, 16], "attribut": [1, 2, 3, 6, 8, 11], "databricks_bas": 2, "databricks_sql": [3, 8, 14], "function": [3, 6, 11, 18], "submodul": [4, 5, 10, 12, 15, 17, 19, 25], "subpackag": 5, "packag": [5, 27, 29, 30], "oper": [6, 7, 8, 9, 10, 31, 32, 33, 35, 36, 37, 38, 39, 40], "databricks_repo": 7, "databricks_workflow": [9, 11], "plugin": [11, 12, 43], "sensor": [13, 14, 15, 39], "databricks_partit": 13, "trigger": [16, 17, 42], "util": [18, 19], "test": [20, 21, 22, 23, 24, 25], "system": [20, 21, 22, 23, 24, 25], "example_databrick": 20, "example_databricks_repo": 21, "example_databricks_sensor": 22, "example_databricks_sql": 23, "example_databricks_workflow": 24, "changelog": 26, "6": [26, 27], "13": [26, 27], "0": [26, 27], "featur": [26, 44], "misc": 26, "12": [26, 27], "bug": 26, "fix": 26, "11": [26, 27], "10": [26, 27], "9": [26, 27], "8": [26, 27], "7": [26, 27], "5": [26, 27], "4": [26, 27], "3": [26, 27], "2": [26, 27], "1": [26, 27], "break": 26, "chang": 26, "yank": 26, "apach": [27, 29], "connect": 28, "authent": 28, "default": 28, "id": 28, "configur": 28, "instal": [29, 30], "requir": 29, "cross": 29, "depend": 29, "download": 29, "offici": 29, "from": [30, 39, 42], "sourc": 30, "releas": [30, 45], "integr": 30, "verifi": 30, "pypi": 30, "databrickscopyintooper": 31, "us": [31, 33, 35, 36, 37, 38, 39, 40, 41], "exampl": [31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44], "import": 31, "csv": 31, "data": [31, 39], "databrickscreatejobsoper": 33, "specifi": [33, 36, 37, 40], "paramet": [33, 40], "json": [33, 40], "name": [33, 40], "pair": 33, "databricksrunnowoper": [33, 38], "databricksnotebookoper": 34, "run": [34, 41, 42], "notebook": [34, 41], "new": 34, "cluster": 34, "an": 34, "exist": 34, "databricksreposcreateoper": 35, "creat": 35, "repo": [35, 36, 37], "databricksreposdeleteoper": 36, "delet": 36, "path": [36, 37], "databricksreposupdateoper": 37, "updat": 37, "databricksrunnowdeferrableoper": 38, "databrickssqloper": 39, "select": 39, "file": 39, "execut": 39, "multipl": 39, "statement": 39, "databrickssqlsensor": 39, "databrickspartitionsensor": 39, "databrickssubmitrunoper": 40, "databrickssubmitrundeferrableoper": 40, "databrickstaskoper": 41, "sql": 41, "queri": 41, "databricksworkflowtaskgroup": 42, "what": 42, "dag": 42, "look": 42, "like": 42, "The": 42, "follow": 42, "imag": 42, "displai": 42, "result": 42, "workflow": 42, "ui": 42, "base": 42, "abov": 42, "correspond": 42, "i": 42, "depict": 42, "below": 42, "databricksworkflowplugin": 44, "overview": 44, "note": 44, "usag": 44, "secur": 45, "patch": 45}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"airflow.providers.databricks.exceptions": [[0, "module-airflow.providers.databricks.exceptions"]], "Module Contents": [[0, "module-contents"], [1, "module-contents"], [2, "module-contents"], [3, "module-contents"], [6, "module-contents"], [7, "module-contents"], [8, "module-contents"], [9, "module-contents"], [11, "module-contents"], [13, "module-contents"], [14, "module-contents"], [16, "module-contents"], [18, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [24, "module-contents"]], "airflow.providers.databricks.hooks.databricks": [[1, "module-airflow.providers.databricks.hooks.databricks"]], "Classes": [[1, "classes"], [2, "classes"], [3, "classes"], [6, "classes"], [7, "classes"], [8, "classes"], [9, "classes"], [11, "classes"], [13, "classes"], [14, "classes"], [16, "classes"]], "Attributes": [[1, "attributes"], [2, "attributes"], [3, "attributes"], [6, "attributes"], [8, "attributes"], [11, "attributes"]], "airflow.providers.databricks.hooks.databricks_base": [[2, "module-airflow.providers.databricks.hooks.databricks_base"]], "airflow.providers.databricks.hooks.databricks_sql": [[3, "module-airflow.providers.databricks.hooks.databricks_sql"]], "Functions": [[3, "functions"], [6, "functions"], [11, "functions"], [18, "functions"]], "airflow.providers.databricks.hooks": [[4, "module-airflow.providers.databricks.hooks"]], "Submodules": [[4, "submodules"], [5, "submodules"], [10, "submodules"], [12, "submodules"], [15, "submodules"], [17, "submodules"], [19, "submodules"], [25, "submodules"]], "airflow.providers.databricks": [[5, "module-airflow.providers.databricks"]], "Subpackages": [[5, "subpackages"]], "Package Contents": [[5, "package-contents"]], "airflow.providers.databricks.operators.databricks": [[6, "module-airflow.providers.databricks.operators.databricks"]], "airflow.providers.databricks.operators.databricks_repos": [[7, "module-airflow.providers.databricks.operators.databricks_repos"]], "airflow.providers.databricks.operators.databricks_sql": [[8, "module-airflow.providers.databricks.operators.databricks_sql"]], "airflow.providers.databricks.operators.databricks_workflow": [[9, "module-airflow.providers.databricks.operators.databricks_workflow"]], "airflow.providers.databricks.operators": [[10, "module-airflow.providers.databricks.operators"]], "airflow.providers.databricks.plugins.databricks_workflow": [[11, "module-airflow.providers.databricks.plugins.databricks_workflow"]], "airflow.providers.databricks.plugins": [[12, "module-airflow.providers.databricks.plugins"]], "airflow.providers.databricks.sensors.databricks_partition": [[13, "module-airflow.providers.databricks.sensors.databricks_partition"]], "airflow.providers.databricks.sensors.databricks_sql": [[14, "module-airflow.providers.databricks.sensors.databricks_sql"]], "airflow.providers.databricks.sensors": [[15, "module-airflow.providers.databricks.sensors"]], "airflow.providers.databricks.triggers.databricks": [[16, "module-airflow.providers.databricks.triggers.databricks"]], "airflow.providers.databricks.triggers": [[17, "module-airflow.providers.databricks.triggers"]], "airflow.providers.databricks.utils.databricks": [[18, "module-airflow.providers.databricks.utils.databricks"]], "airflow.providers.databricks.utils": [[19, "module-airflow.providers.databricks.utils"]], "tests.system.databricks.example_databricks": [[20, "module-tests.system.databricks.example_databricks"]], "tests.system.databricks.example_databricks_repos": [[21, "module-tests.system.databricks.example_databricks_repos"]], "tests.system.databricks.example_databricks_sensors": [[22, "module-tests.system.databricks.example_databricks_sensors"]], "tests.system.databricks.example_databricks_sql": [[23, "module-tests.system.databricks.example_databricks_sql"]], "tests.system.databricks.example_databricks_workflow": [[24, "module-tests.system.databricks.example_databricks_workflow"]], "tests.system.databricks": [[25, "module-tests.system.databricks"]], "Changelog": [[26, "changelog"]], "6.13.0": [[26, "id1"], [27, "id1"]], "Features": [[26, "features"], [26, "id3"], [26, "id5"], [26, "id8"], [26, "id13"], [26, "id17"], [26, "id20"], [26, "id24"], [26, "id29"], [26, "id32"], [26, "id36"], [26, "id39"], [26, "id49"], [26, "id52"], [26, "id56"], [26, "id59"], [26, "id70"], [26, "id75"], [26, "id78"], [26, "id87"], [26, "id89"], [26, "id93"], [26, "id96"], [26, "id101"], [26, "id104"], [26, "id106"], [26, "id110"], [26, "id113"], [26, "id116"], [26, "id120"], [26, "id122"], [44, "features"]], "Misc": [[26, "misc"], [26, "id6"], [26, "id9"], [26, "id11"], [26, "id15"], [26, "id22"], [26, "id26"], [26, "id30"], [26, "id34"], [26, "id37"], [26, "id44"], [26, "id45"], [26, "id54"], [26, "id57"], [26, "id60"], [26, "id62"], [26, "id65"], [26, "id68"], [26, "id72"], [26, "id76"], [26, "id86"], [26, "id90"], [26, "id108"], [26, "id114"], [26, "id118"], [26, "id127"]], "6.12.0": [[26, "id2"], [27, "id2"]], "Bug Fixes": [[26, "bug-fixes"], [26, "id14"], [26, "id18"], [26, "id21"], [26, "id25"], [26, "id33"], [26, "id40"], [26, "id43"], [26, "id53"], [26, "id64"], [26, "id67"], [26, "id71"], [26, "id80"], [26, "id83"], [26, "id91"], [26, "id94"], [26, "id97"], [26, "id102"], [26, "id107"], [26, "id111"], [26, "id117"], [26, "id123"], [26, "id125"]], "6.11.0": [[26, "id4"], [27, "id3"]], "6.10.0": [[26, "id7"], [27, "id4"]], "6.9.0": [[26, "id10"], [27, "id6"]], "6.8.0": [[26, "id12"], [27, "id7"]], "6.7.0": [[26, "id16"], [27, "id8"]], "6.6.0": [[26, "id19"], [27, "id9"]], "6.5.0": [[26, "id23"], [27, "id10"]], "6.4.0": [[26, "id27"], [27, "id11"]], "6.3.0": [[26, "id31"], [27, "id12"]], "6.2.0": [[26, "id35"], [27, "id13"]], "6.1.0": [[26, "id38"], [27, "id14"]], "6.0.0": [[26, "id41"], [27, "id15"]], "Breaking changes": [[26, "breaking-changes"], [26, "id47"], [26, "id82"], [26, "id99"], [26, "id129"]], "5.0.1 (YANKED)": [[26, "yanked"]], "5.0.0": [[26, "id46"], [27, "id17"]], "4.7.0": [[26, "id48"], [27, "id18"]], "4.6.0": [[26, "id50"], [27, "id19"]], "4.5.0": [[26, "id55"], [27, "id20"]], "4.4.0": [[26, "id58"], [27, "id21"]], "4.3.3": [[26, "id61"], [27, "id22"]], "4.3.2": [[26, "id63"], [27, "id24"]], "4.3.1": [[26, "id66"], [27, "id25"]], "4.3.0": [[26, "id69"], [27, "id26"]], "4.2.0": [[26, "id73"], [27, "id27"]], "4.1.0": [[26, "id77"], [27, "id29"]], "4.0.1": [[26, "id79"], [27, "id30"]], "4.0.0": [[26, "id81"], [27, "id31"]], "3.4.0 (YANKED)": [[26, "id84"]], "3.3.0": [[26, "id88"], [27, "id33"]], "3.2.0": [[26, "id92"], [27, "id35"]], "3.1.0": [[26, "id95"], [27, "id37"]], "3.0.0": [[26, "id98"], [27, "id38"]], "2.7.0": [[26, "id103"], [27, "id39"]], "2.6.0": [[26, "id105"], [27, "id40"]], "2.5.0": [[26, "id109"], [27, "id41"]], "2.4.0": [[26, "id112"], [27, "id42"]], "2.3.0": [[26, "id115"], [27, "id44"]], "2.2.0": [[26, "id119"], [27, "id45"]], "2.1.0": [[26, "id121"], [27, "id46"]], "2.0.2": [[26, "id124"], [27, "id47"]], "2.0.1": [[26, "id126"], [27, "id48"]], "2.0.0": [[26, "id128"], [27, "id49"]], "1.0.1": [[26, "id130"], [27, "id50"]], "1.0.0": [[26, "id131"], [27, "id51"]], "Package apache-airflow-providers-databricks": [[27, "package-apache-airflow-providers-databricks"]], "5.0.1": [[27, "id16"]], "3.4.0": [[27, "id32"]], "Databricks Connection": [[28, "databricks-connection"]], "Authenticating to Databricks": [[28, "authenticating-to-databricks"]], "Default Connection IDs": [[28, "default-connection-ids"]], "Configuring the Connection": [[28, "configuring-the-connection"]], "apache-airflow-providers-databricks": [[29, "apache-airflow-providers-databricks"]], "apache-airflow-providers-databricks package": [[29, "apache-airflow-providers-databricks-package"]], "Provider package": [[29, "provider-package"]], "Installation": [[29, "installation"]], "Requirements": [[29, "requirements"]], "Cross provider package dependencies": [[29, "cross-provider-package-dependencies"]], "Downloading official packages": [[29, "downloading-official-packages"]], "Installing from sources": [[30, "installing-from-sources"]], "Released packages": [[30, "released-packages"]], "Release integrity": [[30, "release-integrity"]], "Verifying PyPI releases": [[30, "verifying-pypi-releases"]], "DatabricksCopyIntoOperator": [[31, "databrickscopyintooperator"]], "Using the Operator": [[31, "using-the-operator"], [33, "using-the-operator"], [35, "using-the-operator"], [36, "using-the-operator"], [37, "using-the-operator"], [38, "using-the-operator"], [39, "using-the-operator"], [40, "using-the-operator"]], "Examples": [[31, "examples"], [33, "examples"], [34, "examples"], [35, "examples"], [36, "examples"], [37, "examples"], [39, "examples"], [39, "id1"], [39, "id3"], [40, "examples"], [41, "examples"], [42, "examples"], [44, "examples"]], "Importing CSV data": [[31, "importing-csv-data"]], "Databricks Operators": [[32, "databricks-operators"]], "DatabricksCreateJobsOperator": [[33, "databrickscreatejobsoperator"]], "Specifying parameters as JSON": [[33, "specifying-parameters-as-json"], [40, "specifying-parameters-as-json"]], "Using named parameters": [[33, "using-named-parameters"], [40, "using-named-parameters"]], "Pairing with DatabricksRunNowOperator": [[33, "pairing-with-databricksrunnowoperator"]], "DatabricksNotebookOperator": [[34, "databricksnotebookoperator"]], "Running a notebook in Databricks on a new cluster": [[34, "running-a-notebook-in-databricks-on-a-new-cluster"]], "Running a notebook in Databricks on an existing cluster": [[34, "running-a-notebook-in-databricks-on-an-existing-cluster"]], "DatabricksReposCreateOperator": [[35, "databricksreposcreateoperator"]], "Create a Databricks Repo": [[35, "create-a-databricks-repo"]], "DatabricksReposDeleteOperator": [[36, "databricksreposdeleteoperator"]], "Deleting Databricks Repo by specifying path": [[36, "deleting-databricks-repo-by-specifying-path"]], "DatabricksReposUpdateOperator": [[37, "databricksreposupdateoperator"]], "Updating Databricks Repo by specifying path": [[37, "updating-databricks-repo-by-specifying-path"]], "DatabricksRunNowOperator": [[38, "databricksrunnowoperator"]], "DatabricksRunNowDeferrableOperator": [[38, "databricksrunnowdeferrableoperator"]], "DatabricksSqlOperator": [[39, "databrickssqloperator"]], "Selecting data": [[39, "selecting-data"]], "Selecting data into a file": [[39, "selecting-data-into-a-file"]], "Executing multiple statements": [[39, "executing-multiple-statements"]], "Executing multiple statements from a file": [[39, "executing-multiple-statements-from-a-file"]], "DatabricksSqlSensor": [[39, "databrickssqlsensor"]], "Using the Sensor": [[39, "using-the-sensor"], [39, "id2"]], "DatabricksPartitionSensor": [[39, "databrickspartitionsensor"]], "DatabricksSubmitRunOperator": [[40, "databrickssubmitrunoperator"]], "DatabricksSubmitRunDeferrableOperator": [[40, "databrickssubmitrundeferrableoperator"]], "DatabricksTaskOperator": [[41, "databrickstaskoperator"]], "Running a notebook in Databricks using DatabricksTaskOperator": [[41, "running-a-notebook-in-databricks-using-databrickstaskoperator"]], "Running a SQL query in Databricks using DatabricksTaskOperator": [[41, "running-a-sql-query-in-databricks-using-databrickstaskoperator"]], "DatabricksWorkflowTaskGroup": [[42, "databricksworkflowtaskgroup"]], "Example of what a DAG looks like with a DatabricksWorkflowTaskGroup": [[42, "example-of-what-a-dag-looks-like-with-a-databricksworkflowtaskgroup"]], "The following image displays the resulting Databricks Workflow in the Airflow UI (based on the above example provided)": [[42, "the-following-image-displays-the-resulting-databricks-workflow-in-the-airflow-ui-based-on-the-above-example-provided"]], "The corresponding Databricks Workflow  in the Databricks UI for the run triggered from the Airflow DAG is depicted below": [[42, "the-corresponding-databricks-workflow-in-the-databricks-ui-for-the-run-triggered-from-the-airflow-dag-is-depicted-below"]], "Databricks Plugins": [[43, "databricks-plugins"]], "DatabricksWorkflowPlugin": [[44, "databricksworkflowplugin"]], "Overview": [[44, "overview"]], "Notes": [[44, "notes"]], "Usage": [[44, "usage"]], "Releasing security patches": [[45, "releasing-security-patches"]]}, "indexentries": {"databrickssqlexecutionerror": [[0, "airflow.providers.databricks.exceptions.DatabricksSqlExecutionError"]], "databrickssqlexecutiontimeout": [[0, "airflow.providers.databricks.exceptions.DatabricksSqlExecutionTimeout"]], "airflow.providers.databricks.exceptions": [[0, "module-airflow.providers.databricks.exceptions"]], "module": [[0, "module-airflow.providers.databricks.exceptions"], [1, "module-airflow.providers.databricks.hooks.databricks"], [2, "module-airflow.providers.databricks.hooks.databricks_base"], [3, "module-airflow.providers.databricks.hooks.databricks_sql"], [4, "module-airflow.providers.databricks.hooks"], [5, "module-airflow.providers.databricks"], [6, "module-airflow.providers.databricks.operators.databricks"], [7, "module-airflow.providers.databricks.operators.databricks_repos"], [8, "module-airflow.providers.databricks.operators.databricks_sql"], [9, "module-airflow.providers.databricks.operators.databricks_workflow"], [10, "module-airflow.providers.databricks.operators"], [11, "module-airflow.providers.databricks.plugins.databricks_workflow"], [12, "module-airflow.providers.databricks.plugins"], [13, "module-airflow.providers.databricks.sensors.databricks_partition"], [14, "module-airflow.providers.databricks.sensors.databricks_sql"], [15, "module-airflow.providers.databricks.sensors"], [16, "module-airflow.providers.databricks.triggers.databricks"], [17, "module-airflow.providers.databricks.triggers"], [18, "module-airflow.providers.databricks.utils.databricks"], [19, "module-airflow.providers.databricks.utils"], [20, "module-tests.system.databricks.example_databricks"], [21, "module-tests.system.databricks.example_databricks_repos"], [22, "module-tests.system.databricks.example_databricks_sensors"], [23, "module-tests.system.databricks.example_databricks_sql"], [24, "module-tests.system.databricks.example_databricks_workflow"], [25, "module-tests.system.databricks"]], "blocked (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[1, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.BLOCKED"]], "cancel_all_runs_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.CANCEL_ALL_RUNS_ENDPOINT"]], "cancel_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.CANCEL_RUN_ENDPOINT"]], "cluster_life_cycle_states (airflow.providers.databricks.hooks.databricks.clusterstate attribute)": [[1, "airflow.providers.databricks.hooks.databricks.ClusterState.CLUSTER_LIFE_CYCLE_STATES"]], "create_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.CREATE_ENDPOINT"]], "clusterstate (class in airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.ClusterState"]], "delete_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.DELETE_RUN_ENDPOINT"]], "databrickshook (class in airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook"]], "get_cluster_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.GET_CLUSTER_ENDPOINT"]], "get_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.GET_RUN_ENDPOINT"]], "install_libs_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.INSTALL_LIBS_ENDPOINT"]], "internal_error (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[1, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.INTERNAL_ERROR"]], "list_jobs_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.LIST_JOBS_ENDPOINT"]], "list_pipelines_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.LIST_PIPELINES_ENDPOINT"]], "output_runs_job_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.OUTPUT_RUNS_JOB_ENDPOINT"]], "pending (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[1, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.PENDING"]], "queued (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[1, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.QUEUED"]], "repair_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.REPAIR_RUN_ENDPOINT"]], "reset_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.RESET_ENDPOINT"]], "restart_cluster_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.RESTART_CLUSTER_ENDPOINT"]], "running (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[1, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.RUNNING"]], "run_life_cycle_states (airflow.providers.databricks.hooks.databricks.runstate attribute)": [[1, "airflow.providers.databricks.hooks.databricks.RunState.RUN_LIFE_CYCLE_STATES"]], "run_now_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.RUN_NOW_ENDPOINT"]], "runlifecyclestate (class in airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState"]], "runstate (class in airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.RunState"]], "skipped (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[1, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.SKIPPED"]], "spark_versions_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.SPARK_VERSIONS_ENDPOINT"]], "start_cluster_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.START_CLUSTER_ENDPOINT"]], "submit_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.SUBMIT_RUN_ENDPOINT"]], "terminated (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[1, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.TERMINATED"]], "terminate_cluster_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.TERMINATE_CLUSTER_ENDPOINT"]], "terminating (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[1, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.TERMINATING"]], "uninstall_libs_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.UNINSTALL_LIBS_ENDPOINT"]], "update_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.UPDATE_ENDPOINT"]], "waiting_for_retry (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[1, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.WAITING_FOR_RETRY"]], "workspace_get_status_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[1, "airflow.providers.databricks.hooks.databricks.WORKSPACE_GET_STATUS_ENDPOINT"]], "__eq__() (airflow.providers.databricks.hooks.databricks.clusterstate method)": [[1, "airflow.providers.databricks.hooks.databricks.ClusterState.__eq__"]], "__eq__() (airflow.providers.databricks.hooks.databricks.runstate method)": [[1, "airflow.providers.databricks.hooks.databricks.RunState.__eq__"]], "__repr__() (airflow.providers.databricks.hooks.databricks.clusterstate method)": [[1, "airflow.providers.databricks.hooks.databricks.ClusterState.__repr__"]], "__repr__() (airflow.providers.databricks.hooks.databricks.runstate method)": [[1, "airflow.providers.databricks.hooks.databricks.RunState.__repr__"]], "a_get_cluster_state() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_cluster_state"]], "a_get_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_run"]], "a_get_run_output() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_run_output"]], "a_get_run_page_url() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_run_page_url"]], "a_get_run_state() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_run_state"]], "airflow.providers.databricks.hooks.databricks": [[1, "module-airflow.providers.databricks.hooks.databricks"]], "cancel_all_runs() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.cancel_all_runs"]], "cancel_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.cancel_run"]], "create_job() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.create_job"]], "create_repo() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.create_repo"]], "delete_repo() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.delete_repo"]], "delete_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.delete_run"]], "find_job_id_by_name() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.find_job_id_by_name"]], "find_pipeline_id_by_name() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.find_pipeline_id_by_name"]], "from_json() (airflow.providers.databricks.hooks.databricks.clusterstate class method)": [[1, "airflow.providers.databricks.hooks.databricks.ClusterState.from_json"]], "from_json() (airflow.providers.databricks.hooks.databricks.runstate class method)": [[1, "airflow.providers.databricks.hooks.databricks.RunState.from_json"]], "get_cluster_state() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_cluster_state"]], "get_job_id() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_job_id"]], "get_latest_repair_id() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_latest_repair_id"]], "get_repo_by_path() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_repo_by_path"]], "get_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run"]], "get_run_output() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_output"]], "get_run_page_url() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_page_url"]], "get_run_state() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state"]], "get_run_state_lifecycle() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state_lifecycle"]], "get_run_state_message() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state_message"]], "get_run_state_result() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state_result"]], "get_run_state_str() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state_str"]], "hook_name (airflow.providers.databricks.hooks.databricks.databrickshook attribute)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.hook_name"]], "install() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.install"]], "is_running (airflow.providers.databricks.hooks.databricks.clusterstate property)": [[1, "airflow.providers.databricks.hooks.databricks.ClusterState.is_running"]], "is_successful (airflow.providers.databricks.hooks.databricks.runstate property)": [[1, "airflow.providers.databricks.hooks.databricks.RunState.is_successful"]], "is_terminal (airflow.providers.databricks.hooks.databricks.clusterstate property)": [[1, "airflow.providers.databricks.hooks.databricks.ClusterState.is_terminal"]], "is_terminal (airflow.providers.databricks.hooks.databricks.runstate property)": [[1, "airflow.providers.databricks.hooks.databricks.RunState.is_terminal"]], "list_jobs() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.list_jobs"]], "list_pipelines() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.list_pipelines"]], "repair_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.repair_run"]], "reset_job() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.reset_job"]], "restart_cluster() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.restart_cluster"]], "run_now() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.run_now"]], "start_cluster() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.start_cluster"]], "submit_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.submit_run"]], "terminate_cluster() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.terminate_cluster"]], "test_connection() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.test_connection"]], "to_json() (airflow.providers.databricks.hooks.databricks.clusterstate method)": [[1, "airflow.providers.databricks.hooks.databricks.ClusterState.to_json"]], "to_json() (airflow.providers.databricks.hooks.databricks.runstate method)": [[1, "airflow.providers.databricks.hooks.databricks.RunState.to_json"]], "uninstall() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.uninstall"]], "update_job() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.update_job"]], "update_job_permission() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.update_job_permission"]], "update_repo() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks.DatabricksHook.update_repo"]], "azure_management_endpoint (in module airflow.providers.databricks.hooks.databricks_base)": [[2, "airflow.providers.databricks.hooks.databricks_base.AZURE_MANAGEMENT_ENDPOINT"]], "azure_metadata_service_instance_url (in module airflow.providers.databricks.hooks.databricks_base)": [[2, "airflow.providers.databricks.hooks.databricks_base.AZURE_METADATA_SERVICE_INSTANCE_URL"]], "azure_metadata_service_token_url (in module airflow.providers.databricks.hooks.databricks_base)": [[2, "airflow.providers.databricks.hooks.databricks_base.AZURE_METADATA_SERVICE_TOKEN_URL"]], "basedatabrickshook (class in airflow.providers.databricks.hooks.databricks_base)": [[2, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook"]], "bearerauth (class in airflow.providers.databricks.hooks.databricks_base)": [[2, "airflow.providers.databricks.hooks.databricks_base.BearerAuth"]], "default_azure_credential_setting_key (in module airflow.providers.databricks.hooks.databricks_base)": [[2, "airflow.providers.databricks.hooks.databricks_base.DEFAULT_AZURE_CREDENTIAL_SETTING_KEY"]], "default_databricks_scope (in module airflow.providers.databricks.hooks.databricks_base)": [[2, "airflow.providers.databricks.hooks.databricks_base.DEFAULT_DATABRICKS_SCOPE"]], "oidc_token_service_url (in module airflow.providers.databricks.hooks.databricks_base)": [[2, "airflow.providers.databricks.hooks.databricks_base.OIDC_TOKEN_SERVICE_URL"]], "token_refresh_lead_time (in module airflow.providers.databricks.hooks.databricks_base)": [[2, "airflow.providers.databricks.hooks.databricks_base.TOKEN_REFRESH_LEAD_TIME"]], "__aenter__() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[2, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.__aenter__"]], "__aexit__() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[2, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.__aexit__"]], "airflow.providers.databricks.hooks.databricks_base": [[2, "module-airflow.providers.databricks.hooks.databricks_base"]], "conn_name_attr (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook attribute)": [[2, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.conn_name_attr"]], "conn_type (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook attribute)": [[2, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.conn_type"]], "databricks_conn() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[2, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.databricks_conn"]], "default_conn_name (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook attribute)": [[2, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.default_conn_name"]], "encode() (airflow.providers.databricks.hooks.databricks_base.bearerauth method)": [[2, "airflow.providers.databricks.hooks.databricks_base.BearerAuth.encode"]], "extra_parameters (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook attribute)": [[2, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.extra_parameters"]], "get_conn() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[2, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.get_conn"]], "host() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[2, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.host"]], "user_agent_header() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[2, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.user_agent_header"]], "user_agent_value() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[2, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.user_agent_value"]], "databrickssqlhook (class in airflow.providers.databricks.hooks.databricks_sql)": [[3, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook"]], "list_sql_endpoints_endpoint (in module airflow.providers.databricks.hooks.databricks_sql)": [[3, "airflow.providers.databricks.hooks.databricks_sql.LIST_SQL_ENDPOINTS_ENDPOINT"]], "t (in module airflow.providers.databricks.hooks.databricks_sql)": [[3, "airflow.providers.databricks.hooks.databricks_sql.T"]], "airflow.providers.databricks.hooks.databricks_sql": [[3, "module-airflow.providers.databricks.hooks.databricks_sql"]], "bulk_dump() (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook method)": [[3, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.bulk_dump"]], "bulk_load() (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook method)": [[3, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.bulk_load"]], "create_timeout_thread() (in module airflow.providers.databricks.hooks.databricks_sql)": [[3, "airflow.providers.databricks.hooks.databricks_sql.create_timeout_thread"]], "get_conn() (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook method)": [[3, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.get_conn"]], "hook_name (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook attribute)": [[3, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.hook_name"]], "run() (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook method)": [[3, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.run"]], "airflow.providers.databricks.hooks": [[4, "module-airflow.providers.databricks.hooks"]], "__version__ (in module airflow.providers.databricks)": [[5, "airflow.providers.databricks.__version__"]], "airflow.providers.databricks": [[5, "module-airflow.providers.databricks"]], "caller (airflow.providers.databricks.operators.databricks.databricksnotebookoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksNotebookOperator.CALLER"]], "caller (airflow.providers.databricks.operators.databricks.databrickstaskoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksTaskOperator.CALLER"]], "defer_method_name (in module airflow.providers.databricks.operators.databricks)": [[6, "airflow.providers.databricks.operators.databricks.DEFER_METHOD_NAME"]], "databrickscreatejobsoperator (class in airflow.providers.databricks.operators.databricks)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator"]], "databricksjobrunlink (class in airflow.providers.databricks.operators.databricks)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksJobRunLink"]], "databricksnotebookoperator (class in airflow.providers.databricks.operators.databricks)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksNotebookOperator"]], "databricksrunnowdeferrableoperator (class in airflow.providers.databricks.operators.databricks)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksRunNowDeferrableOperator"]], "databricksrunnowoperator (class in airflow.providers.databricks.operators.databricks)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator"]], "databrickssubmitrundeferrableoperator (class in airflow.providers.databricks.operators.databricks)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunDeferrableOperator"]], "databrickssubmitrunoperator (class in airflow.providers.databricks.operators.databricks)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"]], "databrickstaskbaseoperator (class in airflow.providers.databricks.operators.databricks)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksTaskBaseOperator"]], "databrickstaskoperator (class in airflow.providers.databricks.operators.databricks)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksTaskOperator"]], "xcom_job_id_key (in module airflow.providers.databricks.operators.databricks)": [[6, "airflow.providers.databricks.operators.databricks.XCOM_JOB_ID_KEY"]], "xcom_run_id_key (in module airflow.providers.databricks.operators.databricks)": [[6, "airflow.providers.databricks.operators.databricks.XCOM_RUN_ID_KEY"]], "xcom_run_page_url_key (in module airflow.providers.databricks.operators.databricks)": [[6, "airflow.providers.databricks.operators.databricks.XCOM_RUN_PAGE_URL_KEY"]], "airflow.providers.databricks.operators.databricks": [[6, "module-airflow.providers.databricks.operators.databricks"]], "execute() (airflow.providers.databricks.operators.databricks.databrickscreatejobsoperator method)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks.databricksrunnowoperator method)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks.databrickssubmitrundeferrableoperator method)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunDeferrableOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator method)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks.databrickstaskbaseoperator method)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksTaskBaseOperator.execute"]], "execute_complete() (airflow.providers.databricks.operators.databricks.databricksrunnowoperator method)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.execute_complete"]], "execute_complete() (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator method)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.execute_complete"]], "execute_complete() (airflow.providers.databricks.operators.databricks.databrickstaskbaseoperator method)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksTaskBaseOperator.execute_complete"]], "get_link() (airflow.providers.databricks.operators.databricks.databricksjobrunlink method)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksJobRunLink.get_link"]], "is_repair_reason_match_exist() (in module airflow.providers.databricks.operators.databricks)": [[6, "airflow.providers.databricks.operators.databricks.is_repair_reason_match_exist"]], "monitor_databricks_job() (airflow.providers.databricks.operators.databricks.databrickstaskbaseoperator method)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksTaskBaseOperator.monitor_databricks_job"]], "name (airflow.providers.databricks.operators.databricks.databricksjobrunlink attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksJobRunLink.name"]], "on_kill() (airflow.providers.databricks.operators.databricks.databricksrunnowoperator method)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.on_kill"]], "on_kill() (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator method)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.on_kill"]], "operator_extra_links (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.operator_extra_links"]], "operator_extra_links (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.operator_extra_links"]], "template_ext (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.template_ext"]], "template_ext (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.template_ext"]], "template_fields (airflow.providers.databricks.operators.databricks.databrickscreatejobsoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks.databricksnotebookoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksNotebookOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks.databrickstaskoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksTaskOperator.template_fields"]], "ui_color (airflow.providers.databricks.operators.databricks.databrickscreatejobsoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator.ui_color"]], "ui_color (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.ui_color"]], "ui_color (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.ui_color"]], "ui_fgcolor (airflow.providers.databricks.operators.databricks.databrickscreatejobsoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator.ui_fgcolor"]], "ui_fgcolor (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.ui_fgcolor"]], "ui_fgcolor (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.ui_fgcolor"]], "update_job_for_repair() (in module airflow.providers.databricks.operators.databricks)": [[6, "airflow.providers.databricks.operators.databricks.update_job_for_repair"]], "databricksreposcreateoperator (class in airflow.providers.databricks.operators.databricks_repos)": [[7, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator"]], "databricksreposdeleteoperator (class in airflow.providers.databricks.operators.databricks_repos)": [[7, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposDeleteOperator"]], "databricksreposupdateoperator (class in airflow.providers.databricks.operators.databricks_repos)": [[7, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposUpdateOperator"]], "__aws_code_commit_regexp__ (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.__aws_code_commit_regexp__"]], "__detect_repo_provider__() (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator static method)": [[7, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.__detect_repo_provider__"]], "__git_providers__ (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.__git_providers__"]], "__repos_path_regexp__ (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.__repos_path_regexp__"]], "airflow.providers.databricks.operators.databricks_repos": [[7, "module-airflow.providers.databricks.operators.databricks_repos"]], "execute() (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator method)": [[7, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks_repos.databricksreposdeleteoperator method)": [[7, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposDeleteOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks_repos.databricksreposupdateoperator method)": [[7, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposUpdateOperator.execute"]], "template_fields (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks_repos.databricksreposdeleteoperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposDeleteOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks_repos.databricksreposupdateoperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposUpdateOperator.template_fields"]], "copy_into_approved_formats (in module airflow.providers.databricks.operators.databricks_sql)": [[8, "airflow.providers.databricks.operators.databricks_sql.COPY_INTO_APPROVED_FORMATS"]], "databrickscopyintooperator (class in airflow.providers.databricks.operators.databricks_sql)": [[8, "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator"]], "databrickssqloperator (class in airflow.providers.databricks.operators.databricks_sql)": [[8, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator"]], "airflow.providers.databricks.operators.databricks_sql": [[8, "module-airflow.providers.databricks.operators.databricks_sql"]], "conn_id_field (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator attribute)": [[8, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.conn_id_field"]], "execute() (airflow.providers.databricks.operators.databricks_sql.databrickscopyintooperator method)": [[8, "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator.execute"]], "get_db_hook() (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator method)": [[8, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.get_db_hook"]], "on_kill() (airflow.providers.databricks.operators.databricks_sql.databrickscopyintooperator method)": [[8, "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator.on_kill"]], "template_ext (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator attribute)": [[8, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.template_ext"]], "template_fields (airflow.providers.databricks.operators.databricks_sql.databrickscopyintooperator attribute)": [[8, "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator attribute)": [[8, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.template_fields"]], "template_fields_renderers (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator attribute)": [[8, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.template_fields_renderers"]], "databricksworkflowtaskgroup (class in airflow.providers.databricks.operators.databricks_workflow)": [[9, "airflow.providers.databricks.operators.databricks_workflow.DatabricksWorkflowTaskGroup"]], "workflowrunmetadata (class in airflow.providers.databricks.operators.databricks_workflow)": [[9, "airflow.providers.databricks.operators.databricks_workflow.WorkflowRunMetadata"]], "__exit__() (airflow.providers.databricks.operators.databricks_workflow.databricksworkflowtaskgroup method)": [[9, "airflow.providers.databricks.operators.databricks_workflow.DatabricksWorkflowTaskGroup.__exit__"]], "airflow.providers.databricks.operators.databricks_workflow": [[9, "module-airflow.providers.databricks.operators.databricks_workflow"]], "conn_id (airflow.providers.databricks.operators.databricks_workflow.workflowrunmetadata attribute)": [[9, "airflow.providers.databricks.operators.databricks_workflow.WorkflowRunMetadata.conn_id"]], "is_databricks (airflow.providers.databricks.operators.databricks_workflow.databricksworkflowtaskgroup attribute)": [[9, "airflow.providers.databricks.operators.databricks_workflow.DatabricksWorkflowTaskGroup.is_databricks"]], "job_id (airflow.providers.databricks.operators.databricks_workflow.workflowrunmetadata attribute)": [[9, "airflow.providers.databricks.operators.databricks_workflow.WorkflowRunMetadata.job_id"]], "run_id (airflow.providers.databricks.operators.databricks_workflow.workflowrunmetadata attribute)": [[9, "airflow.providers.databricks.operators.databricks_workflow.WorkflowRunMetadata.run_id"]], "airflow.providers.databricks.operators": [[10, "module-airflow.providers.databricks.operators"]], "databricksworkflowplugin (class in airflow.providers.databricks.plugins.databricks_workflow)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.DatabricksWorkflowPlugin"]], "repair_wait_attempts (in module airflow.providers.databricks.plugins.databricks_workflow)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.REPAIR_WAIT_ATTEMPTS"]], "repair_wait_delay (in module airflow.providers.databricks.plugins.databricks_workflow)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.REPAIR_WAIT_DELAY"]], "repairdatabrickstasks (class in airflow.providers.databricks.plugins.databricks_workflow)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.RepairDatabricksTasks"]], "workflowjobrepairallfailedlink (class in airflow.providers.databricks.plugins.databricks_workflow)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairAllFailedLink"]], "workflowjobrepairsingletasklink (class in airflow.providers.databricks.plugins.databricks_workflow)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairSingleTaskLink"]], "workflowjobrunlink (class in airflow.providers.databricks.plugins.databricks_workflow)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRunLink"]], "airflow.providers.databricks.plugins.databricks_workflow": [[11, "module-airflow.providers.databricks.plugins.databricks_workflow"]], "airflow_app (in module airflow.providers.databricks.plugins.databricks_workflow)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.airflow_app"]], "appbuilder_views (airflow.providers.databricks.plugins.databricks_workflow.databricksworkflowplugin attribute)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.DatabricksWorkflowPlugin.appbuilder_views"]], "default_view (airflow.providers.databricks.plugins.databricks_workflow.repairdatabrickstasks attribute)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.RepairDatabricksTasks.default_view"]], "get_auth_decorator() (in module airflow.providers.databricks.plugins.databricks_workflow)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.get_auth_decorator"]], "get_databricks_task_ids() (in module airflow.providers.databricks.plugins.databricks_workflow)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.get_databricks_task_ids"]], "get_launch_task_id() (in module airflow.providers.databricks.plugins.databricks_workflow)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.get_launch_task_id"]], "get_link() (airflow.providers.databricks.plugins.databricks_workflow.workflowjobrepairallfailedlink method)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairAllFailedLink.get_link"]], "get_link() (airflow.providers.databricks.plugins.databricks_workflow.workflowjobrepairsingletasklink method)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairSingleTaskLink.get_link"]], "get_link() (airflow.providers.databricks.plugins.databricks_workflow.workflowjobrunlink method)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRunLink.get_link"]], "get_task_group_children() (airflow.providers.databricks.plugins.databricks_workflow.workflowjobrepairallfailedlink class method)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairAllFailedLink.get_task_group_children"]], "get_task_instance() (in module airflow.providers.databricks.plugins.databricks_workflow)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.get_task_instance"]], "get_tasks_to_run() (airflow.providers.databricks.plugins.databricks_workflow.workflowjobrepairallfailedlink method)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairAllFailedLink.get_tasks_to_run"]], "get_xcom_result() (in module airflow.providers.databricks.plugins.databricks_workflow)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.get_xcom_result"]], "name (airflow.providers.databricks.plugins.databricks_workflow.databricksworkflowplugin attribute)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.DatabricksWorkflowPlugin.name"]], "name (airflow.providers.databricks.plugins.databricks_workflow.workflowjobrepairallfailedlink attribute)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairAllFailedLink.name"]], "name (airflow.providers.databricks.plugins.databricks_workflow.workflowjobrepairsingletasklink attribute)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRepairSingleTaskLink.name"]], "name (airflow.providers.databricks.plugins.databricks_workflow.workflowjobrunlink attribute)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.WorkflowJobRunLink.name"]], "operator_extra_links (airflow.providers.databricks.plugins.databricks_workflow.databricksworkflowplugin attribute)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.DatabricksWorkflowPlugin.operator_extra_links"]], "repair() (airflow.providers.databricks.plugins.databricks_workflow.repairdatabrickstasks method)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.RepairDatabricksTasks.repair"]], "repair_databricks_package (in module airflow.providers.databricks.plugins.databricks_workflow)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.repair_databricks_package"]], "repair_databricks_view (in module airflow.providers.databricks.plugins.databricks_workflow)": [[11, "airflow.providers.databricks.plugins.databricks_workflow.repair_databricks_view"]], "airflow.providers.databricks.plugins": [[12, "module-airflow.providers.databricks.plugins"]], "databrickspartitionsensor (class in airflow.providers.databricks.sensors.databricks_partition)": [[13, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor"]], "airflow.providers.databricks.sensors.databricks_partition": [[13, "module-airflow.providers.databricks.sensors.databricks_partition"]], "poke() (airflow.providers.databricks.sensors.databricks_partition.databrickspartitionsensor method)": [[13, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor.poke"]], "template_ext (airflow.providers.databricks.sensors.databricks_partition.databrickspartitionsensor attribute)": [[13, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor.template_ext"]], "template_fields (airflow.providers.databricks.sensors.databricks_partition.databrickspartitionsensor attribute)": [[13, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor.template_fields"]], "template_fields_renderers (airflow.providers.databricks.sensors.databricks_partition.databrickspartitionsensor attribute)": [[13, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor.template_fields_renderers"]], "databrickssqlsensor (class in airflow.providers.databricks.sensors.databricks_sql)": [[14, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor"]], "airflow.providers.databricks.sensors.databricks_sql": [[14, "module-airflow.providers.databricks.sensors.databricks_sql"]], "hook() (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor method)": [[14, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.hook"]], "poke() (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor method)": [[14, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.poke"]], "template_ext (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor attribute)": [[14, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.template_ext"]], "template_fields (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor attribute)": [[14, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.template_fields"]], "template_fields_renderers (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor attribute)": [[14, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.template_fields_renderers"]], "airflow.providers.databricks.sensors": [[15, "module-airflow.providers.databricks.sensors"]], "databricksexecutiontrigger (class in airflow.providers.databricks.triggers.databricks)": [[16, "airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger"]], "airflow.providers.databricks.triggers.databricks": [[16, "module-airflow.providers.databricks.triggers.databricks"]], "run() (airflow.providers.databricks.triggers.databricks.databricksexecutiontrigger method)": [[16, "airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger.run"]], "serialize() (airflow.providers.databricks.triggers.databricks.databricksexecutiontrigger method)": [[16, "airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger.serialize"]], "airflow.providers.databricks.triggers": [[17, "module-airflow.providers.databricks.triggers"]], "airflow.providers.databricks.utils.databricks": [[18, "module-airflow.providers.databricks.utils.databricks"]], "normalise_json_content() (in module airflow.providers.databricks.utils.databricks)": [[18, "airflow.providers.databricks.utils.databricks.normalise_json_content"]], "validate_trigger_event() (in module airflow.providers.databricks.utils.databricks)": [[18, "airflow.providers.databricks.utils.databricks.validate_trigger_event"]], "airflow.providers.databricks.utils": [[19, "module-airflow.providers.databricks.utils"]], "dag_id (in module tests.system.databricks.example_databricks)": [[20, "tests.system.databricks.example_databricks.DAG_ID"]], "env_id (in module tests.system.databricks.example_databricks)": [[20, "tests.system.databricks.example_databricks.ENV_ID"]], "query_id (in module tests.system.databricks.example_databricks)": [[20, "tests.system.databricks.example_databricks.QUERY_ID"]], "warehouse_id (in module tests.system.databricks.example_databricks)": [[20, "tests.system.databricks.example_databricks.WAREHOUSE_ID"]], "job (in module tests.system.databricks.example_databricks)": [[20, "tests.system.databricks.example_databricks.job"]], "test_run (in module tests.system.databricks.example_databricks)": [[20, "tests.system.databricks.example_databricks.test_run"]], "tests.system.databricks.example_databricks": [[20, "module-tests.system.databricks.example_databricks"]], "dag_id (in module tests.system.databricks.example_databricks_repos)": [[21, "tests.system.databricks.example_databricks_repos.DAG_ID"]], "env_id (in module tests.system.databricks.example_databricks_repos)": [[21, "tests.system.databricks.example_databricks_repos.ENV_ID"]], "default_args (in module tests.system.databricks.example_databricks_repos)": [[21, "tests.system.databricks.example_databricks_repos.default_args"]], "repo_path (in module tests.system.databricks.example_databricks_repos)": [[21, "tests.system.databricks.example_databricks_repos.repo_path"]], "test_run (in module tests.system.databricks.example_databricks_repos)": [[21, "tests.system.databricks.example_databricks_repos.test_run"]], "tests.system.databricks.example_databricks_repos": [[21, "module-tests.system.databricks.example_databricks_repos"]], "dag_id (in module tests.system.databricks.example_databricks_sensors)": [[22, "tests.system.databricks.example_databricks_sensors.DAG_ID"]], "env_id (in module tests.system.databricks.example_databricks_sensors)": [[22, "tests.system.databricks.example_databricks_sensors.ENV_ID"]], "connection_id (in module tests.system.databricks.example_databricks_sensors)": [[22, "tests.system.databricks.example_databricks_sensors.connection_id"]], "test_run (in module tests.system.databricks.example_databricks_sensors)": [[22, "tests.system.databricks.example_databricks_sensors.test_run"]], "tests.system.databricks.example_databricks_sensors": [[22, "module-tests.system.databricks.example_databricks_sensors"]], "dag_id (in module tests.system.databricks.example_databricks_sql)": [[23, "tests.system.databricks.example_databricks_sql.DAG_ID"]], "env_id (in module tests.system.databricks.example_databricks_sql)": [[23, "tests.system.databricks.example_databricks_sql.ENV_ID"]], "connection_id (in module tests.system.databricks.example_databricks_sql)": [[23, "tests.system.databricks.example_databricks_sql.connection_id"]], "test_run (in module tests.system.databricks.example_databricks_sql)": [[23, "tests.system.databricks.example_databricks_sql.test_run"]], "tests.system.databricks.example_databricks_sql": [[23, "module-tests.system.databricks.example_databricks_sql"]], "databricks_conn_id (in module tests.system.databricks.example_databricks_workflow)": [[24, "tests.system.databricks.example_databricks_workflow.DATABRICKS_CONN_ID"]], "databricks_notification_email (in module tests.system.databricks.example_databricks_workflow)": [[24, "tests.system.databricks.example_databricks_workflow.DATABRICKS_NOTIFICATION_EMAIL"]], "execution_timeout (in module tests.system.databricks.example_databricks_workflow)": [[24, "tests.system.databricks.example_databricks_workflow.EXECUTION_TIMEOUT"]], "group_id (in module tests.system.databricks.example_databricks_workflow)": [[24, "tests.system.databricks.example_databricks_workflow.GROUP_ID"]], "query_id (in module tests.system.databricks.example_databricks_workflow)": [[24, "tests.system.databricks.example_databricks_workflow.QUERY_ID"]], "user (in module tests.system.databricks.example_databricks_workflow)": [[24, "tests.system.databricks.example_databricks_workflow.USER"]], "warehouse_id (in module tests.system.databricks.example_databricks_workflow)": [[24, "tests.system.databricks.example_databricks_workflow.WAREHOUSE_ID"]], "dag (in module tests.system.databricks.example_databricks_workflow)": [[24, "tests.system.databricks.example_databricks_workflow.dag"]], "job_cluster_spec (in module tests.system.databricks.example_databricks_workflow)": [[24, "tests.system.databricks.example_databricks_workflow.job_cluster_spec"]], "task_group (in module tests.system.databricks.example_databricks_workflow)": [[24, "tests.system.databricks.example_databricks_workflow.task_group"]], "test_run (in module tests.system.databricks.example_databricks_workflow)": [[24, "tests.system.databricks.example_databricks_workflow.test_run"]], "tests.system.databricks.example_databricks_workflow": [[24, "module-tests.system.databricks.example_databricks_workflow"]], "tests.system.databricks": [[25, "module-tests.system.databricks"]]}})