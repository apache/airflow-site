Search.setIndex({"docnames": ["_api/airflow/providers/databricks/hooks/databricks/index", "_api/airflow/providers/databricks/hooks/databricks_base/index", "_api/airflow/providers/databricks/hooks/databricks_sql/index", "_api/airflow/providers/databricks/hooks/index", "_api/airflow/providers/databricks/index", "_api/airflow/providers/databricks/operators/databricks/index", "_api/airflow/providers/databricks/operators/databricks_repos/index", "_api/airflow/providers/databricks/operators/databricks_sql/index", "_api/airflow/providers/databricks/operators/databricks_workflow/index", "_api/airflow/providers/databricks/operators/index", "_api/airflow/providers/databricks/sensors/databricks_partition/index", "_api/airflow/providers/databricks/sensors/databricks_sql/index", "_api/airflow/providers/databricks/sensors/index", "_api/airflow/providers/databricks/triggers/databricks/index", "_api/airflow/providers/databricks/triggers/index", "_api/airflow/providers/databricks/utils/databricks/index", "_api/airflow/providers/databricks/utils/index", "_api/tests/system/providers/databricks/example_databricks/index", "_api/tests/system/providers/databricks/example_databricks_repos/index", "_api/tests/system/providers/databricks/example_databricks_sensors/index", "_api/tests/system/providers/databricks/example_databricks_sql/index", "_api/tests/system/providers/databricks/example_databricks_workflow/index", "_api/tests/system/providers/databricks/index", "changelog", "commits", "connections/databricks", "index", "installing-providers-from-sources", "operators/copy_into", "operators/index", "operators/jobs_create", "operators/notebook", "operators/repos_create", "operators/repos_delete", "operators/repos_update", "operators/run_now", "operators/sql", "operators/submit_run", "operators/task", "operators/workflow", "security"], "filenames": ["_api/airflow/providers/databricks/hooks/databricks/index.rst", "_api/airflow/providers/databricks/hooks/databricks_base/index.rst", "_api/airflow/providers/databricks/hooks/databricks_sql/index.rst", "_api/airflow/providers/databricks/hooks/index.rst", "_api/airflow/providers/databricks/index.rst", "_api/airflow/providers/databricks/operators/databricks/index.rst", "_api/airflow/providers/databricks/operators/databricks_repos/index.rst", "_api/airflow/providers/databricks/operators/databricks_sql/index.rst", "_api/airflow/providers/databricks/operators/databricks_workflow/index.rst", "_api/airflow/providers/databricks/operators/index.rst", "_api/airflow/providers/databricks/sensors/databricks_partition/index.rst", "_api/airflow/providers/databricks/sensors/databricks_sql/index.rst", "_api/airflow/providers/databricks/sensors/index.rst", "_api/airflow/providers/databricks/triggers/databricks/index.rst", "_api/airflow/providers/databricks/triggers/index.rst", "_api/airflow/providers/databricks/utils/databricks/index.rst", "_api/airflow/providers/databricks/utils/index.rst", "_api/tests/system/providers/databricks/example_databricks/index.rst", "_api/tests/system/providers/databricks/example_databricks_repos/index.rst", "_api/tests/system/providers/databricks/example_databricks_sensors/index.rst", "_api/tests/system/providers/databricks/example_databricks_sql/index.rst", "_api/tests/system/providers/databricks/example_databricks_workflow/index.rst", "_api/tests/system/providers/databricks/index.rst", "changelog.rst", "commits.rst", "connections/databricks.rst", "index.rst", "installing-providers-from-sources.rst", "operators/copy_into.rst", "operators/index.rst", "operators/jobs_create.rst", "operators/notebook.rst", "operators/repos_create.rst", "operators/repos_delete.rst", "operators/repos_update.rst", "operators/run_now.rst", "operators/sql.rst", "operators/submit_run.rst", "operators/task.rst", "operators/workflow.rst", "security.rst"], "titles": ["<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.hooks.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.hooks.databricks_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.hooks.databricks_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.hooks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators.databricks_repos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators.databricks_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators.databricks_workflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.sensors.databricks_partition</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.sensors.databricks_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.sensors</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.triggers.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.triggers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.utils.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks.example_databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks.example_databricks_repos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks.example_databricks_sensors</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks.example_databricks_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks.example_databricks_workflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks</span></code>", "Changelog", "Package apache-airflow-providers-databricks", "Databricks Connection", "<code class=\"docutils literal notranslate\"><span class=\"pre\">apache-airflow-providers-databricks</span></code>", "Installing from sources", "DatabricksCopyIntoOperator", "Databricks Operators", "DatabricksCreateJobsOperator", "DatabricksNotebookOperator", "DatabricksReposCreateOperator", "DatabricksReposDeleteOperator", "DatabricksReposUpdateOperator", "DatabricksRunNowOperator", "DatabricksSqlOperator", "DatabricksSubmitRunOperator", "DatabricksTaskOperator", "DatabricksWorkflowTaskGroup", "Releasing security patches"], "terms": {"thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "enabl": [0, 1, 24, 25], "submit": [0, 1, 5, 8, 24, 37], "run": [0, 1, 2, 5, 8, 10, 11, 13, 17, 20, 23, 24, 25, 27, 30, 35, 36, 37], "job": [0, 1, 5, 8, 17, 23, 24, 30, 31, 34, 35, 37, 39], "platform": [0, 1], "intern": [0, 1, 2, 7, 10, 11, 25], "oper": [0, 1, 4, 10, 23, 24, 25, 38], "talk": [0, 1], "api": [0, 1, 2, 5, 6, 13, 17, 23, 24, 25, 30, 32, 33, 34, 35, 37], "2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "1": [0, 1, 5, 6, 8, 26, 30, 31, 35, 36, 37], "now": [0, 5, 7, 23, 24, 35], "endpoint": [0, 1, 2, 5, 6, 7, 23, 24, 25, 28, 30, 32, 33, 34, 35, 37], "http": [0, 1, 2, 5, 6, 7, 10, 11, 17, 23, 24, 25, 27, 28, 31, 32, 36, 39], "doc": [0, 5, 6, 17, 23, 24], "com": [0, 5, 6, 17, 18, 23, 27, 32, 33, 34, 37], "dev": [0, 5, 6, 24], "tool": [0, 5, 6, 24], "latest": [0, 5, 6, 17, 23, 24, 34, 40], "html": [0, 5, 6, 17], "jobsrunnow": [0, 5], "_": [0, 39], "get_cluster_endpoint": 0, "get": [0, 2, 5, 7, 11, 23, 24, 27, 30, 37, 40], "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "cluster": [0, 2, 5, 7, 8, 10, 11, 17, 25, 28, 36, 37], "sourc": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 15, 17, 18, 19, 20, 21, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39], "restart_cluster_endpoint": 0, "post": [0, 6], "restart": 0, "start_cluster_endpoint": 0, "start": 0, "terminate_cluster_endpoint": 0, "delet": [0, 6, 23, 24], "create_endpoint": 0, "creat": [0, 5, 6, 7, 8, 11, 17, 20, 23, 24, 27, 30, 36, 39], "reset_endpoint": 0, "reset": [0, 5, 23, 24, 30], "run_now_endpoint": 0, "submit_run_endpoint": 0, "get_run_endpoint": 0, "cancel_run_endpoint": 0, "cancel": [0, 5, 23, 24], "delete_run_endpoint": 0, "repair_run_endpoint": 0, "repair": [0, 5, 23, 24], "output_runs_job_endpoint": 0, "output": [0, 7, 20, 23, 24], "cancel_all_runs_endpoint": 0, "all": [0, 2, 5, 7, 8, 10, 11, 23, 24, 25, 26, 30, 35, 36, 39, 40], "install_libs_endpoint": 0, "librari": [0, 1, 5, 37, 38, 39], "instal": [0, 5, 8, 23, 24, 40], "uninstall_libs_endpoint": 0, "uninstal": [0, 24], "list_jobs_endpoint": 0, "list": [0, 2, 5, 7, 8, 10, 11, 23, 24, 32, 36], "list_pipelines_endpoint": 0, "pipelin": [0, 5, 23, 24, 37], "workspace_get_status_endpoint": 0, "workspac": [0, 5, 17, 25, 31, 36, 38, 39], "statu": [0, 23, 24], "spark_versions_endpoint": 0, "spark": [0, 2, 5, 7, 8, 10, 11, 17, 24, 25, 37], "version": [0, 2, 5, 7, 10, 11, 23, 24, 26, 27, 35, 37, 39, 40], "runlifecyclest": 0, "base": [0, 1, 2, 5, 6, 7, 8, 10, 11, 13, 23, 24, 36], "enum": 0, "life": 0, "cycl": 0, "state": [0, 17, 23, 24], "concept": [0, 24], "see": [0, 5, 6, 15, 23, 24, 25, 26, 32], "more": [0, 5, 6, 7, 8, 17, 23, 24, 25, 35, 37], "inform": [0, 5, 7, 8, 13, 17, 23, 24, 40], "azur": [0, 23, 24, 25], "listrun": 0, "life_cycle_st": 0, "block": [0, 23, 24], "internal_error": 0, "pend": 0, "queu": [0, 23, 24], "skip": [0, 23, 24], "termin": [0, 5], "waiting_for_retri": 0, "runstat": [0, 17], "result_st": [0, 17], "state_messag": 0, "arg": [0, 5, 24], "kwarg": [0, 2, 5, 6, 7, 8, 10, 11], "util": [0, 4, 6, 8, 35, 37], "properti": [0, 8], "is_termin": 0, "bool": [0, 2, 5, 6, 7, 32], "true": [0, 2, 5, 7, 8, 25, 28], "current": [0, 2, 5, 30, 37], "i": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40], "is_success": 0, "result": [0, 2, 5, 10, 11, 13, 23, 24], "success": [0, 17], "run_life_cycle_st": [0, 23, 24], "__eq__": 0, "other": [0, 5, 23, 24, 28, 35, 36, 39], "return": [0, 1, 2, 5, 6, 7, 10, 11, 13, 23, 24, 30], "self": [0, 5, 27], "valu": [0, 5, 6, 7, 20, 23, 24, 25, 36, 37], "__repr__": 0, "repr": 0, "to_json": 0, "classmethod": 0, "from_json": 0, "data": [0, 7, 20, 23, 24], "clusterst": [0, 23, 24], "is_run": 0, "cluster_life_cycle_st": 0, "resiz": 0, "error": [0, 8, 23, 24, 30, 37], "unknown": [0, 1, 27], "databrickshook": [0, 23, 24], "databricks_conn_id": [0, 1, 2, 5, 6, 7, 8, 10, 11, 13, 21, 23, 24, 28, 32, 33, 34, 36, 38, 39], "basedatabrickshook": [0, 1, 2], "default_conn_nam": [0, 1, 2, 7, 10, 11], "timeout_second": [0, 1, 5, 30, 37], "180": [0, 1], "retry_limit": [0, 1, 13], "3": [0, 1, 5, 6, 13, 26, 30, 31, 36, 39], "retry_delai": [0, 1, 13], "retry_arg": [0, 1, 13], "none": [0, 1, 2, 5, 6, 7, 8, 10, 11, 13, 27], "caller": [0, 1, 2, 5, 13], "databricks_bas": [0, 2, 3, 4], "interact": [0, 1, 2, 36], "paramet": [0, 1, 2, 5, 6, 7, 8, 10, 11, 13, 23, 24, 25, 28, 32, 33, 34, 35, 36, 39], "str": [0, 1, 2, 5, 6, 7, 8, 10, 11, 13, 24, 32, 33, 34], "refer": [0, 1, 2, 5, 6, 7, 10, 11, 13, 17, 37], "connect": [0, 1, 2, 5, 6, 7, 8, 10, 11, 13, 23, 24, 32, 33, 34, 36], "int": [0, 1, 5, 6, 7, 8, 13, 36], "The": [0, 1, 2, 5, 8, 13, 17, 20, 23, 25, 26, 27, 28, 30, 35, 36, 37, 40], "amount": [0, 1, 5, 6, 32, 33, 34], "time": [0, 1, 5, 6, 8, 13, 23, 24, 32, 33, 34, 36, 37, 39], "second": [0, 1, 5, 6, 13, 17, 20, 30, 32, 33, 34, 37, 39], "request": [0, 1, 2, 5, 7, 10, 11, 24, 25, 26], "wait": [0, 1, 5, 6, 13, 32, 33, 34, 36], "befor": [0, 1, 2, 5, 23, 24, 34], "out": [0, 1, 6, 23, 24, 40], "number": [0, 1, 5, 6, 7, 8, 13, 24, 32, 33, 34], "retri": [0, 1, 5, 6, 13, 23, 24, 32, 33, 34, 39], "case": [0, 1, 5, 6, 13, 23, 37, 40], "servic": [0, 1, 13, 23, 24, 25], "outag": [0, 1, 13], "float": [0, 1, 5, 6], "between": [0, 1, 5, 6, 13, 32, 33, 34], "might": [0, 1, 5, 6, 26, 40], "point": [0, 1, 5, 6, 24], "dict": [0, 1, 2, 5, 7, 8, 10, 11, 13, 23, 24], "ani": [0, 1, 2, 5, 7, 8, 10, 11, 13, 23, 27], "an": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40], "option": [0, 1, 2, 5, 6, 7, 10, 11, 13, 23, 24, 25, 28, 32, 35, 36], "dictionari": [0, 1, 2, 5, 6, 7, 8, 10, 11, 13, 25], "argument": [0, 1, 5, 13, 23, 24, 25, 30], "pass": [0, 1, 2, 5, 7, 8, 13, 20, 24, 30, 35, 37, 39], "tenac": [0, 1, 5, 13], "hook_nam": [0, 2], "create_job": 0, "json": [0, 5, 7, 23, 24, 25, 28, 35], "call": [0, 1, 2, 5, 13, 23, 24, 30, 35, 37], "us": [0, 2, 5, 6, 7, 8, 10, 11, 13, 17, 20, 21, 23, 24, 25, 26, 27, 31, 39, 40], "bodi": [0, 24], "job_id": [0, 5, 8, 23, 24, 30, 35], "type": [0, 5, 7, 13, 23, 24, 25, 30, 35, 36, 37], "reset_job": 0, "new_set": 0, "run_now": [0, 30], "run_id": [0, 5, 8, 13], "submit_run": 0, "list_job": [0, 23, 24], "limit": [0, 36], "25": [0, 24], "expand_task": 0, "fals": [0, 2, 5, 6, 13, 31], "job_nam": [0, 5, 35], "page_token": [0, 23], "include_user_nam": 0, "batch": [0, 24], "size": 0, "retriev": [0, 5, 23, 24], "whether": [0, 2, 5], "includ": [0, 23, 24, 26, 30, 37, 40], "task": [0, 5, 8, 13, 17, 20, 23, 24, 30, 31, 35, 36, 37, 38, 39], "detail": [0, 5, 23, 24, 27], "respons": [0, 23, 24], "name": [0, 1, 2, 5, 6, 7, 8, 10, 11, 23, 24, 25, 28, 32, 33, 34, 35, 36, 39], "search": [0, 23, 24], "page": [0, 13, 24, 27], "token": [0, 1, 5, 6, 23, 24, 25], "first": [0, 5, 7, 17, 20, 23, 24, 30, 35, 37], "A": [0, 5, 8], "find_job_id_by_nam": 0, "find": 0, "id": [0, 5, 6, 7, 8, 10, 11, 13, 23, 24, 27, 33, 34, 35, 36, 37], "its": [0, 6, 23, 32, 34, 36], "ar": [0, 5, 7, 8, 13, 23, 24, 25, 26, 27, 28, 30, 35, 36, 37, 39, 40], "multipl": [0, 30, 35, 37], "same": [0, 5, 6, 7, 23, 30, 35, 37], "rais": [0, 8, 23, 24], "airflowexcept": 0, "look": [0, 5, 7, 8], "up": [0, 5, 24], "wa": [0, 2, 5, 13, 23, 30], "found": [0, 28, 35, 36, 40], "list_pipelin": 0, "batch_siz": 0, "pipeline_nam": [0, 37], "notebook_path": [0, 5, 30, 31, 37, 38, 39], "delta": [0, 5, 20, 37], "live": [0, 5, 37], "tabl": [0, 2, 5, 7, 10, 20, 28, 36, 37], "cannot": [0, 5, 23, 24], "combin": 0, "path": [0, 2, 5, 6, 7, 10, 11, 13, 17, 20, 23, 24, 25, 28, 32, 36, 37], "notebook": [0, 5, 8, 17, 23, 24, 37, 39], "find_pipeline_id_by_nam": 0, "pipeline_id": [0, 5, 37], "guid": [0, 5, 7, 8, 24, 27], "string": [0, 2, 7, 10, 11, 23, 24, 28, 32, 33, 34, 36], "get_run_page_url": 0, "run_page_url": [0, 5, 13], "url": [0, 6, 13, 25, 32], "async": [0, 1, 13, 23, 24], "a_get_run_page_url": 0, "get_job_id": 0, "from": [0, 5, 6, 7, 11, 15, 20, 23, 24, 25, 26, 28, 32, 40], "given": [0, 5, 6, 7, 32, 34, 36], "get_run_st": 0, "pleas": [0, 5, 23, 27], "note": [0, 2, 5, 24, 25, 30, 35, 37], "method": [0, 5, 8, 23, 24, 25], "failur": [0, 5], "unless": [0, 2], "you": [0, 5, 23, 25, 26, 27, 30, 32, 33, 34, 35, 37, 39, 40], "have": [0, 5, 17, 23, 24, 25, 36, 40], "xcom": [0, 5, 23, 24, 30], "pickl": 0, "can": [0, 5, 6, 7, 23, 25, 26, 27, 30, 32, 35, 36, 37, 38, 39, 40], "done": [0, 40], "follow": [0, 5, 23, 24, 25, 27, 28, 30, 32, 33, 34, 35, 36, 37, 40], "environ": [0, 25], "variabl": [0, 25], "airflow__core__enable_xcom_pickl": 0, "If": [0, 2, 5, 6, 7, 8, 10, 11, 13, 23, 25, 27, 30, 32, 37, 39], "do": [0, 8, 23, 24, 27, 36, 37, 39], "want": [0, 13, 23, 27, 40], "get_run_state_str": 0, "describ": [0, 2, 7, 10, 11, 27, 35], "get_run_state_lifecycl": 0, "get_run_state_result": 0, "get_run_state_messag": 0, "individu": [0, 7, 24], "compon": [0, 25], "a_get_run_st": 0, "get_run": 0, "a_get_run": 0, "represent": [0, 5], "lifecycl": 0, "messag": 0, "get_run_output": 0, "a_get_run_output": 0, "cancel_run": 0, "cancel_all_run": 0, "activ": [0, 25], "asynchron": [0, 13], "canon": 0, "identifi": 0, "delete_run": 0, "non": [0, 24], "repair_run": [0, 5, 13, 23, 24, 35], "re": [0, 13, 24, 25], "one": [0, 5, 23, 24, 27, 30, 35, 36, 37], "get_latest_repair_id": 0, "exist": [0, 5, 6, 8, 26, 30, 32, 33, 34, 35, 36, 37, 39], "els": [0, 23, 24], "get_cluster_st": 0, "cluster_id": 0, "a_get_cluster_st": 0, "restart_clust": 0, "contain": [0, 5, 6, 7, 8, 10, 11, 25, 27, 28], "specif": [0, 5, 7, 8, 24, 25, 36, 37, 39], "start_clust": 0, "terminate_clust": 0, "function": [0, 2, 11, 23, 24, 35, 37], "arrai": [0, 5, 37], "update_repo": [0, 34], "repo_id": [0, 6, 33, 34], "updat": [0, 6, 23, 24, 30, 39], "repo": [0, 6, 18, 23, 24, 31, 39], "payload": [0, 5, 24, 30, 35, 37], "metadata": [0, 1, 5, 8], "delete_repo": [0, 33], "create_repo": [0, 32], "get_repo_by_path": 0, "obtain": [0, 25], "repositori": [0, 5, 6, 32], "doesn": 0, "t": [0, 2, 6, 7, 23, 24, 25, 32, 33, 34, 35, 39], "update_job_permiss": 0, "permiss": [0, 5, 23, 24, 25], "test_connect": [0, 23, 24], "test": [0, 23, 24, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40], "ui": [0, 5, 30], "6": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "7": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "10": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "dev0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "experiment": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "featur": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "azure_metadata_service_token_url": 1, "169": 1, "254": 1, "ident": [1, 23, 24, 25], "oauth2": 1, "azure_metadata_service_instance_url": 1, "instanc": [1, 5, 23, 24], "token_refresh_lead_tim": 1, "120": 1, "azure_management_endpoint": 1, "manag": [1, 8, 23, 24, 25, 27], "core": [1, 24, 28], "window": [1, 28], "net": [1, 28], "default_databricks_scop": 1, "2ff814a6": 1, "3304": 1, "4ab8": 1, "85cb": 1, "cd0e6f879c1d": 1, "oidc_token_service_url": 1, "oidc": 1, "v1": 1, "basehook": 1, "conn_name_attr": 1, "databricks_default": [1, 5, 6, 19, 25, 36], "conn_typ": 1, "extra_paramet": 1, "host": [1, 5, 6, 23, 24, 25], "use_azure_managed_ident": [1, 25], "azure_ad_endpoint": [1, 25], "azure_resource_id": [1, 25], "databricks_conn": [1, 38, 39], "get_conn": [1, 2], "user_agent_head": 1, "user_agent_valu": 1, "__aenter__": 1, "__aexit__": 1, "err": 1, "bearerauth": 1, "aiohttp": [1, 23, 24, 26], "basicauth": [1, 23, 24], "onli": [1, 2, 5, 7, 23, 25, 28, 35, 36, 40], "ship": 1, "bearer": [1, 25], "auth": [1, 23, 24, 25], "we": [1, 5, 6, 17, 23, 24, 32, 36, 39, 40], "need": [1, 5, 13, 23, 24, 25, 26, 32, 33, 34, 37], "subclass": 1, "encod": [1, 25], "credenti": [1, 7, 25], "list_sql_endpoints_endpoint": 2, "sql": [2, 7, 10, 11, 20, 23, 24, 25, 26, 28, 36], "databrickssqlhook": [2, 7, 10, 11, 23, 24], "http_path": [2, 7, 10, 11, 25, 28, 36], "sql_endpoint_nam": [2, 7, 28, 36], "session_configur": [2, 7, 10, 11, 25], "http_header": [2, 7, 10, 11], "catalog": [2, 7, 10, 11, 36], "schema": [2, 7, 10, 11, 36], "return_tupl": [2, 23, 24], "common": [2, 5, 6, 7, 23, 24, 26], "dbapihook": [2, 10, 11, 23, 24], "specifi": [2, 5, 6, 7, 10, 11, 20, 23, 24, 25, 26, 28, 32, 35, 36, 39], "should": [2, 5, 6, 7, 10, 11, 13, 23, 24, 25, 27, 36, 37, 40], "either": [2, 5, 7, 10, 11, 13, 25, 33, 34, 35, 37], "": [2, 5, 6, 7, 10, 11, 23, 24, 25, 27, 30, 32, 36, 37], "extra": [2, 5, 6, 7, 10, 11, 23, 24, 25, 26], "must": [2, 5, 6, 7, 8, 10, 11, 25, 32, 36, 37], "abov": [2, 7, 27], "session": [2, 7, 10, 11, 23, 24, 25], "default": [2, 5, 6, 7, 8, 10, 11, 13, 24, 36, 40], "could": [2, 7, 10, 11, 25, 28, 36], "tupl": [2, 7, 10, 11, 13, 23, 24], "k": [2, 7, 10, 11], "v": [2, 7, 10, 11, 36], "pair": [2, 5, 7, 10, 11], "set": [2, 5, 7, 10, 11, 17, 23, 24, 25], "header": [2, 7, 10, 11, 24, 25, 28], "everi": [2, 5, 7, 10, 11, 13], "initi": [2, 7, 10, 11, 23, 24, 30, 37], "requir": [2, 5, 6, 7, 10, 11, 23, 24, 25, 28, 32, 33, 34, 35, 36, 39, 40], "dbr": [2, 7], "9": [2, 7, 10, 11, 23, 24, 26, 37], "namedtupl": [2, 23, 24], "object": [2, 5, 7, 11, 23, 24, 25, 37], "instead": [2, 5, 23, 24, 25, 37], "row": [2, 7, 23, 24], "In": [2, 5, 13, 17, 30, 35, 37], "futur": 2, "releas": [2, 23, 24, 26, 34], "becom": 2, "ensur": [2, 23, 24], "backward": 2, "compat": [2, 23, 24], "dure": [2, 5, 23, 24, 30, 37], "transit": 2, "phase": 2, "flag": [2, 25], "also": [2, 5, 7, 23, 27, 30, 37], "remov": [2, 23, 24, 27], "addit": [2, 7, 10, 11, 35], "connector": [2, 7, 10, 11, 23, 24, 25, 26], "iter": [2, 11], "autocommit": 2, "map": [2, 5, 25], "handler": [2, 10, 11], "split_stat": 2, "return_last": 2, "callabl": [2, 10, 11], "command": [2, 5, 7, 24, 28, 37], "statement": [2, 7, 11, 20, 23, 24], "them": [2, 23, 24, 26], "execut": [2, 5, 6, 7, 11, 17, 23, 24, 30, 34, 37, 39], "sequenti": [2, 17], "what": 2, "queri": [2, 7, 11, 23, 24, 36, 39], "commit": [2, 24], "so": [2, 23, 24, 30, 36, 40], "ha": [2, 17, 23], "effect": [2, 35, 37], "render": [2, 5, 6, 7], "which": [2, 5, 7, 8, 17, 20, 23, 24, 25, 37, 40], "each": [2, 5, 8, 30, 35, 36, 37], "split": 2, "singl": [2, 7, 8, 13, 37, 39], "separ": [2, 24, 40], "last": 2, "after": [2, 23, 24, 30], "express": [2, 7, 23, 24], "abstract": 2, "bulk_dump": 2, "tmp_file": 2, "dump": 2, "databas": [2, 7], "tab": 2, "delimit": 2, "file": [2, 5, 7, 20, 23, 24, 27, 28, 37], "target": 2, "bulk_load": 2, "load": [2, 20, 24, 28], "databricks_sql": [3, 4, 9, 12, 23, 24], "hook": [4, 7, 11, 23, 24, 25], "databricks_repo": [4, 9], "databricks_workflow": [4, 9], "sensor": [4, 23, 24], "databricks_partit": [4, 12], "trigger": [4, 5, 23, 24, 35], "__version__": [4, 24], "defer_method_nam": 5, "execute_complet": [5, 23, 24], "xcom_run_id_kei": 5, "xcom_job_id_kei": 5, "xcom_run_page_url_kei": 5, "normalise_json_cont": 5, "databricksjobrunlink": [5, 23, 24], "model": [5, 6, 7, 40], "baseoperatorlink": 5, "construct": [5, 7], "link": [5, 23, 24, 27], "monitor": [5, 31, 38, 39], "get_link": 5, "ti_kei": 5, "extern": [5, 36], "system": [5, 25, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39], "old": [5, 24], "signatur": [5, 24, 26, 27], "dttm": 5, "datetim": 5, "That": [5, 23], "still": [5, 23], "support": [5, 7, 23, 24, 25, 26, 28, 30, 32, 36, 37], "runtim": [5, 10, 11, 23, 24], "deprec": [5, 23, 24], "baseoper": [5, 6, 7, 23, 24], "associ": 5, "taskinstancekei": [5, 24], "taskinst": [5, 23, 24], "databrickscreatejobsoper": [5, 23, 24, 29], "descript": [5, 23, 24, 30], "tag": [5, 6, 30, 32, 34], "job_clust": [5, 8, 30, 39], "email_notif": [5, 30, 39], "webhook_notif": [5, 30], "notification_set": [5, 30], "schedul": [5, 30], "max_concurrent_run": [5, 8, 30], "git_sourc": [5, 23, 24, 30, 37], "access_control_list": [5, 30], "polling_period_second": [5, 13], "30": [5, 13, 24], "databricks_retry_limit": [5, 6, 32, 33, 34], "databricks_retry_delai": [5, 6, 32, 33, 34], "databricks_retry_arg": 5, "directli": [5, 30, 35, 37], "e": [5, 13, 25], "etc": 5, "merg": [5, 30, 37], "thei": [5, 13, 30, 36, 37], "conflict": [5, 30, 37, 39], "take": [5, 7, 8, 30, 35, 37], "preced": [5, 30, 37], "overrid": [5, 8, 23, 24, 30, 37], "top": [5, 26, 27, 30, 35, 37], "level": [5, 8, 23, 24, 30, 35, 37, 39], "kei": [5, 6, 27, 30, 37], "templat": [5, 6, 7, 10, 11, 23, 24], "For": [5, 7, 8, 17, 24, 25, 26, 27, 35, 36], "about": [5, 17, 24, 27, 40], "jinja": [5, 6, 7, 23, 24], "jobtaskset": 5, "share": [5, 30, 31, 38, 39], "reus": [5, 25], "jobclust": 5, "jobemailnotif": 5, "webhooknotif": 5, "notif": [5, 23, 24], "timeout": [5, 36], "appli": [5, 23, 24], "cronschedul": 5, "maximum": [5, 8], "allow": [5, 23, 24, 25, 35, 37], "concurr": [5, 8], "remot": 5, "gitsourc": 5, "accesscontrolrequestforus": 5, "accesscontrolrequestforgroup": 5, "accesscontrolrequestforserviceprincip": 5, "order": [5, 24, 26], "acl": [5, 23, 24], "consid": [5, 25], "control": [5, 7, 13, 30, 37, 39], "rate": [5, 13], "poll": [5, 13], "By": [5, 6, 13, 27], "backend": [5, 6, 24, 32, 33, 34], "unreach": [5, 6, 32, 33, 34], "Its": [5, 6], "greater": [5, 6], "than": [5, 6, 30], "equal": [5, 6], "template_field": [5, 6, 7, 10, 11, 23, 24], "sequenc": [5, 6, 7, 10, 11, 23, 24], "ui_color": 5, "1cb1c2": 5, "ui_fgcolor": 5, "fff": 5, "context": [5, 6, 7, 8, 10, 11, 13, 24], "deriv": [5, 6, 7, 23, 24], "when": [5, 6, 7, 13, 23, 24, 25, 26, 30, 37, 39, 40], "get_template_context": [5, 6, 7], "databrickssubmitrunoper": [5, 17, 23, 24, 29], "spark_jar_task": [5, 37], "notebook_task": [5, 30, 37, 38, 39], "spark_python_task": [5, 37], "spark_submit_task": [5, 37], "pipeline_task": [5, 23, 24, 37], "dbt_task": [5, 37], "new_clust": [5, 30, 31, 37], "existing_cluster_id": [5, 31, 37], "run_nam": [5, 37], "do_xcom_push": [5, 23, 24], "idempotency_token": [5, 35], "wait_for_termin": [5, 23, 24], "deferr": [5, 23, 24, 35, 37], "conf": 5, "getboolean": 5, "default_deferr": [5, 23, 24], "fallback": 5, "jobsrunssubmit": 5, "There": [5, 23, 25, 27, 30, 35, 36, 37, 39], "three": [5, 30, 37], "wai": [5, 25, 30, 35, 36, 37], "instanti": [5, 13, 30, 35, 37], "how": [5, 7, 8, 24, 27], "runsubmittaskset": 5, "100": [5, 31], "item": 5, "main": [5, 23, 24, 27, 37, 40], "jar": [5, 8, 17, 37], "actual": [5, 32], "OR": 5, "field": [5, 6, 23, 24, 25], "jobssparkjartask": 5, "jobsnotebooktask": 5, "python": [5, 8, 23, 24, 26, 27, 37], "jobssparkpythontask": 5, "jobssparksubmittask": 5, "least": [5, 23, 32], "jobspipelinetask": 5, "dbt": [5, 23, 24, 37], "spec": [5, 37], "new": [5, 17, 23, 24, 30, 35, 37, 40], "except": [5, 6, 23, 24, 32, 35, 40], "jobsclusterspecnewclust": 5, "managedlibrarieslibrari": 5, "task_id": [5, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39], "superclass": 5, "guarante": 5, "idempot": 5, "alreadi": [5, 6, 27, 32, 39], "doe": [5, 23, 39], "most": [5, 27], "64": 5, "charact": [5, 24], "repres": [5, 23, 24, 36], "access": [5, 25, 36], "consist": [5, 23], "subject": [5, 24], "user_nam": 5, "user": [5, 6, 18, 21, 23, 24, 25, 27, 32, 33, 34, 36, 37, 39], "group_nam": 5, "group": [5, 8, 39], "permission_level": 5, "document": [5, 7, 23, 24, 25, 28, 32, 35, 36], "mean": 5, "To": [5, 6, 27, 32, 33, 34, 39], "authent": [5, 6, 7, 23, 24], "leav": [5, 6, 25], "empti": [5, 6, 23, 24, 25], "push": [5, 23], "git": [5, 6, 32, 34], "mode": [5, 23, 24], "template_ext": [5, 7, 10, 11, 23, 24], "tpl": 5, "operator_extra_link": 5, "on_kil": 5, "clean": [5, 24], "subprocess": 5, "kill": 5, "thread": 5, "multiprocess": 5, "within": [5, 23, 24, 30, 38, 39], "ghost": 5, "process": [5, 13, 23, 24], "behind": 5, "event": [5, 13, 15, 23, 24, 36], "databrickssubmitrundeferrableoper": [5, 29], "databricksrunnowoper": [5, 23, 24, 29], "notebook_param": [5, 8, 35, 39], "python_param": [5, 8, 35], "jar_param": [5, 8, 35], "spark_submit_param": [5, 8, 35], "python_named_param": 5, "cancel_previous_run": [5, 23, 24, 35], "two": [5, 17, 35], "typic": [5, 30, 35, 37], "our": [5, 24, 30, 35, 37], "through": [5, 30, 35, 37], "exampl": [5, 10, 17, 20, 21, 24, 25, 26, 27, 35], "42": 5, "dry": 5, "oldest": 5, "1457570074236": 5, "notebook_run": [5, 37], "anoth": [5, 13, 35, 37], "accomplish": [5, 30, 35, 37], "thing": [5, 30, 35, 36, 37], "exactli": [5, 30, 35, 36, 37], "your": [5, 23, 39], "code": [5, 7, 23, 24, 27, 34, 39], "would": 5, "like": [5, 13, 32, 33, 34], "dougla": 5, "adam": 5, "org": [5, 27, 31, 39], "apach": [5, 23, 27], "sparkpi": 5, "where": [5, 37, 40], "both": [5, 17, 25, 30, 37], "AND": [5, 30, 37], "togeth": [5, 7, 30, 37], "python_named_paramet": [5, 35], "It": [5, 27, 35, 36, 37], "mutual": 5, "exclus": 5, "g": [5, 13, 25], "john": 5, "ag": 5, "35": 5, "dbutil": 5, "widget": 5, "upon": 5, "conjunct": 5, "exce": 5, "000": 5, "byte": 5, "line": [5, 24], "overwrit": 5, "wheel": [5, 26], "script": [5, 24, 27], "databricksrunnowdeferrableoper": [5, 23, 24, 29], "databrickstaskbaseoper": 5, "job_cluster_kei": [5, 30, 38, 39], "5": [5, 26], "workflow_run_metadata": 5, "abc": [5, 10, 36], "workflow": [5, 8, 38], "log": [5, 23, 24], "notebook_packag": [5, 8, 31, 39], "param": [5, 23, 24, 37], "expect": 5, "conn_id": [5, 8], "monitor_databricks_job": 5, "defer": [5, 13, 23, 24], "launch": [5, 31, 38, 39], "databricksnotebookoper": [5, 21, 23, 24, 29, 39], "part": [5, 38], "databricksworkflowtaskgroup": [5, 8, 21, 23, 24, 29, 38], "advantag": [5, 39], "cheaper": 5, "locat": [5, 7, 28], "local": [5, 27], "defin": [5, 8, 23, 24, 25, 39], "otherwis": [5, 23], "visit": 5, "jobscreat": 5, "databrickstaskoper": [5, 23, 24, 29, 39], "task_config": [5, 38, 39], "configur": [5, 7, 28, 36], "databricksreposcreateoper": [6, 29], "git_url": [6, 32], "git_provid": [6, 32], "branch": [6, 32, 34, 40], "repo_path": [6, 18, 32, 33, 34], "ignore_existing_repo": [6, 32], "check": [6, 10, 23, 24, 27, 30, 36, 37], "guess": [6, 32], "format": [6, 7, 20, 23, 24, 28, 36], "folder": [6, 24, 27], "directori": [6, 25, 27, 32], "checkout": [6, 32], "don": [6, 23, 24, 32], "throw": [6, 32, 35], "__git_providers__": 6, "__aws_code_commit_regexp__": 6, "__repos_path_regexp__": 6, "static": [6, 24], "__detect_repo_provider__": 6, "databricksreposupdateoper": [6, 29], "patch": [6, 24], "omit": 6, "databricksreposdeleteoper": [6, 29], "databrickssqloper": [7, 20, 23, 24, 25, 29], "output_path": [7, 36], "output_format": [7, 36], "csv": 7, "csv_param": 7, "client_paramet": [7, 10, 11], "sqlexecutequeryoper": [7, 23, 24], "recogn": 7, "end": [7, 24], "write": 7, "select": [7, 20, 27], "possibl": [7, 24, 39], "jsonl": [7, 36], "dictwrit": 7, "template_fields_render": [7, 10, 11], "conn_id_field": 7, "get_db_hook": 7, "copy_into_approved_format": 7, "avro": [7, 28], "orc": [7, 28], "parquet": [7, 28], "text": [7, 28], "binaryfil": [7, 28], "databrickscopyintooper": [7, 20, 23, 24, 29], "table_nam": [7, 10, 28, 36], "file_loc": [7, 20, 28], "file_format": [7, 28], "pattern": 7, "expression_list": 7, "storage_credenti": 7, "encrypt": 7, "format_opt": [7, 28], "force_copi": [7, 28], "copy_opt": 7, "valid": [7, 15, 23, 24, 27], "copi": [7, 28], "INTO": [7, 28], "piec": 7, "import": [7, 23, 24, 27], "regex": 7, "match": [7, 23, 24, 27, 39], "against": [7, 36], "uniti": 7, "storag": 7, "destin": 7, "forc": 7, "integ": [7, 32, 33, 34], "n": 7, "right": 7, "workflowrunmetadata": 8, "existing_clust": 8, "extra_job_param": [8, 39], "task_group": [8, 21, 39], "taskgroup": 8, "produc": [8, 39], "those": [8, 26, 27], "elig": 8, "_convert_to_databricks_workflow_task": 8, "pars": 8, "definit": [8, 17, 39], "These": 8, "packag": [8, 23, 25, 31, 38, 39], "under": [8, 30], "And": 8, "is_databrick": 8, "__exit__": 8, "_type": 8, "_valu": 8, "_tb": 8, "exit": 8, "add": [8, 23, 24, 25], "_createdatabricksworkflowoper": 8, "databrickspartitionsensor": [10, 23, 24, 29], "sql_warehouse_nam": [10, 11, 36], "partit": [10, 36], "partition_oper": [10, 36], "fetch_all_handl": [10, 11], "basesensoroper": [10, 11], "detect": [10, 23, 24, 30, 37], "presenc": [10, 36], "warehous": [10, 11, 36], "below": [10, 11, 26, 27], "purpos": [10, 11, 39], "date": [10, 36], "2023": [10, 24, 36], "01": [10, 24, 36], "03": [10, 24, 36], "def": [10, 36], "comparison": [10, 36], "poke": [10, 11, 36], "databrickssqlsensor": [11, 23, 24, 29], "databricksexecutiontrigg": [13, 15], "basetrigg": 13, "handl": [13, 23, 24], "logic": 13, "commun": 13, "serial": [13, 23, 24], "reconstruct": 13, "keyword": 13, "yield": [13, 23, 24], "whenev": [13, 39], "fire": 13, "off": 13, "finish": [13, 36], "thu": 13, "immedi": 13, "resum": 13, "veri": 13, "quickli": 13, "mai": [13, 24, 25, 37], "workload": 13, "being": 13, "move": [13, 23, 24], "multi": [13, 23, 24], "assum": 13, "persist": 13, "reli": [13, 23, 30], "cleanup": [13, 24], "longer": 13, "validate_trigger_ev": 15, "correct": [15, 23, 24, 27], "receiv": [15, 40], "dag": [17, 20, 21, 23, 24, 38], "upload": 17, "dbf": [17, 37], "becaus": [17, 30, 37, 39], "downstream": [17, 36], "depend": [17, 23, 24, 35, 40], "NOT": 17, "until": [17, 36], "complet": [17, 23], "successfulli": 17, "env_id": [17, 18, 19, 20], "dag_id": [17, 18, 19, 20], "example_databricks_oper": 17, "query_id": [17, 21, 38, 39], "warehouse_id": [17, 21, 38, 39], "test_run": [17, 18, 19, 20, 21], "default_arg": [18, 24], "example_databricks_repos_oper": 18, "domain": [18, 32, 33, 34], "demo": [18, 32, 33, 34], "connection_id": [19, 20, 28, 36], "insert": [20, 36], "third": [20, 30], "store": [20, 36], "fourth": 20, "written": 20, "final": [20, 23, 24], "example_databricks_sql_oper": 20, "my_connect": 20, "execution_timeout": [21, 39], "databricks_notification_email": [21, 39], "group_id": [21, 39], "job_cluster_spec": [21, 39], "example_databrick": [22, 30, 31, 37, 38], "example_databricks_repo": [22, 32, 33, 34], "example_databricks_sensor": [22, 36], "example_databricks_sql": [22, 28, 36], "example_databricks_workflow": [22, 39], "airflow": [23, 25, 27, 31, 32, 33, 34, 35, 37, 38, 40], "provid": [23, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38, 40], "databrick": [23, 27, 28, 30, 35, 36, 37], "make": [23, 24], "40471": [23, 24], "40332": [23, 24], "40013": [23, 24], "39771": [23, 24], "40178": [23, 24], "implement": [23, 24], "per": [23, 24], "lowest": [23, 24], "direct": [23, 24], "resolut": [23, 24], "39946": [23, 24], "lower": [23, 24], "info": [23, 24], "debug": [23, 24], "reduc": [23, 24], "verbos": [23, 24], "39941": [23, 24], "panda": [23, 24, 26], "minimum": [23, 24, 26], "12": [23, 24, 27, 30, 31, 37], "40272": [23, 24], "39295": [23, 24], "fail": [23, 24], "39354": [23, 24], "faster": [23, 24], "airflow_vers": [23, 24], "39552": [23, 24], "simplifi": [23, 24], "39497": [23, 24], "better": [23, 24], "39742": [23, 24], "avail": [23, 27, 31, 37], "explain": 23, "polici": [23, 40], "39178": [23, 24], "39175": [23, 24], "feat": [23, 24], "39110": [23, 24], "bump": [23, 24], "39240": [23, 24], "38702": [23, 24], "38619": [23, 24], "38962": [23, 24], "remain": [23, 24], "d401": [23, 24], "37434": [23, 24], "38741": [23, 24], "slash": [23, 24], "38918": [23, 24], "typo": [23, 24], "latest_repair_id": 23, "39050": [23, 24], "refactor": [23, 24], "redund": [23, 24], "38397": [23, 24], "renam": [23, 24], "compli": [23, 24], "38052": [23, 24], "work": [23, 24, 25], "37025": [23, 24], "min": [23, 24], "avoid": [23, 24], "cve": [23, 24], "2024": [23, 24], "23829": [23, 24], "23334": [23, 24], "37110": [23, 24], "switch": [23, 24, 25], "class": [23, 24, 26, 28, 36, 37], "decor": [23, 24], "36876": [23, 24], "rid": [23, 24], "pytest": [23, 24], "httpx": [23, 24], "37334": [23, 24], "36601": [23, 24], "36827": [23, 24], "column": [23, 24], "attribut": [23, 24], "36949": [23, 24], "36862": [23, 24], "structur": [23, 24, 39], "dbapi": [23, 24], "36205": 23, "fetchon": [23, 24], "odbchook": [23, 24], "36161": [23, 24], "36017": [23, 24], "36248": [23, 24], "snippet": [23, 24], "docstr": [23, 24], "via": [23, 24, 26, 27, 32, 33, 34, 35, 36, 37, 39], "ruff": [23, 24], "36262": [23, 24], "been": 23, "reason": [23, 40], "broken": [23, 24], "pyodbc": [23, 24], "serializ": [23, 24], "make_serializ": [23, 24], "32319": [23, 24], "offset": [23, 24], "favor": 23, "pagin": [23, 24], "similarli": 23, "34926": [23, 24], "35156": [23, 24], "34643": [23, 24], "respect": [23, 24, 36], "soft_fail": [23, 24], "34544": [23, 24], "34517": [23, 24], "decod": [23, 24], "f": [23, 24, 39], "34518": [23, 24], "34728": [23, 24], "httpbasicauth": [23, 24], "34590": [23, 24], "33472": [23, 24], "deploy": [23, 24], "33886": [23, 24], "accept": [23, 24, 36], "32903": [23, 24], "replac": [23, 24], "concaten": [23, 24], "unpack": [23, 24], "33933": [23, 24], "improv": [23, 24], "modul": [23, 24], "some": [23, 24], "33754": [23, 24], "liter": [23, 24], "33761": [23, 24], "33752": [23, 24], "exclud": [23, 24], "due": [23, 24], "properli": 23, "declar": 23, "urllib3": 23, "github": [23, 24, 32], "issu": 23, "190": 23, "princip": [23, 24, 25], "oauth": [23, 24, 25], "33005": [23, 24], "py": [23, 24, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39], "32340": [23, 24], "33519": [23, 24], "duplic": [23, 24], "sort": [23, 24], "33675": [23, 24], "condit": [23, 24], "len": [23, 24], "33569": [23, 24], "smaller": [23, 24], "33234": [23, 24], "conn": [23, 24], "30784": [23, 24], "32806": [23, 24], "miss": [23, 24], "32689": [23, 24], "accur": [23, 24], "31846": [23, 24], "modifi": [23, 24, 39], "parent": [23, 24], "32253": [23, 24], "config": [23, 24], "31712": [23, 24], "drop": [23, 24, 27, 36], "loop": [23, 24], "stop": [23, 24], "31985": [23, 24], "annot": [23, 24], "31888": [23, 24], "31780": [23, 24], "relat": [23, 24, 25, 36], "again": [23, 24], "31898": [23, 24], "31899": [23, 24], "31703": [23, 24], "30963": [23, 24], "31136": [23, 24], "31038": [23, 24], "databr": [23, 24], "30744": [23, 24], "30786": [23, 24], "30980": [23, 24], "30917": [23, 24], "30761": [23, 24], "inact": [23, 24], "30646": [23, 24], "30477": [23, 24], "taskflow": [23, 24], "29840": [23, 24], "conform": 23, "semant": 23, "kind": 23, "previous": 23, "pre": [23, 24], "cursor": 23, "just": 23, "last_descript": 23, "suitabl": 23, "gener": [23, 24, 25, 36], "lineag": 23, "analysi": 23, "had": 23, "custom": 23, "behaviour": [23, 24], "adapt": 23, "standard": [23, 24, 31], "approach": [23, 30, 37], "howev": 23, "unchang": 23, "continu": 23, "without": 23, "introduc": [23, 24, 35, 37], "27854": [23, 24], "27888": [23, 24], "27868": [23, 24], "27912": [23, 24], "databricskssqloper": 23, "27196": [23, 24], "urlpars": [23, 24], "urlsplit": [23, 24], "27389": [23, 24], "25717": [23, 24], "27446": [23, 24], "25623": [23, 24], "bound": [23, 24], "25789": [23, 24], "26628": [23, 24], "agent": [23, 24], "25873": [23, 24], "25578": [23, 24], "25260": [23, 24], "telemetri": [23, 24], "25115": [23, 24], "unifi": [23, 24], "23971": [23, 24], "25114": [23, 24], "convert": [23, 24], "boolean": [23, 24, 25], "deep_string_coerc": [23, 24], "25394": [23, 24], "correctli": [23, 24], "25427": [23, 24], "x": [23, 24, 30, 31, 37], "25674": [23, 24], "ad": [23, 24, 25], "24945": [23, 24], "24617": [23, 24], "24836": [23, 24], "functool": [23, 24], "cached_properti": [23, 24], "24582": [23, 24], "19736": [23, 24], "23620": [23, 24], "23622": [23, 24], "23641": [23, 24], "unboundlocalerror": [23, 24], "23815": [23, 24], "dbsql": [23, 24], "further": [23, 24], "23199": [23, 24], "22422": [23, 24], "22541": [23, 24], "22886": [23, 24], "22885": [23, 24], "hoc": [23, 24], "22571": [23, 24], "22278": [23, 24], "mistakenli": 23, "install_requir": 23, "22382": 23, "22076": [23, 24], "429": [23, 24], "well": [23, 24, 27, 38], "21852": [23, 24], "22221": [23, 24], "show": [23, 24], "21709": [23, 24], "21663": [23, 24], "18925": [23, 24], "21530": [23, 24], "21363": [23, 24], "januari": [23, 24], "2022": [23, 24], "delai": [23, 24], "21439": [23, 24], "21494": [23, 24], "20536": [23, 24], "20526": [23, 24], "attr": [23, 24], "20540": [23, 24], "verif": [23, 24], "20550": [23, 24], "19723": [23, 24], "sp": [23, 24], "cloud": [23, 24, 25], "19722": [23, 24], "pat": [23, 24, 25], "password": [23, 24, 25], "19585": [23, 24], "19544": [23, 24], "19412": [23, 24], "aad": [23, 24, 25], "19335": [23, 24], "19443": [23, 24], "db": [23, 24], "__init__": [23, 24], "20180": [23, 24], "fixup": [23, 24], "19099": [23, 24], "expir": [23, 24], "20036": [23, 24], "18339": [23, 24], "optimis": 23, "auto": [23, 24], "apply_default": [23, 24], "15667": [23, 24], "upgrad": [23, 24, 40], "automat": [23, 24], "manual": 23, "migrat": [23, 24], "readm": [23, 24], "chang": [24, 40], "high": 24, "changelog": 24, "07": [24, 39], "02": 24, "4fb2140f39": 24, "a62bd83188": 24, "06": 24, "27": [24, 26], "enforc": 24, "pydocstyl": 24, "rule": [24, 40], "d213": 24, "40448": 24, "de5c751cff": 24, "22": 24, "bug": [24, 40], "fix": [24, 40], "6e5ae26382": 24, "prepar": [24, 40], "2nd": 24, "wave": 24, "june": 24, "40273": 24, "81c331e29a": 24, "17": 24, "a1f9b7de28": 24, "14": [24, 26], "68bd42a7ff": 24, "04": 24, "c0f27094ab": 24, "f0ea079594": 24, "05": 24, "2ecf7fa07d": 24, "26": 24, "34500f3a2f": 24, "3rd": 24, "39738": 24, "f18e6340d8": 24, "21": 24, "1e4663f34c": 24, "2b1a2f8d56": 24, "11": [24, 27, 31, 37], "reappli": 24, "39554": 24, "2c05187b07": 24, "73918925ed": 24, "08": 24, "2d103e115c": 24, "fe4605a10": 24, "1st": 24, "39328": 24, "42dbccaac2": 24, "7683344c9c": 24, "ead9b00f7c": 24, "04ac0c1b32": 24, "23": 24, "paramat": 24, "16": 24, "13df6569d6": 24, "rc3": 24, "april": 24, "38995": 24, "39054": 24, "66df296a6e": 24, "629545bea2": 24, "f9dcc82fb6": 24, "13": 24, "rc2": 24, "4a669fb1a9": 24, "5fa80b6aea": 24, "rc1": 24, "38863": 24, "6f21f7dc9b": 24, "4e6d3fa4cf": 24, "39b684d91a": 24, "c74947a69d": 24, "b5b972a106": 24, "18": [24, 31, 39], "yank": 24, "38262": 24, "0a74928894": 24, "38240": 24, "aa75fbb2b8": 24, "restor": 24, "38207": 24, "4742fc0ea5": 24, "15": 24, "8fc984873a": 24, "38070": 24, "83316b8158": 24, "march": 24, "37876": 24, "14d9bff3ad": 24, "24": 24, "37665": 24, "5a0be392e6": 24, "comment": 24, "37488": 24, "e346253760": 24, "bfb054e9e8": 24, "februari": 24, "37326": 24, "78294c24e2": 24, "0c4210af62": 24, "31": 24, "6d748c923b": 24, "dec2662190": 24, "cead3da4a6": 24, "round": 24, "jan": 24, "37019": 24, "0b680c9492": 24, "revert": 24, "logger_nam": 24, "logger": 24, "36675": 24, "37015": 24, "c0f7601391": 24, "347373986c": 24, "2b4da0101f": 24, "36945": 24, "13b0930bf4": 24, "574102fd29": 24, "c439ab87c4": 24, "build": [24, 27], "hatchl": 24, "36537": 24, "6bd450da1e": 24, "f7b663d9af": 24, "mypi": 24, "full": [24, 30, 37], "ci": 24, "36638": 24, "19ebcac239": 24, "36640": 24, "6937ae7647": 24, "speed": 24, "autocomplet": 24, "breez": 24, "36499": 24, "77b563bfc5": 24, "break": [24, 40], "36382": 24, "b15d5578da": 24, "decemb": 24, "36380": 24, "f5883d6e7b": 24, "36373": 24, "5fe5d31a46": 24, "322aa649": 24, "e9ba37bb58": 24, "64931b1a65": 24, "36190": 24, "36010f6d0e": 24, "999b70178a": 24, "36112": 24, "d0918d77ee": 24, "0b23d5601c": 24, "novemb": 24, "35836": 24, "99534e47f3": 24, "19": 24, "reproduc": 24, "35693": 24, "064fc2b775": 24, "99df205f42": 24, "35686": 24, "1b059c57d6": 24, "35537": 24, "10bac853d2": 24, "28": 24, "d1c58d86de": 24, "octob": 24, "35233": 24, "3592ff4046": 24, "35187": 24, "a8784e3c35": 24, "dd7ba3cae1": 24, "292": 24, "35053": 24, "7a93b19138": 24, "daskexecutor": 24, "inclus": 24, "34935": 24, "e9987d5059": 24, "34916": 24, "946b539f0d": 24, "0c8e30e43b": 24, "7ebf4220c9": 24, "09": 24, "usag": [24, 28, 30, 32, 33, 34, 36, 37], "34320": 24, "a1ef232230": 24, "f26fa6d602": 24, "3813ed69c7": 24, "966c2bce9f": 24, "dfec053371": 24, "21990ed894": 24, "34201": 24, "c45617c4d5": 24, "55976af32": 24, "concatin": 24, "f7a005db8c": 24, "9d8c77e447": 24, "b11525702c": 24, "c90eec9365": 24, "c077d19060": 24, "aug": 24, "33730": 24, "dc47c460dc": 24, "4154cc04ce": 24, "2dbb963324": 24, "1cdd82391e": 24, "a91ee7ac2f": 24, "20": 24, "8bf53dd554": 24, "5f8f25b34c": 24, "ecldud": 24, "33311": 24, "b5a4d36383": 24, "33291": 24, "9736143468": 24, "29": 24, "d06b7af69a": 24, "juli": 24, "32875": 24, "58e21c66fd": 24, "6313e52932": 24, "60c49ab2df": 24, "225e3041d2": 24, "32381": 24, "3878fe6fab": 24, "spuriou": 24, "32373": 24, "cb4927a018": 24, "32298": 24, "f8593503cb": 24, "6b4350e89c": 24, "d1aa509bbd": 24, "d205": 24, "32243": 24, "09d4718d3a": 24, "32125": 24, "79bcc2e668": 24, "32001": 24, "8b146152d6": 24, "32015": 24, "69bc90b824": 24, "66299338eb": 24, "7b096483fa": 24, "049c6184b7": 24, "9276310a43": 24, "31681": 24, "86b5ba2802": 24, "dc5bf3fd02": 24, "discover": 24, "yaml": 24, "31576": 24, "a59076eae": 24, "d400": 24, "31427": 24, "9fa75aaf7a": 24, "45548b9451": 24, "31416": 24, "abea189022": 24, "31393": 24, "f5aed58d9f": 24, "circular": 24, "caus": 24, "31379": 24, "d9ff55cf6d": 24, "31252": 24, "fdc7a31aeb": 24, "edd7133a13": 24, "3df0be0f6f": 24, "ac46902154": 24, "31033": 24, "0a30706aa7": 24, "airflowproviderdeprecationwarn": 24, "30975": 24, "eef5bc7f16": 24, "autom": 24, "30994": 24, "a7eb32a5b2": 24, "9409446097": 24, "cli": 24, "cmd": 24, "30822": 24, "ecb9a9ea78": 24, "9bebf85e24": 24, "7d02277ae1": 24, "e46ce78b66": 24, "adhoc": 24, "30787": 24, "37cf0506b5": 24, "1e311cf036": 24, "d23a3bbed8": 24, "mechan": 24, "suspend": 24, "30422": 24, "55dbf1ff1f": 24, "30378": 24, "c3867781e0": 24, "29950": 24, "c405ecb63": 24, "25bdbc8e67": 24, "27937": 24, "db5375bea7": 24, "2e20e9f7eb": 24, "relas": 24, "27774": 24, "80c327bd3b": 24, "ea306c9462": 24, "a343bba1e3": 24, "12c3c39d1a": 24, "27613": 24, "00af5c007": 24, "eb06c65556": 24, "9ab1a6a3e7": 24, "style": 24, "26872": 24, "78b8ea2f22": 24, "2a34dc9e84": 24, "normal": 24, "27205": 24, "ecd4d6654f": 24, "f8db64c35c": 24, "septemb": 24, "26731": 24, "89e44c46ad": 24, "06acf40a43": 24, "pep": 24, "563": 24, "postpon": 24, "evalu": 24, "26289": 24, "5066844513": 24, "period": 24, "batch02": 24, "25268": 24, "25a9c6a905": 24, "9535ec0bba": 24, "ca9229b6f": 24, "7d0525a55b": 24, "rc4": 24, "25720": 24, "4d32f61fd0": 24, "e5ac6c7cfb": 24, "august": 24, "25618": 24, "52f2f5bfa8": 24, "0255a0a5e7": 24, "679a85325a": 24, "82f842ffc5": 24, "24599": 24, "54a8c4fd2a": 24, "7438707747": 24, "df00436569": 24, "2f70daf5ac": 24, "d2459a241b": 24, "25030": 24, "8dfe7bf5ff": 24, "acaa0635c8": 24, "lazi": 24, "interpol": 24, "24910": 24, "46bbfdade0": 24, "96b01a8012": 24, "bad": 24, "codebas": 24, "24841": 24, "0de31bd73a": 24, "insid": [24, 25], "24672": 24, "510a6bab45": 24, "24702": 24, "ed37c3a0e8": 24, "9c59831ee7": 24, "dcdcf3a2b8": 24, "24307": 24, "717a7588bc": 24, "doubl": 24, "24292": 24, "aeabe994b3": 24, "24231": 24, "027b707d21": 24, "explanatori": 24, "contributor": [24, 25], "24229": 24, "ddf9013098": 24, "aip": 24, "47": 24, "design": [24, 36], "22442": 24, "24203": 24, "acf89510cd": 24, "92ddcf4ac6": 24, "flake8": 24, "implicit": 24, "concat": 24, "plugin": 24, "23873": 24, "6150d28323": 24, "cf5a78e91c": 24, "d0a5b3a4f2": 24, "75c60923e0": 24, "23631": 24, "428a439953": 24, "23591": 24, "a58506b2a6": 24, "address": 24, "review": 24, "6a3d6cc32b": 24, "7b3bf4e435": 24, "f02b0b6b40": 24, "8b6b0848a3": 24, "brees": 24, "pull": 24, "verifi": [24, 26], "imag": 24, "23104": 24, "40831144be": 24, "22979": 24, "7be57eb256": 24, "aa8c08db38": 24, "6933022e94": 24, "22884": 24, "56ab82ed7a": 24, "mid": 24, "22819": 24, "1b12c93ed3": 24, "95169d1d07": 24, "352d7f72dd": 24, "c063fc688c": 24, "black": 24, "precommit": 24, "22521": 24, "d7dbfb7e26": 24, "bugfix": [24, 40], "22383": 24, "cc920963a6": 24, "16adc035b1": 24, "classifi": 24, "22226": 24, "12e9e2c695": 24, "af9d85ccd8": 24, "4014194320": 24, "f5b96315fe": 24, "feb": 24, "22056": 24, "62bf1276f6": 24, "27d19e7626": 24, "a1845c68f9": 24, "7cca82495b": 24, "0a2d0d1ecb": 24, "d94fa37830": 24, "6c3a67d4fc": 24, "2021": [24, 27], "21257": 24, "602abe8394": 24, "sphinx": 24, "autoapi": 24, "typehint": 24, "20951": 24, "f77417eb0d": 24, "k8": 24, "pypi": [24, 26, 31, 38, 39, 40], "20614": 24, "97496ba2b4": 24, "20523": 24, "0bf424f37f": 24, "20598": 24, "d56e7b56bb": 24, "friendli": 24, "20571": 24, "a0821235fb": 24, "everywher": 24, "20565": 24, "c5c18c54fa": 24, "d3b3161f0d": 24, "58afc19377": 24, "e7659d08b0": 24, "cad39274d9": 24, "20265": 24, "820bfed515": 24, "20205": 24, "66f94f95c2": 24, "545ca59ba9": 24, "unhid": 24, "entri": 24, "20128": 24, "637db1a0ba": 24, "20086": 24, "728e94a47": 24, "19835": 24, "4925b37b66": 24, "853576d901": 24, "19882": 24, "11998848a4": 24, "56bdfe7a84": 24, "244627e3da": 24, "0a4a8bdb94": 24, "8ae878953b": 24, "28b51fb7bd": 24, "3a0c455855": 24, "d9567eb106": 24, "19321": 24, "f5ad26dcdd": 24, "840ea3efb9": 24, "18613": 24, "ef037e7021": 24, "start_dat": 24, "misc": 24, "18597": 24, "0b7b13372f": 24, "0a68588479": 24, "17890": 24, "be75dcd39c": 24, "meta": 24, "76ed2a49c6": 24, "lazili": 24, "17682": 24, "87f408b1e7": 24, "17116": 24, "b916b75079": 24, "17015": 24, "866a601b76": 24, "pylint": 24, "toolchain": 24, "16682": 24, "bbc627a3da": 24, "16501": 24, "cbf8001d76": 24, "synchron": 24, "buggfix": 24, "16464": 24, "1fba5402bb": 24, "16405": 24, "9c94b72d44": 24, "16294": 24, "37681bca00": 24, "807ad32ce5": 24, "pip": [24, 26, 27], "15576": 24, "df143aee8d": 24, "rework": 24, "15444": 24, "49cae1f052": 24, "15410": 24, "68e4c4dcb0": 24, "backport": 24, "14886": 24, "88bdcfa0df": 24, "14013": 24, "ac2f72c98d": 24, "13767": 24, "a9ac2b040b": 24, "flynt": 24, "13732": 24, "3fd5ef3555": 24, "logo": 24, "integr": [24, 25], "13717": 24, "295d66f914": 24, "2020": 24, "grammar": 24, "warn": [24, 27], "13380": 24, "6cf76d7ac0": 24, "13148": 24, "32971a1a2d": 24, "12955": 24, "b40dffa085": 24, "rema": 24, "12917": 24, "9b39f24780": 24, "dynam": 24, "form": 24, "12558": 24, "bd90136aaf": 24, "12681": 24, "c34ef853c8": 24, "12444": 24, "0080354502": 24, "0b2": 24, "12449": 24, "7ca0b6f121": 24, "markdownlint": 24, "md003": 24, "head": 24, "12427": 24, "12438": 24, "ae7cb4a1e2": 24, "wrong": 24, "hash": 24, "12390": 24, "6889a333cf": 24, "ref": 24, "12366": 24, "7825e8f590": 24, "12304": 24, "b027223132": 24, "12316": 24, "85a18e13d9": 24, "project": [24, 37], "cross": 24, "12212": 24, "59eb5de78c": 24, "come": 24, "0beta1": 24, "12206": 24, "b2a28d1590": 24, "12082": 24, "7e0d08e1f0": 24, "12175": 24, "4e8f9cc8d0": 24, "formmatt": 24, "9550": 24, "8c42cf1b00": 24, "pyupgrad": 24, "11447": 24, "5a439e84eb": 24, "2a1": 24, "11855": 24, "872b1566a1": 24, "setup": [24, 36], "11826": 24, "349b0811c3": 24, "d200": 24, "11688": 24, "16e7129719": 24, "11487": 24, "0a0e1af800": 24, "markdown": 24, "toc": 24, "11249": 24, "ca4238eb4d": 24, "month": 24, "11242": 24, "5220e4c384": 24, "11238": 24, "54353f8745": 24, "increas": 24, "coverag": 24, "five": 24, "differ": [24, 25, 27], "11170": 24, "966a06d96b": 24, "fetch": 24, "suppli": [24, 36], "10762": 24, "9549274d11": 24, "8b1": 24, "10818": 24, "fdd9b6f65b": 24, "10543": 24, "bfefcce0c9": 24, "rest": [24, 30, 37], "10462": 24, "3696c34c28": 24, "word": 24, "10528": 24, "2f2d8dbfaf": 24, "noinspect": 24, "nativ": 24, "intellij": 24, "10525": 24, "ee7ca128a1": 24, "refernc": 24, "10483": 24, "cdec301254": 24, "10205": 24, "7d24b088cd": 24, "example_dag": 24, "9985": 24, "e13a14c873": 24, "whitespac": 24, "9458": 24, "d0e7db4024": 24, "fresh": 24, "9408": 24, "12af6a0800": 24, "23rc1": 24, "9404": 24, "c7e5bce57f": 24, "candid": 24, "9370": 24, "f6bd817a3a": 24, "transfer": 24, "9320": 24, "0b0e4f7a4c": 24, "9026": 24, "00642a46d0": 24, "wrongli": 24, "8994": 24, "f1073381ed": 24, "8846": 24, "375d1ca229": 24, "8898": 24, "12c5e5d8a": 24, "8891": 24, "f3521fb0e3": 24, "regener": 24, "8886": 24, "92585ca4cb": 24, "8807": 24, "649935e8c": 24, "8472": 24, "_do_api_cal": 24, "8473": 24, "16903ba3a6": 24, "8474": 24, "8475": 24, "5648dfbc30": 24, "super": 24, "amazon": 24, "cloudant": 24, "7827": 24, "3320e432a1": 24, "6817": 24, "keep": [24, 39], "face": 24, "untouch": 24, "7517": 24, "4d03e33c11": 24, "explicit": 24, "md": 24, "squash": 24, "rebas": 24, "7456": 24, "97a429f9d0": 24, "6714": 24, "magic": 24, "utf": 24, "8": [24, 31, 37], "7338": 24, "83c037873f": 24, "6674": [24, 27], "accord": 24, "7287": 24, "c42a375e79": 24, "6644": 24, "7265": 24, "sever": 25, "person": 25, "recommend": [25, 27, 39], "login": 25, "usernam": 25, "account": [25, 28], "discourag": 25, "secret": 25, "outsid": [25, 39], "owner": [25, 27], "vm": 25, "assign": 25, "sent": 25, "basic": 25, "plan": 25, "httpoper": 25, "aw": 25, "secur": 25, "necessari": 25, "service_principal_oauth": 25, "client": 25, "azure_tenant_id": 25, "tenant": 25, "resourc": 25, "isn": [25, 33, 34, 35], "special": [25, 36], "govcloud": 25, "china": 25, "germani": 25, "protocol": 25, "microsoftonlin": 25, "de": 25, "uri": [25, 28], "syntax": 25, "export": 25, "airflow_conn_databricks_default": 25, "yourtoken": 25, "4": 26, "mergedeep": 26, "python_vers": 26, "pyarrow": 26, "checksum": [26, 27], "site": 26, "sdist": [26, 27], "asc": [26, 27], "sha512": [26, 27], "download": 27, "offici": 27, "choos": 27, "down": 27, "left": 27, "whl": 27, "origin": 27, "softwar": 27, "foundat": 27, "pgp": 27, "essenti": 27, "sha": 27, "gpg": 27, "relev": 27, "distribut": 27, "mirror": 27, "pgpk": 27, "ka": 27, "binari": 27, "pgpv": 27, "tar": 27, "gz": 27, "made": 27, "sat": 27, "sep": 27, "49": 27, "54": 27, "bst": 27, "rsa": 27, "cde15c6e4d3a8ec4ecf4ba4b6674e08ad7de406f": 27, "issuer": 27, "kaxilnaik": 27, "good": [27, 40], "kaxil": 27, "naik": 27, "aka": 27, "gmail": 27, "certifi": 27, "trust": 27, "indic": 27, "belong": 27, "primari": 27, "fingerprint": 27, "cde1": 27, "5c6e": 27, "4d3a": 27, "8ec4": 27, "ecf4": 27, "ba4b": 27, "e08a": 27, "d7de": 27, "406f": 27, "worri": 27, "certif": 27, "sign": 27, "why": 27, "server": 27, "previou": 27, "step": 27, "know": 27, "sum": 27, "shasum": 27, "512": 27, "diff": 27, "bin": [27, 31], "bash": 27, "package_vers": 27, "package_nam": 27, "provider_download_dir": 27, "mktemp": 27, "d": [27, 39], "dep": 27, "dest": 27, "curl": 27, "apache_airflow_providers_databrick": 27, "py3": 27, "l": 27, "o": 27, "echo": 27, "la": 27, "onc": 27, "instruct": [27, 40], "chapter": 27, "temporari": 27, "One": [28, 36], "copy_into": 28, "import_csv": 28, "my_tabl": 28, "abfss": 28, "df": 28, "my": 28, "past": 30, "rememb": 30, "repeat": 30, "rather": 30, "ones": 30, "fall": 30, "With": [30, 37, 39], "over": [30, 37], "underli": [30, 37], "harder": [30, 37], "lack": [30, 37], "task_kei": 30, "spark_vers": [30, 31, 37], "scala2": [30, 31, 37], "node_type_id": [30, 31, 37], "i3": [30, 31], "xlarg": [30, 31, 37], "num_work": [30, 31, 37], "jobs_create_json": 30, "jobs_create_nam": 30, "return_valu": 30, "ti": 30, "xcom_pul": 30, "new_cluster_spec": 31, "cluster_nam": 31, "aws_attribut": [31, 37], "first_on_demand": 31, "spot_with_fallback": 31, "zone_id": 31, "u": 31, "east": 31, "2b": 31, "spot_bid_price_perc": 31, "ebs_volume_count": 31, "spark_env_var": 31, "pyspark_python": 31, "python3": 31, "enable_elastic_disk": 31, "data_security_mod": 31, "legacy_single_user_standard": 31, "runtime_engin": 31, "notebook_1": [31, 38, 39], "simplejson": [31, 38, 39], "simpl": [31, 36, 39], "faker": [31, 38, 39], "notebook_2": [31, 39], "input": [32, 33, 34], "user_email": [32, 33, 34], "repo_nam": [32, 33, 34], "decim": [32, 33, 34], "usual": 34, "worker": [35, 37], "extens": 36, "new_lin": 36, "select_data": 36, "my_airflow_t": 36, "select_into_fil": 36, "select_data_into_fil": 36, "tmp": 36, "perform": 36, "create_and_populate_t": 36, "create_fil": 36, "create_and_populate_from_fil": 36, "starter": 36, "sql_sensor": 36, "hive_metastor": 36, "sql_sensor_task": 36, "temp": 36, "sample_table_3": 36, "60": 36, "someth": 36, "occur": 36, "happen": 36, "succe": 36, "arriv": 36, "interv": 36, "poke_interv": 36, "rang": 36, "partition_nam": 36, "partition_valu": 36, "partition_sensor": 36, "partition_sensor_task": 36, "sample_table_2": 36, "db3": 37, "preparedata": 37, "here": [37, 39], "invok": 37, "r3": 37, "on_demand": 37, "notebook_task_param": 37, "main_class_nam": 37, "processdata": 37, "lib": 37, "etl": 37, "standalon": 38, "task_operator_nb_1": [38, 39], "nb_1": [38, 39], "shared_job_clust": [38, 39], "task_operator_sql_queri": 38, "sql_queri": [38, 39], "sql_task": [38, 39], "75": 39, "cost": 39, "reduct": 39, "40": 39, "dbu": 39, "comput": 39, "compar": 39, "few": 39, "author": 39, "interfac": 39, "web": 39, "price": 39, "begin": 39, "test_workflow_": 39, "pin": 39, "index": 39, "on_start": 39, "workflow_notebook_1": 39, "timedelta": 39, "600": 39, "workflow_notebook_2": 39, "foo": 39, "bar": 39, "dag_nam": 39, "minim": 39, "independ": 40, "itself": 40, "vulner": 40, "publish": 40, "develop": 40, "alwai": 40, "next": 40, "strict": 40, "semver": 40, "scope": 40, "major": 40, "minor": 40, "patchlevel": 40, "critic": 40, "band": 40, "stakehold": 40, "decid": 40, "cherri": 40, "pick": 40, "older": 40, "mix": 40, "govern": 40, "interest": 40, "parti": 40}, "objects": {"airflow.providers": [[4, 0, 0, "-", "databricks"]], "airflow.providers.databricks": [[4, 1, 1, "", "__version__"], [3, 0, 0, "-", "hooks"], [9, 0, 0, "-", "operators"], [12, 0, 0, "-", "sensors"], [14, 0, 0, "-", "triggers"], [16, 0, 0, "-", "utils"]], "airflow.providers.databricks.hooks": [[0, 0, 0, "-", "databricks"], [1, 0, 0, "-", "databricks_base"], [2, 0, 0, "-", "databricks_sql"]], "airflow.providers.databricks.hooks.databricks": [[0, 1, 1, "", "CANCEL_ALL_RUNS_ENDPOINT"], [0, 1, 1, "", "CANCEL_RUN_ENDPOINT"], [0, 1, 1, "", "CREATE_ENDPOINT"], [0, 2, 1, "", "ClusterState"], [0, 1, 1, "", "DELETE_RUN_ENDPOINT"], [0, 2, 1, "", "DatabricksHook"], [0, 1, 1, "", "GET_CLUSTER_ENDPOINT"], [0, 1, 1, "", "GET_RUN_ENDPOINT"], [0, 1, 1, "", "INSTALL_LIBS_ENDPOINT"], [0, 1, 1, "", "LIST_JOBS_ENDPOINT"], [0, 1, 1, "", "LIST_PIPELINES_ENDPOINT"], [0, 1, 1, "", "OUTPUT_RUNS_JOB_ENDPOINT"], [0, 1, 1, "", "REPAIR_RUN_ENDPOINT"], [0, 1, 1, "", "RESET_ENDPOINT"], [0, 1, 1, "", "RESTART_CLUSTER_ENDPOINT"], [0, 1, 1, "", "RUN_NOW_ENDPOINT"], [0, 2, 1, "", "RunLifeCycleState"], [0, 2, 1, "", "RunState"], [0, 1, 1, "", "SPARK_VERSIONS_ENDPOINT"], [0, 1, 1, "", "START_CLUSTER_ENDPOINT"], [0, 1, 1, "", "SUBMIT_RUN_ENDPOINT"], [0, 1, 1, "", "TERMINATE_CLUSTER_ENDPOINT"], [0, 1, 1, "", "UNINSTALL_LIBS_ENDPOINT"], [0, 1, 1, "", "WORKSPACE_GET_STATUS_ENDPOINT"]], "airflow.providers.databricks.hooks.databricks.ClusterState": [[0, 3, 1, "", "CLUSTER_LIFE_CYCLE_STATES"], [0, 4, 1, "", "__eq__"], [0, 4, 1, "", "__repr__"], [0, 4, 1, "", "from_json"], [0, 5, 1, "", "is_running"], [0, 5, 1, "", "is_terminal"], [0, 4, 1, "", "to_json"]], "airflow.providers.databricks.hooks.databricks.DatabricksHook": [[0, 4, 1, "", "a_get_cluster_state"], [0, 4, 1, "", "a_get_run"], [0, 4, 1, "", "a_get_run_output"], [0, 4, 1, "", "a_get_run_page_url"], [0, 4, 1, "", "a_get_run_state"], [0, 4, 1, "", "cancel_all_runs"], [0, 4, 1, "", "cancel_run"], [0, 4, 1, "", "create_job"], [0, 4, 1, "", "create_repo"], [0, 4, 1, "", "delete_repo"], [0, 4, 1, "", "delete_run"], [0, 4, 1, "", "find_job_id_by_name"], [0, 4, 1, "", "find_pipeline_id_by_name"], [0, 4, 1, "", "get_cluster_state"], [0, 4, 1, "", "get_job_id"], [0, 4, 1, "", "get_latest_repair_id"], [0, 4, 1, "", "get_repo_by_path"], [0, 4, 1, "", "get_run"], [0, 4, 1, "", "get_run_output"], [0, 4, 1, "", "get_run_page_url"], [0, 4, 1, "", "get_run_state"], [0, 4, 1, "", "get_run_state_lifecycle"], [0, 4, 1, "", "get_run_state_message"], [0, 4, 1, "", "get_run_state_result"], [0, 4, 1, "", "get_run_state_str"], [0, 3, 1, "", "hook_name"], [0, 4, 1, "", "install"], [0, 4, 1, "", "list_jobs"], [0, 4, 1, "", "list_pipelines"], [0, 4, 1, "", "repair_run"], [0, 4, 1, "", "reset_job"], [0, 4, 1, "", "restart_cluster"], [0, 4, 1, "", "run_now"], [0, 4, 1, "", "start_cluster"], [0, 4, 1, "", "submit_run"], [0, 4, 1, "", "terminate_cluster"], [0, 4, 1, "", "test_connection"], [0, 4, 1, "", "uninstall"], [0, 4, 1, "", "update_job_permission"], [0, 4, 1, "", "update_repo"]], "airflow.providers.databricks.hooks.databricks.RunLifeCycleState": [[0, 3, 1, "", "BLOCKED"], [0, 3, 1, "", "INTERNAL_ERROR"], [0, 3, 1, "", "PENDING"], [0, 3, 1, "", "QUEUED"], [0, 3, 1, "", "RUNNING"], [0, 3, 1, "", "SKIPPED"], [0, 3, 1, "", "TERMINATED"], [0, 3, 1, "", "TERMINATING"], [0, 3, 1, "", "WAITING_FOR_RETRY"]], "airflow.providers.databricks.hooks.databricks.RunState": [[0, 3, 1, "", "RUN_LIFE_CYCLE_STATES"], [0, 4, 1, "", "__eq__"], [0, 4, 1, "", "__repr__"], [0, 4, 1, "", "from_json"], [0, 5, 1, "", "is_successful"], [0, 5, 1, "", "is_terminal"], [0, 4, 1, "", "to_json"]], "airflow.providers.databricks.hooks.databricks_base": [[1, 1, 1, "", "AZURE_MANAGEMENT_ENDPOINT"], [1, 1, 1, "", "AZURE_METADATA_SERVICE_INSTANCE_URL"], [1, 1, 1, "", "AZURE_METADATA_SERVICE_TOKEN_URL"], [1, 2, 1, "", "BaseDatabricksHook"], [1, 2, 1, "", "BearerAuth"], [1, 1, 1, "", "DEFAULT_DATABRICKS_SCOPE"], [1, 1, 1, "", "OIDC_TOKEN_SERVICE_URL"], [1, 1, 1, "", "TOKEN_REFRESH_LEAD_TIME"]], "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook": [[1, 4, 1, "", "__aenter__"], [1, 4, 1, "", "__aexit__"], [1, 3, 1, "", "conn_name_attr"], [1, 3, 1, "", "conn_type"], [1, 4, 1, "", "databricks_conn"], [1, 3, 1, "", "default_conn_name"], [1, 3, 1, "", "extra_parameters"], [1, 4, 1, "", "get_conn"], [1, 4, 1, "", "host"], [1, 4, 1, "", "user_agent_header"], [1, 4, 1, "", "user_agent_value"]], "airflow.providers.databricks.hooks.databricks_base.BearerAuth": [[1, 4, 1, "", "encode"]], "airflow.providers.databricks.hooks.databricks_sql": [[2, 2, 1, "", "DatabricksSqlHook"], [2, 1, 1, "", "LIST_SQL_ENDPOINTS_ENDPOINT"], [2, 1, 1, "", "T"]], "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook": [[2, 4, 1, "", "bulk_dump"], [2, 4, 1, "", "bulk_load"], [2, 4, 1, "", "get_conn"], [2, 3, 1, "", "hook_name"], [2, 4, 1, "", "run"]], "airflow.providers.databricks.operators": [[5, 0, 0, "-", "databricks"], [6, 0, 0, "-", "databricks_repos"], [7, 0, 0, "-", "databricks_sql"], [8, 0, 0, "-", "databricks_workflow"]], "airflow.providers.databricks.operators.databricks": [[5, 1, 1, "", "DEFER_METHOD_NAME"], [5, 2, 1, "", "DatabricksCreateJobsOperator"], [5, 2, 1, "", "DatabricksJobRunLink"], [5, 2, 1, "", "DatabricksNotebookOperator"], [5, 2, 1, "", "DatabricksRunNowDeferrableOperator"], [5, 2, 1, "", "DatabricksRunNowOperator"], [5, 2, 1, "", "DatabricksSubmitRunDeferrableOperator"], [5, 2, 1, "", "DatabricksSubmitRunOperator"], [5, 2, 1, "", "DatabricksTaskBaseOperator"], [5, 2, 1, "", "DatabricksTaskOperator"], [5, 1, 1, "", "XCOM_JOB_ID_KEY"], [5, 1, 1, "", "XCOM_RUN_ID_KEY"], [5, 1, 1, "", "XCOM_RUN_PAGE_URL_KEY"], [5, 6, 1, "", "normalise_json_content"]], "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator": [[5, 4, 1, "", "execute"], [5, 3, 1, "", "template_fields"], [5, 3, 1, "", "ui_color"], [5, 3, 1, "", "ui_fgcolor"]], "airflow.providers.databricks.operators.databricks.DatabricksJobRunLink": [[5, 4, 1, "", "get_link"], [5, 3, 1, "", "name"]], "airflow.providers.databricks.operators.databricks.DatabricksNotebookOperator": [[5, 3, 1, "", "CALLER"], [5, 3, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator": [[5, 4, 1, "", "execute"], [5, 4, 1, "", "execute_complete"], [5, 4, 1, "", "on_kill"], [5, 3, 1, "", "operator_extra_links"], [5, 3, 1, "", "template_ext"], [5, 3, 1, "", "template_fields"], [5, 3, 1, "", "ui_color"], [5, 3, 1, "", "ui_fgcolor"]], "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunDeferrableOperator": [[5, 4, 1, "", "execute"]], "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator": [[5, 4, 1, "", "execute"], [5, 4, 1, "", "execute_complete"], [5, 4, 1, "", "on_kill"], [5, 3, 1, "", "operator_extra_links"], [5, 3, 1, "", "template_ext"], [5, 3, 1, "", "template_fields"], [5, 3, 1, "", "ui_color"], [5, 3, 1, "", "ui_fgcolor"]], "airflow.providers.databricks.operators.databricks.DatabricksTaskBaseOperator": [[5, 4, 1, "", "execute"], [5, 4, 1, "", "execute_complete"], [5, 4, 1, "", "monitor_databricks_job"]], "airflow.providers.databricks.operators.databricks.DatabricksTaskOperator": [[5, 3, 1, "", "CALLER"], [5, 3, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_repos": [[6, 2, 1, "", "DatabricksReposCreateOperator"], [6, 2, 1, "", "DatabricksReposDeleteOperator"], [6, 2, 1, "", "DatabricksReposUpdateOperator"]], "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator": [[6, 3, 1, "", "__aws_code_commit_regexp__"], [6, 4, 1, "", "__detect_repo_provider__"], [6, 3, 1, "", "__git_providers__"], [6, 3, 1, "", "__repos_path_regexp__"], [6, 4, 1, "", "execute"], [6, 3, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_repos.DatabricksReposDeleteOperator": [[6, 4, 1, "", "execute"], [6, 3, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_repos.DatabricksReposUpdateOperator": [[6, 4, 1, "", "execute"], [6, 3, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_sql": [[7, 1, 1, "", "COPY_INTO_APPROVED_FORMATS"], [7, 2, 1, "", "DatabricksCopyIntoOperator"], [7, 2, 1, "", "DatabricksSqlOperator"]], "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator": [[7, 4, 1, "", "execute"], [7, 3, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator": [[7, 3, 1, "", "conn_id_field"], [7, 4, 1, "", "get_db_hook"], [7, 3, 1, "", "template_ext"], [7, 3, 1, "", "template_fields"], [7, 3, 1, "", "template_fields_renderers"]], "airflow.providers.databricks.operators.databricks_workflow": [[8, 2, 1, "", "DatabricksWorkflowTaskGroup"], [8, 2, 1, "", "WorkflowRunMetadata"]], "airflow.providers.databricks.operators.databricks_workflow.DatabricksWorkflowTaskGroup": [[8, 4, 1, "", "__exit__"], [8, 3, 1, "", "is_databricks"]], "airflow.providers.databricks.operators.databricks_workflow.WorkflowRunMetadata": [[8, 3, 1, "", "conn_id"], [8, 3, 1, "", "job_id"], [8, 3, 1, "", "run_id"]], "airflow.providers.databricks.sensors": [[10, 0, 0, "-", "databricks_partition"], [11, 0, 0, "-", "databricks_sql"]], "airflow.providers.databricks.sensors.databricks_partition": [[10, 2, 1, "", "DatabricksPartitionSensor"]], "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor": [[10, 4, 1, "", "poke"], [10, 3, 1, "", "template_ext"], [10, 3, 1, "", "template_fields"], [10, 3, 1, "", "template_fields_renderers"]], "airflow.providers.databricks.sensors.databricks_sql": [[11, 2, 1, "", "DatabricksSqlSensor"]], "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor": [[11, 4, 1, "", "hook"], [11, 4, 1, "", "poke"], [11, 3, 1, "", "template_ext"], [11, 3, 1, "", "template_fields"], [11, 3, 1, "", "template_fields_renderers"]], "airflow.providers.databricks.triggers": [[13, 0, 0, "-", "databricks"]], "airflow.providers.databricks.triggers.databricks": [[13, 2, 1, "", "DatabricksExecutionTrigger"]], "airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger": [[13, 4, 1, "", "run"], [13, 4, 1, "", "serialize"]], "airflow.providers.databricks.utils": [[15, 0, 0, "-", "databricks"]], "airflow.providers.databricks.utils.databricks": [[15, 6, 1, "", "validate_trigger_event"]], "tests.system.providers": [[22, 0, 0, "-", "databricks"]], "tests.system.providers.databricks": [[17, 0, 0, "-", "example_databricks"], [18, 0, 0, "-", "example_databricks_repos"], [19, 0, 0, "-", "example_databricks_sensors"], [20, 0, 0, "-", "example_databricks_sql"], [21, 0, 0, "-", "example_databricks_workflow"]], "tests.system.providers.databricks.example_databricks": [[17, 1, 1, "", "DAG_ID"], [17, 1, 1, "", "ENV_ID"], [17, 1, 1, "", "QUERY_ID"], [17, 1, 1, "", "WAREHOUSE_ID"], [17, 1, 1, "", "job"], [17, 1, 1, "", "test_run"]], "tests.system.providers.databricks.example_databricks_repos": [[18, 1, 1, "", "DAG_ID"], [18, 1, 1, "", "ENV_ID"], [18, 1, 1, "", "default_args"], [18, 1, 1, "", "repo_path"], [18, 1, 1, "", "test_run"]], "tests.system.providers.databricks.example_databricks_sensors": [[19, 1, 1, "", "DAG_ID"], [19, 1, 1, "", "ENV_ID"], [19, 1, 1, "", "connection_id"], [19, 1, 1, "", "test_run"]], "tests.system.providers.databricks.example_databricks_sql": [[20, 1, 1, "", "DAG_ID"], [20, 1, 1, "", "ENV_ID"], [20, 1, 1, "", "connection_id"], [20, 1, 1, "", "test_run"]], "tests.system.providers.databricks.example_databricks_workflow": [[21, 1, 1, "", "DATABRICKS_CONN_ID"], [21, 1, 1, "", "DATABRICKS_NOTIFICATION_EMAIL"], [21, 1, 1, "", "EXECUTION_TIMEOUT"], [21, 1, 1, "", "GROUP_ID"], [21, 1, 1, "", "QUERY_ID"], [21, 1, 1, "", "USER"], [21, 1, 1, "", "WAREHOUSE_ID"], [21, 1, 1, "", "dag"], [21, 1, 1, "", "job_cluster_spec"], [21, 1, 1, "", "task_group"], [21, 1, 1, "", "test_run"]]}, "objtypes": {"0": "py:module", "1": "py:data", "2": "py:class", "3": "py:attribute", "4": "py:method", "5": "py:property", "6": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "data", "Python data"], "2": ["py", "class", "Python class"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "method", "Python method"], "5": ["py", "property", "Python property"], "6": ["py", "function", "Python function"]}, "titleterms": {"airflow": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 24, 26, 39], "provid": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 39], "databrick": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 29, 31, 32, 33, 34, 38, 39], "hook": [0, 1, 2, 3], "modul": [0, 1, 2, 5, 6, 7, 8, 10, 11, 13, 15, 17, 18, 19, 20, 21], "content": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 15, 17, 18, 19, 20, 21], "class": [0, 1, 2, 5, 6, 7, 8, 10, 11, 13], "attribut": [0, 1, 2, 5, 7], "databricks_bas": 1, "databricks_sql": [2, 7, 11], "submodul": [3, 9, 12, 14, 16, 22], "subpackag": 4, "packag": [4, 24, 26, 27], "oper": [5, 6, 7, 8, 9, 28, 29, 30, 32, 33, 34, 35, 36, 37], "function": [5, 15], "databricks_repo": 6, "databricks_workflow": 8, "sensor": [10, 11, 12, 36], "databricks_partit": 10, "trigger": [13, 14, 39], "util": [15, 16], "test": [17, 18, 19, 20, 21, 22], "system": [17, 18, 19, 20, 21, 22], "example_databrick": 17, "example_databricks_repo": 18, "example_databricks_sensor": 19, "example_databricks_sql": 20, "example_databricks_workflow": 21, "changelog": 23, "6": [23, 24], "7": [23, 24], "0": [23, 24], "featur": 23, "bug": 23, "fix": 23, "misc": 23, "5": [23, 24], "4": [23, 24], "3": [23, 24], "2": [23, 24], "1": [23, 24], "break": 23, "chang": 23, "yank": 23, "apach": [24, 26], "connect": 25, "authent": 25, "default": 25, "id": 25, "configur": 25, "instal": [26, 27], "requir": 26, "cross": 26, "depend": 26, "download": 26, "offici": 26, "from": [27, 36, 39], "sourc": 27, "releas": [27, 40], "integr": 27, "verifi": 27, "pypi": 27, "databrickscopyintooper": 28, "us": [28, 30, 32, 33, 34, 35, 36, 37, 38], "exampl": [28, 30, 31, 32, 33, 34, 36, 37, 38, 39], "import": 28, "csv": 28, "data": [28, 36], "databrickscreatejobsoper": 30, "specifi": [30, 33, 34, 37], "paramet": [30, 37], "json": [30, 37], "name": [30, 37], "pair": 30, "databricksrunnowoper": [30, 35], "databricksnotebookoper": 31, "run": [31, 38, 39], "notebook": [31, 38], "new": 31, "cluster": 31, "an": 31, "exist": 31, "databricksreposcreateoper": 32, "creat": 32, "repo": [32, 33, 34], "databricksreposdeleteoper": 33, "delet": 33, "path": [33, 34], "databricksreposupdateoper": 34, "updat": 34, "databricksrunnowdeferrableoper": 35, "databrickssqloper": 36, "select": 36, "file": 36, "execut": 36, "multipl": 36, "statement": 36, "databrickssqlsensor": 36, "databrickspartitionsensor": 36, "databrickssubmitrunoper": 37, "databrickssubmitrundeferrableoper": 37, "databrickstaskoper": 38, "sql": 38, "queri": 38, "databricksworkflowtaskgroup": 39, "what": 39, "dag": 39, "look": 39, "like": 39, "The": 39, "follow": 39, "imag": 39, "displai": 39, "result": 39, "workflow": 39, "ui": 39, "base": 39, "abov": 39, "correspond": 39, "i": 39, "depict": 39, "below": 39, "secur": 40, "patch": 40}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"airflow.providers.databricks.hooks.databricks": [[0, "module-airflow.providers.databricks.hooks.databricks"]], "Module Contents": [[0, "module-contents"], [1, "module-contents"], [2, "module-contents"], [5, "module-contents"], [6, "module-contents"], [7, "module-contents"], [8, "module-contents"], [10, "module-contents"], [11, "module-contents"], [13, "module-contents"], [15, "module-contents"], [17, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"]], "Classes": [[0, "classes"], [1, "classes"], [2, "classes"], [5, "classes"], [6, "classes"], [7, "classes"], [8, "classes"], [10, "classes"], [11, "classes"], [13, "classes"]], "Attributes": [[0, "attributes"], [1, "attributes"], [2, "attributes"], [5, "attributes"], [7, "attributes"]], "airflow.providers.databricks.hooks.databricks_base": [[1, "module-airflow.providers.databricks.hooks.databricks_base"]], "airflow.providers.databricks.hooks.databricks_sql": [[2, "module-airflow.providers.databricks.hooks.databricks_sql"]], "airflow.providers.databricks.hooks": [[3, "module-airflow.providers.databricks.hooks"]], "Submodules": [[3, "submodules"], [9, "submodules"], [12, "submodules"], [14, "submodules"], [16, "submodules"], [22, "submodules"]], "airflow.providers.databricks": [[4, "module-airflow.providers.databricks"]], "Subpackages": [[4, "subpackages"]], "Package Contents": [[4, "package-contents"]], "airflow.providers.databricks.operators.databricks": [[5, "module-airflow.providers.databricks.operators.databricks"]], "Functions": [[5, "functions"], [15, "functions"]], "airflow.providers.databricks.operators.databricks_repos": [[6, "module-airflow.providers.databricks.operators.databricks_repos"]], "airflow.providers.databricks.operators.databricks_sql": [[7, "module-airflow.providers.databricks.operators.databricks_sql"]], "airflow.providers.databricks.operators.databricks_workflow": [[8, "module-airflow.providers.databricks.operators.databricks_workflow"]], "airflow.providers.databricks.operators": [[9, "module-airflow.providers.databricks.operators"]], "airflow.providers.databricks.sensors.databricks_partition": [[10, "module-airflow.providers.databricks.sensors.databricks_partition"]], "airflow.providers.databricks.sensors.databricks_sql": [[11, "module-airflow.providers.databricks.sensors.databricks_sql"]], "airflow.providers.databricks.sensors": [[12, "module-airflow.providers.databricks.sensors"]], "airflow.providers.databricks.triggers.databricks": [[13, "module-airflow.providers.databricks.triggers.databricks"]], "airflow.providers.databricks.triggers": [[14, "module-airflow.providers.databricks.triggers"]], "airflow.providers.databricks.utils.databricks": [[15, "module-airflow.providers.databricks.utils.databricks"]], "airflow.providers.databricks.utils": [[16, "module-airflow.providers.databricks.utils"]], "tests.system.providers.databricks.example_databricks": [[17, "module-tests.system.providers.databricks.example_databricks"]], "tests.system.providers.databricks.example_databricks_repos": [[18, "module-tests.system.providers.databricks.example_databricks_repos"]], "tests.system.providers.databricks.example_databricks_sensors": [[19, "module-tests.system.providers.databricks.example_databricks_sensors"]], "tests.system.providers.databricks.example_databricks_sql": [[20, "module-tests.system.providers.databricks.example_databricks_sql"]], "tests.system.providers.databricks.example_databricks_workflow": [[21, "module-tests.system.providers.databricks.example_databricks_workflow"]], "tests.system.providers.databricks": [[22, "module-tests.system.providers.databricks"]], "Changelog": [[23, "changelog"]], "6.7.0": [[23, "id1"], [24, "id1"]], "Features": [[23, "features"], [23, "id3"], [23, "id6"], [23, "id10"], [23, "id13"], [23, "id17"], [23, "id20"], [23, "id30"], [23, "id33"], [23, "id37"], [23, "id40"], [23, "id51"], [23, "id56"], [23, "id59"], [23, "id68"], [23, "id70"], [23, "id74"], [23, "id77"], [23, "id82"], [23, "id85"], [23, "id87"], [23, "id91"], [23, "id94"], [23, "id97"], [23, "id101"], [23, "id103"]], "Bug Fixes": [[23, "bug-fixes"], [23, "id4"], [23, "id7"], [23, "id14"], [23, "id21"], [23, "id24"], [23, "id34"], [23, "id45"], [23, "id48"], [23, "id52"], [23, "id61"], [23, "id64"], [23, "id72"], [23, "id75"], [23, "id78"], [23, "id83"], [23, "id88"], [23, "id92"], [23, "id98"], [23, "id104"], [23, "id106"]], "6.6.0": [[23, "id2"], [24, "id2"]], "Misc": [[23, "misc"], [23, "id8"], [23, "id11"], [23, "id15"], [23, "id18"], [23, "id25"], [23, "id26"], [23, "id35"], [23, "id38"], [23, "id41"], [23, "id43"], [23, "id46"], [23, "id49"], [23, "id53"], [23, "id57"], [23, "id67"], [23, "id71"], [23, "id89"], [23, "id95"], [23, "id99"], [23, "id108"]], "6.5.0": [[23, "id5"], [24, "id3"]], "6.4.0": [[23, "id9"], [24, "id4"]], "6.3.0": [[23, "id12"], [24, "id5"]], "6.2.0": [[23, "id16"], [24, "id6"]], "6.1.0": [[23, "id19"], [24, "id7"]], "6.0.0": [[23, "id22"], [24, "id8"]], "Breaking changes": [[23, "breaking-changes"], [23, "id28"], [23, "id63"], [23, "id80"], [23, "id110"]], "5.0.1 (YANKED)": [[23, "yanked"]], "5.0.0": [[23, "id27"], [24, "id10"]], "4.7.0": [[23, "id29"], [24, "id11"]], "4.6.0": [[23, "id31"], [24, "id12"]], "4.5.0": [[23, "id36"], [24, "id13"]], "4.4.0": [[23, "id39"], [24, "id14"]], "4.3.3": [[23, "id42"], [24, "id15"]], "4.3.2": [[23, "id44"], [24, "id17"]], "4.3.1": [[23, "id47"], [24, "id18"]], "4.3.0": [[23, "id50"], [24, "id19"]], "4.2.0": [[23, "id54"], [24, "id20"]], "4.1.0": [[23, "id58"], [24, "id22"]], "4.0.1": [[23, "id60"], [24, "id23"]], "4.0.0": [[23, "id62"], [24, "id24"]], "3.4.0 (YANKED)": [[23, "id65"]], "3.3.0": [[23, "id69"], [24, "id26"]], "3.2.0": [[23, "id73"], [24, "id28"]], "3.1.0": [[23, "id76"], [24, "id30"]], "3.0.0": [[23, "id79"], [24, "id31"]], "2.7.0": [[23, "id84"], [24, "id32"]], "2.6.0": [[23, "id86"], [24, "id33"]], "2.5.0": [[23, "id90"], [24, "id34"]], "2.4.0": [[23, "id93"], [24, "id35"]], "2.3.0": [[23, "id96"], [24, "id37"]], "2.2.0": [[23, "id100"], [24, "id38"]], "2.1.0": [[23, "id102"], [24, "id39"]], "2.0.2": [[23, "id105"], [24, "id40"]], "2.0.1": [[23, "id107"], [24, "id41"]], "2.0.0": [[23, "id109"], [24, "id42"]], "1.0.1": [[23, "id111"], [24, "id43"]], "1.0.0": [[23, "id112"], [24, "id44"]], "Package apache-airflow-providers-databricks": [[24, "package-apache-airflow-providers-databricks"]], "5.0.1": [[24, "id9"]], "3.4.0": [[24, "id25"]], "Databricks Connection": [[25, "databricks-connection"]], "Authenticating to Databricks": [[25, "authenticating-to-databricks"]], "Default Connection IDs": [[25, "default-connection-ids"]], "Configuring the Connection": [[25, "configuring-the-connection"]], "apache-airflow-providers-databricks": [[26, "apache-airflow-providers-databricks"]], "apache-airflow-providers-databricks package": [[26, "apache-airflow-providers-databricks-package"]], "Provider package": [[26, "provider-package"]], "Installation": [[26, "installation"]], "Requirements": [[26, "requirements"]], "Cross provider package dependencies": [[26, "cross-provider-package-dependencies"]], "Downloading official packages": [[26, "downloading-official-packages"]], "Installing from sources": [[27, "installing-from-sources"]], "Released packages": [[27, "released-packages"]], "Release integrity": [[27, "release-integrity"]], "Verifying PyPI releases": [[27, "verifying-pypi-releases"]], "DatabricksCopyIntoOperator": [[28, "databrickscopyintooperator"]], "Using the Operator": [[28, "using-the-operator"], [30, "using-the-operator"], [32, "using-the-operator"], [33, "using-the-operator"], [34, "using-the-operator"], [35, "using-the-operator"], [36, "using-the-operator"], [37, "using-the-operator"]], "Examples": [[28, "examples"], [30, "examples"], [31, "examples"], [32, "examples"], [33, "examples"], [34, "examples"], [36, "examples"], [36, "id1"], [36, "id3"], [37, "examples"], [38, "examples"], [39, "examples"]], "Importing CSV data": [[28, "importing-csv-data"]], "Databricks Operators": [[29, "databricks-operators"]], "DatabricksCreateJobsOperator": [[30, "databrickscreatejobsoperator"]], "Specifying parameters as JSON": [[30, "specifying-parameters-as-json"], [37, "specifying-parameters-as-json"]], "Using named parameters": [[30, "using-named-parameters"], [37, "using-named-parameters"]], "Pairing with DatabricksRunNowOperator": [[30, "pairing-with-databricksrunnowoperator"]], "DatabricksNotebookOperator": [[31, "databricksnotebookoperator"]], "Running a notebook in Databricks on a new cluster": [[31, "running-a-notebook-in-databricks-on-a-new-cluster"]], "Running a notebook in Databricks on an existing cluster": [[31, "running-a-notebook-in-databricks-on-an-existing-cluster"]], "DatabricksReposCreateOperator": [[32, "databricksreposcreateoperator"]], "Create a Databricks Repo": [[32, "create-a-databricks-repo"]], "DatabricksReposDeleteOperator": [[33, "databricksreposdeleteoperator"]], "Deleting Databricks Repo by specifying path": [[33, "deleting-databricks-repo-by-specifying-path"]], "DatabricksReposUpdateOperator": [[34, "databricksreposupdateoperator"]], "Updating Databricks Repo by specifying path": [[34, "updating-databricks-repo-by-specifying-path"]], "DatabricksRunNowOperator": [[35, "databricksrunnowoperator"]], "DatabricksRunNowDeferrableOperator": [[35, "databricksrunnowdeferrableoperator"]], "DatabricksSqlOperator": [[36, "databrickssqloperator"]], "Selecting data": [[36, "selecting-data"]], "Selecting data into a file": [[36, "selecting-data-into-a-file"]], "Executing multiple statements": [[36, "executing-multiple-statements"]], "Executing multiple statements from a file": [[36, "executing-multiple-statements-from-a-file"]], "DatabricksSqlSensor": [[36, "databrickssqlsensor"]], "Using the Sensor": [[36, "using-the-sensor"], [36, "id2"]], "DatabricksPartitionSensor": [[36, "databrickspartitionsensor"]], "DatabricksSubmitRunOperator": [[37, "databrickssubmitrunoperator"]], "DatabricksSubmitRunDeferrableOperator": [[37, "databrickssubmitrundeferrableoperator"]], "DatabricksTaskOperator": [[38, "databrickstaskoperator"]], "Running a notebook in Databricks using DatabricksTaskOperator": [[38, "running-a-notebook-in-databricks-using-databrickstaskoperator"]], "Running a SQL query in Databricks using DatabricksTaskOperator": [[38, "running-a-sql-query-in-databricks-using-databrickstaskoperator"]], "DatabricksWorkflowTaskGroup": [[39, "databricksworkflowtaskgroup"]], "Example of what a DAG looks like with a DatabricksWorkflowTaskGroup": [[39, "example-of-what-a-dag-looks-like-with-a-databricksworkflowtaskgroup"]], "The following image displays the resulting Databricks Workflow in the Airflow UI (based on the above example provided)": [[39, "the-following-image-displays-the-resulting-databricks-workflow-in-the-airflow-ui-based-on-the-above-example-provided"]], "The corresponding Databricks Workflow  in the Databricks UI for the run triggered from the Airflow DAG is depicted below": [[39, "the-corresponding-databricks-workflow-in-the-databricks-ui-for-the-run-triggered-from-the-airflow-dag-is-depicted-below"]], "Releasing security patches": [[40, "releasing-security-patches"]]}, "indexentries": {"blocked (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.BLOCKED"]], "cancel_all_runs_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.CANCEL_ALL_RUNS_ENDPOINT"]], "cancel_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.CANCEL_RUN_ENDPOINT"]], "cluster_life_cycle_states (airflow.providers.databricks.hooks.databricks.clusterstate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.CLUSTER_LIFE_CYCLE_STATES"]], "create_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.CREATE_ENDPOINT"]], "clusterstate (class in airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState"]], "delete_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.DELETE_RUN_ENDPOINT"]], "databrickshook (class in airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook"]], "get_cluster_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.GET_CLUSTER_ENDPOINT"]], "get_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.GET_RUN_ENDPOINT"]], "install_libs_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.INSTALL_LIBS_ENDPOINT"]], "internal_error (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.INTERNAL_ERROR"]], "list_jobs_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.LIST_JOBS_ENDPOINT"]], "list_pipelines_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.LIST_PIPELINES_ENDPOINT"]], "output_runs_job_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.OUTPUT_RUNS_JOB_ENDPOINT"]], "pending (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.PENDING"]], "queued (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.QUEUED"]], "repair_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.REPAIR_RUN_ENDPOINT"]], "reset_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.RESET_ENDPOINT"]], "restart_cluster_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.RESTART_CLUSTER_ENDPOINT"]], "running (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.RUNNING"]], "run_life_cycle_states (airflow.providers.databricks.hooks.databricks.runstate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.RUN_LIFE_CYCLE_STATES"]], "run_now_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.RUN_NOW_ENDPOINT"]], "runlifecyclestate (class in airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState"]], "runstate (class in airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.RunState"]], "skipped (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.SKIPPED"]], "spark_versions_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.SPARK_VERSIONS_ENDPOINT"]], "start_cluster_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.START_CLUSTER_ENDPOINT"]], "submit_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.SUBMIT_RUN_ENDPOINT"]], "terminated (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.TERMINATED"]], "terminate_cluster_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.TERMINATE_CLUSTER_ENDPOINT"]], "terminating (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.TERMINATING"]], "uninstall_libs_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.UNINSTALL_LIBS_ENDPOINT"]], "waiting_for_retry (airflow.providers.databricks.hooks.databricks.runlifecyclestate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunLifeCycleState.WAITING_FOR_RETRY"]], "workspace_get_status_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.WORKSPACE_GET_STATUS_ENDPOINT"]], "__eq__() (airflow.providers.databricks.hooks.databricks.clusterstate method)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.__eq__"]], "__eq__() (airflow.providers.databricks.hooks.databricks.runstate method)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.__eq__"]], "__repr__() (airflow.providers.databricks.hooks.databricks.clusterstate method)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.__repr__"]], "__repr__() (airflow.providers.databricks.hooks.databricks.runstate method)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.__repr__"]], "a_get_cluster_state() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_cluster_state"]], "a_get_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_run"]], "a_get_run_output() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_run_output"]], "a_get_run_page_url() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_run_page_url"]], "a_get_run_state() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_run_state"]], "airflow.providers.databricks.hooks.databricks": [[0, "module-airflow.providers.databricks.hooks.databricks"]], "cancel_all_runs() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.cancel_all_runs"]], "cancel_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.cancel_run"]], "create_job() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.create_job"]], "create_repo() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.create_repo"]], "delete_repo() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.delete_repo"]], "delete_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.delete_run"]], "find_job_id_by_name() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.find_job_id_by_name"]], "find_pipeline_id_by_name() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.find_pipeline_id_by_name"]], "from_json() (airflow.providers.databricks.hooks.databricks.clusterstate class method)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.from_json"]], "from_json() (airflow.providers.databricks.hooks.databricks.runstate class method)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.from_json"]], "get_cluster_state() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_cluster_state"]], "get_job_id() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_job_id"]], "get_latest_repair_id() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_latest_repair_id"]], "get_repo_by_path() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_repo_by_path"]], "get_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run"]], "get_run_output() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_output"]], "get_run_page_url() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_page_url"]], "get_run_state() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state"]], "get_run_state_lifecycle() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state_lifecycle"]], "get_run_state_message() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state_message"]], "get_run_state_result() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state_result"]], "get_run_state_str() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state_str"]], "hook_name (airflow.providers.databricks.hooks.databricks.databrickshook attribute)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.hook_name"]], "install() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.install"]], "is_running (airflow.providers.databricks.hooks.databricks.clusterstate property)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.is_running"]], "is_successful (airflow.providers.databricks.hooks.databricks.runstate property)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.is_successful"]], "is_terminal (airflow.providers.databricks.hooks.databricks.clusterstate property)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.is_terminal"]], "is_terminal (airflow.providers.databricks.hooks.databricks.runstate property)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.is_terminal"]], "list_jobs() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.list_jobs"]], "list_pipelines() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.list_pipelines"]], "module": [[0, "module-airflow.providers.databricks.hooks.databricks"], [1, "module-airflow.providers.databricks.hooks.databricks_base"], [2, "module-airflow.providers.databricks.hooks.databricks_sql"], [3, "module-airflow.providers.databricks.hooks"], [4, "module-airflow.providers.databricks"], [5, "module-airflow.providers.databricks.operators.databricks"], [6, "module-airflow.providers.databricks.operators.databricks_repos"], [7, "module-airflow.providers.databricks.operators.databricks_sql"], [8, "module-airflow.providers.databricks.operators.databricks_workflow"], [9, "module-airflow.providers.databricks.operators"], [10, "module-airflow.providers.databricks.sensors.databricks_partition"], [11, "module-airflow.providers.databricks.sensors.databricks_sql"], [12, "module-airflow.providers.databricks.sensors"], [13, "module-airflow.providers.databricks.triggers.databricks"], [14, "module-airflow.providers.databricks.triggers"], [15, "module-airflow.providers.databricks.utils.databricks"], [16, "module-airflow.providers.databricks.utils"], [17, "module-tests.system.providers.databricks.example_databricks"], [18, "module-tests.system.providers.databricks.example_databricks_repos"], [19, "module-tests.system.providers.databricks.example_databricks_sensors"], [20, "module-tests.system.providers.databricks.example_databricks_sql"], [21, "module-tests.system.providers.databricks.example_databricks_workflow"], [22, "module-tests.system.providers.databricks"]], "repair_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.repair_run"]], "reset_job() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.reset_job"]], "restart_cluster() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.restart_cluster"]], "run_now() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.run_now"]], "start_cluster() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.start_cluster"]], "submit_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.submit_run"]], "terminate_cluster() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.terminate_cluster"]], "test_connection() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.test_connection"]], "to_json() (airflow.providers.databricks.hooks.databricks.clusterstate method)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.to_json"]], "to_json() (airflow.providers.databricks.hooks.databricks.runstate method)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.to_json"]], "uninstall() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.uninstall"]], "update_job_permission() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.update_job_permission"]], "update_repo() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.update_repo"]], "azure_management_endpoint (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.AZURE_MANAGEMENT_ENDPOINT"]], "azure_metadata_service_instance_url (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.AZURE_METADATA_SERVICE_INSTANCE_URL"]], "azure_metadata_service_token_url (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.AZURE_METADATA_SERVICE_TOKEN_URL"]], "basedatabrickshook (class in airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook"]], "bearerauth (class in airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.BearerAuth"]], "default_databricks_scope (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.DEFAULT_DATABRICKS_SCOPE"]], "oidc_token_service_url (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.OIDC_TOKEN_SERVICE_URL"]], "token_refresh_lead_time (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.TOKEN_REFRESH_LEAD_TIME"]], "__aenter__() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.__aenter__"]], "__aexit__() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.__aexit__"]], "airflow.providers.databricks.hooks.databricks_base": [[1, "module-airflow.providers.databricks.hooks.databricks_base"]], "conn_name_attr (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook attribute)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.conn_name_attr"]], "conn_type (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook attribute)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.conn_type"]], "databricks_conn() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.databricks_conn"]], "default_conn_name (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook attribute)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.default_conn_name"]], "encode() (airflow.providers.databricks.hooks.databricks_base.bearerauth method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BearerAuth.encode"]], "extra_parameters (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook attribute)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.extra_parameters"]], "get_conn() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.get_conn"]], "host() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.host"]], "user_agent_header() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.user_agent_header"]], "user_agent_value() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.user_agent_value"]], "databrickssqlhook (class in airflow.providers.databricks.hooks.databricks_sql)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook"]], "list_sql_endpoints_endpoint (in module airflow.providers.databricks.hooks.databricks_sql)": [[2, "airflow.providers.databricks.hooks.databricks_sql.LIST_SQL_ENDPOINTS_ENDPOINT"]], "t (in module airflow.providers.databricks.hooks.databricks_sql)": [[2, "airflow.providers.databricks.hooks.databricks_sql.T"]], "airflow.providers.databricks.hooks.databricks_sql": [[2, "module-airflow.providers.databricks.hooks.databricks_sql"]], "bulk_dump() (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook method)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.bulk_dump"]], "bulk_load() (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook method)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.bulk_load"]], "get_conn() (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook method)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.get_conn"]], "hook_name (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook attribute)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.hook_name"]], "run() (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook method)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.run"]], "airflow.providers.databricks.hooks": [[3, "module-airflow.providers.databricks.hooks"]], "__version__ (in module airflow.providers.databricks)": [[4, "airflow.providers.databricks.__version__"]], "airflow.providers.databricks": [[4, "module-airflow.providers.databricks"]], "caller (airflow.providers.databricks.operators.databricks.databricksnotebookoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksNotebookOperator.CALLER"]], "caller (airflow.providers.databricks.operators.databricks.databrickstaskoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksTaskOperator.CALLER"]], "defer_method_name (in module airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DEFER_METHOD_NAME"]], "databrickscreatejobsoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator"]], "databricksjobrunlink (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksJobRunLink"]], "databricksnotebookoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksNotebookOperator"]], "databricksrunnowdeferrableoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowDeferrableOperator"]], "databricksrunnowoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator"]], "databrickssubmitrundeferrableoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunDeferrableOperator"]], "databrickssubmitrunoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"]], "databrickstaskbaseoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksTaskBaseOperator"]], "databrickstaskoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksTaskOperator"]], "xcom_job_id_key (in module airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.XCOM_JOB_ID_KEY"]], "xcom_run_id_key (in module airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.XCOM_RUN_ID_KEY"]], "xcom_run_page_url_key (in module airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.XCOM_RUN_PAGE_URL_KEY"]], "airflow.providers.databricks.operators.databricks": [[5, "module-airflow.providers.databricks.operators.databricks"]], "execute() (airflow.providers.databricks.operators.databricks.databrickscreatejobsoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks.databricksrunnowoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks.databrickssubmitrundeferrableoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunDeferrableOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks.databrickstaskbaseoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksTaskBaseOperator.execute"]], "execute_complete() (airflow.providers.databricks.operators.databricks.databricksrunnowoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.execute_complete"]], "execute_complete() (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.execute_complete"]], "execute_complete() (airflow.providers.databricks.operators.databricks.databrickstaskbaseoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksTaskBaseOperator.execute_complete"]], "get_link() (airflow.providers.databricks.operators.databricks.databricksjobrunlink method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksJobRunLink.get_link"]], "monitor_databricks_job() (airflow.providers.databricks.operators.databricks.databrickstaskbaseoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksTaskBaseOperator.monitor_databricks_job"]], "name (airflow.providers.databricks.operators.databricks.databricksjobrunlink attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksJobRunLink.name"]], "normalise_json_content() (in module airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.normalise_json_content"]], "on_kill() (airflow.providers.databricks.operators.databricks.databricksrunnowoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.on_kill"]], "on_kill() (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.on_kill"]], "operator_extra_links (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.operator_extra_links"]], "operator_extra_links (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.operator_extra_links"]], "template_ext (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.template_ext"]], "template_ext (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.template_ext"]], "template_fields (airflow.providers.databricks.operators.databricks.databrickscreatejobsoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks.databricksnotebookoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksNotebookOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks.databrickstaskoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksTaskOperator.template_fields"]], "ui_color (airflow.providers.databricks.operators.databricks.databrickscreatejobsoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator.ui_color"]], "ui_color (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.ui_color"]], "ui_color (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.ui_color"]], "ui_fgcolor (airflow.providers.databricks.operators.databricks.databrickscreatejobsoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator.ui_fgcolor"]], "ui_fgcolor (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.ui_fgcolor"]], "ui_fgcolor (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.ui_fgcolor"]], "databricksreposcreateoperator (class in airflow.providers.databricks.operators.databricks_repos)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator"]], "databricksreposdeleteoperator (class in airflow.providers.databricks.operators.databricks_repos)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposDeleteOperator"]], "databricksreposupdateoperator (class in airflow.providers.databricks.operators.databricks_repos)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposUpdateOperator"]], "__aws_code_commit_regexp__ (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.__aws_code_commit_regexp__"]], "__detect_repo_provider__() (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator static method)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.__detect_repo_provider__"]], "__git_providers__ (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.__git_providers__"]], "__repos_path_regexp__ (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.__repos_path_regexp__"]], "airflow.providers.databricks.operators.databricks_repos": [[6, "module-airflow.providers.databricks.operators.databricks_repos"]], "execute() (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator method)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks_repos.databricksreposdeleteoperator method)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposDeleteOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks_repos.databricksreposupdateoperator method)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposUpdateOperator.execute"]], "template_fields (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks_repos.databricksreposdeleteoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposDeleteOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks_repos.databricksreposupdateoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposUpdateOperator.template_fields"]], "copy_into_approved_formats (in module airflow.providers.databricks.operators.databricks_sql)": [[7, "airflow.providers.databricks.operators.databricks_sql.COPY_INTO_APPROVED_FORMATS"]], "databrickscopyintooperator (class in airflow.providers.databricks.operators.databricks_sql)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator"]], "databrickssqloperator (class in airflow.providers.databricks.operators.databricks_sql)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator"]], "airflow.providers.databricks.operators.databricks_sql": [[7, "module-airflow.providers.databricks.operators.databricks_sql"]], "conn_id_field (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.conn_id_field"]], "execute() (airflow.providers.databricks.operators.databricks_sql.databrickscopyintooperator method)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator.execute"]], "get_db_hook() (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator method)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.get_db_hook"]], "template_ext (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.template_ext"]], "template_fields (airflow.providers.databricks.operators.databricks_sql.databrickscopyintooperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.template_fields"]], "template_fields_renderers (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.template_fields_renderers"]], "databricksworkflowtaskgroup (class in airflow.providers.databricks.operators.databricks_workflow)": [[8, "airflow.providers.databricks.operators.databricks_workflow.DatabricksWorkflowTaskGroup"]], "workflowrunmetadata (class in airflow.providers.databricks.operators.databricks_workflow)": [[8, "airflow.providers.databricks.operators.databricks_workflow.WorkflowRunMetadata"]], "__exit__() (airflow.providers.databricks.operators.databricks_workflow.databricksworkflowtaskgroup method)": [[8, "airflow.providers.databricks.operators.databricks_workflow.DatabricksWorkflowTaskGroup.__exit__"]], "airflow.providers.databricks.operators.databricks_workflow": [[8, "module-airflow.providers.databricks.operators.databricks_workflow"]], "conn_id (airflow.providers.databricks.operators.databricks_workflow.workflowrunmetadata attribute)": [[8, "airflow.providers.databricks.operators.databricks_workflow.WorkflowRunMetadata.conn_id"]], "is_databricks (airflow.providers.databricks.operators.databricks_workflow.databricksworkflowtaskgroup attribute)": [[8, "airflow.providers.databricks.operators.databricks_workflow.DatabricksWorkflowTaskGroup.is_databricks"]], "job_id (airflow.providers.databricks.operators.databricks_workflow.workflowrunmetadata attribute)": [[8, "airflow.providers.databricks.operators.databricks_workflow.WorkflowRunMetadata.job_id"]], "run_id (airflow.providers.databricks.operators.databricks_workflow.workflowrunmetadata attribute)": [[8, "airflow.providers.databricks.operators.databricks_workflow.WorkflowRunMetadata.run_id"]], "airflow.providers.databricks.operators": [[9, "module-airflow.providers.databricks.operators"]], "databrickspartitionsensor (class in airflow.providers.databricks.sensors.databricks_partition)": [[10, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor"]], "airflow.providers.databricks.sensors.databricks_partition": [[10, "module-airflow.providers.databricks.sensors.databricks_partition"]], "poke() (airflow.providers.databricks.sensors.databricks_partition.databrickspartitionsensor method)": [[10, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor.poke"]], "template_ext (airflow.providers.databricks.sensors.databricks_partition.databrickspartitionsensor attribute)": [[10, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor.template_ext"]], "template_fields (airflow.providers.databricks.sensors.databricks_partition.databrickspartitionsensor attribute)": [[10, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor.template_fields"]], "template_fields_renderers (airflow.providers.databricks.sensors.databricks_partition.databrickspartitionsensor attribute)": [[10, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor.template_fields_renderers"]], "databrickssqlsensor (class in airflow.providers.databricks.sensors.databricks_sql)": [[11, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor"]], "airflow.providers.databricks.sensors.databricks_sql": [[11, "module-airflow.providers.databricks.sensors.databricks_sql"]], "hook() (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor method)": [[11, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.hook"]], "poke() (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor method)": [[11, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.poke"]], "template_ext (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor attribute)": [[11, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.template_ext"]], "template_fields (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor attribute)": [[11, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.template_fields"]], "template_fields_renderers (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor attribute)": [[11, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.template_fields_renderers"]], "airflow.providers.databricks.sensors": [[12, "module-airflow.providers.databricks.sensors"]], "databricksexecutiontrigger (class in airflow.providers.databricks.triggers.databricks)": [[13, "airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger"]], "airflow.providers.databricks.triggers.databricks": [[13, "module-airflow.providers.databricks.triggers.databricks"]], "run() (airflow.providers.databricks.triggers.databricks.databricksexecutiontrigger method)": [[13, "airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger.run"]], "serialize() (airflow.providers.databricks.triggers.databricks.databricksexecutiontrigger method)": [[13, "airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger.serialize"]], "airflow.providers.databricks.triggers": [[14, "module-airflow.providers.databricks.triggers"]], "airflow.providers.databricks.utils.databricks": [[15, "module-airflow.providers.databricks.utils.databricks"]], "validate_trigger_event() (in module airflow.providers.databricks.utils.databricks)": [[15, "airflow.providers.databricks.utils.databricks.validate_trigger_event"]], "airflow.providers.databricks.utils": [[16, "module-airflow.providers.databricks.utils"]], "dag_id (in module tests.system.providers.databricks.example_databricks)": [[17, "tests.system.providers.databricks.example_databricks.DAG_ID"]], "env_id (in module tests.system.providers.databricks.example_databricks)": [[17, "tests.system.providers.databricks.example_databricks.ENV_ID"]], "query_id (in module tests.system.providers.databricks.example_databricks)": [[17, "tests.system.providers.databricks.example_databricks.QUERY_ID"]], "warehouse_id (in module tests.system.providers.databricks.example_databricks)": [[17, "tests.system.providers.databricks.example_databricks.WAREHOUSE_ID"]], "job (in module tests.system.providers.databricks.example_databricks)": [[17, "tests.system.providers.databricks.example_databricks.job"]], "test_run (in module tests.system.providers.databricks.example_databricks)": [[17, "tests.system.providers.databricks.example_databricks.test_run"]], "tests.system.providers.databricks.example_databricks": [[17, "module-tests.system.providers.databricks.example_databricks"]], "dag_id (in module tests.system.providers.databricks.example_databricks_repos)": [[18, "tests.system.providers.databricks.example_databricks_repos.DAG_ID"]], "env_id (in module tests.system.providers.databricks.example_databricks_repos)": [[18, "tests.system.providers.databricks.example_databricks_repos.ENV_ID"]], "default_args (in module tests.system.providers.databricks.example_databricks_repos)": [[18, "tests.system.providers.databricks.example_databricks_repos.default_args"]], "repo_path (in module tests.system.providers.databricks.example_databricks_repos)": [[18, "tests.system.providers.databricks.example_databricks_repos.repo_path"]], "test_run (in module tests.system.providers.databricks.example_databricks_repos)": [[18, "tests.system.providers.databricks.example_databricks_repos.test_run"]], "tests.system.providers.databricks.example_databricks_repos": [[18, "module-tests.system.providers.databricks.example_databricks_repos"]], "dag_id (in module tests.system.providers.databricks.example_databricks_sensors)": [[19, "tests.system.providers.databricks.example_databricks_sensors.DAG_ID"]], "env_id (in module tests.system.providers.databricks.example_databricks_sensors)": [[19, "tests.system.providers.databricks.example_databricks_sensors.ENV_ID"]], "connection_id (in module tests.system.providers.databricks.example_databricks_sensors)": [[19, "tests.system.providers.databricks.example_databricks_sensors.connection_id"]], "test_run (in module tests.system.providers.databricks.example_databricks_sensors)": [[19, "tests.system.providers.databricks.example_databricks_sensors.test_run"]], "tests.system.providers.databricks.example_databricks_sensors": [[19, "module-tests.system.providers.databricks.example_databricks_sensors"]], "dag_id (in module tests.system.providers.databricks.example_databricks_sql)": [[20, "tests.system.providers.databricks.example_databricks_sql.DAG_ID"]], "env_id (in module tests.system.providers.databricks.example_databricks_sql)": [[20, "tests.system.providers.databricks.example_databricks_sql.ENV_ID"]], "connection_id (in module tests.system.providers.databricks.example_databricks_sql)": [[20, "tests.system.providers.databricks.example_databricks_sql.connection_id"]], "test_run (in module tests.system.providers.databricks.example_databricks_sql)": [[20, "tests.system.providers.databricks.example_databricks_sql.test_run"]], "tests.system.providers.databricks.example_databricks_sql": [[20, "module-tests.system.providers.databricks.example_databricks_sql"]], "databricks_conn_id (in module tests.system.providers.databricks.example_databricks_workflow)": [[21, "tests.system.providers.databricks.example_databricks_workflow.DATABRICKS_CONN_ID"]], "databricks_notification_email (in module tests.system.providers.databricks.example_databricks_workflow)": [[21, "tests.system.providers.databricks.example_databricks_workflow.DATABRICKS_NOTIFICATION_EMAIL"]], "execution_timeout (in module tests.system.providers.databricks.example_databricks_workflow)": [[21, "tests.system.providers.databricks.example_databricks_workflow.EXECUTION_TIMEOUT"]], "group_id (in module tests.system.providers.databricks.example_databricks_workflow)": [[21, "tests.system.providers.databricks.example_databricks_workflow.GROUP_ID"]], "query_id (in module tests.system.providers.databricks.example_databricks_workflow)": [[21, "tests.system.providers.databricks.example_databricks_workflow.QUERY_ID"]], "user (in module tests.system.providers.databricks.example_databricks_workflow)": [[21, "tests.system.providers.databricks.example_databricks_workflow.USER"]], "warehouse_id (in module tests.system.providers.databricks.example_databricks_workflow)": [[21, "tests.system.providers.databricks.example_databricks_workflow.WAREHOUSE_ID"]], "dag (in module tests.system.providers.databricks.example_databricks_workflow)": [[21, "tests.system.providers.databricks.example_databricks_workflow.dag"]], "job_cluster_spec (in module tests.system.providers.databricks.example_databricks_workflow)": [[21, "tests.system.providers.databricks.example_databricks_workflow.job_cluster_spec"]], "task_group (in module tests.system.providers.databricks.example_databricks_workflow)": [[21, "tests.system.providers.databricks.example_databricks_workflow.task_group"]], "test_run (in module tests.system.providers.databricks.example_databricks_workflow)": [[21, "tests.system.providers.databricks.example_databricks_workflow.test_run"]], "tests.system.providers.databricks.example_databricks_workflow": [[21, "module-tests.system.providers.databricks.example_databricks_workflow"]], "tests.system.providers.databricks": [[22, "module-tests.system.providers.databricks"]]}})