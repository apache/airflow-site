airflow.providers.databricks.triggers.databricks
================================================

.. py:module:: airflow.providers.databricks.triggers.databricks


Classes
-------

.. autoapisummary::

   airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger
   airflow.providers.databricks.triggers.databricks.DatabricksSQLStatementExecutionTrigger


Module Contents
---------------

.. py:class:: DatabricksExecutionTrigger(run_id, databricks_conn_id, polling_period_seconds = 30, retry_limit = 3, retry_delay = 10, retry_args = None, run_page_url = None, repair_run = False, caller = 'DatabricksExecutionTrigger')

   Bases: :py:obj:`airflow.triggers.base.BaseTrigger`


   The trigger handles the logic of async communication with DataBricks API.

   :param run_id: id of the run
   :param databricks_conn_id: Reference to the :ref:`Databricks connection <howto/connection:databricks>`.
   :param polling_period_seconds: Controls the rate of the poll for the result of this run.
       By default, the trigger will poll every 30 seconds.
   :param retry_limit: The number of times to retry the connection in case of service outages.
   :param retry_delay: The number of seconds to wait between retries.
   :param retry_args: An optional dictionary with arguments passed to ``tenacity.Retrying`` class.
   :param run_page_url: The run page url.


   .. py:attribute:: run_id


   .. py:attribute:: databricks_conn_id


   .. py:attribute:: polling_period_seconds
      :value: 30



   .. py:attribute:: retry_limit
      :value: 3



   .. py:attribute:: retry_delay
      :value: 10



   .. py:attribute:: retry_args
      :value: None



   .. py:attribute:: run_page_url
      :value: None



   .. py:attribute:: repair_run
      :value: False



   .. py:attribute:: hook


   .. py:method:: serialize()

      Return the information needed to reconstruct this Trigger.

      :return: Tuple of (class path, keyword arguments needed to re-instantiate).



   .. py:method:: run()
      :async:


      Run the trigger in an asynchronous context.

      The trigger should yield an Event whenever it wants to fire off
      an event, and return None if it is finished. Single-event triggers
      should thus yield and then immediately return.

      If it yields, it is likely that it will be resumed very quickly,
      but it may not be (e.g. if the workload is being moved to another
      triggerer process, or a multi-event trigger was being used for a
      single-event task defer).

      In either case, Trigger classes should assume they will be persisted,
      and then rely on cleanup() being called when they are no longer needed.



.. py:class:: DatabricksSQLStatementExecutionTrigger(statement_id, databricks_conn_id, end_time, polling_period_seconds = 30, retry_limit = 3, retry_delay = 10, retry_args = None, caller = 'DatabricksSQLStatementExecutionTrigger')

   Bases: :py:obj:`airflow.triggers.base.BaseTrigger`


   The trigger handles the logic of async communication with DataBricks SQL Statements API.

   :param statement_id: ID of the SQL statement.
   :param databricks_conn_id: Reference to the :ref:`Databricks connection <howto/connection:databricks>`.
   :param end_time: The end time (set based on timeout supplied for the operator) for the SQL statement execution.
   :param polling_period_seconds: Controls the rate of the poll for the result of this run.
       By default, the trigger will poll every 30 seconds.
   :param retry_limit: The number of times to retry the connection in case of service outages.
   :param retry_delay: The number of seconds to wait between retries.
   :param retry_args: An optional dictionary with arguments passed to ``tenacity.Retrying`` class.


   .. py:attribute:: statement_id


   .. py:attribute:: databricks_conn_id


   .. py:attribute:: end_time


   .. py:attribute:: polling_period_seconds
      :value: 30



   .. py:attribute:: retry_limit
      :value: 3



   .. py:attribute:: retry_delay
      :value: 10



   .. py:attribute:: retry_args
      :value: None



   .. py:attribute:: hook


   .. py:method:: serialize()

      Return the information needed to reconstruct this Trigger.

      :return: Tuple of (class path, keyword arguments needed to re-instantiate).



   .. py:method:: run()
      :async:


      Run the trigger in an asynchronous context.

      The trigger should yield an Event whenever it wants to fire off
      an event, and return None if it is finished. Single-event triggers
      should thus yield and then immediately return.

      If it yields, it is likely that it will be resumed very quickly,
      but it may not be (e.g. if the workload is being moved to another
      triggerer process, or a multi-event trigger was being used for a
      single-event task defer).

      In either case, Trigger classes should assume they will be persisted,
      and then rely on cleanup() being called when they are no longer needed.



