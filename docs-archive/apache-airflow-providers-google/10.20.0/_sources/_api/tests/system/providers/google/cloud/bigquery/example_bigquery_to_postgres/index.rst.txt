:py:mod:`tests.system.providers.google.cloud.bigquery.example_bigquery_to_postgres`
===================================================================================

.. py:module:: tests.system.providers.google.cloud.bigquery.example_bigquery_to_postgres

.. autoapi-nested-parse::

   Example Airflow DAG for Google BigQuery service.

   This DAG relies on the following OS environment variables

   * AIRFLOW__API__GOOGLE_KEY_PATH - Path to service account key file. Note, you can skip this variable if you
     run this DAG in a Composer environment.



Module Contents
---------------

.. py:data:: ENV_ID

   

.. py:data:: PROJECT_ID

   

.. py:data:: DAG_ID
   :value: 'bigquery_to_postgres'

   

.. py:data:: REGION
   :value: 'us-central1'

   

.. py:data:: ZONE

   

.. py:data:: NETWORK
   :value: 'default'

   

.. py:data:: CONNECTION_ID

   

.. py:data:: CONNECTION_TYPE
   :value: 'postgres'

   

.. py:data:: BIGQUERY_DATASET_NAME

   

.. py:data:: BIGQUERY_TABLE
   :value: 'test_table'

   

.. py:data:: SOURCE_OBJECT_NAME
   :value: 'gs://airflow-system-tests-resources/bigquery/salaries_1k.csv'

   

.. py:data:: BATCH_SIZE
   :value: 500

   

.. py:data:: UPLOAD_DATA_TO_BIGQUERY

   

.. py:data:: DB_NAME
   :value: 'testdb'

   

.. py:data:: DB_PORT
   :value: 5432

   

.. py:data:: DB_USER_NAME
   :value: 'root'

   

.. py:data:: DB_USER_PASSWORD
   :value: 'demo_password'

   

.. py:data:: SETUP_POSTGRES_COMMAND

   

.. py:data:: SQL_TABLE
   :value: 'test_table'

   

.. py:data:: SQL_CREATE_TABLE

   

.. py:data:: GCE_MACHINE_TYPE
   :value: 'n1-standard-1'

   

.. py:data:: GCE_INSTANCE_NAME

   

.. py:data:: GCE_INSTANCE_BODY

   

.. py:data:: FIREWALL_RULE_NAME

   

.. py:data:: CREATE_FIREWALL_RULE_COMMAND

   

.. py:data:: DELETE_FIREWALL_RULE_COMMAND

   

.. py:data:: DELETE_PERSISTENT_DISK_COMMAND

   

.. py:data:: log

   

.. py:data:: create_bigquery_dataset

   

.. py:data:: test_run

   

