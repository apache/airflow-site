:py:mod:`airflow.providers.google.cloud.log.gcs_task_handler`
=============================================================

.. py:module:: airflow.providers.google.cloud.log.gcs_task_handler


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.google.cloud.log.gcs_task_handler.GCSTaskHandler




Attributes
~~~~~~~~~~

.. autoapisummary::

   airflow.providers.google.cloud.log.gcs_task_handler.logger


.. py:data:: logger

   

.. py:class:: GCSTaskHandler(*, base_log_folder, gcs_log_folder, gcp_key_path = None, gcp_keyfile_dict = None, gcp_scopes = _DEFAULT_SCOPESS, project_id = PROVIDE_PROJECT_ID, **kwargs)


   Bases: :py:obj:`airflow.utils.log.file_task_handler.FileTaskHandler`, :py:obj:`airflow.utils.log.logging_mixin.LoggingMixin`

   GCSTaskHandler is a python log handler that handles and reads task instance logs.

   It extends airflow FileTaskHandler and uploads to and reads from GCS remote
   storage. Upon log reading failure, it reads from host machine's local disk.

   :param base_log_folder: Base log folder to place logs.
   :param gcs_log_folder: Path to a remote location where logs will be saved. It must have the prefix
       ``gs://``. For example: ``gs://bucket/remote/log/location``
   :param filename_template: template filename string
   :param gcp_key_path: Path to Google Cloud Service Account file (JSON). Mutually exclusive with
       gcp_keyfile_dict.
       If omitted, authorization based on `the Application Default Credentials
       <https://cloud.google.com/docs/authentication/production#finding_credentials_automatically>`__ will
       be used.
   :param gcp_keyfile_dict: Dictionary of keyfile parameters. Mutually exclusive with gcp_key_path.
   :param gcp_scopes: Comma-separated string containing OAuth2 scopes
   :param project_id: Project ID to read the secrets from. If not passed, the project ID from credentials
       will be used.
   :param delete_local_copy: Whether local log files should be deleted after they are downloaded when using
       remote logging

   .. py:attribute:: trigger_should_wrap
      :value: True

      

   .. py:method:: hook()

      Returns GCSHook if remote_log_conn_id configured.


   .. py:method:: client()

      Returns GCS Client.


   .. py:method:: set_context(ti, *, identifier = None)

      Provide task_instance context to airflow task handler.

      Generally speaking returns None.  But if attr `maintain_propagate` has
      been set to propagate, then returns sentinel MAINTAIN_PROPAGATE. This
      has the effect of overriding the default behavior to set `propagate`
      to False whenever set_context is called.  At time of writing, this
      functionality is only used in unit testing.

      :param ti: task instance object
      :param identifier: if set, adds suffix to log file. For use when relaying exceptional messages
          to task logs from a context other than task or trigger run


   .. py:method:: close()

      Close and upload local log file to remote storage GCS.


   .. py:method:: gcs_write(log, remote_log_location)

      Write the log to the remote location and return `True`; fail silently and return `False` on error.

      :param log: the log to write to the remote_log_location
      :param remote_log_location: the log's location in remote storage
      :return: whether the log is successfully written to remote location or not.



