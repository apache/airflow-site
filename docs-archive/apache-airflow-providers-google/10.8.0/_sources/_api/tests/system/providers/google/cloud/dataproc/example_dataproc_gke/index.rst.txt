:py:mod:`tests.system.providers.google.cloud.dataproc.example_dataproc_gke`
===========================================================================

.. py:module:: tests.system.providers.google.cloud.dataproc.example_dataproc_gke

.. autoapi-nested-parse::

   Example Airflow DAG that show how to create a Dataproc cluster in Google Kubernetes Engine.

   Required environment variables:
   GKE_NAMESPACE = os.environ.get("GKE_NAMESPACE", f"{CLUSTER_NAME}")
   A GKE cluster can support multiple DP clusters running in different namespaces.
   Define a namespace or assign a default one.
   Notice: optional kubernetes_namespace parameter in VIRTUAL_CLUSTER_CONFIG should be the same as GKE_NAMESPACE



Module Contents
---------------

.. py:data:: ENV_ID

   

.. py:data:: DAG_ID
   :value: 'dataproc-gke'

   

.. py:data:: PROJECT_ID

   

.. py:data:: REGION
   :value: 'us-central1'

   

.. py:data:: CLUSTER_NAME

   

.. py:data:: GKE_CLUSTER_NAME

   

.. py:data:: WORKLOAD_POOL

   

.. py:data:: GKE_CLUSTER_CONFIG

   

.. py:data:: GKE_NAMESPACE

   

.. py:data:: VIRTUAL_CLUSTER_CONFIG

   

.. py:data:: create_gke_cluster

   

.. py:data:: test_run

   

