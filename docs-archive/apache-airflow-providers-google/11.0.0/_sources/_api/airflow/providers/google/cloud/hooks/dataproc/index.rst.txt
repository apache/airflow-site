:py:mod:`airflow.providers.google.cloud.hooks.dataproc`
=======================================================

.. py:module:: airflow.providers.google.cloud.hooks.dataproc

.. autoapi-nested-parse::

   This module contains a Google Cloud Dataproc hook.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.google.cloud.hooks.dataproc.DataProcJobBuilder
   airflow.providers.google.cloud.hooks.dataproc.DataprocHook
   airflow.providers.google.cloud.hooks.dataproc.DataprocAsyncHook




.. py:exception:: DataprocResourceIsNotReadyError


   Bases: :py:obj:`airflow.exceptions.AirflowException`

   Raise when resource is not ready for create Dataproc cluster.


.. py:class:: DataProcJobBuilder(project_id, task_id, cluster_name, job_type, properties = None)


   A helper class for building Dataproc job.

   .. py:method:: add_labels(labels = None)

      Set labels for Dataproc job.

      :param labels: Labels for the job query.


   .. py:method:: add_variables(variables = None)

      Set variables for Dataproc job.

      :param variables: Variables for the job query.


   .. py:method:: add_args(args = None)

      Set args for Dataproc job.

      :param args: Args for the job query.


   .. py:method:: add_query(query)

      Set query for Dataproc job.

      :param query: query for the job.


   .. py:method:: add_query_uri(query_uri)

      Set query uri for Dataproc job.

      :param query_uri: URI for the job query.


   .. py:method:: add_jar_file_uris(jars = None)

      Set jars uris for Dataproc job.

      :param jars: List of jars URIs


   .. py:method:: add_archive_uris(archives = None)

      Set archives uris for Dataproc job.

      :param archives: List of archives URIs


   .. py:method:: add_file_uris(files = None)

      Set file uris for Dataproc job.

      :param files: List of files URIs


   .. py:method:: add_python_file_uris(pyfiles = None)

      Set python file uris for Dataproc job.

      :param pyfiles: List of python files URIs


   .. py:method:: set_main(main_jar = None, main_class = None)

      Set Dataproc main class.

      :param main_jar: URI for the main file.
      :param main_class: Name of the main class.
      :raises: ValueError


   .. py:method:: set_python_main(main)

      Set Dataproc main python file uri.

      :param main: URI for the python main file.


   .. py:method:: set_job_name(name)

      Set Dataproc job name.

      Job name is sanitized, replacing dots by underscores.

      :param name: Job name.


   .. py:method:: build()

      Return Dataproc job.

      :return: Dataproc job



.. py:class:: DataprocHook(gcp_conn_id = 'google_cloud_default', impersonation_chain = None, **kwargs)


   Bases: :py:obj:`airflow.providers.google.common.hooks.base_google.GoogleBaseHook`

   Google Cloud Dataproc APIs.

   All the methods in the hook where project_id is used must be called with
   keyword arguments rather than positional.

   .. py:method:: get_cluster_client(region = None)

      Create a ClusterControllerClient.


   .. py:method:: get_template_client(region = None)

      Create a WorkflowTemplateServiceClient.


   .. py:method:: get_job_client(region = None)

      Create a JobControllerClient.


   .. py:method:: get_batch_client(region = None)

      Create a BatchControllerClient.


   .. py:method:: get_operations_client(region)

      Create a OperationsClient.


   .. py:method:: dataproc_options_to_args(options)

      Return a formatted cluster parameters from a dictionary of arguments.

      :param options: Dictionary with options
      :return: List of arguments


   .. py:method:: wait_for_operation(operation, timeout = None, result_retry = DEFAULT)

      Wait for a long-lasting operation to complete.


   .. py:method:: create_cluster(region, project_id, cluster_name, cluster_config = None, virtual_cluster_config = None, labels = None, request_id = None, retry = DEFAULT, timeout = None, metadata = ())

      Create a cluster in a specified project.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region in which to handle the request.
      :param cluster_name: Name of the cluster to create.
      :param labels: Labels that will be assigned to created cluster.
      :param cluster_config: The cluster config to create. If a dict is
          provided, it must be of the same form as the protobuf message
          :class:`~google.cloud.dataproc_v1.types.ClusterConfig`.
      :param virtual_cluster_config: The virtual cluster config, used when
          creating a Dataproc cluster that does not directly control the
          underlying compute resources, for example, when creating a
          Dataproc-on-GKE cluster with
          :class:`~google.cloud.dataproc_v1.types.VirtualClusterConfig`.
      :param request_id: A unique id used to identify the request. If the
          server receives two *CreateClusterRequest* requests with the same
          ID, the second request will be ignored, and an operation created
          for the first one and stored in the backend is returned.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: delete_cluster(region, cluster_name, project_id, cluster_uuid = None, request_id = None, retry = DEFAULT, timeout = None, metadata = ())

      Delete a cluster in a project.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region in which to handle the request.
      :param cluster_name: Name of the cluster to delete.
      :param cluster_uuid: If specified, the RPC should fail if cluster with
          the UUID does not exist.
      :param request_id: A unique id used to identify the request. If the
          server receives two *DeleteClusterRequest* requests with the same
          ID, the second request will be ignored, and an operation created
          for the first one and stored in the backend is returned.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: diagnose_cluster(region, cluster_name, project_id, tarball_gcs_dir = None, diagnosis_interval = None, jobs = None, yarn_application_ids = None, retry = DEFAULT, timeout = None, metadata = ())

      Get cluster diagnostic information.

      After the operation completes, the response contains the Cloud Storage URI of the diagnostic output report containing a summary of collected diagnostics.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region in which to handle the request.
      :param cluster_name: Name of the cluster.
      :param tarball_gcs_dir:  The output Cloud Storage directory for the diagnostic tarball. If not specified, a task-specific directory in the cluster's staging bucket will be used.
      :param diagnosis_interval: Time interval in which diagnosis should be carried out on the cluster.
      :param jobs: Specifies a list of jobs on which diagnosis is to be performed. Format: `projects/{project}/regions/{region}/jobs/{job}`
      :param yarn_application_ids: Specifies a list of yarn applications on which diagnosis is to be performed.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: get_cluster(region, cluster_name, project_id, retry = DEFAULT, timeout = None, metadata = ())

      Get the resource representation for a cluster in a project.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param cluster_name: The cluster name.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: list_clusters(region, filter_, project_id, page_size = None, retry = DEFAULT, timeout = None, metadata = ())

      List all regions/{region}/clusters in a project.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param filter_: To constrain the clusters to. Case-sensitive.
      :param page_size: The maximum number of resources contained in the
          underlying API response. If page streaming is performed
          per-resource, this parameter does not affect the return value. If
          page streaming is performed per-page, this determines the maximum
          number of resources in a page.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: update_cluster(cluster_name, cluster, update_mask, project_id, region, graceful_decommission_timeout = None, request_id = None, retry = DEFAULT, timeout = None, metadata = ())

      Update a cluster in a project.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param cluster_name: The cluster name.
      :param cluster: Changes to the cluster. If a dict is provided, it must
          be of the same form as the protobuf message
          :class:`~google.cloud.dataproc_v1.types.Cluster`.
      :param update_mask: Specifies the path, relative to ``Cluster``, of the
          field to update. For example, to change the number of workers in a
          cluster to 5, this would be specified as
          ``config.worker_config.num_instances``, and the ``PATCH`` request
          body would specify the new value:

          .. code-block:: python

              {"config": {"workerConfig": {"numInstances": "5"}}}

          Similarly, to change the number of preemptible workers in a cluster
          to 5, this would be ``config.secondary_worker_config.num_instances``
          and the ``PATCH`` request body would be:

          .. code-block:: python

              {"config": {"secondaryWorkerConfig": {"numInstances": "5"}}}

          If a dict is provided, it must be of the same form as the protobuf
          message :class:`~google.cloud.dataproc_v1.types.FieldMask`.
      :param graceful_decommission_timeout: Timeout for graceful YARN
          decommissioning. Graceful decommissioning allows removing nodes from
          the cluster without interrupting jobs in progress. Timeout specifies
          how long to wait for jobs in progress to finish before forcefully
          removing nodes (and potentially interrupting jobs). Default timeout
          is 0 (for forceful decommission), and the maximum allowed timeout is
          one day.

          Only supported on Dataproc image versions 1.2 and higher.

          If a dict is provided, it must be of the same form as the protobuf
          message :class:`~google.cloud.dataproc_v1.types.Duration`.
      :param request_id: A unique id used to identify the request. If the
          server receives two *UpdateClusterRequest* requests with the same
          ID, the second request will be ignored, and an operation created
          for the first one and stored in the backend is returned.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: start_cluster(region, project_id, cluster_name, cluster_uuid = None, request_id = None, retry = DEFAULT, timeout = None, metadata = ())

      Start a cluster in a project.

      :param region: Cloud Dataproc region to handle the request.
      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param cluster_name: The cluster name.
      :param cluster_uuid: The cluster UUID
      :param request_id: A unique id used to identify the request. If the
          server receives two *UpdateClusterRequest* requests with the same
          ID, the second request will be ignored, and an operation created
          for the first one and stored in the backend is returned.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.
      :return: An instance of ``google.api_core.operation.Operation``


   .. py:method:: stop_cluster(region, project_id, cluster_name, cluster_uuid = None, request_id = None, retry = DEFAULT, timeout = None, metadata = ())

      Start a cluster in a project.

      :param region: Cloud Dataproc region to handle the request.
      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param cluster_name: The cluster name.
      :param cluster_uuid: The cluster UUID
      :param request_id: A unique id used to identify the request. If the
          server receives two *UpdateClusterRequest* requests with the same
          ID, the second request will be ignored, and an operation created
          for the first one and stored in the backend is returned.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.
      :return: An instance of ``google.api_core.operation.Operation``


   .. py:method:: create_workflow_template(template, project_id, region, retry = DEFAULT, timeout = None, metadata = ())

      Create a new workflow template.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param template: The Dataproc workflow template to create. If a dict is
          provided, it must be of the same form as the protobuf message
          WorkflowTemplate.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: instantiate_workflow_template(template_name, project_id, region, version = None, request_id = None, parameters = None, retry = DEFAULT, timeout = None, metadata = ())

      Instantiate a template and begins execution.

      :param template_name: Name of template to instantiate.
      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param version: Version of workflow template to instantiate. If
          specified, the workflow will be instantiated only if the current
          version of the workflow template has the supplied version. This
          option cannot be used to instantiate a previous version of workflow
          template.
      :param request_id: A tag that prevents multiple concurrent workflow
          instances with the same tag from running. This mitigates risk of
          concurrent instances started due to retries.
      :param parameters: Map from parameter names to values that should be
          used for those parameters. Values may not exceed 100 characters.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: instantiate_inline_workflow_template(template, project_id, region, request_id = None, retry = DEFAULT, timeout = None, metadata = ())

      Instantiate a template and begin execution.

      :param template: The workflow template to instantiate. If a dict is
          provided, it must be of the same form as the protobuf message
          WorkflowTemplate.
      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param request_id: A tag that prevents multiple concurrent workflow
          instances with the same tag from running. This mitigates risk of
          concurrent instances started due to retries.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: wait_for_job(job_id, project_id, region, wait_time = 10, timeout = None)

      Poll a job to check if it has finished.

      :param job_id: Dataproc job ID.
      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param wait_time: Number of seconds between checks.
      :param timeout: How many seconds wait for job to be ready.


   .. py:method:: get_job(job_id, project_id, region, retry = DEFAULT, timeout = None, metadata = ())

      Get the resource representation for a job in a project.

      :param job_id: Dataproc job ID.
      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: submit_job(job, project_id, region, request_id = None, retry = DEFAULT, timeout = None, metadata = ())

      Submit a job to a cluster.

      :param job: The job resource. If a dict is provided, it must be of the
          same form as the protobuf message Job.
      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param request_id: A tag that prevents multiple concurrent workflow
          instances with the same tag from running. This mitigates risk of
          concurrent instances started due to retries.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: cancel_job(job_id, project_id, region = None, retry = DEFAULT, timeout = None, metadata = ())

      Start a job cancellation request.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param job_id: The job ID.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: create_batch(region, project_id, batch, batch_id = None, request_id = None, retry = DEFAULT, timeout = None, metadata = ())

      Create a batch workload.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param batch: The batch to create.
      :param batch_id: The ID to use for the batch, which will become the
          final component of the batch's resource name. This value must be of
          4-63 characters. Valid characters are ``[a-z][0-9]-``.
      :param request_id: A unique id used to identify the request. If the
          server receives two *CreateBatchRequest* requests with the same
          ID, the second request will be ignored, and an operation created
          for the first one and stored in the backend is returned.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: delete_batch(batch_id, region, project_id, retry = DEFAULT, timeout = None, metadata = ())

      Delete the batch workload resource.

      :param batch_id: The batch ID.
      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: get_batch(batch_id, region, project_id, retry = DEFAULT, timeout = None, metadata = ())

      Get the batch workload resource representation.

      :param batch_id: The batch ID.
      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: list_batches(region, project_id, page_size = None, page_token = None, retry = DEFAULT, timeout = None, metadata = (), filter = None, order_by = None)

      List batch workloads.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param page_size: The maximum number of batches to return in each
          response. The service may return fewer than this value. The default
          page size is 20; the maximum page size is 1000.
      :param page_token: A page token received from a previous ``ListBatches``
          call. Provide this token to retrieve the subsequent page.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.
      :param filter: Result filters as specified in ListBatchesRequest
      :param order_by: How to order results as specified in ListBatchesRequest


   .. py:method:: wait_for_batch(batch_id, region, project_id, wait_check_interval = 10, retry = DEFAULT, timeout = None, metadata = ())

      Wait for a batch job to complete.

      After submission of a batch job, the operator waits for the job to
      complete. This hook is, however, useful in the case when Airflow is
      restarted or the task pid is killed for any reason. In this case, the
      creation would happen again, catching the raised AlreadyExists, and fail
      to this function for waiting on completion.

      :param batch_id: The batch ID.
      :param region: Cloud Dataproc region to handle the request.
      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param wait_check_interval: The amount of time to pause between checks
          for job completion.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: check_error_for_resource_is_not_ready_msg(error_msg)

      Check that reason of error is resource is not ready.



.. py:class:: DataprocAsyncHook(gcp_conn_id = 'google_cloud_default', impersonation_chain = None, **kwargs)


   Bases: :py:obj:`airflow.providers.google.common.hooks.base_google.GoogleBaseHook`

   Asynchronous interaction with Google Cloud Dataproc APIs.

   All the methods in the hook where project_id is used must be called with
   keyword arguments rather than positional.

   .. py:method:: get_cluster_client(region = None)

      Create a ClusterControllerAsyncClient.


   .. py:method:: get_template_client(region = None)

      Create a WorkflowTemplateServiceAsyncClient.


   .. py:method:: get_job_client(region = None)

      Create a JobControllerAsyncClient.


   .. py:method:: get_batch_client(region = None)

      Create a BatchControllerAsyncClient.


   .. py:method:: get_operations_client(region)

      Create a OperationsClient.


   .. py:method:: create_cluster(region, project_id, cluster_name, cluster_config = None, virtual_cluster_config = None, labels = None, request_id = None, retry = DEFAULT, timeout = None, metadata = ())
      :async:

      Create a cluster in a project.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region in which to handle the request.
      :param cluster_name: Name of the cluster to create.
      :param labels: Labels that will be assigned to created cluster.
      :param cluster_config: The cluster config to create. If a dict is
          provided, it must be of the same form as the protobuf message
          :class:`~google.cloud.dataproc_v1.types.ClusterConfig`.
      :param virtual_cluster_config: The virtual cluster config, used when
          creating a Dataproc cluster that does not directly control the
          underlying compute resources, for example, when creating a
          Dataproc-on-GKE cluster with
          :class:`~google.cloud.dataproc_v1.types.VirtualClusterConfig`.
      :param request_id: A unique id used to identify the request. If the
          server receives two *CreateClusterRequest* requests with the same
          ID, the second request will be ignored, and an operation created
          for the first one and stored in the backend is returned.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: delete_cluster(region, cluster_name, project_id, cluster_uuid = None, request_id = None, retry = DEFAULT, timeout = None, metadata = ())
      :async:

      Delete a cluster in a project.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region in which to handle the request.
      :param cluster_name: Name of the cluster to delete.
      :param cluster_uuid: If specified, the RPC should fail if cluster with
          the UUID does not exist.
      :param request_id: A unique id used to identify the request. If the
          server receives two *DeleteClusterRequest* requests with the same
          ID, the second request will be ignored, and an operation created
          for the first one and stored in the backend is returned.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: diagnose_cluster(region, cluster_name, project_id, tarball_gcs_dir = None, diagnosis_interval = None, jobs = None, yarn_application_ids = None, retry = DEFAULT, timeout = None, metadata = ())
      :async:

      Get cluster diagnostic information.

      After the operation completes, the response contains the Cloud Storage URI of the diagnostic output report containing a summary of collected diagnostics.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region in which to handle the request.
      :param cluster_name: Name of the cluster.
      :param tarball_gcs_dir:  The output Cloud Storage directory for the diagnostic tarball. If not specified, a task-specific directory in the cluster's staging bucket will be used.
      :param diagnosis_interval: Time interval in which diagnosis should be carried out on the cluster.
      :param jobs: Specifies a list of jobs on which diagnosis is to be performed. Format: `projects/{project}/regions/{region}/jobs/{job}`
      :param yarn_application_ids: Specifies a list of yarn applications on which diagnosis is to be performed.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: get_cluster(region, cluster_name, project_id, retry = DEFAULT, timeout = None, metadata = ())
      :async:

      Get the resource representation for a cluster in a project.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param cluster_name: The cluster name.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: list_clusters(region, filter_, project_id, page_size = None, retry = DEFAULT, timeout = None, metadata = ())
      :async:

      List all regions/{region}/clusters in a project.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param filter_: To constrain the clusters to. Case-sensitive.
      :param page_size: The maximum number of resources contained in the
          underlying API response. If page streaming is performed
          per-resource, this parameter does not affect the return value. If
          page streaming is performed per-page, this determines the maximum
          number of resources in a page.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: update_cluster(cluster_name, cluster, update_mask, project_id, region, graceful_decommission_timeout = None, request_id = None, retry = DEFAULT, timeout = None, metadata = ())
      :async:

      Update a cluster in a project.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param cluster_name: The cluster name.
      :param cluster: Changes to the cluster. If a dict is provided, it must
          be of the same form as the protobuf message
          :class:`~google.cloud.dataproc_v1.types.Cluster`.
      :param update_mask: Specifies the path, relative to ``Cluster``, of the
          field to update. For example, to change the number of workers in a
          cluster to 5, this would be specified as
          ``config.worker_config.num_instances``, and the ``PATCH`` request
          body would specify the new value:

          .. code-block:: python

              {"config": {"workerConfig": {"numInstances": "5"}}}

          Similarly, to change the number of preemptible workers in a cluster
          to 5, this would be ``config.secondary_worker_config.num_instances``
          and the ``PATCH`` request body would be:

          .. code-block:: python

              {"config": {"secondaryWorkerConfig": {"numInstances": "5"}}}

          If a dict is provided, it must be of the same form as the protobuf
          message :class:`~google.cloud.dataproc_v1.types.FieldMask`.
      :param graceful_decommission_timeout: Timeout for graceful YARN
          decommissioning. Graceful decommissioning allows removing nodes from
          the cluster without interrupting jobs in progress. Timeout specifies
          how long to wait for jobs in progress to finish before forcefully
          removing nodes (and potentially interrupting jobs). Default timeout
          is 0 (for forceful decommission), and the maximum allowed timeout is
          one day.

          Only supported on Dataproc image versions 1.2 and higher.

          If a dict is provided, it must be of the same form as the protobuf
          message :class:`~google.cloud.dataproc_v1.types.Duration`.
      :param request_id: A unique id used to identify the request. If the
          server receives two *UpdateClusterRequest* requests with the same
          ID, the second request will be ignored, and an operation created
          for the first one and stored in the backend is returned.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: create_workflow_template(template, project_id, region, retry = DEFAULT, timeout = None, metadata = ())
      :async:

      Create a new workflow template.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param template: The Dataproc workflow template to create. If a dict is
          provided, it must be of the same form as the protobuf message
          WorkflowTemplate.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: instantiate_workflow_template(template_name, project_id, region, version = None, request_id = None, parameters = None, retry = DEFAULT, timeout = None, metadata = ())
      :async:

      Instantiate a template and begins execution.

      :param template_name: Name of template to instantiate.
      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param version: Version of workflow template to instantiate. If
          specified, the workflow will be instantiated only if the current
          version of the workflow template has the supplied version. This
          option cannot be used to instantiate a previous version of workflow
          template.
      :param request_id: A tag that prevents multiple concurrent workflow
          instances with the same tag from running. This mitigates risk of
          concurrent instances started due to retries.
      :param parameters: Map from parameter names to values that should be
          used for those parameters. Values may not exceed 100 characters.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: instantiate_inline_workflow_template(template, project_id, region, request_id = None, retry = DEFAULT, timeout = None, metadata = ())
      :async:

      Instantiate a template and begin execution.

      :param template: The workflow template to instantiate. If a dict is
          provided, it must be of the same form as the protobuf message
          WorkflowTemplate.
      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param request_id: A tag that prevents multiple concurrent workflow
          instances with the same tag from running. This mitigates risk of
          concurrent instances started due to retries.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: get_operation(region, operation_name)
      :async:


   .. py:method:: get_job(job_id, project_id, region, retry = DEFAULT, timeout = None, metadata = ())
      :async:

      Get the resource representation for a job in a project.

      :param job_id: Dataproc job ID.
      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: submit_job(job, project_id, region, request_id = None, retry = DEFAULT, timeout = None, metadata = ())
      :async:

      Submit a job to a cluster.

      :param job: The job resource. If a dict is provided, it must be of the
          same form as the protobuf message Job.
      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param request_id: A tag that prevents multiple concurrent workflow
          instances with the same tag from running. This mitigates risk of
          concurrent instances started due to retries.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: cancel_job(job_id, project_id, region = None, retry = DEFAULT, timeout = None, metadata = ())
      :async:

      Start a job cancellation request.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param job_id: The job ID.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: create_batch(region, project_id, batch, batch_id = None, request_id = None, retry = DEFAULT, timeout = None, metadata = ())
      :async:

      Create a batch workload.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param batch: The batch to create.
      :param batch_id: The ID to use for the batch, which will become the
          final component of the batch's resource name. This value must be of
          4-63 characters. Valid characters are ``[a-z][0-9]-``.
      :param request_id: A unique id used to identify the request. If the
          server receives two *CreateBatchRequest* requests with the same
          ID, the second request will be ignored, and an operation created
          for the first one and stored in the backend is returned.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: delete_batch(batch_id, region, project_id, retry = DEFAULT, timeout = None, metadata = ())
      :async:

      Delete the batch workload resource.

      :param batch_id: The batch ID.
      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: get_batch(batch_id, region, project_id, retry = DEFAULT, timeout = None, metadata = ())
      :async:

      Get the batch workload resource representation.

      :param batch_id: The batch ID.
      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.


   .. py:method:: list_batches(region, project_id, page_size = None, page_token = None, retry = DEFAULT, timeout = None, metadata = (), filter = None, order_by = None)
      :async:

      List batch workloads.

      :param project_id: Google Cloud project ID that the cluster belongs to.
      :param region: Cloud Dataproc region to handle the request.
      :param page_size: The maximum number of batches to return in each
          response. The service may return fewer than this value. The default
          page size is 20; the maximum page size is 1000.
      :param page_token: A page token received from a previous ``ListBatches``
          call. Provide this token to retrieve the subsequent page.
      :param retry: A retry object used to retry requests. If *None*, requests
          will not be retried.
      :param timeout: The amount of time, in seconds, to wait for the request
          to complete. If *retry* is specified, the timeout applies to each
          individual attempt.
      :param metadata: Additional metadata that is provided to the method.
      :param filter: Result filters as specified in ListBatchesRequest
      :param order_by: How to order results as specified in ListBatchesRequest



