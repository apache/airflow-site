tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor
=============================================================================================

.. py:module:: tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor

.. autoapi-nested-parse::

   Example Airflow DAG that shows how to check Hive partitions existence with Dataproc Metastore Sensor.

   Note that Metastore service must be configured to use gRPC endpoints.



Attributes
----------

.. autoapisummary::

   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.DAG_ID
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.PROJECT_ID
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.ENV_ID
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.REGION
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.NETWORK
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.METASTORE_SERVICE_ID
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.METASTORE_TIMEOUT
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.METASTORE_SERVICE
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.METASTORE_SERVICE_QFN
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.DATAPROC_CLUSTER_NAME
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.DATAPROC_CLUSTER_CONFIG
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.TABLE_NAME
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.COLUMN
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.PARTITION_1
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.PARTITION_2
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.SOURCE_DATA_BUCKET
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.SOURCE_DATA_PATH
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.SOURCE_DATA_FILE_NAME
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.EXTERNAL_TABLE_BUCKET
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.QUERY_CREATE_EXTERNAL_TABLE
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.QUERY_CREATE_PARTITIONED_TABLE
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.QUERY_COPY_DATA_WITH_PARTITIONS
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.create_metastore_service
   tests.system.google.cloud.dataproc_metastore.example_dataproc_metastore_hive_partition_sensor.test_run


Module Contents
---------------

.. py:data:: DAG_ID
   :value: 'hive_partition_sensor'


.. py:data:: PROJECT_ID

.. py:data:: ENV_ID

.. py:data:: REGION
   :value: 'europe-west1'


.. py:data:: NETWORK
   :value: 'default'


.. py:data:: METASTORE_SERVICE_ID
   :value: ''


.. py:data:: METASTORE_TIMEOUT
   :value: 2400


.. py:data:: METASTORE_SERVICE

.. py:data:: METASTORE_SERVICE_QFN
   :value: 'projects/Uninferable/locations/europe-west1/services/'


.. py:data:: DATAPROC_CLUSTER_NAME
   :value: ''


.. py:data:: DATAPROC_CLUSTER_CONFIG

.. py:data:: TABLE_NAME
   :value: 'transactions_partitioned'


.. py:data:: COLUMN
   :value: 'TransactionType'


.. py:data:: PARTITION_1
   :value: ''


.. py:data:: PARTITION_2
   :value: ''


.. py:data:: SOURCE_DATA_BUCKET
   :value: 'airflow-system-tests-resources'


.. py:data:: SOURCE_DATA_PATH
   :value: 'dataproc/hive'


.. py:data:: SOURCE_DATA_FILE_NAME
   :value: 'part-00000.parquet'


.. py:data:: EXTERNAL_TABLE_BUCKET
   :value: "{{task_instance.xcom_pull(task_ids='get_hive_warehouse_bucket_task', key='bucket')}}"


.. py:data:: QUERY_CREATE_EXTERNAL_TABLE
   :value: Multiline-String

   .. raw:: html

      <details><summary>Show Value</summary>

   .. code-block:: python

      """
      CREATE EXTERNAL TABLE IF NOT EXISTS transactions
      (SubmissionDate DATE, TransactionAmount DOUBLE, TransactionType STRING)
      STORED AS PARQUET
      LOCATION 'gs://{{task_instance.xcom_pull(task_ids='get_hive_warehouse_bucket_task', key='bucket')}}/dataproc/hive';
      """

   .. raw:: html

      </details>



.. py:data:: QUERY_CREATE_PARTITIONED_TABLE
   :value: Multiline-String

   .. raw:: html

      <details><summary>Show Value</summary>

   .. code-block:: python

      """
      CREATE EXTERNAL TABLE IF NOT EXISTS transactions_partitioned
      (SubmissionDate DATE, TransactionAmount DOUBLE)
      PARTITIONED BY (TransactionType STRING);
      """

   .. raw:: html

      </details>



.. py:data:: QUERY_COPY_DATA_WITH_PARTITIONS
   :value: Multiline-String

   .. raw:: html

      <details><summary>Show Value</summary>

   .. code-block:: python

      """
      SET hive.exec.dynamic.partition.mode=nonstrict;
      INSERT INTO TABLE transactions_partitioned PARTITION (TransactionType)
      SELECT SubmissionDate,TransactionAmount,TransactionType FROM transactions;
      """

   .. raw:: html

      </details>



.. py:data:: create_metastore_service

.. py:data:: test_run

