airflow.providers.pinecone.operators.pinecone
=============================================

.. py:module:: airflow.providers.pinecone.operators.pinecone


Classes
-------

.. autoapisummary::

   airflow.providers.pinecone.operators.pinecone.PineconeIngestOperator
   airflow.providers.pinecone.operators.pinecone.CreatePodIndexOperator
   airflow.providers.pinecone.operators.pinecone.CreateServerlessIndexOperator


Module Contents
---------------

.. py:class:: PineconeIngestOperator(*, conn_id = PineconeHook.default_conn_name, index_name, input_vectors, namespace = '', batch_size = None, upsert_kwargs = None, **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`


   Ingest vector embeddings into Pinecone.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:PineconeIngestOperator`

   :param conn_id: The connection id to use when connecting to Pinecone.
   :param index_name: Name of the Pinecone index.
   :param input_vectors: Data to be ingested, in the form of a list of vectors, list of tuples,
       or list of dictionaries.
   :param namespace: The namespace to write to. If not specified, the default namespace is used.
   :param batch_size: The number of vectors to upsert in each batch.
   :param upsert_kwargs: .. seealso:: https://docs.pinecone.io/reference/upsert


   .. py:attribute:: template_fields
      :type:  collections.abc.Sequence[str]
      :value: ('index_name', 'input_vectors', 'namespace')



   .. py:attribute:: upsert_kwargs


   .. py:attribute:: conn_id
      :value: 'pinecone_default'



   .. py:attribute:: index_name


   .. py:attribute:: namespace
      :value: ''



   .. py:attribute:: batch_size
      :value: None



   .. py:attribute:: input_vectors


   .. py:property:: hook
      :type: airflow.providers.pinecone.hooks.pinecone.PineconeHook


      Return an instance of the PineconeHook.



   .. py:method:: execute(context)

      Ingest data into Pinecone using the PineconeHook.



.. py:class:: CreatePodIndexOperator(*, conn_id = PineconeHook.default_conn_name, index_name, dimension, environment = None, replicas = None, shards = None, pods = None, pod_type = 'p1.x1', metadata_config = None, source_collection = None, metric = 'cosine', timeout = None, **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`


   Create a pod based index in Pinecone.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:CreatePodIndexOperator`

   :param conn_id: The connection id to use when connecting to Pinecone.
   :param index_name: Name of the Pinecone index.
   :param dimension: The dimension of the vectors to be indexed.
   :param environment: The environment to use when creating the index.
   :param replicas: The number of replicas to use.
   :param shards: The number of shards to use.
   :param pods: The number of pods to use.
   :param pod_type: The type of pod to use. Defaults to p1.x1
   :param metadata_config: The metadata configuration to use.
   :param source_collection: The source collection to use.
   :param metric: The metric to use. Defaults to cosine.
   :param timeout: The timeout to use.


   .. py:attribute:: conn_id
      :value: 'pinecone_default'



   .. py:attribute:: index_name


   .. py:attribute:: dimension


   .. py:attribute:: environment
      :value: None



   .. py:attribute:: replicas
      :value: None



   .. py:attribute:: shards
      :value: None



   .. py:attribute:: pods
      :value: None



   .. py:attribute:: pod_type
      :value: 'p1.x1'



   .. py:attribute:: metadata_config
      :value: None



   .. py:attribute:: source_collection
      :value: None



   .. py:attribute:: metric
      :value: 'cosine'



   .. py:attribute:: timeout
      :value: None



   .. py:property:: hook
      :type: airflow.providers.pinecone.hooks.pinecone.PineconeHook



   .. py:method:: execute(context)

      Derive when creating an operator.

      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



.. py:class:: CreateServerlessIndexOperator(*, conn_id = PineconeHook.default_conn_name, index_name, dimension, cloud, region = None, metric = None, timeout = None, **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`


   Create a serverless index in Pinecone.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:CreateServerlessIndexOperator`

   :param conn_id: The connection id to use when connecting to Pinecone.
   :param index_name: Name of the Pinecone index.
   :param dimension: The dimension of the vectors to be indexed.
   :param cloud: The cloud to use when creating the index.
   :param region: The region to use when creating the index.
   :param metric: The metric to use.
   :param timeout: The timeout to use.


   .. py:attribute:: conn_id
      :value: 'pinecone_default'



   .. py:attribute:: index_name


   .. py:attribute:: dimension


   .. py:attribute:: cloud


   .. py:attribute:: region
      :value: None



   .. py:attribute:: metric
      :value: None



   .. py:attribute:: timeout
      :value: None



   .. py:property:: hook
      :type: airflow.providers.pinecone.hooks.pinecone.PineconeHook



   .. py:method:: execute(context)

      Derive when creating an operator.

      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



