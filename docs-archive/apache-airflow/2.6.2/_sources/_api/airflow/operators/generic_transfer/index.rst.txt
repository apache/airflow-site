:py:mod:`airflow.operators.generic_transfer`
============================================

.. py:module:: airflow.operators.generic_transfer


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.operators.generic_transfer.GenericTransfer




.. py:class:: GenericTransfer(*, sql, destination_table, source_conn_id, destination_conn_id, preoperator = None, insert_args = None, **kwargs)


   Bases: :py:obj:`airflow.models.BaseOperator`

   Moves data from a connection to another.

   Assuming that they both provide the required methods in their respective hooks.
   The source hook needs to expose a `get_records` method, and the destination a
   `insert_rows` method.

   This is meant to be used on small-ish datasets that fit in memory.

   :param sql: SQL query to execute against the source database. (templated)
   :param destination_table: target table. (templated)
   :param source_conn_id: source connection
   :param destination_conn_id: destination connection
   :param preoperator: sql statement or list of statements to be
       executed prior to loading the data. (templated)
   :param insert_args: extra params for `insert_rows` method.

   .. py:attribute:: template_fields
      :type: Sequence[str]
      :value: ('sql', 'destination_table', 'preoperator')

      

   .. py:attribute:: template_ext
      :type: Sequence[str]
      :value: ('.sql', '.hql')

      

   .. py:attribute:: template_fields_renderers

      

   .. py:attribute:: ui_color
      :value: '#b0f07c'

      

   .. py:method:: execute(context)

      This is the main method to derive when creating an operator.
      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



