:mod:`airflow.providers.amazon.aws.operators.redshift`
======================================================

.. py:module:: airflow.providers.amazon.aws.operators.redshift


Module Contents
---------------

.. py:class:: RedshiftSQLOperator(*, sql: Optional[Union[Dict, Iterable]], redshift_conn_id: str = 'redshift_default', parameters: Optional[dict] = None, autocommit: bool = True, **kwargs)

   Bases: :class:`airflow.models.BaseOperator`

   Executes SQL Statements against an Amazon Redshift cluster

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:RedshiftSQLOperator`

   :param sql: the sql code to be executed
   :type sql: Can receive a str representing a sql statement,
       or an iterable of str (sql statements)
   :param redshift_conn_id: reference to
       :ref:`Amazon Redshift connection id<howto/connection:redshift>`
   :type redshift_conn_id: str
   :param parameters: (optional) the parameters to render the SQL query with.
   :type parameters: dict or iterable
   :param autocommit: if True, each command is automatically committed.
       (default value: False)
   :type autocommit: bool

   .. attribute:: template_fields
      :annotation: = ['sql']

      

   .. attribute:: template_ext
      :annotation: = ['.sql']

      

   
   .. method:: get_hook(self)

      Create and return RedshiftSQLHook.
      :return RedshiftSQLHook: A RedshiftSQLHook instance.



   
   .. method:: execute(self, context: dict)

      Execute a statement against Amazon Redshift




