:py:mod:`airflow.providers.amazon.aws.operators.dms`
====================================================

.. py:module:: airflow.providers.amazon.aws.operators.dms


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.amazon.aws.operators.dms.DmsCreateTaskOperator
   airflow.providers.amazon.aws.operators.dms.DmsDeleteTaskOperator
   airflow.providers.amazon.aws.operators.dms.DmsDescribeTasksOperator
   airflow.providers.amazon.aws.operators.dms.DmsStartTaskOperator
   airflow.providers.amazon.aws.operators.dms.DmsStopTaskOperator




.. py:class:: DmsCreateTaskOperator(*, replication_task_id: str, source_endpoint_arn: str, target_endpoint_arn: str, replication_instance_arn: str, table_mappings: dict, migration_type: Optional[str] = 'full-load', create_task_kwargs: Optional[dict] = None, aws_conn_id: str = 'aws_default', **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   Creates AWS DMS replication task.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:DmsCreateTaskOperator`

   :param replication_task_id: Replication task id
   :type replication_task_id: str
   :param source_endpoint_arn: Source endpoint ARN
   :type source_endpoint_arn: str
   :param target_endpoint_arn: Target endpoint ARN
   :type target_endpoint_arn: str
   :param replication_instance_arn: Replication instance ARN
   :type replication_instance_arn: str
   :param table_mappings: Table mappings
   :type table_mappings: dict
   :param migration_type: Migration type ('full-load'|'cdc'|'full-load-and-cdc'), full-load by default.
   :type migration_type: str
   :param create_task_kwargs: Extra arguments for DMS replication task creation.
   :type create_task_kwargs: Optional[dict]
   :param aws_conn_id: The Airflow connection used for AWS credentials.
       If this is None or empty then the default boto3 behaviour is used. If
       running Airflow in a distributed manner and aws_conn_id is None or
       empty, then default boto3 configuration would be used (and must be
       maintained on each worker node).
   :type aws_conn_id: Optional[str]

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['replication_task_id', 'source_endpoint_arn', 'target_endpoint_arn',...

      

   .. py:attribute:: template_ext
      :annotation: :Sequence[str] = []

      

   .. py:attribute:: template_fields_renderers
      

      

   .. py:method:: execute(self, context: airflow.utils.context.Context)

      Creates AWS DMS replication task from Airflow

      :return: replication task arn



.. py:class:: DmsDeleteTaskOperator(*, replication_task_arn: Optional[str] = None, aws_conn_id: str = 'aws_default', **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   Deletes AWS DMS replication task.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:DmsDeleteTaskOperator`

   :param replication_task_arn: Replication task ARN
   :type replication_task_arn: str
   :param aws_conn_id: The Airflow connection used for AWS credentials.
       If this is None or empty then the default boto3 behaviour is used. If
       running Airflow in a distributed manner and aws_conn_id is None or
       empty, then default boto3 configuration would be used (and must be
       maintained on each worker node).
   :type aws_conn_id: Optional[str]

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['replication_task_arn']

      

   .. py:attribute:: template_ext
      :annotation: :Sequence[str] = []

      

   .. py:attribute:: template_fields_renderers
      :annotation: :Dict[str, str]

      

   .. py:method:: execute(self, context: airflow.utils.context.Context)

      Deletes AWS DMS replication task from Airflow

      :return: replication task arn



.. py:class:: DmsDescribeTasksOperator(*, describe_tasks_kwargs: Optional[dict] = None, aws_conn_id: str = 'aws_default', **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   Describes AWS DMS replication tasks.

   :param describe_tasks_kwargs: Describe tasks command arguments
   :type describe_tasks_kwargs: Optional[dict]
   :param aws_conn_id: The Airflow connection used for AWS credentials.
       If this is None or empty then the default boto3 behaviour is used. If
       running Airflow in a distributed manner and aws_conn_id is None or
       empty, then default boto3 configuration would be used (and must be
       maintained on each worker node).
   :type aws_conn_id: Optional[str]

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['describe_tasks_kwargs']

      

   .. py:attribute:: template_ext
      :annotation: :Sequence[str] = []

      

   .. py:attribute:: template_fields_renderers
      :annotation: :Dict[str, str]

      

   .. py:method:: execute(self, context: airflow.utils.context.Context)

      Describes AWS DMS replication tasks from Airflow

      :return: Marker and list of replication tasks
      :rtype: (Optional[str], list)



.. py:class:: DmsStartTaskOperator(*, replication_task_arn: str, start_replication_task_type: Optional[str] = 'start-replication', start_task_kwargs: Optional[dict] = None, aws_conn_id: str = 'aws_default', **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   Starts AWS DMS replication task.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:DmsStartTaskOperator`

   :param replication_task_arn: Replication task ARN
   :type replication_task_arn: str
   :param start_replication_task_type: Replication task start type
       ('start-replication'|'resume-processing'|'reload-target')
   :type start_replication_task_type: Optional[str]
   :param start_task_kwargs: Extra start replication task arguments
   :type start_task_kwargs: Optional[dict]
   :param aws_conn_id: The Airflow connection used for AWS credentials.
       If this is None or empty then the default boto3 behaviour is used. If
       running Airflow in a distributed manner and aws_conn_id is None or
       empty, then default boto3 configuration would be used (and must be
       maintained on each worker node).
   :type aws_conn_id: Optional[str]

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['replication_task_arn', 'start_replication_task_type', 'start_task_kwargs']

      

   .. py:attribute:: template_ext
      :annotation: :Sequence[str] = []

      

   .. py:attribute:: template_fields_renderers
      

      

   .. py:method:: execute(self, context: airflow.utils.context.Context)

      Starts AWS DMS replication task from Airflow

      :return: replication task arn



.. py:class:: DmsStopTaskOperator(*, replication_task_arn: Optional[str] = None, aws_conn_id: str = 'aws_default', **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   Stops AWS DMS replication task.

   :param replication_task_arn: Replication task ARN
   :type replication_task_arn: str
   :param aws_conn_id: The Airflow connection used for AWS credentials.
       If this is None or empty then the default boto3 behaviour is used. If
       running Airflow in a distributed manner and aws_conn_id is None or
       empty, then default boto3 configuration would be used (and must be
       maintained on each worker node).
   :type aws_conn_id: Optional[str]

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['replication_task_arn']

      

   .. py:attribute:: template_ext
      :annotation: :Sequence[str] = []

      

   .. py:attribute:: template_fields_renderers
      :annotation: :Dict[str, str]

      

   .. py:method:: execute(self, context: airflow.utils.context.Context)

      Stops AWS DMS replication task from Airflow

      :return: replication task arn



