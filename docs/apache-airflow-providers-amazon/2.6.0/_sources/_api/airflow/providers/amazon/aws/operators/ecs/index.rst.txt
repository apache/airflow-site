:py:mod:`airflow.providers.amazon.aws.operators.ecs`
====================================================

.. py:module:: airflow.providers.amazon.aws.operators.ecs


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.amazon.aws.operators.ecs.ECSProtocol
   airflow.providers.amazon.aws.operators.ecs.ECSTaskLogFetcher
   airflow.providers.amazon.aws.operators.ecs.ECSOperator



Functions
~~~~~~~~~

.. autoapisummary::

   airflow.providers.amazon.aws.operators.ecs.should_retry



.. py:function:: should_retry(exception: Exception)

   Check if exception is related to ECS resource quota (CPU, MEM).


.. py:class:: ECSProtocol

   Bases: :py:obj:`airflow.typing_compat.Protocol`

   A structured Protocol for ``boto3.client('ecs')``. This is used for type hints on
   :py:meth:`.ECSOperator.client`.

   .. seealso::

       - https://mypy.readthedocs.io/en/latest/protocols.html
       - https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ecs.html

   .. py:method:: run_task(self, **kwargs) -> Dict

      https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ecs.html#ECS.Client.run_task


   .. py:method:: get_waiter(self, x: str) -> botocore.waiter.Waiter

      https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ecs.html#ECS.Client.get_waiter


   .. py:method:: describe_tasks(self, cluster: str, tasks) -> Dict

      https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ecs.html#ECS.Client.describe_tasks


   .. py:method:: stop_task(self, cluster, task, reason: str) -> Dict

      https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ecs.html#ECS.Client.stop_task


   .. py:method:: describe_task_definition(self, taskDefinition: str) -> Dict

      https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ecs.html#ECS.Client.describe_task_definition


   .. py:method:: list_tasks(self, cluster: str, launchType: str, desiredStatus: str, family: str) -> Dict

      https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ecs.html#ECS.Client.list_tasks



.. py:class:: ECSTaskLogFetcher(*, aws_conn_id: Optional[str] = 'aws_default', region_name: Optional[str] = None, log_group: str, log_stream_name: str, fetch_interval: datetime.timedelta, logger: logging.Logger)

   Bases: :py:obj:`threading.Thread`

   Fetches Cloudwatch log events with specific interval as a thread
   and sends the log events to the info channel of the provided logger.

   .. py:method:: run(self) -> None

      Method representing the thread's activity.

      You may override this method in a subclass. The standard run() method
      invokes the callable object passed to the object's constructor as the
      target argument, if any, with sequential and keyword arguments taken
      from the args and kwargs arguments, respectively.



   .. py:method:: get_last_log_messages(self, number_messages) -> list


   .. py:method:: get_last_log_message(self) -> Optional[str]


   .. py:method:: is_stopped(self) -> bool


   .. py:method:: stop(self)



.. py:class:: ECSOperator(*, task_definition: str, cluster: str, overrides: dict, aws_conn_id: Optional[str] = None, region_name: Optional[str] = None, launch_type: str = 'EC2', capacity_provider_strategy: Optional[list] = None, group: Optional[str] = None, placement_constraints: Optional[list] = None, placement_strategy: Optional[list] = None, platform_version: Optional[str] = None, network_configuration: Optional[dict] = None, tags: Optional[dict] = None, awslogs_group: Optional[str] = None, awslogs_region: Optional[str] = None, awslogs_stream_prefix: Optional[str] = None, awslogs_fetch_interval: datetime.timedelta = timedelta(seconds=30), propagate_tags: Optional[str] = None, quota_retry: Optional[dict] = None, reattach: bool = False, number_logs_exception: int = 10, **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   Execute a task on AWS ECS (Elastic Container Service)

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:ECSOperator`

   :param task_definition: the task definition name on Elastic Container Service
   :type task_definition: str
   :param cluster: the cluster name on Elastic Container Service
   :type cluster: str
   :param overrides: the same parameter that boto3 will receive (templated):
       https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ecs.html#ECS.Client.run_task
   :type overrides: dict
   :param aws_conn_id: connection id of AWS credentials / region name. If None,
       credential boto3 strategy will be used
       (http://boto3.readthedocs.io/en/latest/guide/configuration.html).
   :type aws_conn_id: str
   :param region_name: region name to use in AWS Hook.
       Override the region_name in connection (if provided)
   :type region_name: str
   :param launch_type: the launch type on which to run your task ('EC2' or 'FARGATE')
   :type launch_type: str
   :param capacity_provider_strategy: the capacity provider strategy to use for the task.
       When capacity_provider_strategy is specified, the launch_type parameter is omitted.
       If no capacity_provider_strategy or launch_type is specified,
       the default capacity provider strategy for the cluster is used.
   :type capacity_provider_strategy: list
   :param group: the name of the task group associated with the task
   :type group: str
   :param placement_constraints: an array of placement constraint objects to use for
       the task
   :type placement_constraints: list
   :param placement_strategy: an array of placement strategy objects to use for
       the task
   :type placement_strategy: list
   :param platform_version: the platform version on which your task is running
   :type platform_version: str
   :param network_configuration: the network configuration for the task
   :type network_configuration: dict
   :param tags: a dictionary of tags in the form of {'tagKey': 'tagValue'}.
   :type tags: dict
   :param awslogs_group: the CloudWatch group where your ECS container logs are stored.
       Only required if you want logs to be shown in the Airflow UI after your job has
       finished.
   :type awslogs_group: str
   :param awslogs_region: the region in which your CloudWatch logs are stored.
       If None, this is the same as the `region_name` parameter. If that is also None,
       this is the default AWS region based on your connection settings.
   :type awslogs_region: str
   :param awslogs_stream_prefix: the stream prefix that is used for the CloudWatch logs.
       This is usually based on some custom name combined with the name of the container.
       Only required if you want logs to be shown in the Airflow UI after your job has
       finished.
   :type awslogs_stream_prefix: str
   :param awslogs_fetch_interval: the interval that the ECS task log fetcher should wait
       in between each Cloudwatch logs fetches.
   :type awslogs_fetch_interval: timedelta
   :param quota_retry: Config if and how to retry the launch of a new ECS task, to handle
       transient errors.
   :type quota_retry: dict
   :param reattach: If set to True, will check if the task previously launched by the task_instance
       is already running. If so, the operator will attach to it instead of starting a new task.
       This is to avoid relaunching a new task when the connection drops between Airflow and ECS while
       the task is running (when the Airflow worker is restarted for example).
   :type reattach: bool
   :param number_logs_exception: Number of lines from the last Cloudwatch logs to return in the
       AirflowException if an ECS task is stopped (to receive Airflow alerts with the logs of what
       failed in the code running in ECS).
   :type number_logs_exception: int

   .. py:attribute:: ui_color
      :annotation: = #f0ede4

      

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['overrides']

      

   .. py:attribute:: template_fields_renderers
      

      

   .. py:attribute:: REATTACH_XCOM_KEY
      :annotation: = ecs_task_arn

      

   .. py:attribute:: REATTACH_XCOM_TASK_ID_TEMPLATE
      :annotation: = {task_id}_task_arn

      

   .. py:method:: execute(self, context, session=None)

      This is the main method to derive when creating an operator.
      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.


   .. py:method:: get_hook(self) -> airflow.providers.amazon.aws.hooks.base_aws.AwsBaseHook

      Create and return an AwsHook.


   .. py:method:: on_kill(self) -> None

      Override this method to cleanup subprocesses when a task instance
      gets killed. Any use of the threading, subprocess or multiprocessing
      module within an operator needs to be cleaned up or it will leave
      ghost processes behind.



