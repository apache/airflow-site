:py:mod:`airflow.providers.amazon.aws.operators.redshift_sql`
=============================================================

.. py:module:: airflow.providers.amazon.aws.operators.redshift_sql


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.amazon.aws.operators.redshift_sql.RedshiftSQLOperator




.. py:class:: RedshiftSQLOperator(*, sql: Optional[Union[Dict, Iterable]], redshift_conn_id: str = 'redshift_default', parameters: Optional[dict] = None, autocommit: bool = True, **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   Executes SQL Statements against an Amazon Redshift cluster

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:RedshiftSQLOperator`

   :param sql: the sql code to be executed
   :type sql: Can receive a str representing a sql statement,
       or an iterable of str (sql statements)
   :param redshift_conn_id: reference to
       :ref:`Amazon Redshift connection id<howto/connection:redshift>`
   :type redshift_conn_id: str
   :param parameters: (optional) the parameters to render the SQL query with.
   :type parameters: dict or iterable
   :param autocommit: if True, each command is automatically committed.
       (default value: False)
   :type autocommit: bool

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['sql']

      

   .. py:attribute:: template_ext
      :annotation: :Sequence[str] = ['.sql']

      

   .. py:method:: get_hook(self) -> airflow.providers.amazon.aws.hooks.redshift_sql.RedshiftSQLHook

      Create and return RedshiftSQLHook.
      :return RedshiftSQLHook: A RedshiftSQLHook instance.


   .. py:method:: execute(self, context: airflow.utils.context.Context) -> None

      Execute a statement against Amazon Redshift



