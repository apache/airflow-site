:py:mod:`airflow.providers.amazon.aws.operators.emr`
====================================================

.. py:module:: airflow.providers.amazon.aws.operators.emr


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.amazon.aws.operators.emr.EmrAddStepsOperator
   airflow.providers.amazon.aws.operators.emr.EmrStartNotebookExecutionOperator
   airflow.providers.amazon.aws.operators.emr.EmrStopNotebookExecutionOperator
   airflow.providers.amazon.aws.operators.emr.EmrEksCreateClusterOperator
   airflow.providers.amazon.aws.operators.emr.EmrContainerOperator
   airflow.providers.amazon.aws.operators.emr.EmrCreateJobFlowOperator
   airflow.providers.amazon.aws.operators.emr.EmrModifyClusterOperator
   airflow.providers.amazon.aws.operators.emr.EmrTerminateJobFlowOperator
   airflow.providers.amazon.aws.operators.emr.EmrServerlessCreateApplicationOperator
   airflow.providers.amazon.aws.operators.emr.EmrServerlessStartJobOperator
   airflow.providers.amazon.aws.operators.emr.EmrServerlessDeleteApplicationOperator




.. py:class:: EmrAddStepsOperator(*, job_flow_id = None, job_flow_name = None, cluster_states = None, aws_conn_id = 'aws_default', steps = None, wait_for_completion = False, waiter_delay = None, waiter_max_attempts = None, execution_role_arn = None, **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   An operator that adds steps to an existing EMR job_flow.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:EmrAddStepsOperator`

   :param job_flow_id: id of the JobFlow to add steps to. (templated)
   :param job_flow_name: name of the JobFlow to add steps to. Use as an alternative to passing
       job_flow_id. will search for id of JobFlow with matching name in one of the states in
       param cluster_states. Exactly one cluster like this should exist or will fail. (templated)
   :param cluster_states: Acceptable cluster states when searching for JobFlow id by job_flow_name.
       (templated)
   :param aws_conn_id: aws connection to uses
   :param steps: boto3 style steps or reference to a steps file (must be '.json') to
       be added to the jobflow. (templated)
   :param wait_for_completion: If True, the operator will wait for all the steps to be completed.
   :param execution_role_arn: The ARN of the runtime role for a step on the cluster.
   :param do_xcom_push: if True, job_flow_id is pushed to XCom with key job_flow_id.

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['job_flow_id', 'job_flow_name', 'cluster_states', 'steps', 'execution_role_arn']

      

   .. py:attribute:: template_ext
      :annotation: :Sequence[str] = ['.json']

      

   .. py:attribute:: template_fields_renderers
      

      

   .. py:attribute:: ui_color
      :annotation: = #f9c915

      

   .. py:attribute:: operator_extra_links
      

      

   .. py:method:: execute(context)

      This is the main method to derive when creating an operator.
      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



.. py:class:: EmrStartNotebookExecutionOperator(editor_id, relative_path, cluster_id, service_role, notebook_execution_name = None, notebook_params = None, notebook_instance_security_group_id = None, master_instance_security_group_id = None, tags = None, wait_for_completion = False, aws_conn_id = 'aws_default', waiter_countdown = 25 * 60, waiter_check_interval_seconds = 60, **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   An operator that starts an EMR notebook execution.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:EmrStartNotebookExecutionOperator`

   :param editor_id: The unique identifier of the EMR notebook to use for notebook execution.
   :param relative_path: The path and file name of the notebook file for this execution,
       relative to the path specified for the EMR notebook.
   :param cluster_id: The unique identifier of the EMR cluster the notebook is attached to.
   :param service_role: The name or ARN of the IAM role that is used as the service role
       for Amazon EMR (the EMR role) for the notebook execution.
   :param notebook_execution_name: Optional name for the notebook execution.
   :param notebook_params: Input parameters in JSON format passed to the EMR notebook at
       runtime for execution.
   :param: notebook_instance_security_group_id: The unique identifier of the Amazon EC2
       security group to associate with the EMR notebook for this notebook execution.
   :param: master_instance_security_group_id: Optional unique ID of an EC2 security
       group to associate with the master instance of the EMR cluster for this notebook execution.
   :param tags: Optional list of key value pair to associate with the notebook execution.
   :param waiter_countdown: Total amount of time the operator will wait for the notebook to stop.
       Defaults to 25 * 60 seconds.
   :param waiter_check_interval_seconds: Number of seconds between polling the state of the notebook.
       Defaults to 60 seconds.

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['editor_id', 'cluster_id', 'relative_path', 'service_role', 'notebook_execution_name',...

      

   .. py:method:: execute(context)

      This is the main method to derive when creating an operator.
      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



.. py:class:: EmrStopNotebookExecutionOperator(notebook_execution_id, wait_for_completion = False, aws_conn_id = 'aws_default', waiter_countdown = 25 * 60, waiter_check_interval_seconds = 60, **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   An operator that stops a running EMR notebook execution.

    .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:EmrStopNotebookExecutionOperator`

   :param notebook_execution_id: The unique identifier of the notebook execution.
   :param wait_for_completion: If True, the operator will wait for the notebook.
       to be in a STOPPED or FINISHED state. Defaults to False.
   :param aws_conn_id: aws connection to use.
   :param waiter_countdown: Total amount of time the operator will wait for the notebook to stop.
       Defaults to 25 * 60 seconds.
   :param waiter_check_interval_seconds: Number of seconds between polling the state of the notebook.
       Defaults to 60 seconds.

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['notebook_execution_id']

      

   .. py:method:: execute(context)

      This is the main method to derive when creating an operator.
      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



.. py:class:: EmrEksCreateClusterOperator(*, virtual_cluster_name, eks_cluster_name, eks_namespace, virtual_cluster_id = '', aws_conn_id = 'aws_default', tags = None, **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   An operator that creates EMR on EKS virtual clusters.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:EmrEksCreateClusterOperator`

   :param virtual_cluster_name: The name of the EMR EKS virtual cluster to create.
   :param eks_cluster_name: The EKS cluster used by the EMR virtual cluster.
   :param eks_namespace: namespace used by the EKS cluster.
   :param virtual_cluster_id: The EMR on EKS virtual cluster id.
   :param aws_conn_id: The Airflow connection used for AWS credentials.
   :param tags: The tags assigned to created cluster.
       Defaults to None

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['virtual_cluster_name', 'eks_cluster_name', 'eks_namespace']

      

   .. py:attribute:: ui_color
      :annotation: = #f9c915

      

   .. py:method:: hook()

      Create and return an EmrContainerHook.


   .. py:method:: execute(context)

      Create EMR on EKS virtual Cluster



.. py:class:: EmrContainerOperator(*, name, virtual_cluster_id, execution_role_arn, release_label, job_driver, configuration_overrides = None, client_request_token = None, aws_conn_id = 'aws_default', wait_for_completion = True, poll_interval = 30, max_tries = None, tags = None, max_polling_attempts = None, **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   An operator that submits jobs to EMR on EKS virtual clusters.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:EmrContainerOperator`

   :param name: The name of the job run.
   :param virtual_cluster_id: The EMR on EKS virtual cluster ID
   :param execution_role_arn: The IAM role ARN associated with the job run.
   :param release_label: The Amazon EMR release version to use for the job run.
   :param job_driver: Job configuration details, e.g. the Spark job parameters.
   :param configuration_overrides: The configuration overrides for the job run,
       specifically either application configuration or monitoring configuration.
   :param client_request_token: The client idempotency token of the job run request.
       Use this if you want to specify a unique ID to prevent two jobs from getting started.
       If no token is provided, a UUIDv4 token will be generated for you.
   :param aws_conn_id: The Airflow connection used for AWS credentials.
   :param wait_for_completion: Whether or not to wait in the operator for the job to complete.
   :param poll_interval: Time (in seconds) to wait between two consecutive calls to check query status on EMR
   :param max_tries: Deprecated - use max_polling_attempts instead.
   :param max_polling_attempts: Maximum number of times to wait for the job run to finish.
       Defaults to None, which will poll until the job is *not* in a pending, submitted, or running state.
   :param tags: The tags assigned to job runs.
       Defaults to None

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['name', 'virtual_cluster_id', 'execution_role_arn', 'release_label', 'job_driver',...

      

   .. py:attribute:: ui_color
      :annotation: = #f9c915

      

   .. py:method:: hook()

      Create and return an EmrContainerHook.


   .. py:method:: execute(context)

      Run job on EMR Containers


   .. py:method:: on_kill()

      Cancel the submitted job run



.. py:class:: EmrCreateJobFlowOperator(*, aws_conn_id = 'aws_default', emr_conn_id = 'emr_default', job_flow_overrides = None, region_name = None, **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   Creates an EMR JobFlow, reading the config from the EMR connection.
   A dictionary of JobFlow overrides can be passed that override
   the config from the connection.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:EmrCreateJobFlowOperator`

   :param aws_conn_id: The Airflow connection used for AWS credentials.
       If this is None or empty then the default boto3 behaviour is used. If
       running Airflow in a distributed manner and aws_conn_id is None or
       empty, then default boto3 configuration would be used (and must be
       maintained on each worker node)
   :param emr_conn_id: :ref:`Amazon Elastic MapReduce Connection <howto/connection:emr>`.
       Use to receive an initial Amazon EMR cluster configuration:
       ``boto3.client('emr').run_job_flow`` request body.
       If this is None or empty or the connection does not exist,
       then an empty initial configuration is used.
   :param job_flow_overrides: boto3 style arguments or reference to an arguments file
       (must be '.json') to override specific ``emr_conn_id`` extra parameters. (templated)
   :param region_name: Region named passed to EmrHook

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['job_flow_overrides']

      

   .. py:attribute:: template_ext
      :annotation: :Sequence[str] = ['.json']

      

   .. py:attribute:: template_fields_renderers
      

      

   .. py:attribute:: ui_color
      :annotation: = #f9c915

      

   .. py:attribute:: operator_extra_links
      

      

   .. py:method:: execute(context)

      This is the main method to derive when creating an operator.
      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



.. py:class:: EmrModifyClusterOperator(*, cluster_id, step_concurrency_level, aws_conn_id = 'aws_default', **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   An operator that modifies an existing EMR cluster.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:EmrModifyClusterOperator`

   :param cluster_id: cluster identifier
   :param step_concurrency_level: Concurrency of the cluster
   :param aws_conn_id: aws connection to uses
   :param do_xcom_push: if True, cluster_id is pushed to XCom with key cluster_id.

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['cluster_id', 'step_concurrency_level']

      

   .. py:attribute:: template_ext
      :annotation: :Sequence[str] = []

      

   .. py:attribute:: ui_color
      :annotation: = #f9c915

      

   .. py:attribute:: operator_extra_links
      

      

   .. py:method:: execute(context)

      This is the main method to derive when creating an operator.
      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



.. py:class:: EmrTerminateJobFlowOperator(*, job_flow_id, aws_conn_id = 'aws_default', **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   Operator to terminate EMR JobFlows.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:EmrTerminateJobFlowOperator`

   :param job_flow_id: id of the JobFlow to terminate. (templated)
   :param aws_conn_id: aws connection to uses

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['job_flow_id']

      

   .. py:attribute:: template_ext
      :annotation: :Sequence[str] = []

      

   .. py:attribute:: ui_color
      :annotation: = #f9c915

      

   .. py:attribute:: operator_extra_links
      

      

   .. py:method:: execute(context)

      This is the main method to derive when creating an operator.
      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



.. py:class:: EmrServerlessCreateApplicationOperator(release_label, job_type, client_request_token = '', config = None, wait_for_completion = True, aws_conn_id = 'aws_default', waiter_countdown = 25 * 60, waiter_check_interval_seconds = 60, **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   Operator to create Serverless EMR Application

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:EmrServerlessCreateApplicationOperator`

   :param release_label: The EMR release version associated with the application.
   :param job_type: The type of application you want to start, such as Spark or Hive.
   :param wait_for_completion: If true, wait for the Application to start before returning. Default to True.
       If set to False, ``waiter_countdown`` and ``waiter_check_interval_seconds`` will only be applied when
       waiting for the application to be in the ``CREATED`` state.
   :param client_request_token: The client idempotency token of the application to create.
     Its value must be unique for each request.
   :param config: Optional dictionary for arbitrary parameters to the boto API create_application call.
   :param aws_conn_id: AWS connection to use
   :param waiter_countdown: Total amount of time, in seconds, the operator will wait for
       the application to start. Defaults to 25 minutes.
   :param waiter_check_interval_seconds: Number of seconds between polling the state of the application.
       Defaults to 60 seconds.

   .. py:method:: hook()

      Create and return an EmrServerlessHook.


   .. py:method:: execute(context)

      This is the main method to derive when creating an operator.
      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



.. py:class:: EmrServerlessStartJobOperator(application_id, execution_role_arn, job_driver, configuration_overrides, client_request_token = '', config = None, wait_for_completion = True, aws_conn_id = 'aws_default', name = None, waiter_countdown = 25 * 60, waiter_check_interval_seconds = 60, **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   Operator to start EMR Serverless job.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:EmrServerlessStartJobOperator`

   :param application_id: ID of the EMR Serverless application to start.
   :param execution_role_arn: ARN of role to perform action.
   :param job_driver: Driver that the job runs on.
   :param configuration_overrides: Configuration specifications to override existing configurations.
   :param client_request_token: The client idempotency token of the application to create.
     Its value must be unique for each request.
   :param config: Optional dictionary for arbitrary parameters to the boto API start_job_run call.
   :param wait_for_completion: If true, waits for the job to start before returning. Defaults to True.
       If set to False, ``waiter_countdown`` and ``waiter_check_interval_seconds`` will only be applied
       when waiting for the application be to in the ``STARTED`` state.
   :param aws_conn_id: AWS connection to use.
   :param name: Name for the EMR Serverless job. If not provided, a default name will be assigned.
   :param waiter_countdown: Total amount of time, in seconds, the operator will wait for
       the job finish. Defaults to 25 minutes.
   :param waiter_check_interval_seconds: Number of seconds between polling the state of the job.
       Defaults to 60 seconds.

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['application_id', 'execution_role_arn', 'job_driver', 'configuration_overrides']

      

   .. py:method:: hook()

      Create and return an EmrServerlessHook.


   .. py:method:: execute(context)

      This is the main method to derive when creating an operator.
      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



.. py:class:: EmrServerlessDeleteApplicationOperator(application_id, wait_for_completion = True, aws_conn_id = 'aws_default', waiter_countdown = 25 * 60, waiter_check_interval_seconds = 60, **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   Operator to delete EMR Serverless application

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:EmrServerlessDeleteApplicationOperator`

   :param application_id: ID of the EMR Serverless application to delete.
   :param wait_for_completion: If true, wait for the Application to start before returning. Default to True
   :param aws_conn_id: AWS connection to use
   :param waiter_countdown: Total amount of time, in seconds, the operator will wait for
       the application be deleted. Defaults to 25 minutes.
   :param waiter_check_interval_seconds: Number of seconds between polling the state of the application.
       Defaults to 60 seconds.

   .. py:attribute:: template_fields
      :annotation: :Sequence[str] = ['application_id']

      

   .. py:method:: hook()

      Create and return an EmrServerlessHook.


   .. py:method:: execute(context)

      This is the main method to derive when creating an operator.
      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



