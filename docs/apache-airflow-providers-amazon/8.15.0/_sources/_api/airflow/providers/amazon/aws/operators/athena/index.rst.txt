:py:mod:`airflow.providers.amazon.aws.operators.athena`
=======================================================

.. py:module:: airflow.providers.amazon.aws.operators.athena


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.amazon.aws.operators.athena.AthenaOperator




.. py:class:: AthenaOperator(*, query, database, output_location = None, client_request_token = None, workgroup = 'primary', query_execution_context = None, result_configuration = None, sleep_time = 30, max_polling_attempts = None, log_query = True, deferrable = conf.getboolean('operators', 'default_deferrable', fallback=False), catalog = 'AwsDataCatalog', **kwargs)


   Bases: :py:obj:`airflow.providers.amazon.aws.operators.base_aws.AwsBaseOperator`\ [\ :py:obj:`airflow.providers.amazon.aws.hooks.athena.AthenaHook`\ ]

   An operator that submits a Trino/Presto query to Amazon Athena.

   .. note:: if the task is killed while it runs, it'll cancel the athena query that was launched,
       EXCEPT if running in deferrable mode.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:AthenaOperator`

   :param query: Trino/Presto query to be run on Amazon Athena. (templated)
   :param database: Database to select. (templated)
   :param catalog: Catalog to select. (templated)
   :param output_location: s3 path to write the query results into. (templated)
       To run the query, you must specify the query results location using one of the ways:
       either for individual queries using either this setting (client-side),
       or in the workgroup, using WorkGroupConfiguration.
       If none of them is set, Athena issues an error that no output location is provided
   :param client_request_token: Unique token created by user to avoid multiple executions of same query
   :param workgroup: Athena workgroup in which query will be run. (templated)
   :param query_execution_context: Context in which query need to be run
   :param result_configuration: Dict with path to store results in and config related to encryption
   :param sleep_time: Time (in seconds) to wait between two consecutive calls to check query status on Athena
   :param max_polling_attempts: Number of times to poll for query state before function exits
       To limit task execution time, use execution_timeout.
   :param log_query: Whether to log athena query and other execution params when it's executed.
       Defaults to *True*.
   :param aws_conn_id: The Airflow connection used for AWS credentials.
       If this is ``None`` or empty then the default boto3 behaviour is used. If
       running Airflow in a distributed manner and aws_conn_id is None or
       empty, then default boto3 configuration would be used (and must be
       maintained on each worker node).
   :param region_name: AWS region_name. If not specified then the default boto3 behaviour is used.
   :param verify: Whether or not to verify SSL certificates. See:
       https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html
   :param botocore_config: Configuration dictionary (key-values) for botocore client. See:
       https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html

   .. py:attribute:: aws_hook_class

      

   .. py:attribute:: ui_color
      :value: '#44b5e2'

      

   .. py:attribute:: template_fields
      :type: Sequence[str]

      

   .. py:attribute:: template_ext
      :type: Sequence[str]
      :value: ('.sql',)

      

   .. py:attribute:: template_fields_renderers

      

   .. py:attribute:: operator_extra_links
      :value: ()

      

   .. py:method:: execute(context)

      Run Trino/Presto Query on Amazon Athena.


   .. py:method:: execute_complete(context, event=None)


   .. py:method:: on_kill()

      Cancel the submitted Amazon Athena query.


   .. py:method:: get_openlineage_facets_on_start()

      Retrieve OpenLineage data by parsing SQL queries and enriching them with Athena API.

      In addition to CTAS query, query and calculation results are stored in S3 location.
      For that reason additional output is attached with this location.


   .. py:method:: get_openlineage_dataset(database, table)



