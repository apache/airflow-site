:py:mod:`airflow.providers.amazon.aws.operators.bedrock`
========================================================

.. py:module:: airflow.providers.amazon.aws.operators.bedrock


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.amazon.aws.operators.bedrock.BedrockInvokeModelOperator
   airflow.providers.amazon.aws.operators.bedrock.BedrockCustomizeModelOperator
   airflow.providers.amazon.aws.operators.bedrock.BedrockCreateProvisionedModelThroughputOperator




.. py:class:: BedrockInvokeModelOperator(model_id, input_data, content_type = None, accept_type = None, **kwargs)


   Bases: :py:obj:`airflow.providers.amazon.aws.operators.base_aws.AwsBaseOperator`\ [\ :py:obj:`airflow.providers.amazon.aws.hooks.bedrock.BedrockRuntimeHook`\ ]

   Invoke the specified Bedrock model to run inference using the input provided.

   Use InvokeModel to run inference for text models, image models, and embedding models.
   To see the format and content of the input_data field for different models, refer to
   `Inference parameters docs <https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html>`_.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:BedrockInvokeModelOperator`

   :param model_id: The ID of the Bedrock model. (templated)
   :param input_data: Input data in the format specified in the content-type request header. (templated)
   :param content_type: The MIME type of the input data in the request. (templated) Default: application/json
   :param accept: The desired MIME type of the inference body in the response.
       (templated) Default: application/json

   :param aws_conn_id: The Airflow connection used for AWS credentials.
       If this is ``None`` or empty then the default boto3 behaviour is used. If
       running Airflow in a distributed manner and aws_conn_id is None or
       empty, then default boto3 configuration would be used (and must be
       maintained on each worker node).
   :param region_name: AWS region_name. If not specified then the default boto3 behaviour is used.
   :param verify: Whether or not to verify SSL certificates. See:
       https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html
   :param botocore_config: Configuration dictionary (key-values) for botocore client. See:
       https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html

   .. py:attribute:: aws_hook_class

      

   .. py:attribute:: template_fields
      :type: Sequence[str]

      

   .. py:method:: execute(context)

      Derive when creating an operator.

      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



.. py:class:: BedrockCustomizeModelOperator(job_name, custom_model_name, role_arn, base_model_id, training_data_uri, output_data_uri, hyperparameters, ensure_unique_job_name = True, customization_job_kwargs = None, wait_for_completion = True, waiter_delay = 120, waiter_max_attempts = 75, deferrable = conf.getboolean('operators', 'default_deferrable', fallback=False), **kwargs)


   Bases: :py:obj:`airflow.providers.amazon.aws.operators.base_aws.AwsBaseOperator`\ [\ :py:obj:`airflow.providers.amazon.aws.hooks.bedrock.BedrockHook`\ ]

   Create a fine-tuning job to customize a base model.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:BedrockCustomizeModelOperator`

   :param job_name: A unique name for the fine-tuning job.
   :param custom_model_name: A name for the custom model being created.
   :param role_arn: The Amazon Resource Name (ARN) of an IAM role that Amazon Bedrock can assume
       to perform tasks on your behalf.
   :param base_model_id: Name of the base model.
   :param training_data_uri: The S3 URI where the training data is stored.
   :param output_data_uri: The S3 URI where the output data is stored.
   :param hyperparameters: Parameters related to tuning the model.
   :param ensure_unique_job_name: If set to true, operator will check whether a model customization
       job already exists for the name in the config and append the current timestamp if there is a
       name conflict. (Default: True)
   :param customization_job_kwargs: Any optional parameters to pass to the API.

   :param wait_for_completion: Whether to wait for cluster to stop. (default: True)
   :param waiter_delay: Time in seconds to wait between status checks. (default: 120)
   :param waiter_max_attempts: Maximum number of attempts to check for job completion. (default: 75)
   :param deferrable: If True, the operator will wait asynchronously for the cluster to stop.
       This implies waiting for completion. This mode requires aiobotocore module to be installed.
       (default: False)
   :param aws_conn_id: The Airflow connection used for AWS credentials.
       If this is ``None`` or empty then the default boto3 behaviour is used. If
       running Airflow in a distributed manner and aws_conn_id is None or
       empty, then default boto3 configuration would be used (and must be
       maintained on each worker node).
   :param region_name: AWS region_name. If not specified then the default boto3 behaviour is used.
   :param verify: Whether or not to verify SSL certificates. See:
       https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html
   :param botocore_config: Configuration dictionary (key-values) for botocore client. See:
       https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html

   .. py:attribute:: aws_hook_class

      

   .. py:attribute:: template_fields
      :type: Sequence[str]

      

   .. py:method:: execute_complete(context, event = None)


   .. py:method:: execute(context)

      Derive when creating an operator.

      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



.. py:class:: BedrockCreateProvisionedModelThroughputOperator(model_units, provisioned_model_name, model_id, create_throughput_kwargs = None, wait_for_completion = True, waiter_delay = 60, waiter_max_attempts = 20, deferrable = conf.getboolean('operators', 'default_deferrable', fallback=False), **kwargs)


   Bases: :py:obj:`airflow.providers.amazon.aws.operators.base_aws.AwsBaseOperator`\ [\ :py:obj:`airflow.providers.amazon.aws.hooks.bedrock.BedrockHook`\ ]

   Create a fine-tuning job to customize a base model.

   .. seealso::
       For more information on how to use this operator, take a look at the guide:
       :ref:`howto/operator:BedrockCreateProvisionedModelThroughputOperator`

   :param model_units: Number of model units to allocate. (templated)
   :param provisioned_model_name: Unique name for this provisioned throughput. (templated)
   :param model_id: Name or ARN of the model to associate with this provisioned throughput. (templated)
   :param create_throughput_kwargs: Any optional parameters to pass to the API.

   :param wait_for_completion: Whether to wait for cluster to stop. (default: True)
   :param waiter_delay: Time in seconds to wait between status checks. (default: 60)
   :param waiter_max_attempts: Maximum number of attempts to check for job completion. (default: 20)
   :param deferrable: If True, the operator will wait asynchronously for the cluster to stop.
       This implies waiting for completion. This mode requires aiobotocore module to be installed.
       (default: False)
   :param aws_conn_id: The Airflow connection used for AWS credentials.
       If this is ``None`` or empty then the default boto3 behaviour is used. If
       running Airflow in a distributed manner and aws_conn_id is None or
       empty, then default boto3 configuration would be used (and must be
       maintained on each worker node).
   :param region_name: AWS region_name. If not specified then the default boto3 behaviour is used.
   :param verify: Whether or not to verify SSL certificates. See:
       https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html
   :param botocore_config: Configuration dictionary (key-values) for botocore client. See:
       https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html

   .. py:attribute:: aws_hook_class

      

   .. py:attribute:: template_fields
      :type: Sequence[str]

      

   .. py:method:: execute(context)

      Derive when creating an operator.

      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.


   .. py:method:: execute_complete(context, event = None)



