:py:mod:`airflow.providers.amazon.aws.triggers.batch`
=====================================================

.. py:module:: airflow.providers.amazon.aws.triggers.batch


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.amazon.aws.triggers.batch.BatchJobTrigger
   airflow.providers.amazon.aws.triggers.batch.BatchCreateComputeEnvironmentTrigger




.. py:class:: BatchJobTrigger(job_id, region_name = None, aws_conn_id = 'aws_default', waiter_delay = 5, waiter_max_attempts = 720)


   Bases: :py:obj:`airflow.providers.amazon.aws.triggers.base.AwsBaseWaiterTrigger`

   Checks for the status of a submitted job_id to AWS Batch until it reaches a failure or a success state.

   :param job_id: the job ID, to poll for job completion or not
   :param region_name: AWS region name to use
       Override the region_name in connection (if provided)
   :param aws_conn_id: connection id of AWS credentials / region name. If None,
       credential boto3 strategy will be used
   :param waiter_delay: polling period in seconds to check for the status of the job
   :param waiter_max_attempts: The maximum number of attempts to be made.

   .. py:method:: hook()

      Override in subclasses to return the right hook.



.. py:class:: BatchCreateComputeEnvironmentTrigger(compute_env_arn, waiter_delay = 30, waiter_max_attempts = 10, aws_conn_id = 'aws_default', region_name = None)


   Bases: :py:obj:`airflow.providers.amazon.aws.triggers.base.AwsBaseWaiterTrigger`

   Asynchronously poll the boto3 API and wait for the compute environment to be ready.

   :param compute_env_arn: The ARN of the compute env.
   :param waiter_max_attempts: The maximum number of attempts to be made.
   :param aws_conn_id: The Airflow connection used for AWS credentials.
   :param region_name: region name to use in AWS Hook
   :param waiter_delay: The amount of time in seconds to wait between attempts.

   .. py:method:: hook()

      Override in subclasses to return the right hook.



