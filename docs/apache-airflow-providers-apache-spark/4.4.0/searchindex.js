Search.setIndex({"docnames": ["_api/airflow/providers/apache/spark/decorators/index", "_api/airflow/providers/apache/spark/decorators/pyspark/index", "_api/airflow/providers/apache/spark/hooks/index", "_api/airflow/providers/apache/spark/hooks/spark_connect/index", "_api/airflow/providers/apache/spark/hooks/spark_jdbc/index", "_api/airflow/providers/apache/spark/hooks/spark_jdbc_script/index", "_api/airflow/providers/apache/spark/hooks/spark_sql/index", "_api/airflow/providers/apache/spark/hooks/spark_submit/index", "_api/airflow/providers/apache/spark/index", "_api/airflow/providers/apache/spark/operators/index", "_api/airflow/providers/apache/spark/operators/spark_jdbc/index", "_api/airflow/providers/apache/spark/operators/spark_sql/index", "_api/airflow/providers/apache/spark/operators/spark_submit/index", "_api/tests/system/providers/apache/spark/example_pyspark/index", "_api/tests/system/providers/apache/spark/example_spark_dag/index", "_api/tests/system/providers/apache/spark/index", "changelog", "commits", "connections/spark", "decorators/pyspark", "index", "installing-providers-from-sources", "operators", "security"], "filenames": ["_api/airflow/providers/apache/spark/decorators/index.rst", "_api/airflow/providers/apache/spark/decorators/pyspark/index.rst", "_api/airflow/providers/apache/spark/hooks/index.rst", "_api/airflow/providers/apache/spark/hooks/spark_connect/index.rst", "_api/airflow/providers/apache/spark/hooks/spark_jdbc/index.rst", "_api/airflow/providers/apache/spark/hooks/spark_jdbc_script/index.rst", "_api/airflow/providers/apache/spark/hooks/spark_sql/index.rst", "_api/airflow/providers/apache/spark/hooks/spark_submit/index.rst", "_api/airflow/providers/apache/spark/index.rst", "_api/airflow/providers/apache/spark/operators/index.rst", "_api/airflow/providers/apache/spark/operators/spark_jdbc/index.rst", "_api/airflow/providers/apache/spark/operators/spark_sql/index.rst", "_api/airflow/providers/apache/spark/operators/spark_submit/index.rst", "_api/tests/system/providers/apache/spark/example_pyspark/index.rst", "_api/tests/system/providers/apache/spark/example_spark_dag/index.rst", "_api/tests/system/providers/apache/spark/index.rst", "changelog.rst", "commits.rst", "connections/spark.rst", "decorators/pyspark.rst", "index.rst", "installing-providers-from-sources.rst", "operators.rst", "security.rst"], "titles": ["<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.apache.spark.decorators</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.apache.spark.decorators.pyspark</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.apache.spark.hooks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.apache.spark.hooks.spark_connect</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.apache.spark.hooks.spark_jdbc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.apache.spark.hooks.spark_jdbc_script</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.apache.spark.hooks.spark_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.apache.spark.hooks.spark_submit</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.apache.spark</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.apache.spark.operators</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.apache.spark.operators.spark_jdbc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.apache.spark.operators.spark_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.apache.spark.operators.spark_submit</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.apache.spark.example_pyspark</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.apache.spark.example_spark_dag</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.apache.spark</span></code>", "Changelog", "Package apache-airflow-providers-apache-spark", "Apache Spark Connection", "PySpark Decorator", "<code class=\"docutils literal notranslate\"><span class=\"pre\">apache-airflow-providers-apache-spark</span></code>", "Installing from sources", "Apache Spark Operators", "Releasing security patches"], "terms": {"pyspark": [0, 8, 13, 16, 17, 20], "4": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23], "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23], "2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23], "8": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "dev0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "i": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "an": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "experiment": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "featur": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23], "spark_context_kei": 1, "sc": [1, 19], "sourc": [1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 19, 22], "pyspark_task": 1, "python_cal": 1, "none": [1, 4, 6, 7, 10, 11, 12, 17, 21], "multiple_output": 1, "kwarg": [1, 4, 6, 7, 10, 11, 12, 19], "spark_connect": [2, 8], "spark_jdbc": [2, 8, 9], "spark_jdbc_script": [2, 8, 17], "spark_sql": [2, 8, 9], "spark_submit": [2, 4, 8, 9, 10], "sparkconnecthook": 3, "conn_id": [3, 6, 7, 11, 12, 16, 17, 19], "default_conn_nam": [3, 4, 6, 7], "base": [3, 4, 6, 7, 10, 11, 12, 22], "basehook": [3, 6, 7], "util": [3, 7], "log": [3, 7, 16, 17], "logging_mixin": [3, 7], "loggingmixin": [3, 7], "connect": [3, 4, 5, 6, 7, 10, 11, 12, 16, 17, 22], "param_use_ssl": 3, "use_ssl": 3, "param_token": 3, "token": [3, 17, 18], "param_user_id": 3, "user_id": 3, "conn_name_attr": [3, 4, 6, 7], "spark_connect_default": [3, 18], "conn_typ": [3, 4, 6, 7], "hook_nam": [3, 4, 6, 7], "static": [3, 7], "get_ui_field_behaviour": [3, 7], "return": [3, 4, 6, 7, 19], "custom": [3, 7, 16, 17], "field": [3, 7, 16, 17], "behaviour": [3, 7], "get_connection_form_widget": 3, "widget": 3, "add": [3, 4, 10, 16, 17], "form": [3, 17], "get_connection_url": 3, "sparkjdbchook": 4, "spark_app_nam": [4, 10], "jdbc": [4, 5, 10, 16, 17, 18, 22], "spark_conn_id": [4, 7, 10, 16, 17], "spark_conf": [4, 10], "spark_py_fil": [4, 10], "spark_fil": [4, 10], "spark_jar": [4, 10, 22], "num_executor": [4, 6, 7, 10, 11, 12], "executor_cor": [4, 6, 7, 10, 11, 12], "executor_memori": [4, 6, 7, 10, 11, 12], "driver_memori": [4, 7, 10, 12], "verbos": [4, 6, 7, 10, 11, 12, 17], "fals": [4, 7, 10, 12], "princip": [4, 6, 7, 10, 11, 12], "keytab": [4, 6, 7, 10, 11, 12], "cmd_type": [4, 10, 22], "spark_to_jdbc": [4, 5, 10, 22], "jdbc_tabl": [4, 5, 10, 22], "jdbc_conn_id": [4, 10], "default": [4, 5, 6, 7, 10, 11, 12, 17, 23], "jdbc_driver": [4, 10, 22], "metastore_t": [4, 5, 10, 22], "jdbc_truncat": [4, 10], "save_mod": [4, 5, 10, 22], "save_format": [4, 5, 10, 22], "batch_siz": [4, 5, 10], "fetch_siz": [4, 5, 10], "num_partit": [4, 5, 10], "partition_column": [4, 5, 10], "lower_bound": [4, 5, 10], "upper_bound": [4, 5, 10], "create_table_column_typ": [4, 5, 10], "arg": [4, 17], "use_krb5ccach": [4, 7, 10, 12, 16, 17], "sparksubmithook": [4, 7, 10, 12, 16, 17], "extend": [4, 10], "perform": [4, 10, 22], "data": [4, 5, 10, 17, 22], "transfer": [4, 5, 10, 17, 22], "from": [4, 5, 10, 17, 20, 22, 23], "databas": [4, 10, 22], "paramet": [4, 5, 6, 7, 10, 11, 12, 17, 18, 22], "str": [4, 5, 6, 7, 10, 11, 12, 17, 19], "name": [4, 5, 6, 7, 10, 11, 12, 17, 18, 19], "job": [4, 6, 7, 10, 11, 12, 16], "The": [4, 6, 7, 10, 11, 12, 16, 18, 19, 20, 21, 22, 23], "id": [4, 7, 10, 12, 19, 21], "configur": [4, 6, 7, 10, 11, 12, 16, 17, 19, 22], "administr": [4, 7, 10, 12], "dict": [4, 7, 10, 12, 17, 19], "ani": [4, 5, 6, 7, 10, 11, 12, 16, 21], "addit": [4, 7, 10, 12], "properti": [4, 6, 7, 10, 11, 12], "python": [4, 7, 10, 12, 16, 17, 18, 19, 20, 21, 22], "file": [4, 6, 7, 10, 11, 12, 16, 17, 21, 22], "us": [4, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23], "zip": [4, 7, 10, 12], "egg": [4, 7, 10, 12], "py": [4, 7, 10, 12, 16, 17, 19, 22], "upload": [4, 7, 10, 12], "contain": [4, 6, 7, 10, 11, 12, 21], "run": [4, 7, 10, 11, 12, 16, 17, 19, 21, 22], "jar": [4, 7, 10, 12, 22], "driver": [4, 5, 7, 10, 12, 16, 17, 18, 19, 22], "executor": [4, 6, 7, 10, 11, 12], "classpath": [4, 7, 10, 12, 22], "int": [4, 6, 7, 10, 11, 12], "number": [4, 6, 7, 10, 11, 12, 17], "should": [4, 7, 10, 16, 18, 21, 23], "set": [4, 6, 7, 10, 11, 12, 16, 17, 18, 19, 22], "so": [4, 10, 23], "manag": [4, 10, 17, 21, 22], "made": [4, 10, 21], "core": [4, 6, 7, 10, 11, 12, 17], "per": [4, 6, 7, 10, 11, 12, 17], "memori": [4, 6, 7, 10, 11, 12], "e": [4, 6, 7, 10, 11, 12], "g": [4, 6, 7, 10, 11, 12], "1000m": [4, 6, 7, 10, 11, 12], "2g": [4, 6, 7, 10, 11, 12], "alloc": [4, 7, 10, 12], "bool": [4, 6, 7, 10, 11, 12], "whether": [4, 6, 7, 10, 11, 12, 18], "pass": [4, 6, 7, 10, 11, 12, 16, 17, 19], "flag": [4, 6, 7, 10, 11, 12], "submit": [4, 6, 7, 10, 11, 12, 14, 16, 17, 18, 22], "debug": [4, 7, 10, 12], "full": [4, 6, 7, 10, 11, 12, 17], "path": [4, 6, 7, 10, 11, 12, 16, 22], "kerbero": [4, 7, 10, 12, 17], "which": [4, 10, 13, 18, 22, 23], "wai": [4, 10, 19], "flow": [4, 10], "possibl": [4, 10, 17, 22], "valu": [4, 6, 10, 11, 16, 17, 18], "written": [4, 10], "metastor": [4, 10, 22], "jdbc_to_spark": [4, 5, 10, 22], "tabl": [4, 5, 10, 22], "usual": [4, 10], "onli": [4, 6, 7, 10, 11, 12, 16, 17, 18, 23], "truncat": [4, 5, 10], "drop": [4, 10, 16, 17, 21], "recreat": [4, 10], "take": [4, 10, 11, 12, 22], "effect": [4, 10], "overwrit": [4, 10, 22], "also": [4, 10, 21], "schema": [4, 10, 16, 17], "differ": [4, 10, 21, 22], "cannot": [4, 10], "save": [4, 10], "mode": [4, 7, 10, 12, 18, 22], "append": [4, 6, 10, 22], "etc": [4, 10], "format": [4, 10, 17], "parquet": [4, 10], "size": [4, 10], "batch": [4, 10, 17], "insert": [4, 10], "round": [4, 10], "trip": [4, 10], "1000": [4, 10], "fetch": [4, 10], "depend": [4, 7, 10, 12, 17, 22, 23], "maximum": [4, 10], "partit": [4, 10], "can": [4, 7, 10, 12, 16, 18, 19, 20, 21, 22, 23], "simultan": [4, 10], "both": [4, 10, 22], "oper": [4, 8, 16, 17, 18], "cap": [4, 10], "open": [4, 10], "A": [4, 10], "numer": [4, 10], "column": [4, 10], "If": [4, 10, 16, 19, 21], "specifi": [4, 10, 18, 19, 20], "you": [4, 10, 16, 18, 19, 20, 21, 22, 23], "must": [4, 10, 22], "lower": [4, 10], "bound": [4, 10], "rang": [4, 10], "upper": [4, 10], "type": [4, 10, 16, 17, 18], "instead": [4, 7, 10, 12], "when": [4, 7, 10, 11, 12, 18, 20, 23], "creat": [4, 10, 19, 21], "inform": [4, 10, 11, 12, 17, 22, 23], "same": [4, 10, 18, 19], "syntax": [4, 10, 18], "char": [4, 10], "64": [4, 10], "comment": [4, 10, 17], "varchar": [4, 10], "1024": [4, 10], "valid": [4, 10, 16, 17, 21], "sql": [4, 6, 10, 11, 16, 17, 18, 22], "true": [4, 6, 7, 10, 11, 12], "ticket": [4, 7, 10, 12], "cach": [4, 7, 10, 12], "reli": [4, 7, 10, 12], "login": [4, 7, 10, 12], "spark_default": [4, 7, 12, 18], "submit_jdbc_job": 4, "get_conn": [4, 6, 7], "spark_write_to_jdbc": 5, "spark_read_from_jdbc": 5, "set_common_opt": 5, "spark_sourc": 5, "url": [5, 18, 19], "localhost": 5, "5432": 5, "user": [5, 7, 12, 18, 21], "root": 5, "password": [5, 17], "get": [5, 10, 11, 12, 16, 17, 21, 22, 23], "here": 5, "reader": 5, "writer": 5, "resourc": [5, 18], "spark_sess": 5, "sparksqlhook": [6, 11, 16, 17], "conf": [6, 7, 11, 12, 17], "total_executor_cor": [6, 7, 11, 12], "master": [6, 11, 19, 22], "yarn_queu": [6, 11], "wrapper": 6, "around": 6, "binari": [6, 7, 10, 12, 16, 17, 18, 21], "requir": [6, 7, 12, 16, 18, 19, 22, 23], "queri": [6, 11, 22], "execut": [6, 7, 10, 11, 12, 18], "arbitrari": [6, 7, 11, 12], "connection_id": [6, 7, 11, 12], "string": [6, 11, 17, 18], "standalon": [6, 7, 11, 12], "meso": [6, 7, 11, 12], "total": [6, 7, 11, 12], "all": [6, 7, 11, 12, 16, 17, 18, 20, 22, 23], "avail": [6, 7, 10, 11, 12, 16, 19, 21], "worker": [6, 7, 11, 12, 18], "yarn": [6, 7, 11, 12, 17, 18], "1g": [6, 7, 11, 12], "host": [6, 11, 16, 17, 18, 19], "port": [6, 11, 18], "local": [6, 11, 18, 19, 21, 22], "launch": [6, 7, 11, 12, 22], "queue": [6, 11, 18], "spark_sql_default": [6, 11, 18], "run_queri": [6, 17], "cmd": 6, "remot": [6, 7, 12, 18, 19], "popen": [6, 7], "actual": 6, "command": [6, 7, 12, 17, 18, 22], "extra": [6, 7, 16, 17, 18, 20], "argument": [6, 7, 12, 17], "see": [6, 7, 17, 20], "subprocess": [6, 7, 10, 11, 12], "kill": [6, 7, 10, 11, 12, 17], "allowed_spark_binari": 7, "spark2": [7, 12, 16, 18], "spark3": [7, 12, 16, 17, 18], "py_fil": [7, 12], "archiv": [7, 12], "driver_class_path": [7, 12], "java_class": [7, 12], "packag": [7, 12, 16], "exclude_packag": [7, 12], "repositori": [7, 12], "proxy_us": [7, 12], "status_poll_interv": [7, 12], "1": [7, 12, 19, 22], "application_arg": [7, 12], "env_var": [7, 12], "spark_binari": [7, 12, 18], "wrap": [7, 12, 19], "kick": [7, 12], "off": [7, 12], "invalid": [7, 12], "suppli": [7, 12], "separ": [7, 12, 17, 23], "comma": [7, 12], "place": [7, 12], "work": [7, 12], "directori": [7, 12, 21], "each": [7, 12], "For": [7, 10, 11, 12, 17, 18, 19, 20, 21, 22], "exampl": [7, 12, 13, 14, 17, 18, 20, 21, 22], "serial": [7, 12], "object": [7, 12, 19], "unzip": 7, "possibli": 7, "tag": 7, "alia": 7, "applic": [7, 12, 14, 18, 22], "specif": [7, 12, 17], "them": [7, 12, 20], "main": [7, 12, 21, 22, 23], "java": [7, 12], "list": [7, 12, 16, 17], "maven": [7, 12], "coordin": [7, 12], "includ": [7, 12, 17, 18, 23], "exclud": [7, 12], "while": [7, 12], "resolv": [7, 12], "search": [7, 12], "given": [7, 12], "kubernet": [7, 16, 17, 18, 20], "imperson": [7, 12], "second": [7, 12], "wait": [7, 12], "between": [7, 12, 18], "poll": [7, 12], "statu": [7, 12, 16, 17, 20], "cluster": [7, 12, 18, 19, 22], "being": [7, 12], "environ": [7, 12, 17, 18], "variabl": [7, 12, 17, 18], "It": [7, 12, 18, 21], "support": [7, 12, 16, 17, 18, 20, 22], "k8": [7, 12, 16, 17], "too": [7, 12], "process": [7, 10, 11, 12, 17], "some": [7, 12, 18], "distro": [7, 12, 18], "mai": [7, 12, 17, 18], "on_kil": [7, 10, 11, 12], "decor": [8, 16, 17], "hook": [8, 16, 17, 18], "__version__": [8, 17], "sparkjdbcoper": [10, 14], "sparksubmitoper": [10, 12, 14, 16, 17], "As": 10, "assum": 10, "more": [10, 11, 12, 16, 17], "how": [10, 11, 12, 19, 21], "look": [10, 11, 12, 22], "guid": [10, 11, 12, 17, 21], "context": [10, 11, 12], "call": [10, 11, 12, 17], "overrid": [10, 11, 12, 19], "method": [10, 11, 12], "clean": [10, 11, 12, 16, 17], "up": [10, 11, 12, 17, 22], "task": [10, 11, 12, 19], "instanc": [10, 11, 12], "thread": [10, 11, 12], "multiprocess": [10, 11, 12], "within": [10, 11, 12, 19], "need": [10, 11, 12, 20], "leav": [10, 11, 12], "ghost": [10, 11, 12], "behind": [10, 11, 12], "sparksqloper": [11, 14, 17], "model": [11, 12, 23], "baseoper": [11, 12], "templat": [11, 12, 16, 17, 22], "template_field": [11, 12, 17], "sequenc": [11, 12, 17], "_sql": 11, "template_ext": 11, "hql": [11, 22], "template_fields_render": 11, "arrow": 12, "either": 12, "_applic": 12, "_conf": 12, "_file": 12, "_py_fil": 12, "_jar": 12, "_driver_class_path": 12, "_packag": 12, "ui_color": 12, "dag": [13, 14, 16, 17], "test_run": [13, 14], "airflow": [14, 16, 19, 21, 23], "env_id": 14, "dag_id": 14, "example_spark_oper": 14, "submit_job": [14, 22], "example_pyspark": [15, 19], "example_spark_dag": [15, 22], "apach": [16, 19, 21], "provid": [16, 19, 21, 22, 23], "spark": [16, 21], "35247": [16, 17], "option": [16, 17, 18, 19], "35331": [16, 17], "34386": [16, 17], "releas": [16, 17, 20], "explain": 16, "polici": [16, 23], "bump": [16, 17], "min": [16, 17], "version": [16, 17, 20, 21, 23], "34728": [16, 17], "refactor": [16, 17], "regex": [16, 17], "33898": [16, 17], "simplifi": [16, 17], "code": [16, 17, 18, 21], "alibaba": [16, 17], "33227": [16, 17], "conn_prefix": [16, 17], "32946": [16, 17], "now": [16, 17], "expect": 16, "cncf": [16, 17, 20], "7": [16, 17], "instal": [16, 17, 23], "order": [16, 20], "pip": [16, 17, 20, 21], "right": [16, 19], "move": [16, 17], "class": [16, 17, 20], "32767": [16, 17], "renam": [16, 17], "31952": [16, 17], "minimum": [16, 17, 20], "30917": [16, 17], "restrict": [16, 17], "via": [16, 17, 18, 20, 21], "30213": [16, 17], "30223": [16, 17], "allow": [16, 17, 18, 19], "30068": [16, 17], "could": 16, "two": 16, "ar": [16, 18, 19, 20, 21, 23], "home": [16, 17], "anymor": 16, "remov": [16, 17, 21], "27646": [16, 17], "27196": [16, 17], "23716": [16, 17], "backward": [16, 17], "compat": [16, 17], "introduc": [16, 17, 19], "mypi": [16, 17], "problem": [16, 17], "24230": [16, 17], "aip": [16, 17], "47": [16, 17], "migrat": [16, 17], "new": [16, 17, 23], "design": [16, 17], "22439": [16, 17], "24210": [16, 17], "chore": [16, 17], "24219": [16, 17], "mistakenli": 16, "ad": [16, 17], "install_requir": 16, "22382": 16, "trove": 16, "classifi": [16, 17], "pypi": [16, 17, 20, 23], "framework": 16, "param": [16, 17], "render": [16, 17], "doc": [16, 17], "21788": [16, 17], "10": [16, 17], "21237": [16, 17], "21074": [16, 17], "ensur": [16, 17], "respons": [16, 17], "befor": [16, 17], "unknown": [16, 17, 21], "19978": [16, 17], "sparksql": [16, 17], "go": [16, 17], "infinit": [16, 17], "loop": [16, 17], "19449": [16, 17], "optimis": 16, "import": [16, 17, 21], "auto": [16, 17], "appli": [16, 17, 18], "apply_default": [16, 17], "15667": [16, 17], "due": 16, "your": [16, 18, 19], "want": [16, 21, 23], "first": [16, 17], "upgrad": [16, 17, 23], "least": 16, "otherwis": 16, "automat": [16, 17], "have": [16, 17, 19, 23], "manual": 16, "db": 16, "complet": 16, "make": [16, 17, 18, 19], "15794": [16, 17], "except": [16, 17, 23], "redund": [16, 17], "14823": [16, 17], "without": [16, 17], "14187": [16, 17], "updat": [16, 17], "document": [16, 17, 22], "readm": [16, 17], "initi": [16, 19], "detail": [17, 21], "commit": 17, "chang": [17, 23], "high": 17, "level": 17, "changelog": 17, "latest": [17, 23], "2023": 17, "11": [17, 21], "07": 17, "subject": 17, "3b8db612ff": 17, "about": [17, 21, 23], "qubol": 17, "35492": 17, "0a4ed7d557": 17, "01": 17, "880a85bbb7": 17, "28": 17, "d1c58d86de": 17, "prepar": [17, 23], "3rd": 17, "wave": 17, "octob": 17, "fix": [17, 23], "35233": 17, "3592ff4046": 17, "35187": 17, "645d52f129": 17, "21": [17, 19], "dd7ba3cae1": 17, "19": 17, "pre": 17, "ruff": 17, "292": 17, "35053": 17, "b75f9e8806": 17, "18": 17, "35033": 17, "13": 17, "e9987d5059": 17, "1st": 17, "34916": 17, "0c8e30e43b": 17, "05": 17, "7ebf4220c9": 17, "09": 17, "usag": 17, "34320": 17, "08": 17, "21990ed894": 17, "34201": 17, "a7310f9c91": 17, "26": 17, "c077d19060": 17, "aug": 17, "33730": 17, "32feab4100": 17, "22": [17, 19], "c645d8e40c": 17, "12": [17, 21, 22], "d401": 17, "airbyt": 17, "atlassian": 17, "inclus": 17, "33354": 17, "60677b0ba3": 17, "33128": 17, "4f83e831d2": 17, "31": 17, "29": 17, "d06b7af69a": 17, "juli": 17, "32875": 17, "e93460383f": 17, "225e3041d2": 17, "06": 17, "rc2": 17, "32381": 17, "3878fe6fab": 17, "spuriou": 17, "header": 17, "32373": 17, "cb4927a018": 17, "32298": 17, "8c37b74a20": 17, "d205": 17, "common": 17, "32226": 17, "09d4718d3a": 17, "27": 17, "improv": 17, "structur": 17, "32125": 17, "20": 17, "79bcc2e668": 17, "rc1": 17, "june": 17, "32001": 17, "8b146152d6": 17, "note": [17, 18, 19], "32015": 17, "6becb70316": 17, "16": 17, "13890788ae": 17, "docstr": 17, "31730": 17, "9276310a43": 17, "31681": 17, "a473facf6c": 17, "d400": 17, "pydocstyl": 17, "check": [17, 21], "31424": 17, "45548b9451": 17, "31416": 17, "abea189022": 17, "31393": 17, "f5aed58d9f": 17, "circular": 17, "error": 17, "caus": 17, "31379": 17, "d9ff55cf6d": 17, "31252": 17, "eef5bc7f16": 17, "03": 17, "autom": 17, "30994": 17, "a7eb32a5b2": 17, "04": 17, "30": 17, "d23a3bbed8": 17, "mechan": 17, "suspend": 17, "30422": 17, "02": 17, "55dbf1ff1f": 17, "april": 17, "30378": 17, "5d1f201bb0": 17, "d9dea5ce17": 17, "b3259877fa": 17, "15": 17, "2022": 17, "12c3c39d1a": 17, "novemb": 17, "27613": 17, "9358928815": 17, "binarir": 17, "78b8ea2f22": 17, "24": 17, "2a34dc9e84": 17, "23": [17, 19], "enabl": [17, 18], "normal": 17, "27205": 17, "f8db64c35c": 17, "septemb": 17, "": [17, 18, 21], "26731": 17, "06acf40a43": 17, "pep": 17, "563": 17, "postpon": 17, "evalu": 17, "annot": 17, "non": 17, "26289": 17, "e5ac6c7cfb": 17, "august": 17, "25618": 17, "d2459a241b": 17, "25030": 17, "0de31bd73a": 17, "insid": 17, "folder": [17, 21], "24672": 17, "510a6bab45": 17, "yaml": 17, "24702": 17, "dcdcf3a2b8": 17, "24307": 17, "717a7588bc": 17, "descript": 17, "doubl": 17, "24292": 17, "aeabe994b3": 17, "24231": 17, "b4a5783a2a": 17, "9dc2851671": 17, "027b707d21": 17, "explanatori": 17, "contributor": 17, "24229": 17, "a2bfc0e62d": 17, "71e4deb1b0": 17, "d7dbfb7e26": 17, "bugfix": [17, 23], "22383": 17, "14": 17, "16adc035b1": 17, "march": 17, "22226": 17, "f5b96315fe": 17, "feb": 17, "22056": 17, "6322dad2ca": 17, "25": 17, "d94fa37830": 17, "januari": 17, "delai": 17, "21439": 17, "6c3a67d4fc": 17, "2021": [17, 21], "21257": 17, "39e395f981": 17, "cb73053211": 17, "602abe8394": 17, "line": 17, "sphinx": 17, "autoapi": 17, "typehint": 17, "20951": 17, "f77417eb0d": 17, "20614": 17, "97496ba2b4": 17, "decemb": 17, "20523": 17, "83f8e178ba": 17, "even": 17, "ext": 17, "20608": 17, "d56e7b56bb": 17, "friendli": 17, "20571": 17, "485ff6cc64": 17, "20422": 17, "dad2f8103b": 17, "20190": 17, "1a2a2498d6": 17, "20290": 17, "a50d2ac872": 17, "853576d901": 17, "19882": 17, "79b30ff59c": 17, "bug": [17, 23], "ae044884d1": 17, "cleanup": 17, "start_dat": 17, "18657": 17, "d9567eb106": 17, "19321": 17, "86a2a19ad2": 17, "17": 17, "f": 17, "18855": 17, "42dc0767b8": 17, "unnecessari": 17, "concaten": 17, "airflowexcept": 17, "messag": 17, "18817": 17, "0a68588479": 17, "17890": 17, "be75dcd39c": 17, "meta": 17, "76ed2a49c6": 17, "lazili": 17, "individu": 17, "17682": 17, "87f408b1e7": 17, "17116": 17, "91f4d80ff0": 17, "xcomarg": 17, "16869": 17, "b916b75079": 17, "17015": 17, "866a601b76": 17, "pylint": 17, "our": 17, "toolchain": 17, "16682": 17, "bbc627a3da": 17, "16501": 17, "cbf8001d76": 17, "synchron": 17, "after": 17, "buggfix": 17, "16464": 17, "1fba5402bb": 17, "16405": 17, "5c86e3d509": 17, "9c94b72d44": 17, "16294": 17, "37681bca00": 17, "807ad32ce5": 17, "15576": 17, "5b2fe0e740": 17, "popular": 17, "15393": 17, "4b031d39e1": 17, "15534": 17, "657384615f": 17, "9015beb316": 17, "15304": 17, "68e4c4dcb0": 17, "backport": 17, "14886": 17, "589d6dec92": 17, "next": [17, 23], "14487": 17, "f9c9e9c38f": 17, "88bdcfa0df": 17, "14013": 17, "ac2f72c98d": 17, "implement": 17, "tool": 17, "13767": 17, "a9ac2b040b": 17, "switch": 17, "flynt": 17, "13732": 17, "295d66f914": 17, "2020": 17, "grammar": 17, "warn": [17, 21], "13380": 17, "6cf76d7ac0": 17, "typo": 17, "13148": 17, "5090fb0c89": 17, "script": [17, 21, 22], "gener": 17, "integr": 17, "json": [17, 18, 22], "13073": 17, "32971a1a2d": 17, "12955": 17, "b40dffa085": 17, "rema": 17, "modul": 17, "match": [17, 21], "12917": 17, "9b39f24780": 17, "dynam": 17, "12558": 17, "bd90136aaf": 17, "12681": 17, "c34ef853c8": 17, "out": [17, 18, 23], "build": [17, 21], "12444": 17, "0080354502": 17, "0b2": 17, "12449": 17, "ae7cb4a1e2": 17, "wrong": 17, "hash": 17, "12390": 17, "6889a333cf": 17, "ref": 17, "12366": 17, "7825e8f590": 17, "12304": 17, "85a18e13d9": 17, "point": [17, 18], "project": 17, "page": [17, 21], "cross": 17, "12212": 17, "59eb5de78c": 17, "come": 17, "0beta1": 17, "12206": 17, "b2a28d1590": 17, "dev": 17, "12082": 17, "4e8f9cc8d0": 17, "black": 17, "formmatt": 17, "9550": 17, "8c42cf1b00": 17, "pyupgrad": 17, "6": 17, "11447": 17, "5a439e84eb": 17, "2a1": 17, "11855": 17, "872b1566a1": 17, "setup": 17, "11826": 17, "349b0811c3": 17, "d200": 17, "11688": 17, "16e7129719": 17, "11487": 17, "d305876bee": 17, "11448": 17, "0a0e1af800": 17, "broken": 17, "markdown": 17, "link": [17, 21], "toc": 17, "11249": 17, "ca4238eb4d": 17, "month": 17, "11242": 17, "5220e4c384": 17, "11238": 17, "f3e87c5030": 17, "d202": 17, "11032": 17, "fdd9b6f65b": 17, "10543": 17, "d760265452": 17, "No": 17, "whitespac": 17, "surround": 17, "text": 17, "10533": 17, "d1bce91bb2": 17, "d403": 17, "capit": 17, "word": 17, "10530": 17, "3696c34c28": 17, "10528": 17, "ee7ca128a1": 17, "refernc": 17, "10483": 17, "7c206a82a6": 17, "replac": 17, "assig": 17, "augment": 17, "assign": 17, "10468": 17, "3b3287d7ac": 17, "enforc": 17, "keyword": 17, "10170": 17, "7d24b088cd": 17, "stop": 17, "default_arg": 17, "example_dag": 17, "9985": 17, "33f0cd2657": 17, "keep": 17, "function": [17, 19], "signatur": [17, 20, 21], "9784": 17, "1427e4acb4": 17, "8730": 17, "4d74ac2111": 17, "increas": 17, "http": [17, 19, 21], "9729": 17, "0873070e08": 17, "mask": 17, "other": 17, "9615": 17, "13a827d80f": 17, "9044": 17, "067806d598": 17, "test": [17, 19, 22, 23], "9491": 17, "d0e7db4024": 17, "fresh": 17, "9408": 17, "12af6a0800": 17, "final": 17, "23rc1": 17, "9404": 17, "c7e5bce57f": 17, "candid": 17, "9370": 17, "40bf8f28f9": 17, "detect": 17, "lack": 17, "refer": 17, "9290": 17, "f6bd817a3a": 17, "9320": 17, "0b0e4f7a4c": 17, "rc3": 17, "relas": 17, "9026": 17, "00642a46d0": 17, "remain": 17, "wrongli": 17, "8994": 17, "375d1ca229": 17, "8898": 17, "12c5e5d8a": 17, "8891": 17, "f3521fb0e3": 17, "regener": 17, "8886": 17, "92585ca4cb": 17, "8807": 17, "7506c73f17": 17, "8787": 17, "487b5cc50c": 17, "8305": 17, "87969a350d": 17, "6515": 17, "info": 17, "8170": 17, "be1451b0e1": 17, "7026": 17, "7749": 17, "4bde99f132": 17, "7802": 17, "7e6372a681": 17, "super": 17, "7820": 17, "2327aa5a26": 17, "7025": 17, "handl": 17, "its": [17, 22], "properli": 17, "7677": 17, "024b4bf962": 17, "7024": 17, "7676": 17, "b59042b5ab": 17, "6949": 17, "respect": 17, "explicit": 17, "namespac": [17, 18], "7575": 17, "97a429f9d0": 17, "6714": 17, "magic": 17, "utf": 17, "7338": 17, "0481b9a957": 17, "6539": 17, "7142": 17, "case": [18, 23], "dictionari": 18, "follow": [18, 19, 21, 23], "standard": 18, "deploi": [18, 22], "node": 18, "extern": 18, "client": [18, 19], "divid": 18, "multipl": 18, "quota": 18, "authent": 18, "proxi": [18, 19], "ssl": 18, "uri": 18, "compon": 18, "encod": 18, "mongo": 18, "export": 18, "airflow_conn_spark_default": 18, "mysparkclust": 18, "com": [18, 21], "80": 18, "kube": 18, "sure": [18, 19], "trust": [18, 21], "abil": 18, "establish": 18, "commun": [18, 19], "server": [18, 19, 21, 22], "crucial": 18, "understand": 18, "direct": 18, "toward": 18, "malici": 18, "lead": 18, "signific": 18, "secur": 18, "vulner": [18, 23], "risk": 18, "encount": 18, "rce": 18, "attack": 18, "callabl": 19, "inject": 19, "sparksess": 19, "sparkcontext": 19, "config_kwarg": 19, "sparkconf": 19, "show": 19, "system": [19, 22], "def": 19, "spark_task": 19, "pd": 19, "datafram": 19, "df": 19, "createdatafram": 19, "john": 19, "doe": 19, "jane": 19, "3": 19, "joe": 19, "blogg": 19, "ag": 19, "topanda": 19, "In": 19, "decoupl": 19, "architectur": 19, "api": 19, "prefer": 19, "becaus": 19, "To": [19, 21, 22], "prepend": 19, "15002": 19, "built": 19, "grpc": 19, "interfac": 19, "howev": 19, "through": 19, "credenti": 19, "top": [20, 21], "exist": 20, "below": [20, 21], "5": 20, "grpcio": 20, "those": [20, 21], "might": [20, 23], "verifi": 20, "checksum": [20, 21], "site": 20, "sdist": [20, 21], "asc": [20, 21], "sha512": [20, 21], "wheel": 20, "describ": 21, "download": 21, "offici": 21, "most": 21, "choos": 21, "select": [21, 22], "down": 21, "left": 21, "whl": 21, "origin": 21, "softwar": 21, "foundat": 21, "abov": 21, "pgp": 21, "kei": 21, "essenti": 21, "sha": 21, "gpg": 21, "pleas": 21, "well": 21, "relev": 21, "distribut": 21, "recommend": 21, "mirror": 21, "pgpk": 21, "ka": 21, "pgpv": 21, "tar": 21, "gz": 21, "sat": 21, "sep": 21, "49": 21, "54": 21, "bst": 21, "rsa": 21, "cde15c6e4d3a8ec4ecf4ba4b6674e08ad7de406f": 21, "issuer": 21, "kaxilnaik": 21, "org": [21, 22], "good": [21, 23], "kaxil": 21, "naik": 21, "aka": 21, "gmail": 21, "certifi": 21, "There": 21, "indic": 21, "belong": 21, "owner": 21, "primari": 21, "fingerprint": 21, "cde1": 21, "5c6e": 21, "4d3a": 21, "8ec4": 21, "ecf4": 21, "ba4b": 21, "6674": 21, "e08a": 21, "d7de": 21, "406f": 21, "correct": 21, "do": 21, "worri": 21, "certif": 21, "self": 21, "sign": 21, "why": 21, "By": 21, "previou": 21, "step": 21, "know": 21, "alreadi": 21, "sum": 21, "shasum": 21, "512": 21, "diff": 21, "one": 21, "bin": 21, "bash": 21, "package_vers": 21, "package_nam": 21, "provider_download_dir": 21, "mktemp": 21, "d": 21, "dep": 21, "dest": 21, "curl": 21, "apache_airflow_providers_apache_spark": 21, "py3": 21, "l": 21, "o": 21, "echo": 21, "la": 21, "onc": 21, "instruct": [21, 23], "chapter": 21, "temporari": 21, "definit": 22, "write": 22, "saveast": 22, "jdbc_to_spark_job": 22, "foo": 22, "spark_hom": 22, "postgresql": 22, "42": 22, "bar": 22, "task_id": 22, "spark_to_jdbc_job": 22, "further": 22, "dataframewrit": 22, "hive": 22, "servic": 22, "spark_sql_job": 22, "count": 22, "cnt": 22, "temp_tabl": 22, "cli": 22, "care": 22, "src": 22, "pi": 22, "independ": 23, "itself": 23, "publish": 23, "found": 23, "we": 23, "develop": 23, "alwai": 23, "done": 23, "branch": 23, "where": 23, "strict": 23, "semver": 23, "scope": 23, "major": 23, "break": 23, "minor": 23, "patchlevel": 23, "receiv": 23, "rule": 23, "critic": 23, "reason": 23, "band": 23, "stakehold": 23, "decid": 23, "cherri": 23, "pick": 23, "older": 23, "mix": 23, "govern": 23, "interest": 23, "parti": 23}, "objects": {"airflow.providers.apache": [[8, 0, 0, "-", "spark"]], "airflow.providers.apache.spark": [[8, 1, 1, "", "__version__"], [0, 0, 0, "-", "decorators"], [2, 0, 0, "-", "hooks"], [9, 0, 0, "-", "operators"]], "airflow.providers.apache.spark.decorators": [[1, 0, 0, "-", "pyspark"]], "airflow.providers.apache.spark.decorators.pyspark": [[1, 1, 1, "", "SPARK_CONTEXT_KEYS"], [1, 2, 1, "", "pyspark_task"]], "airflow.providers.apache.spark.hooks": [[3, 0, 0, "-", "spark_connect"], [4, 0, 0, "-", "spark_jdbc"], [5, 0, 0, "-", "spark_jdbc_script"], [6, 0, 0, "-", "spark_sql"], [7, 0, 0, "-", "spark_submit"]], "airflow.providers.apache.spark.hooks.spark_connect": [[3, 3, 1, "", "SparkConnectHook"]], "airflow.providers.apache.spark.hooks.spark_connect.SparkConnectHook": [[3, 4, 1, "", "PARAM_TOKEN"], [3, 4, 1, "", "PARAM_USER_ID"], [3, 4, 1, "", "PARAM_USE_SSL"], [3, 4, 1, "", "conn_name_attr"], [3, 4, 1, "", "conn_type"], [3, 4, 1, "", "default_conn_name"], [3, 5, 1, "", "get_connection_form_widgets"], [3, 5, 1, "", "get_connection_url"], [3, 5, 1, "", "get_ui_field_behaviour"], [3, 4, 1, "", "hook_name"]], "airflow.providers.apache.spark.hooks.spark_jdbc": [[4, 3, 1, "", "SparkJDBCHook"]], "airflow.providers.apache.spark.hooks.spark_jdbc.SparkJDBCHook": [[4, 4, 1, "", "conn_name_attr"], [4, 4, 1, "", "conn_type"], [4, 4, 1, "", "default_conn_name"], [4, 5, 1, "", "get_conn"], [4, 4, 1, "", "hook_name"], [4, 5, 1, "", "submit_jdbc_job"]], "airflow.providers.apache.spark.hooks.spark_jdbc_script": [[5, 1, 1, "", "SPARK_READ_FROM_JDBC"], [5, 1, 1, "", "SPARK_WRITE_TO_JDBC"], [5, 2, 1, "", "set_common_options"], [5, 2, 1, "", "spark_read_from_jdbc"], [5, 2, 1, "", "spark_write_to_jdbc"]], "airflow.providers.apache.spark.hooks.spark_sql": [[6, 3, 1, "", "SparkSqlHook"]], "airflow.providers.apache.spark.hooks.spark_sql.SparkSqlHook": [[6, 4, 1, "", "conn_name_attr"], [6, 4, 1, "", "conn_type"], [6, 4, 1, "", "default_conn_name"], [6, 5, 1, "", "get_conn"], [6, 4, 1, "", "hook_name"], [6, 5, 1, "", "kill"], [6, 5, 1, "", "run_query"]], "airflow.providers.apache.spark.hooks.spark_submit": [[7, 1, 1, "", "ALLOWED_SPARK_BINARIES"], [7, 3, 1, "", "SparkSubmitHook"]], "airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook": [[7, 4, 1, "", "conn_name_attr"], [7, 4, 1, "", "conn_type"], [7, 4, 1, "", "default_conn_name"], [7, 5, 1, "", "get_conn"], [7, 5, 1, "", "get_ui_field_behaviour"], [7, 4, 1, "", "hook_name"], [7, 5, 1, "", "on_kill"], [7, 5, 1, "", "submit"]], "airflow.providers.apache.spark.operators": [[10, 0, 0, "-", "spark_jdbc"], [11, 0, 0, "-", "spark_sql"], [12, 0, 0, "-", "spark_submit"]], "airflow.providers.apache.spark.operators.spark_jdbc": [[10, 3, 1, "", "SparkJDBCOperator"]], "airflow.providers.apache.spark.operators.spark_jdbc.SparkJDBCOperator": [[10, 5, 1, "", "execute"], [10, 5, 1, "", "on_kill"]], "airflow.providers.apache.spark.operators.spark_sql": [[11, 3, 1, "", "SparkSqlOperator"]], "airflow.providers.apache.spark.operators.spark_sql.SparkSqlOperator": [[11, 5, 1, "", "execute"], [11, 5, 1, "", "on_kill"], [11, 4, 1, "", "template_ext"], [11, 4, 1, "", "template_fields"], [11, 4, 1, "", "template_fields_renderers"]], "airflow.providers.apache.spark.operators.spark_submit": [[12, 3, 1, "", "SparkSubmitOperator"]], "airflow.providers.apache.spark.operators.spark_submit.SparkSubmitOperator": [[12, 5, 1, "", "execute"], [12, 5, 1, "", "on_kill"], [12, 4, 1, "", "template_fields"], [12, 4, 1, "", "ui_color"]], "tests.system.providers.apache": [[15, 0, 0, "-", "spark"]], "tests.system.providers.apache.spark": [[13, 0, 0, "-", "example_pyspark"], [14, 0, 0, "-", "example_spark_dag"]], "tests.system.providers.apache.spark.example_pyspark": [[13, 1, 1, "", "dag"], [13, 2, 1, "", "example_pyspark"], [13, 1, 1, "", "test_run"]], "tests.system.providers.apache.spark.example_spark_dag": [[14, 1, 1, "", "DAG_ID"], [14, 1, 1, "", "ENV_ID"], [14, 1, 1, "", "submit_job"], [14, 1, 1, "", "test_run"]]}, "objtypes": {"0": "py:module", "1": "py:data", "2": "py:function", "3": "py:class", "4": "py:attribute", "5": "py:method"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "data", "Python data"], "2": ["py", "function", "Python function"], "3": ["py", "class", "Python class"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "method", "Python method"]}, "titleterms": {"airflow": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 20], "provid": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 20], "apach": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 22], "spark": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 22], "decor": [0, 1, 19], "submodul": [0, 2, 9, 15], "pyspark": [1, 19], "modul": [1, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14], "content": [1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14], "function": [1, 5, 13], "attribut": [1, 5, 7, 13], "hook": [2, 3, 4, 5, 6, 7], "spark_connect": 3, "class": [3, 4, 6, 7, 10, 11, 12], "spark_jdbc": [4, 10], "spark_jdbc_script": 5, "spark_sql": [6, 11], "spark_submit": [7, 12], "subpackag": 8, "packag": [8, 17, 20, 21], "oper": [9, 10, 11, 12, 22], "test": [13, 14, 15], "system": [13, 14, 15], "example_pyspark": 13, "example_spark_dag": 14, "changelog": 16, "4": [16, 17], "0": [16, 17], "featur": 16, "3": [16, 17], "2": [16, 17], "misc": 16, "1": [16, 17], "5": [16, 17], "bug": 16, "fix": 16, "break": 16, "chang": 16, "connect": [18, 19], "default": 18, "id": 18, "configur": 18, "paramet": 19, "exampl": 19, "authent": 19, "instal": [20, 21], "requir": 20, "cross": 20, "depend": 20, "download": 20, "offici": 20, "from": 21, "sourc": 21, "releas": [21, 23], "integr": 21, "verifi": 21, "pypi": 21, "prerequisit": 22, "sparkjdbcoper": 22, "us": 22, "refer": 22, "sparksqloper": 22, "sparksubmitoper": 22, "secur": 23, "patch": 23}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"airflow.providers.apache.spark.decorators": [[0, "module-airflow.providers.apache.spark.decorators"]], "Submodules": [[0, "submodules"], [2, "submodules"], [9, "submodules"], [15, "submodules"]], "airflow.providers.apache.spark.decorators.pyspark": [[1, "module-airflow.providers.apache.spark.decorators.pyspark"]], "Module Contents": [[1, "module-contents"], [3, "module-contents"], [4, "module-contents"], [5, "module-contents"], [6, "module-contents"], [7, "module-contents"], [10, "module-contents"], [11, "module-contents"], [12, "module-contents"], [13, "module-contents"], [14, "module-contents"]], "Functions": [[1, "functions"], [5, "functions"], [13, "functions"]], "Attributes": [[1, "attributes"], [5, "attributes"], [7, "attributes"], [13, "attributes"]], "airflow.providers.apache.spark.hooks": [[2, "module-airflow.providers.apache.spark.hooks"]], "airflow.providers.apache.spark.hooks.spark_connect": [[3, "module-airflow.providers.apache.spark.hooks.spark_connect"]], "Classes": [[3, "classes"], [4, "classes"], [6, "classes"], [7, "classes"], [10, "classes"], [11, "classes"], [12, "classes"]], "airflow.providers.apache.spark.hooks.spark_jdbc": [[4, "module-airflow.providers.apache.spark.hooks.spark_jdbc"]], "airflow.providers.apache.spark.hooks.spark_jdbc_script": [[5, "module-airflow.providers.apache.spark.hooks.spark_jdbc_script"]], "airflow.providers.apache.spark.hooks.spark_sql": [[6, "module-airflow.providers.apache.spark.hooks.spark_sql"]], "airflow.providers.apache.spark.hooks.spark_submit": [[7, "module-airflow.providers.apache.spark.hooks.spark_submit"]], "airflow.providers.apache.spark": [[8, "module-airflow.providers.apache.spark"]], "Subpackages": [[8, "subpackages"]], "Package Contents": [[8, "package-contents"]], "airflow.providers.apache.spark.operators": [[9, "module-airflow.providers.apache.spark.operators"]], "airflow.providers.apache.spark.operators.spark_jdbc": [[10, "module-airflow.providers.apache.spark.operators.spark_jdbc"]], "airflow.providers.apache.spark.operators.spark_sql": [[11, "module-airflow.providers.apache.spark.operators.spark_sql"]], "airflow.providers.apache.spark.operators.spark_submit": [[12, "module-airflow.providers.apache.spark.operators.spark_submit"]], "tests.system.providers.apache.spark.example_pyspark": [[13, "module-tests.system.providers.apache.spark.example_pyspark"]], "tests.system.providers.apache.spark.example_spark_dag": [[14, "module-tests.system.providers.apache.spark.example_spark_dag"]], "tests.system.providers.apache.spark": [[15, "module-tests.system.providers.apache.spark"]], "Changelog": [[16, "changelog"]], "4.4.0": [[16, "id1"], [17, "id1"]], "Features": [[16, "features"], [16, "id3"], [16, "id35"]], "4.3.0": [[16, "id2"], [17, "id2"]], "4.2.0": [[16, "id4"], [17, "id3"]], "Misc": [[16, "misc"], [16, "id6"], [16, "id8"], [16, "id11"], [16, "id13"], [16, "id16"], [16, "id21"], [16, "id26"], [16, "id30"], [16, "id33"], [16, "id41"]], "4.1.5": [[16, "id5"], [17, "id4"]], "4.1.4": [[16, "id7"], [17, "id5"]], "4.1.3": [[16, "id9"], [17, "id6"]], "Bug Fixes": [[16, "bug-fixes"], [16, "id18"], [16, "id25"], [16, "id28"], [16, "id32"], [16, "id37"], [16, "id39"]], "4.1.2": [[16, "id10"], [17, "id7"]], "4.1.1": [[16, "id12"], [17, "id8"]], "4.1.0": [[16, "id14"], [17, "id9"]], "4.0.1": [[16, "id17"], [17, "id10"]], "4.0.0": [[16, "id19"], [17, "id11"]], "Breaking changes": [[16, "breaking-changes"], [16, "id23"], [16, "id43"]], "3.0.0": [[16, "id22"], [17, "id13"]], "2.1.3": [[16, "id27"], [17, "id14"]], "2.1.2": [[16, "id29"], [17, "id15"]], "2.1.1": [[16, "id31"], [17, "id16"]], "2.1.0": [[16, "id34"], [17, "id17"]], "2.0.3": [[16, "id36"], [17, "id18"]], "2.0.2": [[16, "id38"], [17, "id19"]], "2.0.1": [[16, "id40"], [17, "id20"]], "2.0.0": [[16, "id42"], [17, "id21"]], "Bug fixes": [[16, "id44"], [16, "id46"], [16, "id48"]], "1.0.3": [[16, "id45"], [17, "id22"]], "1.0.2": [[16, "id47"], [17, "id23"]], "1.0.1": [[16, "id49"], [17, "id24"]], "1.0.0": [[16, "id50"], [17, "id25"]], "Package apache-airflow-providers-apache-spark": [[17, "package-apache-airflow-providers-apache-spark"], [20, "package-apache-airflow-providers-apache-spark"]], "Apache Spark Connection": [[18, "apache-spark-connection"]], "Default Connection IDs": [[18, "default-connection-ids"]], "Configuring the Connection": [[18, "configuring-the-connection"]], "PySpark Decorator": [[19, "pyspark-decorator"]], "Parameters": [[19, "parameters"]], "Example": [[19, "example"]], "Spark Connect": [[19, "spark-connect"]], "Authentication": [[19, "authentication"]], "apache-airflow-providers-apache-spark": [[20, "apache-airflow-providers-apache-spark"]], "Provider package": [[20, "provider-package"]], "Installation": [[20, "installation"]], "Requirements": [[20, "requirements"]], "Cross provider package dependencies": [[20, "cross-provider-package-dependencies"]], "Downloading official packages": [[20, "downloading-official-packages"]], "Installing from sources": [[21, "installing-from-sources"]], "Released packages": [[21, "released-packages"]], "Release integrity": [[21, "release-integrity"]], "Verifying PyPI releases": [[21, "verifying-pypi-releases"]], "Apache Spark Operators": [[22, "apache-spark-operators"]], "Prerequisite": [[22, "prerequisite"]], "SparkJDBCOperator": [[22, "sparkjdbcoperator"]], "Using the operator": [[22, "using-the-operator"], [22, "id1"], [22, "id3"]], "Reference": [[22, "reference"], [22, "id2"], [22, "id4"]], "SparkSqlOperator": [[22, "sparksqloperator"]], "SparkSubmitOperator": [[22, "sparksubmitoperator"]], "Releasing security patches": [[23, "releasing-security-patches"]]}, "indexentries": {"airflow.providers.apache.spark.decorators": [[0, "module-airflow.providers.apache.spark.decorators"]], "module": [[0, "module-airflow.providers.apache.spark.decorators"], [1, "module-airflow.providers.apache.spark.decorators.pyspark"], [2, "module-airflow.providers.apache.spark.hooks"], [3, "module-airflow.providers.apache.spark.hooks.spark_connect"], [4, "module-airflow.providers.apache.spark.hooks.spark_jdbc"], [5, "module-airflow.providers.apache.spark.hooks.spark_jdbc_script"], [6, "module-airflow.providers.apache.spark.hooks.spark_sql"], [7, "module-airflow.providers.apache.spark.hooks.spark_submit"], [8, "module-airflow.providers.apache.spark"], [9, "module-airflow.providers.apache.spark.operators"], [10, "module-airflow.providers.apache.spark.operators.spark_jdbc"], [11, "module-airflow.providers.apache.spark.operators.spark_sql"], [12, "module-airflow.providers.apache.spark.operators.spark_submit"], [13, "module-tests.system.providers.apache.spark.example_pyspark"], [14, "module-tests.system.providers.apache.spark.example_spark_dag"], [15, "module-tests.system.providers.apache.spark"]], "spark_context_keys (in module airflow.providers.apache.spark.decorators.pyspark)": [[1, "airflow.providers.apache.spark.decorators.pyspark.SPARK_CONTEXT_KEYS"]], "airflow.providers.apache.spark.decorators.pyspark": [[1, "module-airflow.providers.apache.spark.decorators.pyspark"]], "pyspark_task() (in module airflow.providers.apache.spark.decorators.pyspark)": [[1, "airflow.providers.apache.spark.decorators.pyspark.pyspark_task"]], "airflow.providers.apache.spark.hooks": [[2, "module-airflow.providers.apache.spark.hooks"]], "param_token (airflow.providers.apache.spark.hooks.spark_connect.sparkconnecthook attribute)": [[3, "airflow.providers.apache.spark.hooks.spark_connect.SparkConnectHook.PARAM_TOKEN"]], "param_user_id (airflow.providers.apache.spark.hooks.spark_connect.sparkconnecthook attribute)": [[3, "airflow.providers.apache.spark.hooks.spark_connect.SparkConnectHook.PARAM_USER_ID"]], "param_use_ssl (airflow.providers.apache.spark.hooks.spark_connect.sparkconnecthook attribute)": [[3, "airflow.providers.apache.spark.hooks.spark_connect.SparkConnectHook.PARAM_USE_SSL"]], "sparkconnecthook (class in airflow.providers.apache.spark.hooks.spark_connect)": [[3, "airflow.providers.apache.spark.hooks.spark_connect.SparkConnectHook"]], "airflow.providers.apache.spark.hooks.spark_connect": [[3, "module-airflow.providers.apache.spark.hooks.spark_connect"]], "conn_name_attr (airflow.providers.apache.spark.hooks.spark_connect.sparkconnecthook attribute)": [[3, "airflow.providers.apache.spark.hooks.spark_connect.SparkConnectHook.conn_name_attr"]], "conn_type (airflow.providers.apache.spark.hooks.spark_connect.sparkconnecthook attribute)": [[3, "airflow.providers.apache.spark.hooks.spark_connect.SparkConnectHook.conn_type"]], "default_conn_name (airflow.providers.apache.spark.hooks.spark_connect.sparkconnecthook attribute)": [[3, "airflow.providers.apache.spark.hooks.spark_connect.SparkConnectHook.default_conn_name"]], "get_connection_form_widgets() (airflow.providers.apache.spark.hooks.spark_connect.sparkconnecthook static method)": [[3, "airflow.providers.apache.spark.hooks.spark_connect.SparkConnectHook.get_connection_form_widgets"]], "get_connection_url() (airflow.providers.apache.spark.hooks.spark_connect.sparkconnecthook method)": [[3, "airflow.providers.apache.spark.hooks.spark_connect.SparkConnectHook.get_connection_url"]], "get_ui_field_behaviour() (airflow.providers.apache.spark.hooks.spark_connect.sparkconnecthook static method)": [[3, "airflow.providers.apache.spark.hooks.spark_connect.SparkConnectHook.get_ui_field_behaviour"]], "hook_name (airflow.providers.apache.spark.hooks.spark_connect.sparkconnecthook attribute)": [[3, "airflow.providers.apache.spark.hooks.spark_connect.SparkConnectHook.hook_name"]], "sparkjdbchook (class in airflow.providers.apache.spark.hooks.spark_jdbc)": [[4, "airflow.providers.apache.spark.hooks.spark_jdbc.SparkJDBCHook"]], "airflow.providers.apache.spark.hooks.spark_jdbc": [[4, "module-airflow.providers.apache.spark.hooks.spark_jdbc"]], "conn_name_attr (airflow.providers.apache.spark.hooks.spark_jdbc.sparkjdbchook attribute)": [[4, "airflow.providers.apache.spark.hooks.spark_jdbc.SparkJDBCHook.conn_name_attr"]], "conn_type (airflow.providers.apache.spark.hooks.spark_jdbc.sparkjdbchook attribute)": [[4, "airflow.providers.apache.spark.hooks.spark_jdbc.SparkJDBCHook.conn_type"]], "default_conn_name (airflow.providers.apache.spark.hooks.spark_jdbc.sparkjdbchook attribute)": [[4, "airflow.providers.apache.spark.hooks.spark_jdbc.SparkJDBCHook.default_conn_name"]], "get_conn() (airflow.providers.apache.spark.hooks.spark_jdbc.sparkjdbchook method)": [[4, "airflow.providers.apache.spark.hooks.spark_jdbc.SparkJDBCHook.get_conn"]], "hook_name (airflow.providers.apache.spark.hooks.spark_jdbc.sparkjdbchook attribute)": [[4, "airflow.providers.apache.spark.hooks.spark_jdbc.SparkJDBCHook.hook_name"]], "submit_jdbc_job() (airflow.providers.apache.spark.hooks.spark_jdbc.sparkjdbchook method)": [[4, "airflow.providers.apache.spark.hooks.spark_jdbc.SparkJDBCHook.submit_jdbc_job"]], "spark_read_from_jdbc (in module airflow.providers.apache.spark.hooks.spark_jdbc_script)": [[5, "airflow.providers.apache.spark.hooks.spark_jdbc_script.SPARK_READ_FROM_JDBC"]], "spark_write_to_jdbc (in module airflow.providers.apache.spark.hooks.spark_jdbc_script)": [[5, "airflow.providers.apache.spark.hooks.spark_jdbc_script.SPARK_WRITE_TO_JDBC"]], "airflow.providers.apache.spark.hooks.spark_jdbc_script": [[5, "module-airflow.providers.apache.spark.hooks.spark_jdbc_script"]], "set_common_options() (in module airflow.providers.apache.spark.hooks.spark_jdbc_script)": [[5, "airflow.providers.apache.spark.hooks.spark_jdbc_script.set_common_options"]], "spark_read_from_jdbc() (in module airflow.providers.apache.spark.hooks.spark_jdbc_script)": [[5, "airflow.providers.apache.spark.hooks.spark_jdbc_script.spark_read_from_jdbc"]], "spark_write_to_jdbc() (in module airflow.providers.apache.spark.hooks.spark_jdbc_script)": [[5, "airflow.providers.apache.spark.hooks.spark_jdbc_script.spark_write_to_jdbc"]], "sparksqlhook (class in airflow.providers.apache.spark.hooks.spark_sql)": [[6, "airflow.providers.apache.spark.hooks.spark_sql.SparkSqlHook"]], "airflow.providers.apache.spark.hooks.spark_sql": [[6, "module-airflow.providers.apache.spark.hooks.spark_sql"]], "conn_name_attr (airflow.providers.apache.spark.hooks.spark_sql.sparksqlhook attribute)": [[6, "airflow.providers.apache.spark.hooks.spark_sql.SparkSqlHook.conn_name_attr"]], "conn_type (airflow.providers.apache.spark.hooks.spark_sql.sparksqlhook attribute)": [[6, "airflow.providers.apache.spark.hooks.spark_sql.SparkSqlHook.conn_type"]], "default_conn_name (airflow.providers.apache.spark.hooks.spark_sql.sparksqlhook attribute)": [[6, "airflow.providers.apache.spark.hooks.spark_sql.SparkSqlHook.default_conn_name"]], "get_conn() (airflow.providers.apache.spark.hooks.spark_sql.sparksqlhook method)": [[6, "airflow.providers.apache.spark.hooks.spark_sql.SparkSqlHook.get_conn"]], "hook_name (airflow.providers.apache.spark.hooks.spark_sql.sparksqlhook attribute)": [[6, "airflow.providers.apache.spark.hooks.spark_sql.SparkSqlHook.hook_name"]], "kill() (airflow.providers.apache.spark.hooks.spark_sql.sparksqlhook method)": [[6, "airflow.providers.apache.spark.hooks.spark_sql.SparkSqlHook.kill"]], "run_query() (airflow.providers.apache.spark.hooks.spark_sql.sparksqlhook method)": [[6, "airflow.providers.apache.spark.hooks.spark_sql.SparkSqlHook.run_query"]], "allowed_spark_binaries (in module airflow.providers.apache.spark.hooks.spark_submit)": [[7, "airflow.providers.apache.spark.hooks.spark_submit.ALLOWED_SPARK_BINARIES"]], "sparksubmithook (class in airflow.providers.apache.spark.hooks.spark_submit)": [[7, "airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"]], "airflow.providers.apache.spark.hooks.spark_submit": [[7, "module-airflow.providers.apache.spark.hooks.spark_submit"]], "conn_name_attr (airflow.providers.apache.spark.hooks.spark_submit.sparksubmithook attribute)": [[7, "airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook.conn_name_attr"]], "conn_type (airflow.providers.apache.spark.hooks.spark_submit.sparksubmithook attribute)": [[7, "airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook.conn_type"]], "default_conn_name (airflow.providers.apache.spark.hooks.spark_submit.sparksubmithook attribute)": [[7, "airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook.default_conn_name"]], "get_conn() (airflow.providers.apache.spark.hooks.spark_submit.sparksubmithook method)": [[7, "airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook.get_conn"]], "get_ui_field_behaviour() (airflow.providers.apache.spark.hooks.spark_submit.sparksubmithook static method)": [[7, "airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook.get_ui_field_behaviour"]], "hook_name (airflow.providers.apache.spark.hooks.spark_submit.sparksubmithook attribute)": [[7, "airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook.hook_name"]], "on_kill() (airflow.providers.apache.spark.hooks.spark_submit.sparksubmithook method)": [[7, "airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook.on_kill"]], "submit() (airflow.providers.apache.spark.hooks.spark_submit.sparksubmithook method)": [[7, "airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook.submit"]], "__version__ (in module airflow.providers.apache.spark)": [[8, "airflow.providers.apache.spark.__version__"]], "airflow.providers.apache.spark": [[8, "module-airflow.providers.apache.spark"]], "airflow.providers.apache.spark.operators": [[9, "module-airflow.providers.apache.spark.operators"]], "sparkjdbcoperator (class in airflow.providers.apache.spark.operators.spark_jdbc)": [[10, "airflow.providers.apache.spark.operators.spark_jdbc.SparkJDBCOperator"]], "airflow.providers.apache.spark.operators.spark_jdbc": [[10, "module-airflow.providers.apache.spark.operators.spark_jdbc"]], "execute() (airflow.providers.apache.spark.operators.spark_jdbc.sparkjdbcoperator method)": [[10, "airflow.providers.apache.spark.operators.spark_jdbc.SparkJDBCOperator.execute"]], "on_kill() (airflow.providers.apache.spark.operators.spark_jdbc.sparkjdbcoperator method)": [[10, "airflow.providers.apache.spark.operators.spark_jdbc.SparkJDBCOperator.on_kill"]], "sparksqloperator (class in airflow.providers.apache.spark.operators.spark_sql)": [[11, "airflow.providers.apache.spark.operators.spark_sql.SparkSqlOperator"]], "airflow.providers.apache.spark.operators.spark_sql": [[11, "module-airflow.providers.apache.spark.operators.spark_sql"]], "execute() (airflow.providers.apache.spark.operators.spark_sql.sparksqloperator method)": [[11, "airflow.providers.apache.spark.operators.spark_sql.SparkSqlOperator.execute"]], "on_kill() (airflow.providers.apache.spark.operators.spark_sql.sparksqloperator method)": [[11, "airflow.providers.apache.spark.operators.spark_sql.SparkSqlOperator.on_kill"]], "template_ext (airflow.providers.apache.spark.operators.spark_sql.sparksqloperator attribute)": [[11, "airflow.providers.apache.spark.operators.spark_sql.SparkSqlOperator.template_ext"]], "template_fields (airflow.providers.apache.spark.operators.spark_sql.sparksqloperator attribute)": [[11, "airflow.providers.apache.spark.operators.spark_sql.SparkSqlOperator.template_fields"]], "template_fields_renderers (airflow.providers.apache.spark.operators.spark_sql.sparksqloperator attribute)": [[11, "airflow.providers.apache.spark.operators.spark_sql.SparkSqlOperator.template_fields_renderers"]], "sparksubmitoperator (class in airflow.providers.apache.spark.operators.spark_submit)": [[12, "airflow.providers.apache.spark.operators.spark_submit.SparkSubmitOperator"]], "airflow.providers.apache.spark.operators.spark_submit": [[12, "module-airflow.providers.apache.spark.operators.spark_submit"]], "execute() (airflow.providers.apache.spark.operators.spark_submit.sparksubmitoperator method)": [[12, "airflow.providers.apache.spark.operators.spark_submit.SparkSubmitOperator.execute"]], "on_kill() (airflow.providers.apache.spark.operators.spark_submit.sparksubmitoperator method)": [[12, "airflow.providers.apache.spark.operators.spark_submit.SparkSubmitOperator.on_kill"]], "template_fields (airflow.providers.apache.spark.operators.spark_submit.sparksubmitoperator attribute)": [[12, "airflow.providers.apache.spark.operators.spark_submit.SparkSubmitOperator.template_fields"]], "ui_color (airflow.providers.apache.spark.operators.spark_submit.sparksubmitoperator attribute)": [[12, "airflow.providers.apache.spark.operators.spark_submit.SparkSubmitOperator.ui_color"]], "dag (in module tests.system.providers.apache.spark.example_pyspark)": [[13, "tests.system.providers.apache.spark.example_pyspark.dag"]], "example_pyspark() (in module tests.system.providers.apache.spark.example_pyspark)": [[13, "tests.system.providers.apache.spark.example_pyspark.example_pyspark"]], "test_run (in module tests.system.providers.apache.spark.example_pyspark)": [[13, "tests.system.providers.apache.spark.example_pyspark.test_run"]], "tests.system.providers.apache.spark.example_pyspark": [[13, "module-tests.system.providers.apache.spark.example_pyspark"]], "dag_id (in module tests.system.providers.apache.spark.example_spark_dag)": [[14, "tests.system.providers.apache.spark.example_spark_dag.DAG_ID"]], "env_id (in module tests.system.providers.apache.spark.example_spark_dag)": [[14, "tests.system.providers.apache.spark.example_spark_dag.ENV_ID"]], "submit_job (in module tests.system.providers.apache.spark.example_spark_dag)": [[14, "tests.system.providers.apache.spark.example_spark_dag.submit_job"]], "test_run (in module tests.system.providers.apache.spark.example_spark_dag)": [[14, "tests.system.providers.apache.spark.example_spark_dag.test_run"]], "tests.system.providers.apache.spark.example_spark_dag": [[14, "module-tests.system.providers.apache.spark.example_spark_dag"]], "tests.system.providers.apache.spark": [[15, "module-tests.system.providers.apache.spark"]]}})