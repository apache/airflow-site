:py:mod:`airflow.providers.databricks.hooks.databricks`
=======================================================

.. py:module:: airflow.providers.databricks.hooks.databricks

.. autoapi-nested-parse::

   Databricks hook.

   This hook enable the submitting and running of jobs to the Databricks platform. Internally the
   operators talk to the ``api/2.0/jobs/runs/submit``
   `endpoint <https://docs.databricks.com/api/latest/jobs.html#runs-submit>`_.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.databricks.hooks.databricks.RunState
   airflow.providers.databricks.hooks.databricks.DatabricksHook




Attributes
~~~~~~~~~~

.. autoapisummary::

   airflow.providers.databricks.hooks.databricks.RESTART_CLUSTER_ENDPOINT
   airflow.providers.databricks.hooks.databricks.START_CLUSTER_ENDPOINT
   airflow.providers.databricks.hooks.databricks.TERMINATE_CLUSTER_ENDPOINT
   airflow.providers.databricks.hooks.databricks.RUN_NOW_ENDPOINT
   airflow.providers.databricks.hooks.databricks.SUBMIT_RUN_ENDPOINT
   airflow.providers.databricks.hooks.databricks.GET_RUN_ENDPOINT
   airflow.providers.databricks.hooks.databricks.CANCEL_RUN_ENDPOINT
   airflow.providers.databricks.hooks.databricks.INSTALL_LIBS_ENDPOINT
   airflow.providers.databricks.hooks.databricks.UNINSTALL_LIBS_ENDPOINT
   airflow.providers.databricks.hooks.databricks.USER_AGENT_HEADER
   airflow.providers.databricks.hooks.databricks.RUN_LIFE_CYCLE_STATES
   airflow.providers.databricks.hooks.databricks.AZURE_DEFAULT_AD_ENDPOINT
   airflow.providers.databricks.hooks.databricks.AZURE_TOKEN_SERVICE_URL
   airflow.providers.databricks.hooks.databricks.AZURE_METADATA_SERVICE_TOKEN_URL
   airflow.providers.databricks.hooks.databricks.AZURE_METADATA_SERVICE_INSTANCE_URL
   airflow.providers.databricks.hooks.databricks.TOKEN_REFRESH_LEAD_TIME
   airflow.providers.databricks.hooks.databricks.AZURE_MANAGEMENT_ENDPOINT
   airflow.providers.databricks.hooks.databricks.DEFAULT_DATABRICKS_SCOPE


.. py:data:: RESTART_CLUSTER_ENDPOINT
   :annotation: = ['POST', 'api/2.0/clusters/restart']

   

.. py:data:: START_CLUSTER_ENDPOINT
   :annotation: = ['POST', 'api/2.0/clusters/start']

   

.. py:data:: TERMINATE_CLUSTER_ENDPOINT
   :annotation: = ['POST', 'api/2.0/clusters/delete']

   

.. py:data:: RUN_NOW_ENDPOINT
   :annotation: = ['POST', 'api/2.1/jobs/run-now']

   

.. py:data:: SUBMIT_RUN_ENDPOINT
   :annotation: = ['POST', 'api/2.1/jobs/runs/submit']

   

.. py:data:: GET_RUN_ENDPOINT
   :annotation: = ['GET', 'api/2.1/jobs/runs/get']

   

.. py:data:: CANCEL_RUN_ENDPOINT
   :annotation: = ['POST', 'api/2.1/jobs/runs/cancel']

   

.. py:data:: INSTALL_LIBS_ENDPOINT
   :annotation: = ['POST', 'api/2.0/libraries/install']

   

.. py:data:: UNINSTALL_LIBS_ENDPOINT
   :annotation: = ['POST', 'api/2.0/libraries/uninstall']

   

.. py:data:: USER_AGENT_HEADER
   

   

.. py:data:: RUN_LIFE_CYCLE_STATES
   :annotation: = ['PENDING', 'RUNNING', 'TERMINATING', 'TERMINATED', 'SKIPPED', 'INTERNAL_ERROR']

   

.. py:data:: AZURE_DEFAULT_AD_ENDPOINT
   :annotation: = https://login.microsoftonline.com

   

.. py:data:: AZURE_TOKEN_SERVICE_URL
   :annotation: = {}/{}/oauth2/token

   

.. py:data:: AZURE_METADATA_SERVICE_TOKEN_URL
   :annotation: = http://169.254.169.254/metadata/identity/oauth2/token

   

.. py:data:: AZURE_METADATA_SERVICE_INSTANCE_URL
   :annotation: = http://169.254.169.254/metadata/instance

   

.. py:data:: TOKEN_REFRESH_LEAD_TIME
   :annotation: = 120

   

.. py:data:: AZURE_MANAGEMENT_ENDPOINT
   :annotation: = https://management.core.windows.net/

   

.. py:data:: DEFAULT_DATABRICKS_SCOPE
   :annotation: = 2ff814a6-3304-4ab8-85cb-cd0e6f879c1d

   

.. py:class:: RunState(life_cycle_state: str, result_state: str = '', state_message: str = '', *args, **kwargs)

   Utility class for the run state concept of Databricks runs.

   .. py:method:: is_terminal(self) -> bool
      :property:

      True if the current state is a terminal state.


   .. py:method:: is_successful(self) -> bool
      :property:

      True if the result state is SUCCESS


   .. py:method:: __eq__(self, other: object) -> bool

      Return self==value.


   .. py:method:: __repr__(self) -> str

      Return repr(self).



.. py:class:: DatabricksHook(databricks_conn_id: str = default_conn_name, timeout_seconds: int = 180, retry_limit: int = 3, retry_delay: float = 1.0)

   Bases: :py:obj:`airflow.hooks.base.BaseHook`

   Interact with Databricks.

   :param databricks_conn_id: Reference to the :ref:`Databricks connection <howto/connection:databricks>`.
   :type databricks_conn_id: str
   :param timeout_seconds: The amount of time in seconds the requests library
       will wait before timing-out.
   :type timeout_seconds: int
   :param retry_limit: The number of times to retry the connection in case of
       service outages.
   :type retry_limit: int
   :param retry_delay: The number of seconds to wait between retries (it
       might be a floating point number).
   :type retry_delay: float

   .. py:attribute:: conn_name_attr
      :annotation: = databricks_conn_id

      

   .. py:attribute:: default_conn_name
      :annotation: = databricks_default

      

   .. py:attribute:: conn_type
      :annotation: = databricks

      

   .. py:attribute:: hook_name
      :annotation: = Databricks

      

   .. py:method:: run_now(self, json: dict) -> int

      Utility function to call the ``api/2.0/jobs/run-now`` endpoint.

      :param json: The data used in the body of the request to the ``run-now`` endpoint.
      :type json: dict
      :return: the run_id as an int
      :rtype: str


   .. py:method:: submit_run(self, json: dict) -> int

      Utility function to call the ``api/2.0/jobs/runs/submit`` endpoint.

      :param json: The data used in the body of the request to the ``submit`` endpoint.
      :type json: dict
      :return: the run_id as an int
      :rtype: str


   .. py:method:: get_run_page_url(self, run_id: int) -> str

      Retrieves run_page_url.

      :param run_id: id of the run
      :return: URL of the run page


   .. py:method:: get_job_id(self, run_id: int) -> int

      Retrieves job_id from run_id.

      :param run_id: id of the run
      :type run_id: int
      :return: Job id for given Databricks run


   .. py:method:: get_run_state(self, run_id: int) -> RunState

      Retrieves run state of the run.

      Please note that any Airflow tasks that call the ``get_run_state`` method will result in
      failure unless you have enabled xcom pickling.  This can be done using the following
      environment variable: ``AIRFLOW__CORE__ENABLE_XCOM_PICKLING``

      If you do not want to enable xcom pickling, use the ``get_run_state_str`` method to get
      a string describing state, or ``get_run_state_lifecycle``, ``get_run_state_result``, or
      ``get_run_state_message`` to get individual components of the run state.

      :param run_id: id of the run
      :return: state of the run


   .. py:method:: get_run_state_str(self, run_id: int) -> str

      Return the string representation of RunState.

      :param run_id: id of the run
      :return: string describing run state


   .. py:method:: get_run_state_lifecycle(self, run_id: int) -> str

      Returns the lifecycle state of the run

      :param run_id: id of the run
      :return: string with lifecycle state


   .. py:method:: get_run_state_result(self, run_id: int) -> str

      Returns the resulting state of the run

      :param run_id: id of the run
      :return: string with resulting state


   .. py:method:: get_run_state_message(self, run_id: int) -> str

      Returns the state message for the run

      :param run_id: id of the run
      :return: string with state message


   .. py:method:: cancel_run(self, run_id: int) -> None

      Cancels the run.

      :param run_id: id of the run


   .. py:method:: restart_cluster(self, json: dict) -> None

      Restarts the cluster.

      :param json: json dictionary containing cluster specification.


   .. py:method:: start_cluster(self, json: dict) -> None

      Starts the cluster.

      :param json: json dictionary containing cluster specification.


   .. py:method:: terminate_cluster(self, json: dict) -> None

      Terminates the cluster.

      :param json: json dictionary containing cluster specification.


   .. py:method:: install(self, json: dict) -> None

      Install libraries on the cluster.

      Utility function to call the ``2.0/libraries/install`` endpoint.

      :param json: json dictionary containing cluster_id and an array of library
      :type json: dict


   .. py:method:: uninstall(self, json: dict) -> None

      Uninstall libraries on the cluster.

      Utility function to call the ``2.0/libraries/uninstall`` endpoint.

      :param json: json dictionary containing cluster_id and an array of library
      :type json: dict



