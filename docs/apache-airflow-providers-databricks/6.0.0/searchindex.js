Search.setIndex({"docnames": ["_api/airflow/providers/databricks/hooks/databricks/index", "_api/airflow/providers/databricks/hooks/databricks_base/index", "_api/airflow/providers/databricks/hooks/databricks_sql/index", "_api/airflow/providers/databricks/hooks/index", "_api/airflow/providers/databricks/index", "_api/airflow/providers/databricks/operators/databricks/index", "_api/airflow/providers/databricks/operators/databricks_repos/index", "_api/airflow/providers/databricks/operators/databricks_sql/index", "_api/airflow/providers/databricks/operators/index", "_api/airflow/providers/databricks/sensors/databricks_partition/index", "_api/airflow/providers/databricks/sensors/databricks_sql/index", "_api/airflow/providers/databricks/sensors/index", "_api/airflow/providers/databricks/triggers/databricks/index", "_api/airflow/providers/databricks/triggers/index", "_api/airflow/providers/databricks/utils/databricks/index", "_api/airflow/providers/databricks/utils/index", "_api/tests/system/providers/databricks/example_databricks/index", "_api/tests/system/providers/databricks/example_databricks_repos/index", "_api/tests/system/providers/databricks/example_databricks_sensors/index", "_api/tests/system/providers/databricks/example_databricks_sql/index", "_api/tests/system/providers/databricks/index", "changelog", "commits", "connections/databricks", "index", "installing-providers-from-sources", "operators/copy_into", "operators/index", "operators/jobs_create", "operators/repos_create", "operators/repos_delete", "operators/repos_update", "operators/run_now", "operators/sql", "operators/submit_run", "security"], "filenames": ["_api/airflow/providers/databricks/hooks/databricks/index.rst", "_api/airflow/providers/databricks/hooks/databricks_base/index.rst", "_api/airflow/providers/databricks/hooks/databricks_sql/index.rst", "_api/airflow/providers/databricks/hooks/index.rst", "_api/airflow/providers/databricks/index.rst", "_api/airflow/providers/databricks/operators/databricks/index.rst", "_api/airflow/providers/databricks/operators/databricks_repos/index.rst", "_api/airflow/providers/databricks/operators/databricks_sql/index.rst", "_api/airflow/providers/databricks/operators/index.rst", "_api/airflow/providers/databricks/sensors/databricks_partition/index.rst", "_api/airflow/providers/databricks/sensors/databricks_sql/index.rst", "_api/airflow/providers/databricks/sensors/index.rst", "_api/airflow/providers/databricks/triggers/databricks/index.rst", "_api/airflow/providers/databricks/triggers/index.rst", "_api/airflow/providers/databricks/utils/databricks/index.rst", "_api/airflow/providers/databricks/utils/index.rst", "_api/tests/system/providers/databricks/example_databricks/index.rst", "_api/tests/system/providers/databricks/example_databricks_repos/index.rst", "_api/tests/system/providers/databricks/example_databricks_sensors/index.rst", "_api/tests/system/providers/databricks/example_databricks_sql/index.rst", "_api/tests/system/providers/databricks/index.rst", "changelog.rst", "commits.rst", "connections/databricks.rst", "index.rst", "installing-providers-from-sources.rst", "operators/copy_into.rst", "operators/index.rst", "operators/jobs_create.rst", "operators/repos_create.rst", "operators/repos_delete.rst", "operators/repos_update.rst", "operators/run_now.rst", "operators/sql.rst", "operators/submit_run.rst", "security.rst"], "titles": ["<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.hooks.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.hooks.databricks_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.hooks.databricks_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.hooks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators.databricks_repos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators.databricks_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.operators</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.sensors.databricks_partition</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.sensors.databricks_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.sensors</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.triggers.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.triggers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.utils.databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">airflow.providers.databricks.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks.example_databricks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks.example_databricks_repos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks.example_databricks_sensors</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks.example_databricks_sql</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">tests.system.providers.databricks</span></code>", "Changelog", "Package apache-airflow-providers-databricks", "Databricks Connection", "<code class=\"docutils literal notranslate\"><span class=\"pre\">apache-airflow-providers-databricks</span></code>", "Installing from sources", "DatabricksCopyIntoOperator", "Databricks Operators", "DatabricksCreateJobsOperator", "DatabricksReposCreateOperator", "DatabricksReposDeleteOperator", "DatabricksReposUpdateOperator", "DatabricksRunNowOperator", "DatabricksSqlOperator", "DatabricksSubmitRunOperator", "Releasing security patches"], "terms": {"thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "enabl": [0, 1, 22, 23], "submit": [0, 1, 5, 22, 34], "run": [0, 1, 2, 5, 9, 10, 12, 16, 19, 21, 22, 23, 25, 28, 32, 33, 34], "job": [0, 1, 5, 16, 21, 22, 28, 31, 32, 34], "platform": [0, 1], "intern": [0, 1, 2, 7, 9, 10, 23], "oper": [0, 1, 4, 9, 21, 22, 23], "talk": [0, 1], "api": [0, 1, 2, 5, 6, 12, 16, 21, 22, 23, 28, 29, 30, 31, 32, 34], "2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "1": [0, 1, 5, 6, 24, 28, 32, 33, 34], "now": [0, 5, 7, 21, 22, 32], "endpoint": [0, 1, 2, 5, 6, 7, 23, 26, 28, 29, 30, 31, 32, 34], "http": [0, 1, 2, 5, 6, 7, 9, 10, 16, 21, 22, 23, 25, 26, 29, 33], "doc": [0, 5, 6, 16, 21, 22], "com": [0, 1, 5, 6, 16, 17, 21, 25, 29, 30, 31, 34], "dev": [0, 5, 6, 22], "tool": [0, 5, 6, 22], "latest": [0, 5, 6, 16, 21, 22, 31, 35], "html": [0, 5, 6, 16], "jobsrunnow": [0, 5], "_": 0, "get_cluster_endpoint": 0, "get": [0, 2, 5, 7, 10, 22, 25, 28, 34, 35], "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "cluster": [0, 2, 5, 7, 9, 10, 16, 23, 26, 33, 34], "sourc": [0, 1, 2, 4, 5, 6, 7, 9, 10, 12, 14, 16, 17, 18, 19, 26, 28, 29, 30, 31, 33, 34], "restart_cluster_endpoint": 0, "post": [0, 6], "restart": 0, "start_cluster_endpoint": 0, "start": 0, "terminate_cluster_endpoint": 0, "delet": [0, 6, 21, 22], "create_endpoint": 0, "creat": [0, 5, 6, 7, 10, 16, 19, 21, 22, 25, 28, 33], "reset_endpoint": 0, "reset": [0, 5, 28], "run_now_endpoint": 0, "submit_run_endpoint": 0, "get_run_endpoint": 0, "cancel_run_endpoint": 0, "cancel": [0, 21, 22], "delete_run_endpoint": 0, "repair_run_endpoint": 0, "repair": [0, 21, 22], "output_runs_job_endpoint": 0, "output": [0, 7, 19, 21, 22], "cancel_all_runs_endpoint": 0, "all": [0, 2, 7, 9, 10, 14, 21, 22, 23, 24, 28, 32, 33, 35], "install_libs_endpoint": 0, "librari": [0, 1, 5, 34], "instal": [0, 21, 22, 35], "uninstall_libs_endpoint": 0, "uninstal": [0, 22], "list_jobs_endpoint": 0, "list": [0, 2, 5, 7, 9, 10, 21, 22, 29, 33], "list_pipelines_endpoint": 0, "pipelin": [0, 5, 21, 22, 34], "workspace_get_status_endpoint": 0, "workspac": [0, 5, 16, 23, 33], "statu": [0, 21, 22], "spark_versions_endpoint": 0, "spark": [0, 2, 5, 7, 9, 10, 16, 22, 23, 34], "version": [0, 2, 5, 7, 9, 10, 21, 22, 24, 25, 32, 34, 35], "runstat": [0, 16], "life_cycle_st": 0, "result_st": [0, 16], "state_messag": 0, "arg": [0, 5, 22], "kwarg": [0, 2, 5, 6, 7, 9, 10], "util": [0, 4, 6, 32, 34], "state": [0, 16, 21, 22], "concept": [0, 22], "properti": 0, "is_termin": 0, "bool": [0, 2, 5, 6, 7, 29], "true": [0, 2, 5, 7, 14, 23, 26], "current": [0, 2, 5, 28, 34], "i": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "termin": [0, 5], "is_success": 0, "result": [0, 2, 5, 9, 10, 12, 21], "success": [0, 16], "run_life_cycle_st": [0, 21, 22], "pend": 0, "skip": [0, 21, 22], "internal_error": 0, "queu": [0, 21, 22], "__eq__": 0, "other": [0, 5, 21, 22, 26, 32, 33], "return": [0, 1, 2, 5, 6, 7, 9, 10, 12, 21, 22, 28], "self": [0, 5, 14, 25], "valu": [0, 5, 6, 7, 14, 19, 21, 22, 23, 33, 34], "__repr__": 0, "repr": 0, "to_json": 0, "classmethod": 0, "from_json": 0, "data": [0, 7, 19, 21, 22], "clusterst": [0, 21, 22], "is_run": 0, "cluster_life_cycle_st": 0, "resiz": 0, "error": [0, 21, 22, 28, 34], "unknown": [0, 1, 25], "databrickshook": [0, 21, 22], "databricks_conn_id": [0, 1, 2, 5, 6, 7, 9, 10, 12, 21, 22, 26, 29, 30, 31, 33], "basedatabrickshook": [0, 1, 2], "default_conn_nam": [0, 1, 2, 7, 9, 10], "timeout_second": [0, 1, 5, 28, 34], "180": [0, 1], "retry_limit": [0, 1, 12], "3": [0, 1, 5, 6, 12, 24, 28, 33], "retry_delai": [0, 1, 12], "retry_arg": [0, 1, 12], "none": [0, 1, 2, 5, 6, 7, 9, 10, 12, 25], "caller": [0, 1, 2], "base": [0, 1, 2, 5, 6, 7, 9, 10, 12, 21, 22, 33], "databricks_bas": [0, 2, 3, 4], "interact": [0, 1, 2, 33], "paramet": [0, 1, 2, 5, 6, 7, 9, 10, 12, 21, 22, 23, 26, 29, 30, 31, 32, 33], "str": [0, 1, 2, 5, 6, 7, 9, 10, 12, 22, 29, 30, 31], "refer": [0, 1, 2, 5, 6, 7, 9, 10, 12, 16, 34], "connect": [0, 1, 2, 5, 6, 7, 9, 10, 12, 21, 22, 29, 30, 31, 33], "int": [0, 1, 5, 6, 7, 12, 33], "The": [0, 1, 2, 5, 12, 14, 16, 19, 21, 23, 24, 25, 26, 28, 32, 33, 34, 35], "amount": [0, 1, 5, 6, 29, 30, 31], "time": [0, 1, 5, 6, 12, 21, 22, 29, 30, 31, 33, 34], "second": [0, 1, 5, 6, 12, 16, 19, 28, 29, 30, 31, 34], "request": [0, 1, 2, 5, 7, 9, 10, 22, 23, 24], "wait": [0, 1, 5, 6, 12, 29, 30, 31, 33], "befor": [0, 1, 2, 31], "out": [0, 1, 6, 21, 22, 35], "number": [0, 1, 5, 6, 7, 12, 22, 29, 30, 31], "retri": [0, 1, 5, 6, 12, 21, 22, 29, 30, 31], "case": [0, 1, 5, 6, 12, 21, 34, 35], "servic": [0, 1, 12, 21, 22, 23], "outag": [0, 1, 12], "float": [0, 1, 5, 6], "between": [0, 1, 5, 6, 12, 29, 30, 31], "might": [0, 1, 5, 6, 24, 35], "point": [0, 1, 5, 6, 22], "dict": [0, 1, 2, 5, 7, 9, 10, 12, 14, 21, 22], "ani": [0, 1, 2, 5, 7, 9, 10, 12, 21, 25], "an": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "option": [0, 1, 2, 5, 6, 7, 9, 10, 12, 21, 22, 23, 26, 29, 32, 33], "dictionari": [0, 1, 2, 5, 6, 7, 9, 10, 12, 23], "argument": [0, 1, 5, 12, 21, 22, 23, 28], "pass": [0, 1, 2, 5, 7, 12, 19, 22, 28, 32, 34], "tenac": [0, 1, 5, 12], "hook_nam": [0, 2], "create_job": 0, "json": [0, 5, 7, 14, 21, 22, 23, 26, 32], "function": [0, 2, 5, 10, 21, 22, 32, 34], "call": [0, 2, 5, 12, 21, 22, 28, 32, 34], "us": [0, 2, 5, 6, 7, 9, 10, 12, 16, 19, 21, 22, 23, 24, 25, 35], "bodi": [0, 22], "job_id": [0, 5, 22, 28, 32], "type": [0, 5, 7, 12, 14, 21, 22, 23, 28, 32, 33, 34], "reset_job": 0, "new_set": 0, "run_now": [0, 28], "run_id": [0, 5, 12], "submit_run": 0, "list_job": [0, 21, 22], "limit": [0, 33], "25": [0, 22], "expand_task": 0, "fals": [0, 2, 5, 6, 14], "job_nam": [0, 5, 32], "page_token": [0, 21], "batch": [0, 22], "size": 0, "retriev": [0, 5, 21], "whether": [0, 2, 5], "includ": [0, 22, 28, 34, 35], "task": [0, 5, 12, 16, 19, 21, 22, 28, 32, 33, 34], "detail": [0, 5, 21, 22, 25], "respons": [0, 21, 22], "name": [0, 2, 5, 6, 7, 9, 10, 21, 22, 23, 26, 29, 30, 31, 32, 33], "search": [0, 21, 22], "page": [0, 12, 22, 25], "token": [0, 1, 5, 6, 21, 22, 23], "first": [0, 5, 7, 16, 19, 21, 22, 28, 32, 34], "A": [0, 5], "find_job_id_by_nam": 0, "find": 0, "id": [0, 5, 6, 7, 9, 10, 12, 21, 22, 25, 30, 31, 32, 33, 34], "its": [0, 6, 21, 29, 31, 33], "ar": [0, 5, 7, 12, 21, 22, 23, 24, 25, 26, 28, 32, 33, 34, 35], "multipl": [0, 28, 32, 34], "same": [0, 5, 6, 7, 21, 28, 32, 34], "rais": 0, "airflowexcept": 0, "look": [0, 5, 7], "up": [0, 5, 22], "wa": [0, 2, 5, 12, 21, 28], "found": [0, 26, 32, 33, 35], "list_pipelin": 0, "batch_siz": 0, "pipeline_nam": [0, 34], "notebook_path": [0, 28, 34], "delta": [0, 5, 19, 34], "live": [0, 5, 34], "tabl": [0, 2, 5, 7, 9, 19, 26, 33, 34], "cannot": [0, 5, 21, 22], "combin": 0, "path": [0, 2, 5, 6, 7, 9, 10, 12, 16, 19, 23, 26, 29, 33, 34], "notebook": [0, 5, 16, 34], "find_pipeline_id_by_nam": 0, "pipeline_id": [0, 5, 34], "guid": [0, 5, 7, 22, 25], "string": [0, 2, 7, 9, 10, 14, 21, 22, 26, 29, 30, 31, 33], "get_run_page_url": 0, "run_page_url": [0, 5, 12], "url": [0, 6, 12, 23, 29], "async": [0, 1, 12, 21, 22], "a_get_run_page_url": 0, "get_job_id": 0, "from": [0, 5, 6, 7, 10, 14, 19, 21, 22, 23, 24, 26, 29, 35], "given": [0, 5, 6, 7, 29, 31, 33], "get_run_st": 0, "pleas": [0, 21, 25], "note": [0, 2, 5, 22, 23, 28, 32, 34], "method": [0, 5, 21, 22, 23], "failur": 0, "unless": [0, 2], "you": [0, 5, 21, 23, 24, 25, 28, 29, 30, 31, 32, 34, 35], "have": [0, 5, 14, 16, 21, 22, 23, 33, 35], "xcom": [0, 5, 21, 28], "pickl": 0, "can": [0, 5, 6, 7, 14, 21, 23, 24, 25, 28, 29, 32, 33, 34, 35], "done": [0, 35], "follow": [0, 5, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35], "environ": [0, 23], "variabl": [0, 23], "airflow__core__enable_xcom_pickl": 0, "If": [0, 2, 5, 6, 7, 9, 10, 12, 21, 23, 25, 28, 29, 34], "do": [0, 21, 22, 25, 33, 34], "want": [0, 12, 21, 25, 35], "get_run_state_str": 0, "describ": [0, 2, 7, 9, 10, 25, 32], "get_run_state_lifecycl": 0, "get_run_state_result": 0, "get_run_state_messag": 0, "individu": [0, 7, 22], "compon": [0, 23], "a_get_run_st": 0, "get_run": 0, "inform": [0, 5, 7, 12, 16, 21, 22, 35], "a_get_run": 0, "represent": [0, 5], "lifecycl": 0, "messag": 0, "get_run_output": 0, "cancel_run": 0, "cancel_all_run": 0, "activ": [0, 23], "asynchron": [0, 12], "canon": 0, "identifi": 0, "delete_run": 0, "non": [0, 14, 22], "repair_run": 0, "re": [0, 12, 22, 23], "one": [0, 5, 14, 21, 22, 25, 28, 32, 33, 34], "more": [0, 5, 6, 7, 16, 21, 22, 23, 32, 34], "get_cluster_st": 0, "cluster_id": 0, "a_get_cluster_st": 0, "restart_clust": 0, "contain": [0, 5, 6, 7, 9, 10, 14, 23, 25, 26], "specif": [0, 5, 7, 22, 23, 33, 34], "start_clust": 0, "terminate_clust": 0, "arrai": [0, 5, 34], "update_repo": [0, 31], "repo_id": [0, 6, 30, 31], "updat": [0, 6, 21, 22, 28], "repo": [0, 6, 17, 21, 22], "payload": [0, 5, 22, 28, 32, 34], "metadata": [0, 1], "delete_repo": [0, 30], "create_repo": [0, 29], "get_repo_by_path": 0, "obtain": [0, 23], "repositori": [0, 5, 6, 29], "exist": [0, 5, 6, 24, 28, 29, 30, 31, 32, 33, 34], "doesn": 0, "t": [0, 2, 6, 7, 21, 22, 23, 29, 30, 31, 32], "test_connect": [0, 21, 22], "test": [0, 21, 22, 26, 28, 29, 30, 31, 33, 34, 35], "ui": [0, 5, 28], "6": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "9": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "dev0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "experiment": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "featur": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "azure_default_ad_endpoint": 1, "login": [1, 23], "microsoftonlin": [1, 23], "azure_token_service_url": 1, "oauth2": 1, "azure_metadata_service_token_url": 1, "169": 1, "254": 1, "ident": [1, 21, 22, 23], "azure_metadata_service_instance_url": 1, "instanc": [1, 5, 21, 22], "token_refresh_lead_tim": 1, "120": 1, "azure_management_endpoint": 1, "manag": [1, 21, 22, 23, 25], "core": [1, 22, 26], "window": [1, 26], "net": [1, 26], "default_databricks_scop": 1, "2ff814a6": 1, "3304": 1, "4ab8": 1, "85cb": 1, "cd0e6f879c1d": 1, "oidc_token_service_url": 1, "oidc": 1, "v1": 1, "basehook": 1, "conn_name_attr": 1, "databricks_default": [1, 5, 6, 18, 23, 33], "conn_typ": 1, "extra_paramet": 1, "host": [1, 5, 6, 21, 22, 23], "use_azure_managed_ident": [1, 23], "azure_ad_endpoint": [1, 23], "azure_resource_id": [1, 23], "databricks_conn": 1, "get_conn": [1, 2], "user_agent_head": 1, "user_agent_valu": 1, "__aenter__": 1, "__aexit__": 1, "err": 1, "bearerauth": 1, "aiohttp": [1, 21, 22, 24], "basicauth": [1, 21, 22], "onli": [1, 2, 5, 7, 14, 21, 23, 26, 32, 33, 35], "ship": 1, "bearer": [1, 23], "auth": [1, 23], "we": [1, 5, 6, 14, 16, 21, 22, 29, 33, 35], "need": [1, 5, 12, 21, 22, 23, 24, 29, 30, 31, 34], "subclass": 1, "encod": [1, 23], "credenti": [1, 7, 23], "list_sql_endpoints_endpoint": 2, "sql": [2, 7, 9, 10, 19, 21, 22, 23, 24, 26, 33], "databrickssqlhook": [2, 7, 9, 10, 21, 22], "http_path": [2, 7, 9, 10, 23, 26, 33], "sql_endpoint_nam": [2, 7, 26, 33], "session_configur": [2, 7, 9, 10, 23], "http_header": [2, 7, 9, 10], "catalog": [2, 7, 9, 10, 33], "schema": [2, 7, 9, 10, 33], "return_tupl": 2, "common": [2, 5, 6, 7, 21, 22, 24], "dbapihook": [2, 9, 10, 21, 22], "specifi": [2, 5, 6, 7, 9, 10, 19, 21, 22, 23, 24, 26, 29, 32, 33], "should": [2, 5, 6, 7, 9, 10, 12, 21, 22, 23, 25, 33, 34, 35], "either": [2, 5, 7, 9, 10, 12, 23, 30, 31, 32, 34], "": [2, 5, 6, 7, 9, 10, 21, 22, 23, 25, 28, 29, 33, 34], "extra": [2, 5, 6, 7, 9, 10, 22, 23, 24], "must": [2, 5, 6, 7, 9, 10, 14, 23, 29, 33, 34], "abov": [2, 7, 25], "session": [2, 7, 9, 10, 21, 22, 23], "default": [2, 5, 6, 7, 9, 10, 12, 22, 33, 35], "could": [2, 7, 9, 10, 23, 26, 33], "tupl": [2, 7, 9, 10, 12, 21], "k": [2, 7, 9, 10], "v": [2, 7, 9, 10, 33], "pair": [2, 7, 9, 10], "set": [2, 5, 7, 9, 10, 16, 23], "header": [2, 7, 9, 10, 22, 23, 26], "everi": [2, 5, 7, 9, 10, 12], "initi": [2, 7, 9, 10, 21, 22, 28, 34], "requir": [2, 5, 6, 7, 9, 10, 21, 23, 26, 29, 30, 31, 32, 33, 35], "dbr": [2, 7], "namedtupl": 2, "object": [2, 5, 7, 10, 21, 22, 23, 34], "instead": [2, 5, 21, 22, 23, 34], "row": [2, 7, 21, 22], "In": [2, 5, 12, 16, 28, 32, 34], "futur": 2, "releas": [2, 21, 22, 24, 31], "becom": 2, "ensur": 2, "backward": 2, "compat": [2, 21, 22], "dure": [2, 5, 28, 34], "transit": 2, "phase": 2, "flag": [2, 23], "also": [2, 5, 7, 21, 25, 28, 34], "remov": [2, 21, 22, 25], "addit": [2, 7, 9, 10, 32], "connector": [2, 7, 9, 10, 21, 22, 23, 24], "iter": [2, 10], "autocommit": 2, "map": [2, 5, 23], "handler": [2, 9, 10], "split_stat": 2, "return_last": 2, "callabl": [2, 9, 10], "command": [2, 5, 7, 22, 26, 34], "statement": [2, 7, 10, 19, 21, 22], "them": [2, 21, 22, 24], "execut": [2, 5, 6, 7, 10, 16, 21, 22, 28, 31, 34], "sequenti": [2, 16], "what": 2, "queri": [2, 7, 10, 21, 22, 33], "commit": [2, 22], "so": [2, 21, 22, 28, 33, 35], "ha": [2, 16, 21], "effect": [2, 32, 34], "render": [2, 5, 6, 7], "which": [2, 5, 7, 16, 19, 21, 22, 23, 34, 35], "each": [2, 5, 28, 32, 33, 34], "split": 2, "singl": [2, 7, 12, 34], "separ": [2, 22, 35], "last": 2, "after": [2, 21, 22, 28], "express": [2, 7], "abstract": 2, "bulk_dump": 2, "tmp_file": 2, "dump": 2, "databas": [2, 7], "tab": 2, "delimit": 2, "file": [2, 5, 7, 19, 21, 22, 25, 26, 34], "target": 2, "bulk_load": 2, "load": [2, 19, 22, 26], "databricks_sql": [3, 4, 8, 11], "hook": [4, 7, 10, 21, 22, 23], "databricks_repo": [4, 8], "sensor": [4, 21, 22], "databricks_partit": [4, 11], "trigger": [4, 5, 21, 22, 32], "__version__": [4, 22], "defer_method_nam": 5, "execute_complet": [5, 21, 22], "xcom_run_id_kei": 5, "xcom_job_id_kei": 5, "xcom_run_page_url_kei": 5, "databricksjobrunlink": [5, 21, 22], "model": [5, 6, 7, 35], "baseoperatorlink": 5, "construct": [5, 7], "link": [5, 21, 22, 25], "monitor": 5, "see": [5, 6, 14, 21, 22, 23, 24, 29], "get_link": 5, "ti_kei": 5, "extern": [5, 33], "system": [5, 23, 26, 28, 29, 30, 31, 33, 34], "old": [5, 22], "signatur": [5, 22, 24, 25], "dttm": 5, "datetim": 5, "That": [5, 21], "still": [5, 21], "support": [5, 7, 21, 22, 23, 24, 26, 28, 29, 33, 34], "runtim": [5, 9, 10, 21, 22], "deprec": [5, 21, 22], "baseoper": [5, 6, 7], "associ": 5, "taskinstancekei": [5, 22], "taskinst": [5, 21, 22], "databrickscreatejobsoper": [5, 27], "tag": [5, 6, 28, 29, 31], "job_clust": [5, 28], "email_notif": [5, 28], "webhook_notif": [5, 28], "schedul": [5, 28], "max_concurrent_run": [5, 28], "git_sourc": [5, 21, 22, 28, 34], "access_control_list": [5, 28], "polling_period_second": [5, 12], "30": [5, 12, 22], "databricks_retry_limit": [5, 6, 29, 30, 31], "databricks_retry_delai": [5, 6, 29, 30, 31], "databricks_retry_arg": 5, "directli": [5, 28, 32, 34], "e": [5, 12, 23], "etc": 5, "merg": [5, 28, 34], "thei": [5, 12, 14, 28, 33, 34], "conflict": [5, 28, 34], "take": [5, 7, 28, 32, 34], "preced": [5, 28, 34], "overrid": [5, 21, 22, 28, 34], "top": [5, 24, 25, 28, 32, 34], "level": [5, 22, 28, 32, 34], "kei": [5, 6, 25, 28, 34], "templat": [5, 6, 7, 9, 10, 21, 22], "For": [5, 7, 16, 22, 23, 24, 25, 32, 33], "about": [5, 16, 22, 25, 35], "jinja": [5, 6, 7], "jobtaskset": 5, "share": [5, 28], "reus": [5, 23], "jobclust": 5, "jobemailnotif": 5, "webhooknotif": 5, "timeout": [5, 33], "appli": [5, 21, 22], "cronschedul": 5, "maximum": 5, "allow": [5, 21, 22, 23, 32, 34], "concurr": 5, "remot": 5, "gitsourc": 5, "permiss": [5, 23], "accesscontrolrequestforus": 5, "accesscontrolrequestforgroup": 5, "accesscontrolrequestforserviceprincip": 5, "order": [5, 24], "acl": 5, "consid": [5, 23], "control": [5, 7, 12, 28, 34], "rate": [5, 12], "poll": [5, 12], "By": [5, 6, 12, 25], "backend": [5, 6, 29, 30, 31], "unreach": [5, 6, 29, 30, 31], "Its": [5, 6], "greater": [5, 6], "than": [5, 6, 28], "equal": [5, 6], "template_field": [5, 6, 7, 9, 10, 21, 22], "sequenc": [5, 6, 7, 9, 10, 21, 22], "ui_color": 5, "1cb1c2": 5, "ui_fgcolor": 5, "fff": 5, "context": [5, 6, 7, 9, 10, 12, 22], "deriv": [5, 6, 7, 21, 22], "when": [5, 6, 7, 12, 14, 21, 22, 23, 24, 28, 34, 35], "get_template_context": [5, 6, 7], "databrickssubmitrunoper": [5, 16, 21, 22, 27], "spark_jar_task": [5, 34], "notebook_task": [5, 28, 34], "spark_python_task": [5, 34], "spark_submit_task": [5, 34], "pipeline_task": [5, 21, 22, 34], "dbt_task": [5, 34], "new_clust": [5, 28, 34], "existing_cluster_id": [5, 34], "run_nam": [5, 34], "do_xcom_push": [5, 21, 22], "idempotency_token": 5, "wait_for_termin": [5, 21, 22], "deferr": [5, 21, 22, 32, 34], "conf": 5, "getboolean": 5, "default_deferr": [5, 21, 22], "fallback": 5, "jobsrunssubmit": 5, "There": [5, 23, 25, 28, 32, 33, 34], "three": [5, 28, 34], "wai": [5, 23, 28, 32, 33, 34], "instanti": [5, 12, 28, 32, 34], "how": [5, 7, 22, 25], "runsubmittaskset": 5, "100": 5, "item": 5, "main": [5, 22, 25, 34, 35], "jar": [5, 16, 34], "actual": [5, 29], "OR": 5, "field": [5, 6, 14, 21, 22, 23], "jobssparkjartask": 5, "jobsnotebooktask": 5, "python": [5, 21, 22, 24, 25, 34], "jobssparkpythontask": 5, "jobssparksubmittask": 5, "least": [5, 21, 29], "jobspipelinetask": 5, "dbt": [5, 21, 22, 34], "spec": [5, 34], "new": [5, 16, 21, 22, 28, 32, 34, 35], "except": [5, 6, 14, 21, 22, 29, 32, 35], "jobsclusterspecnewclust": 5, "managedlibrarieslibrari": 5, "task_id": [5, 26, 28, 29, 30, 31, 33, 34], "superclass": 5, "guarante": 5, "idempot": 5, "alreadi": [5, 6, 25, 29], "doe": [5, 14, 21], "most": [5, 25], "64": 5, "charact": [5, 22], "repres": [5, 21, 22, 33], "access": [5, 23, 33], "consist": [5, 21], "subject": [5, 22], "user_nam": 5, "user": [5, 6, 17, 21, 22, 23, 25, 29, 30, 31, 33, 34], "group_nam": 5, "group": 5, "permission_level": 5, "document": [5, 7, 21, 22, 23, 26, 29, 32, 33], "mean": 5, "To": [5, 6, 25, 29, 30, 31], "authent": [5, 6, 7, 21, 22], "leav": [5, 6, 23], "empti": [5, 6, 21, 22, 23], "push": [5, 21], "git": [5, 6, 29, 31], "mode": 5, "template_ext": [5, 7, 9, 10, 21, 22], "tpl": 5, "operator_extra_link": 5, "on_kil": 5, "clean": [5, 22], "subprocess": 5, "kill": 5, "thread": 5, "multiprocess": 5, "within": [5, 21, 22, 28], "ghost": 5, "process": [5, 12, 21, 22], "behind": 5, "event": [5, 12, 14, 21, 22, 33], "databrickssubmitrundeferrableoper": [5, 27], "databricksrunnowoper": [5, 21, 22, 27], "notebook_param": [5, 32], "python_param": [5, 32], "jar_param": [5, 32], "spark_submit_param": [5, 32], "python_named_param": 5, "two": [5, 16, 32], "typic": [5, 28, 32, 34], "our": [5, 22, 28, 32, 34], "through": [5, 28, 32, 34], "exampl": [5, 9, 16, 19, 22, 23, 24, 25, 32], "42": 5, "dry": 5, "oldest": 5, "1457570074236": 5, "notebook_run": [5, 34], "anoth": [5, 12, 32, 34], "accomplish": [5, 28, 32, 34], "thing": [5, 28, 32, 33, 34], "exactli": [5, 28, 32, 33, 34], "your": [5, 21], "code": [5, 7, 21, 22, 25, 31], "would": 5, "like": [5, 12, 29, 30, 31], "dougla": 5, "adam": 5, "org": [5, 25], "apach": [5, 21, 25], "sparkpi": 5, "where": [5, 34, 35], "both": [5, 16, 23, 28, 34], "AND": [5, 28, 34], "togeth": [5, 7, 28, 34], "python_named_paramet": [5, 32], "It": [5, 25, 32, 33, 34], "mutual": 5, "exclus": 5, "g": [5, 12, 23], "john": 5, "ag": 5, "35": 5, "dbutil": 5, "widget": 5, "upon": 5, "conjunct": 5, "exce": 5, "10": [5, 12, 21, 22, 24, 34], "000": 5, "byte": 5, "line": [5, 22], "overwrit": 5, "wheel": [5, 24], "script": [5, 22, 25], "databricksrunnowdeferrableoper": [5, 21, 22, 27], "databricksreposcreateoper": [6, 27], "git_url": [6, 29], "git_provid": [6, 29], "branch": [6, 29, 31, 35], "repo_path": [6, 17, 29, 30, 31], "ignore_existing_repo": [6, 29], "check": [6, 9, 21, 22, 25, 28, 33, 34], "guess": [6, 29], "format": [6, 7, 19, 21, 22, 26, 33], "folder": [6, 22, 25], "directori": [6, 23, 25, 29], "checkout": [6, 29], "don": [6, 21, 22, 29], "throw": [6, 14, 29, 32], "__git_providers__": 6, "__aws_code_commit_regexp__": 6, "__repos_path_regexp__": 6, "static": [6, 22], "__detect_repo_provider__": 6, "databricksreposupdateoper": [6, 27], "patch": [6, 22], "omit": 6, "databricksreposdeleteoper": [6, 27], "databrickssqloper": [7, 19, 21, 22, 23, 27], "output_path": [7, 33], "output_format": [7, 33], "csv": 7, "csv_param": 7, "client_paramet": [7, 9, 10], "sqlexecutequeryoper": [7, 21, 22], "recogn": 7, "end": [7, 22], "write": 7, "select": [7, 19, 25], "possibl": [7, 22], "jsonl": [7, 33], "dictwrit": 7, "template_fields_render": [7, 9, 10], "conn_id_field": 7, "get_db_hook": 7, "copy_into_approved_format": 7, "avro": [7, 26], "orc": [7, 26], "parquet": [7, 26], "text": [7, 26], "binaryfil": [7, 26], "databrickscopyintooper": [7, 19, 21, 22, 27], "table_nam": [7, 9, 26, 33], "file_loc": [7, 19, 26], "file_format": [7, 26], "pattern": 7, "expression_list": 7, "storage_credenti": 7, "encrypt": 7, "format_opt": [7, 26], "force_copi": [7, 26], "copy_opt": 7, "valid": [7, 14, 25], "copi": [7, 26], "INTO": [7, 26], "piec": 7, "locat": [7, 26], "import": [7, 21, 22, 25], "regex": 7, "match": [7, 21, 22, 25], "configur": [7, 26, 33], "against": [7, 33], "uniti": 7, "storag": 7, "destin": 7, "forc": 7, "integ": [7, 29, 30, 31], "n": 7, "right": 7, "_file_loc": 7, "_file": 7, "_table_nam": 7, "databrickspartitionsensor": [9, 21, 22, 27], "sql_warehouse_nam": [9, 10, 33], "partit": [9, 33], "partition_oper": [9, 33], "fetch_all_handl": [9, 10], "basesensoroper": [9, 10], "detect": [9, 21, 22, 28, 34], "presenc": [9, 33], "warehous": [9, 10, 33], "below": [9, 10, 24, 25], "purpos": [9, 10], "date": [9, 33], "2023": [9, 22, 33], "01": [9, 22, 33], "03": [9, 22, 33], "abc": [9, 33], "def": [9, 33], "comparison": [9, 33], "poke": [9, 10, 33], "databrickssqlsensor": [10, 21, 22, 27], "databricksexecutiontrigg": [12, 14], "basetrigg": 12, "handl": [12, 21, 22], "logic": 12, "commun": 12, "serial": [12, 21, 22], "reconstruct": 12, "keyword": 12, "yield": [12, 21, 22], "whenev": 12, "fire": 12, "off": 12, "finish": [12, 33], "thu": 12, "immedi": 12, "resum": 12, "veri": 12, "quickli": 12, "mai": [12, 22, 23, 34], "workload": 12, "being": 12, "move": [12, 21, 22], "multi": [12, 21, 22], "defer": 12, "assum": 12, "persist": 12, "reli": [12, 21, 28], "cleanup": [12, 22], "longer": 12, "normalise_json_cont": 14, "json_path": 14, "normal": [14, 22], "numer": 14, "boolean": [14, 21, 22, 23], "reason": [14, 35], "why": [14, 25], "becaus": [14, 16, 28, 34], "render_templ": 14, "fail": [14, 21, 22], "convert": [14, 21, 22], "understand": 14, "validate_trigger_ev": 14, "correct": [14, 21, 22, 25], "receiv": [14, 35], "dag": [16, 19, 21, 22], "upload": 16, "dbf": [16, 34], "downstream": [16, 33], "depend": [16, 21, 22, 32, 35], "NOT": 16, "until": [16, 33], "complet": [16, 21], "successfulli": 16, "definit": 16, "env_id": [16, 17, 18, 19], "dag_id": [16, 17, 18, 19], "example_databricks_oper": 16, "test_run": [16, 17, 18, 19], "default_arg": [17, 22], "example_databricks_repos_oper": 17, "domain": [17, 29, 30, 31], "demo": [17, 29, 30, 31], "connection_id": [18, 19, 26, 33], "insert": [19, 33], "third": [19, 28], "store": [19, 33], "fourth": 19, "written": 19, "final": [19, 21, 22], "example_databricks_sql_oper": 19, "my_connect": 19, "example_databrick": [20, 28, 34], "example_databricks_repo": [20, 29, 30, 31], "example_databricks_sensor": [20, 33], "example_databricks_sql": [20, 26, 33], "airflow": [21, 23, 25, 29, 30, 31, 32, 34, 35], "provid": [21, 25, 26, 28, 29, 30, 31, 33, 34, 35], "databrick": [21, 25, 26, 28, 32, 33, 34], "avail": [21, 25, 34], "explain": 21, "polici": [21, 35], "structur": [21, 22], "dbapi": [21, 22], "class": [21, 22, 24, 26, 33, 34], "36205": 21, "implement": [21, 22], "fetchon": [21, 22], "odbchook": [21, 22], "36161": [21, 22], "bump": [21, 22], "minimum": [21, 22, 24], "36017": [21, 22], "typo": [21, 22], "36248": [21, 22], "add": [21, 22, 23], "snippet": [21, 22], "docstr": [21, 22], "via": [21, 22, 24, 25, 29, 30, 31, 32, 33, 34], "ruff": [21, 22], "36262": [21, 22], "make": [21, 22], "pyodbc": [21, 22], "serializ": [21, 22], "make_serializ": [21, 22], "32319": [21, 22], "offset": [21, 22], "been": 21, "favor": 21, "faster": 21, "pagin": [21, 22], "similarli": 21, "34926": [21, 22], "35156": [21, 22], "34643": [21, 22], "respect": [21, 22, 33], "soft_fail": [21, 22], "34544": [21, 22], "34517": [21, 22], "decod": [21, 22], "f": [21, 22], "34518": [21, 22], "min": [21, 22], "34728": [21, 22], "httpbasicauth": [21, 22], "34590": [21, 22], "33472": [21, 22], "deploy": [21, 22], "33886": [21, 22], "accept": [21, 22, 33], "32903": [21, 22], "replac": [21, 22], "concaten": [21, 22], "unpack": [21, 22], "33933": [21, 22], "improv": [21, 22], "modul": [21, 22], "some": [21, 22], "block": [21, 22], "33754": [21, 22], "liter": [21, 22], "33761": [21, 22], "33752": [21, 22], "exclud": 21, "due": [21, 22], "properli": 21, "declar": 21, "urllib3": 21, "github": [21, 22, 29], "issu": 21, "190": 21, "princip": [21, 22, 23], "oauth": [21, 22, 23], "33005": [21, 22], "py": [21, 22, 26, 28, 29, 30, 31, 33, 34], "32340": [21, 22], "33519": [21, 22], "refactor": [21, 22], "duplic": [21, 22], "sort": [21, 22], "33675": [21, 22], "simplifi": [21, 22], "condit": [21, 22], "len": [21, 22], "33569": [21, 22], "smaller": [21, 22], "33234": [21, 22], "conn": [21, 22], "30784": [21, 22], "32806": [21, 22], "miss": [21, 22], "32689": [21, 22], "accur": [21, 22], "31846": [21, 22], "modifi": [21, 22], "parent": [21, 22], "32253": [21, 22], "config": [21, 22], "31712": [21, 22], "drop": [21, 22, 25, 33], "loop": [21, 22], "stop": [21, 22], "31985": [21, 22], "annot": [21, 22], "31888": [21, 22], "31780": [21, 22], "relat": [21, 22, 23, 33], "again": [21, 22], "31898": [21, 22], "31899": [21, 22], "31703": [21, 22], "30963": [21, 22], "31136": [21, 22], "31038": [21, 22], "param": [21, 22, 34], "databr": [21, 22], "30744": [21, 22], "30786": [21, 22], "30980": [21, 22], "30917": [21, 22], "30761": [21, 22], "inact": [21, 22], "30646": [21, 22], "30477": [21, 22], "taskflow": [21, 22], "29840": [21, 22], "conform": 21, "semant": 21, "kind": 21, "previous": 21, "pre": [21, 22], "cursor": 21, "descript": [21, 22], "just": 21, "last_descript": 21, "suitabl": 21, "gener": [21, 22, 23, 33], "lineag": 21, "analysi": 21, "had": 21, "custom": 21, "behaviour": [21, 22], "adapt": 21, "standard": 21, "approach": [21, 28, 34], "howev": 21, "unchang": 21, "continu": 21, "work": [21, 23], "without": 21, "introduc": [21, 22, 32, 34], "27854": [21, 22], "27888": [21, 22], "27868": [21, 22], "27912": [21, 22], "27196": [21, 22], "urlpars": [21, 22], "urlsplit": [21, 22], "27389": [21, 22], "25717": [21, 22], "27446": [21, 22], "25623": [21, 22], "lower": [21, 22], "bound": [21, 22], "25789": [21, 22], "26628": [21, 22], "agent": [21, 22], "25873": [21, 22], "25578": [21, 22], "25260": [21, 22], "telemetri": [21, 22], "25115": [21, 22], "unifi": [21, 22], "23971": [21, 22], "25114": [21, 22], "deep_string_coerc": [21, 22], "25394": [21, 22], "correctli": [21, 22], "25427": [21, 22], "x": [21, 22, 28, 34], "25674": [21, 22], "ad": [21, 22, 23], "24945": [21, 22], "24617": [21, 22], "24836": [21, 22], "functool": [21, 22], "cached_properti": [21, 22], "24582": [21, 22], "19736": [21, 22], "23620": [21, 22], "defin": [21, 22, 23], "23622": [21, 22], "23641": [21, 22], "unboundlocalerror": [21, 22], "23815": [21, 22], "dbsql": [21, 22], "switch": [21, 22, 23], "further": [21, 22], "23199": [21, 22], "22422": [21, 22], "22541": [21, 22], "22886": [21, 22], "22885": [21, 22], "hoc": [21, 22], "22571": [21, 22], "22278": [21, 22], "mistakenli": 21, "install_requir": 21, "22382": 21, "22076": [21, 22], "429": [21, 22], "well": [21, 22, 25], "21852": [21, 22], "22221": [21, 22], "show": [21, 22], "21709": [21, 22], "21663": [21, 22], "18925": [21, 22], "21530": [21, 22], "21363": [21, 22], "januari": [21, 22], "2022": [21, 22], "delai": [21, 22], "21439": [21, 22], "21494": [21, 22], "20536": [21, 22], "20526": [21, 22], "attr": [21, 22], "20540": [21, 22], "verif": [21, 22], "20550": [21, 22], "19723": [21, 22], "azur": [21, 22, 23], "sp": [21, 22], "cloud": [21, 22, 23], "19722": [21, 22], "pat": [21, 22, 23], "password": [21, 22, 23], "19585": [21, 22], "19544": [21, 22], "19412": [21, 22], "aad": [21, 22, 23], "19335": [21, 22], "19443": [21, 22], "db": [21, 22], "__init__": [21, 22], "20180": [21, 22], "fixup": [21, 22], "19099": [21, 22], "expir": [21, 22], "20036": [21, 22], "18339": [21, 22], "optimis": 21, "auto": [21, 22], "apply_default": [21, 22], "decor": [21, 22], "15667": [21, 22], "upgrad": [21, 22, 35], "otherwis": 21, "packag": [21, 23], "automat": [21, 22], "manual": 21, "migrat": [21, 22], "readm": [21, 22], "chang": [22, 35], "high": 22, "changelog": 22, "12": [22, 25, 28, 34], "23": 22, "b15d5578da": 22, "2nd": 22, "wave": 22, "decemb": 22, "36380": 22, "f5883d6e7b": 22, "prepar": [22, 35], "36373": 22, "5fe5d31a46": 22, "22": 22, "322aa649": 22, "21": 22, "fix": [22, 35], "e9ba37bb58": 22, "17": 22, "64931b1a65": 22, "1st": 22, "rc2": 22, "36190": 22, "36010f6d0e": 22, "11": [22, 25, 34], "999b70178a": 22, "08": 22, "36112": 22, "d0918d77ee": 22, "07": 22, "24": 22, "0b23d5601c": 22, "novemb": 22, "35836": 22, "99534e47f3": 22, "19": 22, "reproduc": 22, "build": [22, 25], "35693": 22, "064fc2b775": 22, "99df205f42": 22, "16": 22, "reappli": 22, "35686": 22, "1b059c57d6": 22, "35537": 22, "10bac853d2": 22, "28": 22, "d1c58d86de": 22, "3rd": 22, "octob": 22, "35233": 22, "3592ff4046": 22, "35187": 22, "a8784e3c35": 22, "dd7ba3cae1": 22, "292": 22, "35053": 22, "7a93b19138": 22, "d401": 22, "daskexecutor": 22, "inclus": 22, "34935": 22, "13": 22, "e9987d5059": 22, "34916": 22, "946b539f0d": 22, "0c8e30e43b": 22, "05": 22, "7ebf4220c9": 22, "09": 22, "usag": [22, 26, 28, 29, 30, 31, 33, 34], "34320": 22, "a1ef232230": 22, "f26fa6d602": 22, "3813ed69c7": 22, "966c2bce9f": 22, "dfec053371": 22, "21990ed894": 22, "34201": 22, "c45617c4d5": 22, "55976af32": 22, "31": 22, "concatin": 22, "f7a005db8c": 22, "9d8c77e447": 22, "27": [22, 24], "b11525702c": 22, "26": 22, "c90eec9365": 22, "c077d19060": 22, "aug": 22, "33730": 22, "dc47c460dc": 22, "4154cc04ce": 22, "2dbb963324": 22, "1cdd82391e": 22, "a91ee7ac2f": 22, "20": 22, "8bf53dd554": 22, "14": 22, "5f8f25b34c": 22, "ecldud": 22, "bug": [22, 35], "33311": 22, "b5a4d36383": 22, "33291": 22, "9736143468": 22, "29": 22, "d06b7af69a": 22, "juli": 22, "32875": 22, "58e21c66fd": 22, "6313e52932": 22, "60c49ab2df": 22, "06": 22, "225e3041d2": 22, "32381": 22, "3878fe6fab": 22, "spuriou": 22, "32373": 22, "cb4927a018": 22, "32298": 22, "f8593503cb": 22, "6b4350e89c": 22, "d1aa509bbd": 22, "d205": 22, "32243": 22, "09d4718d3a": 22, "32125": 22, "79bcc2e668": 22, "rc1": 22, "june": 22, "32001": 22, "8b146152d6": 22, "32015": 22, "69bc90b824": 22, "66299338eb": 22, "18": 22, "7b096483fa": 22, "049c6184b7": 22, "9276310a43": 22, "31681": 22, "86b5ba2802": 22, "04": 22, "dc5bf3fd02": 22, "02": 22, "discover": 22, "yaml": 22, "31576": 22, "a59076eae": 22, "d400": 22, "pydocstyl": 22, "31427": 22, "9fa75aaf7a": 22, "45548b9451": 22, "31416": 22, "abea189022": 22, "31393": 22, "f5aed58d9f": 22, "circular": 22, "caus": 22, "31379": 22, "d9ff55cf6d": 22, "31252": 22, "fdc7a31aeb": 22, "edd7133a13": 22, "3df0be0f6f": 22, "ac46902154": 22, "31033": 22, "0a30706aa7": 22, "airflowproviderdeprecationwarn": 22, "30975": 22, "eef5bc7f16": 22, "full": [22, 28, 34], "autom": 22, "30994": 22, "a7eb32a5b2": 22, "9409446097": 22, "cli": 22, "cmd": 22, "info": 22, "30822": 22, "ecb9a9ea78": 22, "9bebf85e24": 22, "7d02277ae1": 22, "e46ce78b66": 22, "adhoc": 22, "30787": 22, "37cf0506b5": 22, "1e311cf036": 22, "d23a3bbed8": 22, "mechan": 22, "suspend": 22, "30422": 22, "55dbf1ff1f": 22, "april": 22, "30378": 22, "c3867781e0": 22, "29950": 22, "c405ecb63": 22, "25bdbc8e67": 22, "rc3": 22, "27937": 22, "db5375bea7": 22, "2e20e9f7eb": 22, "relas": 22, "27774": 22, "80c327bd3b": 22, "ea306c9462": 22, "a343bba1e3": 22, "15": 22, "12c3c39d1a": 22, "27613": 22, "00af5c007": 22, "eb06c65556": 22, "9ab1a6a3e7": 22, "style": 22, "26872": 22, "78b8ea2f22": 22, "2a34dc9e84": 22, "27205": 22, "ecd4d6654f": 22, "f8db64c35c": 22, "septemb": 22, "26731": 22, "89e44c46ad": 22, "06acf40a43": 22, "pep": 22, "563": 22, "postpon": 22, "evalu": 22, "26289": 22, "5066844513": 22, "period": 22, "batch02": 22, "25268": 22, "25a9c6a905": 22, "9535ec0bba": 22, "ca9229b6f": 22, "7d0525a55b": 22, "rc4": 22, "25720": 22, "4d32f61fd0": 22, "e5ac6c7cfb": 22, "august": 22, "25618": 22, "52f2f5bfa8": 22, "0255a0a5e7": 22, "679a85325a": 22, "82f842ffc5": 22, "24599": 22, "54a8c4fd2a": 22, "7438707747": 22, "df00436569": 22, "2f70daf5ac": 22, "d2459a241b": 22, "25030": 22, "8dfe7bf5ff": 22, "acaa0635c8": 22, "lazi": 22, "log": 22, "interpol": 22, "24910": 22, "46bbfdade0": 22, "96b01a8012": 22, "bad": 22, "codebas": 22, "24841": 22, "0de31bd73a": 22, "insid": [22, 23], "24672": 22, "510a6bab45": 22, "24702": 22, "ed37c3a0e8": 22, "9c59831ee7": 22, "dcdcf3a2b8": 22, "24307": 22, "717a7588bc": 22, "doubl": 22, "24292": 22, "aeabe994b3": 22, "24231": 22, "027b707d21": 22, "explanatori": 22, "contributor": [22, 23], "24229": 22, "ddf9013098": 22, "aip": 22, "47": 22, "design": [22, 33], "22442": 22, "24203": 22, "acf89510cd": 22, "92ddcf4ac6": 22, "flake8": 22, "implicit": 22, "concat": 22, "plugin": 22, "23873": 22, "6150d28323": 22, "cf5a78e91c": 22, "d0a5b3a4f2": 22, "75c60923e0": 22, "23631": 22, "428a439953": 22, "23591": 22, "a58506b2a6": 22, "address": 22, "review": 22, "comment": 22, "6a3d6cc32b": 22, "7b3bf4e435": 22, "f02b0b6b40": 22, "8b6b0848a3": 22, "brees": 22, "pull": 22, "verifi": [22, 24], "imag": 22, "23104": 22, "40831144be": 22, "march": 22, "22979": 22, "7be57eb256": 22, "aa8c08db38": 22, "6933022e94": 22, "mypi": 22, "22884": 22, "56ab82ed7a": 22, "mid": 22, "22819": 22, "1b12c93ed3": 22, "95169d1d07": 22, "352d7f72dd": 22, "c063fc688c": 22, "black": 22, "precommit": 22, "22521": 22, "d7dbfb7e26": 22, "bugfix": [22, 35], "22383": 22, "cc920963a6": 22, "16adc035b1": 22, "classifi": 22, "22226": 22, "12e9e2c695": 22, "af9d85ccd8": 22, "4014194320": 22, "f5b96315fe": 22, "feb": 22, "22056": 22, "62bf1276f6": 22, "27d19e7626": 22, "a1845c68f9": 22, "7cca82495b": 22, "0a2d0d1ecb": 22, "d94fa37830": 22, "6c3a67d4fc": 22, "2021": [22, 25], "21257": 22, "602abe8394": 22, "sphinx": 22, "autoapi": 22, "typehint": 22, "20951": 22, "f77417eb0d": 22, "k8": 22, "pypi": [22, 24, 35], "20614": 22, "97496ba2b4": 22, "20523": 22, "0bf424f37f": 22, "20598": 22, "d56e7b56bb": 22, "friendli": 22, "20571": 22, "a0821235fb": 22, "everywher": 22, "20565": 22, "c5c18c54fa": 22, "d3b3161f0d": 22, "58afc19377": 22, "e7659d08b0": 22, "cad39274d9": 22, "20265": 22, "820bfed515": 22, "20205": 22, "66f94f95c2": 22, "545ca59ba9": 22, "unhid": 22, "entri": 22, "20128": 22, "637db1a0ba": 22, "20086": 22, "728e94a47": 22, "19835": 22, "4925b37b66": 22, "853576d901": 22, "19882": 22, "11998848a4": 22, "56bdfe7a84": 22, "244627e3da": 22, "0a4a8bdb94": 22, "8ae878953b": 22, "28b51fb7bd": 22, "3a0c455855": 22, "d9567eb106": 22, "19321": 22, "f5ad26dcdd": 22, "840ea3efb9": 22, "18613": 22, "ef037e7021": 22, "start_dat": 22, "misc": 22, "18597": 22, "0b7b13372f": 22, "0a68588479": 22, "17890": 22, "be75dcd39c": 22, "meta": 22, "76ed2a49c6": 22, "lazili": 22, "17682": 22, "87f408b1e7": 22, "17116": 22, "b916b75079": 22, "17015": 22, "866a601b76": 22, "pylint": 22, "toolchain": 22, "16682": 22, "bbc627a3da": 22, "16501": 22, "cbf8001d76": 22, "synchron": 22, "buggfix": 22, "16464": 22, "1fba5402bb": 22, "16405": 22, "9c94b72d44": 22, "16294": 22, "37681bca00": 22, "807ad32ce5": 22, "pip": [22, 24, 25], "15576": 22, "df143aee8d": 22, "rework": 22, "15444": 22, "49cae1f052": 22, "15410": 22, "68e4c4dcb0": 22, "backport": 22, "14886": 22, "88bdcfa0df": 22, "14013": 22, "ac2f72c98d": 22, "13767": 22, "a9ac2b040b": 22, "flynt": 22, "13732": 22, "3fd5ef3555": 22, "logo": 22, "integr": [22, 23], "13717": 22, "295d66f914": 22, "2020": 22, "grammar": 22, "warn": [22, 25], "13380": 22, "6cf76d7ac0": 22, "13148": 22, "32971a1a2d": 22, "12955": 22, "b40dffa085": 22, "renam": 22, "rema": 22, "12917": 22, "9b39f24780": 22, "dynam": 22, "form": 22, "per": 22, "12558": 22, "bd90136aaf": 22, "12681": 22, "c34ef853c8": 22, "12444": 22, "0080354502": 22, "0b2": 22, "12449": 22, "7ca0b6f121": 22, "markdownlint": 22, "rule": [22, 35], "md003": 22, "head": 22, "12427": 22, "12438": 22, "ae7cb4a1e2": 22, "wrong": 22, "hash": 22, "12390": 22, "6889a333cf": 22, "ref": 22, "12366": 22, "7825e8f590": 22, "12304": 22, "b027223132": 22, "12316": 22, "85a18e13d9": 22, "project": [22, 34], "cross": 22, "12212": 22, "59eb5de78c": 22, "come": 22, "0beta1": 22, "12206": 22, "b2a28d1590": 22, "12082": 22, "7e0d08e1f0": 22, "12175": 22, "4e8f9cc8d0": 22, "formmatt": 22, "9550": 22, "8c42cf1b00": 22, "pyupgrad": 22, "11447": 22, "5a439e84eb": 22, "2a1": 22, "11855": 22, "872b1566a1": 22, "setup": [22, 33], "11826": 22, "349b0811c3": 22, "d200": 22, "11688": 22, "16e7129719": 22, "11487": 22, "0a0e1af800": 22, "broken": 22, "markdown": 22, "toc": 22, "11249": 22, "ca4238eb4d": 22, "month": 22, "11242": 22, "5220e4c384": 22, "11238": 22, "54353f8745": 22, "increas": 22, "coverag": 22, "five": 22, "differ": [22, 23, 25], "11170": 22, "966a06d96b": 22, "fetch": 22, "suppli": [22, 33], "10762": 22, "9549274d11": 22, "8b1": 22, "10818": 22, "fdd9b6f65b": 22, "10543": 22, "bfefcce0c9": 22, "rest": [22, 28, 34], "10462": 22, "3696c34c28": 22, "word": 22, "10528": 22, "2f2d8dbfaf": 22, "noinspect": 22, "nativ": 22, "intellij": 22, "10525": 22, "ee7ca128a1": 22, "refernc": 22, "10483": 22, "cdec301254": 22, "10205": 22, "7d24b088cd": 22, "example_dag": 22, "9985": 22, "e13a14c873": 22, "whitespac": 22, "9458": 22, "d0e7db4024": 22, "fresh": 22, "9408": 22, "12af6a0800": 22, "23rc1": 22, "9404": 22, "c7e5bce57f": 22, "candid": 22, "9370": 22, "f6bd817a3a": 22, "transfer": 22, "9320": 22, "0b0e4f7a4c": 22, "9026": 22, "00642a46d0": 22, "remain": 22, "wrongli": 22, "8994": 22, "f1073381ed": 22, "8846": 22, "375d1ca229": 22, "8898": 22, "12c5e5d8a": 22, "8891": 22, "f3521fb0e3": 22, "regener": 22, "8886": 22, "92585ca4cb": 22, "8807": 22, "649935e8c": 22, "8472": 22, "_do_api_cal": 22, "8473": 22, "16903ba3a6": 22, "8474": 22, "8475": 22, "5648dfbc30": 22, "super": 22, "amazon": 22, "cloudant": 22, "7827": 22, "3320e432a1": 22, "6817": 22, "keep": 22, "face": 22, "untouch": 22, "7517": 22, "4d03e33c11": 22, "explicit": 22, "md": 22, "squash": 22, "rebas": 22, "7456": 22, "97a429f9d0": 22, "6714": 22, "magic": 22, "utf": 22, "8": [22, 34], "7338": 22, "83c037873f": 22, "6674": [22, 25], "accord": 22, "7287": 22, "c42a375e79": 22, "6644": 22, "7265": 22, "sever": 23, "person": 23, "recommend": [23, 25], "usernam": 23, "account": [23, 26], "discourag": 23, "secret": 23, "outsid": 23, "owner": [23, 25], "vm": 23, "assign": 23, "sent": 23, "basic": 23, "plan": 23, "httpoper": 23, "aw": 23, "secur": 23, "necessari": 23, "service_principal_oauth": 23, "client": 23, "azure_tenant_id": 23, "tenant": 23, "resourc": 23, "isn": [23, 30, 31, 32], "special": [23, 33], "govcloud": 23, "china": 23, "germani": 23, "protocol": 23, "de": 23, "uri": [23, 26], "syntax": 23, "export": 23, "airflow_conn_databricks_default": 23, "yourtoken": 23, "4": 24, "those": [24, 25], "checksum": [24, 25], "site": 24, "sdist": [24, 25], "asc": [24, 25], "sha512": [24, 25], "download": 25, "offici": 25, "choos": 25, "down": 25, "left": 25, "whl": 25, "origin": 25, "softwar": 25, "foundat": 25, "pgp": 25, "essenti": 25, "sha": 25, "gpg": 25, "relev": 25, "distribut": 25, "mirror": 25, "pgpk": 25, "ka": 25, "binari": 25, "pgpv": 25, "tar": 25, "gz": 25, "made": 25, "sat": 25, "sep": 25, "49": 25, "54": 25, "bst": 25, "rsa": 25, "cde15c6e4d3a8ec4ecf4ba4b6674e08ad7de406f": 25, "issuer": 25, "kaxilnaik": 25, "good": [25, 35], "kaxil": 25, "naik": 25, "aka": 25, "gmail": 25, "certifi": 25, "trust": 25, "indic": 25, "belong": 25, "primari": 25, "fingerprint": 25, "cde1": 25, "5c6e": 25, "4d3a": 25, "8ec4": 25, "ecf4": 25, "ba4b": 25, "e08a": 25, "d7de": 25, "406f": 25, "worri": 25, "certif": 25, "sign": 25, "server": 25, "previou": 25, "step": 25, "know": 25, "sum": 25, "shasum": 25, "512": 25, "diff": 25, "local": 25, "bin": 25, "bash": 25, "package_vers": 25, "package_nam": 25, "provider_download_dir": 25, "mktemp": 25, "d": 25, "dep": 25, "dest": 25, "curl": 25, "apache_airflow_providers_databrick": 25, "py3": 25, "l": 25, "o": 25, "echo": 25, "la": 25, "onc": 25, "instruct": [25, 35], "chapter": 25, "temporari": 25, "One": [26, 33], "copy_into": 26, "import_csv": 26, "my_tabl": 26, "abfss": 26, "df": 26, "my": 26, "past": 28, "rememb": 28, "repeat": 28, "rather": 28, "ones": 28, "fall": 28, "under": 28, "With": [28, 34], "over": [28, 34], "underli": [28, 34], "harder": [28, 34], "lack": [28, 34], "task_kei": 28, "job_cluster_kei": 28, "spark_vers": [28, 34], "7": 28, "scala2": [28, 34], "node_type_id": [28, 34], "i3": 28, "xlarg": [28, 34], "num_work": [28, 34], "jobs_create_json": 28, "jobs_create_nam": 28, "return_valu": 28, "ti": 28, "xcom_pul": 28, "input": [29, 30, 31], "user_email": [29, 30, 31], "repo_nam": [29, 30, 31], "decim": [29, 30, 31], "usual": 31, "worker": [32, 34], "simpl": 33, "extens": 33, "new_lin": 33, "select_data": 33, "my_airflow_t": 33, "select_into_fil": 33, "select_data_into_fil": 33, "tmp": 33, "perform": 33, "create_and_populate_t": 33, "create_fil": 33, "create_and_populate_from_fil": 33, "starter": 33, "sql_sensor": 33, "hive_metastor": 33, "sql_sensor_task": 33, "temp": 33, "sample_table_3": 33, "60": 33, "someth": 33, "occur": 33, "happen": 33, "succe": 33, "arriv": 33, "interv": 33, "poke_interv": 33, "rang": 33, "partition_nam": 33, "partition_valu": 33, "partition_sensor": 33, "partition_sensor_task": 33, "sample_table_2": 33, "db3": 34, "preparedata": 34, "here": 34, "invok": 34, "r3": 34, "aws_attribut": 34, "on_demand": 34, "notebook_task_param": 34, "main_class_nam": 34, "processdata": 34, "lib": 34, "etl": 34, "independ": 35, "itself": 35, "vulner": 35, "publish": 35, "develop": 35, "alwai": 35, "next": 35, "strict": 35, "semver": 35, "scope": 35, "major": 35, "break": 35, "minor": 35, "patchlevel": 35, "critic": 35, "band": 35, "stakehold": 35, "decid": 35, "cherri": 35, "pick": 35, "older": 35, "mix": 35, "govern": 35, "interest": 35, "parti": 35}, "objects": {"airflow.providers": [[4, 0, 0, "-", "databricks"]], "airflow.providers.databricks": [[4, 1, 1, "", "__version__"], [3, 0, 0, "-", "hooks"], [8, 0, 0, "-", "operators"], [11, 0, 0, "-", "sensors"], [13, 0, 0, "-", "triggers"], [15, 0, 0, "-", "utils"]], "airflow.providers.databricks.hooks": [[0, 0, 0, "-", "databricks"], [1, 0, 0, "-", "databricks_base"], [2, 0, 0, "-", "databricks_sql"]], "airflow.providers.databricks.hooks.databricks": [[0, 1, 1, "", "CANCEL_ALL_RUNS_ENDPOINT"], [0, 1, 1, "", "CANCEL_RUN_ENDPOINT"], [0, 1, 1, "", "CREATE_ENDPOINT"], [0, 2, 1, "", "ClusterState"], [0, 1, 1, "", "DELETE_RUN_ENDPOINT"], [0, 2, 1, "", "DatabricksHook"], [0, 1, 1, "", "GET_CLUSTER_ENDPOINT"], [0, 1, 1, "", "GET_RUN_ENDPOINT"], [0, 1, 1, "", "INSTALL_LIBS_ENDPOINT"], [0, 1, 1, "", "LIST_JOBS_ENDPOINT"], [0, 1, 1, "", "LIST_PIPELINES_ENDPOINT"], [0, 1, 1, "", "OUTPUT_RUNS_JOB_ENDPOINT"], [0, 1, 1, "", "REPAIR_RUN_ENDPOINT"], [0, 1, 1, "", "RESET_ENDPOINT"], [0, 1, 1, "", "RESTART_CLUSTER_ENDPOINT"], [0, 1, 1, "", "RUN_NOW_ENDPOINT"], [0, 2, 1, "", "RunState"], [0, 1, 1, "", "SPARK_VERSIONS_ENDPOINT"], [0, 1, 1, "", "START_CLUSTER_ENDPOINT"], [0, 1, 1, "", "SUBMIT_RUN_ENDPOINT"], [0, 1, 1, "", "TERMINATE_CLUSTER_ENDPOINT"], [0, 1, 1, "", "UNINSTALL_LIBS_ENDPOINT"], [0, 1, 1, "", "WORKSPACE_GET_STATUS_ENDPOINT"]], "airflow.providers.databricks.hooks.databricks.ClusterState": [[0, 3, 1, "", "CLUSTER_LIFE_CYCLE_STATES"], [0, 4, 1, "", "__eq__"], [0, 4, 1, "", "__repr__"], [0, 4, 1, "", "from_json"], [0, 5, 1, "", "is_running"], [0, 5, 1, "", "is_terminal"], [0, 4, 1, "", "to_json"]], "airflow.providers.databricks.hooks.databricks.DatabricksHook": [[0, 4, 1, "", "a_get_cluster_state"], [0, 4, 1, "", "a_get_run"], [0, 4, 1, "", "a_get_run_page_url"], [0, 4, 1, "", "a_get_run_state"], [0, 4, 1, "", "cancel_all_runs"], [0, 4, 1, "", "cancel_run"], [0, 4, 1, "", "create_job"], [0, 4, 1, "", "create_repo"], [0, 4, 1, "", "delete_repo"], [0, 4, 1, "", "delete_run"], [0, 4, 1, "", "find_job_id_by_name"], [0, 4, 1, "", "find_pipeline_id_by_name"], [0, 4, 1, "", "get_cluster_state"], [0, 4, 1, "", "get_job_id"], [0, 4, 1, "", "get_repo_by_path"], [0, 4, 1, "", "get_run"], [0, 4, 1, "", "get_run_output"], [0, 4, 1, "", "get_run_page_url"], [0, 4, 1, "", "get_run_state"], [0, 4, 1, "", "get_run_state_lifecycle"], [0, 4, 1, "", "get_run_state_message"], [0, 4, 1, "", "get_run_state_result"], [0, 4, 1, "", "get_run_state_str"], [0, 3, 1, "", "hook_name"], [0, 4, 1, "", "install"], [0, 4, 1, "", "list_jobs"], [0, 4, 1, "", "list_pipelines"], [0, 4, 1, "", "repair_run"], [0, 4, 1, "", "reset_job"], [0, 4, 1, "", "restart_cluster"], [0, 4, 1, "", "run_now"], [0, 4, 1, "", "start_cluster"], [0, 4, 1, "", "submit_run"], [0, 4, 1, "", "terminate_cluster"], [0, 4, 1, "", "test_connection"], [0, 4, 1, "", "uninstall"], [0, 4, 1, "", "update_repo"]], "airflow.providers.databricks.hooks.databricks.RunState": [[0, 3, 1, "", "RUN_LIFE_CYCLE_STATES"], [0, 4, 1, "", "__eq__"], [0, 4, 1, "", "__repr__"], [0, 4, 1, "", "from_json"], [0, 5, 1, "", "is_successful"], [0, 5, 1, "", "is_terminal"], [0, 4, 1, "", "to_json"]], "airflow.providers.databricks.hooks.databricks_base": [[1, 1, 1, "", "AZURE_DEFAULT_AD_ENDPOINT"], [1, 1, 1, "", "AZURE_MANAGEMENT_ENDPOINT"], [1, 1, 1, "", "AZURE_METADATA_SERVICE_INSTANCE_URL"], [1, 1, 1, "", "AZURE_METADATA_SERVICE_TOKEN_URL"], [1, 1, 1, "", "AZURE_TOKEN_SERVICE_URL"], [1, 2, 1, "", "BaseDatabricksHook"], [1, 2, 1, "", "BearerAuth"], [1, 1, 1, "", "DEFAULT_DATABRICKS_SCOPE"], [1, 1, 1, "", "OIDC_TOKEN_SERVICE_URL"], [1, 1, 1, "", "TOKEN_REFRESH_LEAD_TIME"]], "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook": [[1, 4, 1, "", "__aenter__"], [1, 4, 1, "", "__aexit__"], [1, 3, 1, "", "conn_name_attr"], [1, 3, 1, "", "conn_type"], [1, 4, 1, "", "databricks_conn"], [1, 3, 1, "", "default_conn_name"], [1, 3, 1, "", "extra_parameters"], [1, 4, 1, "", "get_conn"], [1, 4, 1, "", "host"], [1, 4, 1, "", "user_agent_header"], [1, 4, 1, "", "user_agent_value"]], "airflow.providers.databricks.hooks.databricks_base.BearerAuth": [[1, 4, 1, "", "encode"]], "airflow.providers.databricks.hooks.databricks_sql": [[2, 2, 1, "", "DatabricksSqlHook"], [2, 1, 1, "", "LIST_SQL_ENDPOINTS_ENDPOINT"], [2, 1, 1, "", "T"]], "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook": [[2, 4, 1, "", "bulk_dump"], [2, 4, 1, "", "bulk_load"], [2, 4, 1, "", "get_conn"], [2, 3, 1, "", "hook_name"], [2, 4, 1, "", "run"]], "airflow.providers.databricks.operators": [[5, 0, 0, "-", "databricks"], [6, 0, 0, "-", "databricks_repos"], [7, 0, 0, "-", "databricks_sql"]], "airflow.providers.databricks.operators.databricks": [[5, 1, 1, "", "DEFER_METHOD_NAME"], [5, 2, 1, "", "DatabricksCreateJobsOperator"], [5, 2, 1, "", "DatabricksJobRunLink"], [5, 2, 1, "", "DatabricksRunNowDeferrableOperator"], [5, 2, 1, "", "DatabricksRunNowOperator"], [5, 2, 1, "", "DatabricksSubmitRunDeferrableOperator"], [5, 2, 1, "", "DatabricksSubmitRunOperator"], [5, 1, 1, "", "XCOM_JOB_ID_KEY"], [5, 1, 1, "", "XCOM_RUN_ID_KEY"], [5, 1, 1, "", "XCOM_RUN_PAGE_URL_KEY"]], "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator": [[5, 4, 1, "", "execute"], [5, 3, 1, "", "template_fields"], [5, 3, 1, "", "ui_color"], [5, 3, 1, "", "ui_fgcolor"]], "airflow.providers.databricks.operators.databricks.DatabricksJobRunLink": [[5, 4, 1, "", "get_link"], [5, 3, 1, "", "name"]], "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator": [[5, 4, 1, "", "execute"], [5, 4, 1, "", "execute_complete"], [5, 4, 1, "", "on_kill"], [5, 3, 1, "", "operator_extra_links"], [5, 3, 1, "", "template_ext"], [5, 3, 1, "", "template_fields"], [5, 3, 1, "", "ui_color"], [5, 3, 1, "", "ui_fgcolor"]], "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunDeferrableOperator": [[5, 4, 1, "", "execute"], [5, 4, 1, "", "execute_complete"]], "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator": [[5, 4, 1, "", "execute"], [5, 4, 1, "", "execute_complete"], [5, 4, 1, "", "on_kill"], [5, 3, 1, "", "operator_extra_links"], [5, 3, 1, "", "template_ext"], [5, 3, 1, "", "template_fields"], [5, 3, 1, "", "ui_color"], [5, 3, 1, "", "ui_fgcolor"]], "airflow.providers.databricks.operators.databricks_repos": [[6, 2, 1, "", "DatabricksReposCreateOperator"], [6, 2, 1, "", "DatabricksReposDeleteOperator"], [6, 2, 1, "", "DatabricksReposUpdateOperator"]], "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator": [[6, 3, 1, "", "__aws_code_commit_regexp__"], [6, 4, 1, "", "__detect_repo_provider__"], [6, 3, 1, "", "__git_providers__"], [6, 3, 1, "", "__repos_path_regexp__"], [6, 4, 1, "", "execute"], [6, 3, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_repos.DatabricksReposDeleteOperator": [[6, 4, 1, "", "execute"], [6, 3, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_repos.DatabricksReposUpdateOperator": [[6, 4, 1, "", "execute"], [6, 3, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_sql": [[7, 1, 1, "", "COPY_INTO_APPROVED_FORMATS"], [7, 2, 1, "", "DatabricksCopyIntoOperator"], [7, 2, 1, "", "DatabricksSqlOperator"]], "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator": [[7, 4, 1, "", "execute"], [7, 3, 1, "", "template_fields"]], "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator": [[7, 3, 1, "", "conn_id_field"], [7, 4, 1, "", "get_db_hook"], [7, 3, 1, "", "template_ext"], [7, 3, 1, "", "template_fields"], [7, 3, 1, "", "template_fields_renderers"]], "airflow.providers.databricks.sensors": [[9, 0, 0, "-", "databricks_partition"], [10, 0, 0, "-", "databricks_sql"]], "airflow.providers.databricks.sensors.databricks_partition": [[9, 2, 1, "", "DatabricksPartitionSensor"]], "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor": [[9, 4, 1, "", "poke"], [9, 3, 1, "", "template_ext"], [9, 3, 1, "", "template_fields"], [9, 3, 1, "", "template_fields_renderers"]], "airflow.providers.databricks.sensors.databricks_sql": [[10, 2, 1, "", "DatabricksSqlSensor"]], "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor": [[10, 4, 1, "", "hook"], [10, 4, 1, "", "poke"], [10, 3, 1, "", "template_ext"], [10, 3, 1, "", "template_fields"], [10, 3, 1, "", "template_fields_renderers"]], "airflow.providers.databricks.triggers": [[12, 0, 0, "-", "databricks"]], "airflow.providers.databricks.triggers.databricks": [[12, 2, 1, "", "DatabricksExecutionTrigger"]], "airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger": [[12, 4, 1, "", "run"], [12, 4, 1, "", "serialize"]], "airflow.providers.databricks.utils": [[14, 0, 0, "-", "databricks"]], "airflow.providers.databricks.utils.databricks": [[14, 6, 1, "", "normalise_json_content"], [14, 6, 1, "", "validate_trigger_event"]], "tests.system.providers": [[20, 0, 0, "-", "databricks"]], "tests.system.providers.databricks": [[16, 0, 0, "-", "example_databricks"], [17, 0, 0, "-", "example_databricks_repos"], [18, 0, 0, "-", "example_databricks_sensors"], [19, 0, 0, "-", "example_databricks_sql"]], "tests.system.providers.databricks.example_databricks": [[16, 1, 1, "", "DAG_ID"], [16, 1, 1, "", "ENV_ID"], [16, 1, 1, "", "job"], [16, 1, 1, "", "test_run"]], "tests.system.providers.databricks.example_databricks_repos": [[17, 1, 1, "", "DAG_ID"], [17, 1, 1, "", "ENV_ID"], [17, 1, 1, "", "default_args"], [17, 1, 1, "", "repo_path"], [17, 1, 1, "", "test_run"]], "tests.system.providers.databricks.example_databricks_sensors": [[18, 1, 1, "", "DAG_ID"], [18, 1, 1, "", "ENV_ID"], [18, 1, 1, "", "connection_id"], [18, 1, 1, "", "test_run"]], "tests.system.providers.databricks.example_databricks_sql": [[19, 1, 1, "", "DAG_ID"], [19, 1, 1, "", "ENV_ID"], [19, 1, 1, "", "connection_id"], [19, 1, 1, "", "test_run"]]}, "objtypes": {"0": "py:module", "1": "py:data", "2": "py:class", "3": "py:attribute", "4": "py:method", "5": "py:property", "6": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "data", "Python data"], "2": ["py", "class", "Python class"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "method", "Python method"], "5": ["py", "property", "Python property"], "6": ["py", "function", "Python function"]}, "titleterms": {"airflow": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 22, 24], "provid": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24], "databrick": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 27, 29, 30, 31], "hook": [0, 1, 2, 3], "modul": [0, 1, 2, 5, 6, 7, 9, 10, 12, 14, 16, 17, 18, 19], "content": [0, 1, 2, 4, 5, 6, 7, 9, 10, 12, 14, 16, 17, 18, 19], "class": [0, 1, 2, 5, 6, 7, 9, 10, 12], "attribut": [0, 1, 2, 5, 7], "databricks_bas": 1, "databricks_sql": [2, 7, 10], "submodul": [3, 8, 11, 13, 15, 20], "subpackag": 4, "packag": [4, 22, 24, 25], "oper": [5, 6, 7, 8, 26, 27, 28, 29, 30, 31, 32, 33, 34], "databricks_repo": 6, "sensor": [9, 10, 11, 33], "databricks_partit": 9, "trigger": [12, 13], "util": [14, 15], "function": 14, "test": [16, 17, 18, 19, 20], "system": [16, 17, 18, 19, 20], "example_databrick": 16, "example_databricks_repo": 17, "example_databricks_sensor": 18, "example_databricks_sql": 19, "changelog": 21, "6": [21, 22], "0": [21, 22], "break": 21, "chang": 21, "bug": 21, "fix": 21, "misc": 21, "5": [21, 22], "1": [21, 22], "4": [21, 22], "7": [21, 22], "featur": 21, "3": [21, 22], "2": [21, 22], "apach": [22, 24], "connect": 23, "authent": 23, "default": 23, "id": 23, "configur": 23, "instal": [24, 25], "requir": 24, "cross": 24, "depend": 24, "download": 24, "offici": 24, "from": [25, 33], "sourc": 25, "releas": [25, 35], "integr": 25, "verifi": 25, "pypi": 25, "databrickscopyintooper": 26, "us": [26, 28, 29, 30, 31, 32, 33, 34], "exampl": [26, 28, 29, 30, 31, 33, 34], "import": 26, "csv": 26, "data": [26, 33], "databrickscreatejobsoper": 28, "specifi": [28, 30, 31, 34], "paramet": [28, 34], "json": [28, 34], "name": [28, 34], "pair": 28, "databricksrunnowoper": [28, 32], "databricksreposcreateoper": 29, "creat": 29, "repo": [29, 30, 31], "databricksreposdeleteoper": 30, "delet": 30, "path": [30, 31], "databricksreposupdateoper": 31, "updat": 31, "databricksrunnowdeferrableoper": 32, "databrickssqloper": 33, "select": 33, "file": 33, "execut": 33, "multipl": 33, "statement": 33, "databrickssqlsensor": 33, "databrickspartitionsensor": 33, "databrickssubmitrunoper": 34, "databrickssubmitrundeferrableoper": 34, "secur": 35, "patch": 35}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"airflow.providers.databricks.hooks.databricks": [[0, "module-airflow.providers.databricks.hooks.databricks"]], "Module Contents": [[0, "module-contents"], [1, "module-contents"], [2, "module-contents"], [5, "module-contents"], [6, "module-contents"], [7, "module-contents"], [9, "module-contents"], [10, "module-contents"], [12, "module-contents"], [14, "module-contents"], [16, "module-contents"], [17, "module-contents"], [18, "module-contents"], [19, "module-contents"]], "Classes": [[0, "classes"], [1, "classes"], [2, "classes"], [5, "classes"], [6, "classes"], [7, "classes"], [9, "classes"], [10, "classes"], [12, "classes"]], "Attributes": [[0, "attributes"], [1, "attributes"], [2, "attributes"], [5, "attributes"], [7, "attributes"]], "airflow.providers.databricks.hooks.databricks_base": [[1, "module-airflow.providers.databricks.hooks.databricks_base"]], "airflow.providers.databricks.hooks.databricks_sql": [[2, "module-airflow.providers.databricks.hooks.databricks_sql"]], "airflow.providers.databricks.hooks": [[3, "module-airflow.providers.databricks.hooks"]], "Submodules": [[3, "submodules"], [8, "submodules"], [11, "submodules"], [13, "submodules"], [15, "submodules"], [20, "submodules"]], "airflow.providers.databricks": [[4, "module-airflow.providers.databricks"]], "Subpackages": [[4, "subpackages"]], "Package Contents": [[4, "package-contents"]], "airflow.providers.databricks.operators.databricks": [[5, "module-airflow.providers.databricks.operators.databricks"]], "airflow.providers.databricks.operators.databricks_repos": [[6, "module-airflow.providers.databricks.operators.databricks_repos"]], "airflow.providers.databricks.operators.databricks_sql": [[7, "module-airflow.providers.databricks.operators.databricks_sql"]], "airflow.providers.databricks.operators": [[8, "module-airflow.providers.databricks.operators"]], "airflow.providers.databricks.sensors.databricks_partition": [[9, "module-airflow.providers.databricks.sensors.databricks_partition"]], "airflow.providers.databricks.sensors.databricks_sql": [[10, "module-airflow.providers.databricks.sensors.databricks_sql"]], "airflow.providers.databricks.sensors": [[11, "module-airflow.providers.databricks.sensors"]], "airflow.providers.databricks.triggers.databricks": [[12, "module-airflow.providers.databricks.triggers.databricks"]], "airflow.providers.databricks.triggers": [[13, "module-airflow.providers.databricks.triggers"]], "airflow.providers.databricks.utils.databricks": [[14, "module-airflow.providers.databricks.utils.databricks"]], "Functions": [[14, "functions"]], "airflow.providers.databricks.utils": [[15, "module-airflow.providers.databricks.utils"]], "tests.system.providers.databricks.example_databricks": [[16, "module-tests.system.providers.databricks.example_databricks"]], "tests.system.providers.databricks.example_databricks_repos": [[17, "module-tests.system.providers.databricks.example_databricks_repos"]], "tests.system.providers.databricks.example_databricks_sensors": [[18, "module-tests.system.providers.databricks.example_databricks_sensors"]], "tests.system.providers.databricks.example_databricks_sql": [[19, "module-tests.system.providers.databricks.example_databricks_sql"]], "tests.system.providers.databricks": [[20, "module-tests.system.providers.databricks"]], "Changelog": [[21, "changelog"]], "6.0.0": [[21, "id1"], [22, "id1"]], "Breaking changes": [[21, "breaking-changes"], [21, "id5"], [21, "id39"], [21, "id56"], [21, "id86"]], "Bug Fixes": [[21, "bug-fixes"], [21, "id10"], [21, "id21"], [21, "id24"], [21, "id28"], [21, "id37"], [21, "id40"], [21, "id48"], [21, "id51"], [21, "id54"], [21, "id59"], [21, "id64"], [21, "id68"], [21, "id74"], [21, "id80"], [21, "id82"]], "Misc": [[21, "misc"], [21, "id3"], [21, "id11"], [21, "id14"], [21, "id17"], [21, "id19"], [21, "id22"], [21, "id25"], [21, "id29"], [21, "id33"], [21, "id43"], [21, "id47"], [21, "id65"], [21, "id71"], [21, "id75"], [21, "id84"]], "5.0.1": [[21, "id2"], [22, "id2"]], "5.0.0": [[21, "id4"], [22, "id3"]], "4.7.0": [[21, "id6"], [22, "id4"]], "Features": [[21, "features"], [21, "id9"], [21, "id13"], [21, "id16"], [21, "id27"], [21, "id32"], [21, "id35"], [21, "id44"], [21, "id46"], [21, "id50"], [21, "id53"], [21, "id58"], [21, "id61"], [21, "id63"], [21, "id67"], [21, "id70"], [21, "id73"], [21, "id77"], [21, "id79"]], "4.6.0": [[21, "id7"], [22, "id5"]], "4.5.0": [[21, "id12"], [22, "id6"]], "4.4.0": [[21, "id15"], [22, "id7"]], "4.3.3": [[21, "id18"], [22, "id8"]], "4.3.2": [[21, "id20"], [22, "id10"]], "4.3.1": [[21, "id23"], [22, "id11"]], "4.3.0": [[21, "id26"], [22, "id12"]], "4.2.0": [[21, "id30"], [22, "id13"]], "4.1.0": [[21, "id34"], [22, "id15"]], "4.0.1": [[21, "id36"], [22, "id16"]], "4.0.0": [[21, "id38"], [22, "id17"]], "3.4.0": [[21, "id41"], [22, "id18"]], "3.3.0": [[21, "id45"], [22, "id19"]], "3.2.0": [[21, "id49"], [22, "id21"]], "3.1.0": [[21, "id52"], [22, "id23"]], "3.0.0": [[21, "id55"], [22, "id24"]], "2.7.0": [[21, "id60"], [22, "id25"]], "2.6.0": [[21, "id62"], [22, "id26"]], "2.5.0": [[21, "id66"], [22, "id27"]], "2.4.0": [[21, "id69"], [22, "id28"]], "2.3.0": [[21, "id72"], [22, "id30"]], "2.2.0": [[21, "id76"], [22, "id31"]], "2.1.0": [[21, "id78"], [22, "id32"]], "2.0.2": [[21, "id81"], [22, "id33"]], "2.0.1": [[21, "id83"], [22, "id34"]], "2.0.0": [[21, "id85"], [22, "id35"]], "1.0.1": [[21, "id87"], [22, "id36"]], "1.0.0": [[21, "id88"], [22, "id37"]], "Package apache-airflow-providers-databricks": [[22, "package-apache-airflow-providers-databricks"], [24, "package-apache-airflow-providers-databricks"]], "Databricks Connection": [[23, "databricks-connection"]], "Authenticating to Databricks": [[23, "authenticating-to-databricks"]], "Default Connection IDs": [[23, "default-connection-ids"]], "Configuring the Connection": [[23, "configuring-the-connection"]], "apache-airflow-providers-databricks": [[24, "apache-airflow-providers-databricks"]], "Provider package": [[24, "provider-package"]], "Installation": [[24, "installation"]], "Requirements": [[24, "requirements"]], "Cross provider package dependencies": [[24, "cross-provider-package-dependencies"]], "Downloading official packages": [[24, "downloading-official-packages"]], "Installing from sources": [[25, "installing-from-sources"]], "Released packages": [[25, "released-packages"]], "Release integrity": [[25, "release-integrity"]], "Verifying PyPI releases": [[25, "verifying-pypi-releases"]], "DatabricksCopyIntoOperator": [[26, "databrickscopyintooperator"]], "Using the Operator": [[26, "using-the-operator"], [28, "using-the-operator"], [29, "using-the-operator"], [30, "using-the-operator"], [31, "using-the-operator"], [32, "using-the-operator"], [33, "using-the-operator"], [34, "using-the-operator"]], "Examples": [[26, "examples"], [28, "examples"], [29, "examples"], [30, "examples"], [31, "examples"], [33, "examples"], [33, "id1"], [33, "id3"], [34, "examples"]], "Importing CSV data": [[26, "importing-csv-data"]], "Databricks Operators": [[27, "databricks-operators"]], "DatabricksCreateJobsOperator": [[28, "databrickscreatejobsoperator"]], "Specifying parameters as JSON": [[28, "specifying-parameters-as-json"], [34, "specifying-parameters-as-json"]], "Using named parameters": [[28, "using-named-parameters"], [34, "using-named-parameters"]], "Pairing with DatabricksRunNowOperator": [[28, "pairing-with-databricksrunnowoperator"]], "DatabricksReposCreateOperator": [[29, "databricksreposcreateoperator"]], "Create a Databricks Repo": [[29, "create-a-databricks-repo"]], "DatabricksReposDeleteOperator": [[30, "databricksreposdeleteoperator"]], "Deleting Databricks Repo by specifying path": [[30, "deleting-databricks-repo-by-specifying-path"]], "DatabricksReposUpdateOperator": [[31, "databricksreposupdateoperator"]], "Updating Databricks Repo by specifying path": [[31, "updating-databricks-repo-by-specifying-path"]], "DatabricksRunNowOperator": [[32, "databricksrunnowoperator"]], "DatabricksRunNowDeferrableOperator": [[32, "databricksrunnowdeferrableoperator"]], "DatabricksSqlOperator": [[33, "databrickssqloperator"]], "Selecting data": [[33, "selecting-data"]], "Selecting data into a file": [[33, "selecting-data-into-a-file"]], "Executing multiple statements": [[33, "executing-multiple-statements"]], "Executing multiple statements from a file": [[33, "executing-multiple-statements-from-a-file"]], "DatabricksSqlSensor": [[33, "databrickssqlsensor"]], "Using the Sensor": [[33, "using-the-sensor"], [33, "id2"]], "DatabricksPartitionSensor": [[33, "databrickspartitionsensor"]], "DatabricksSubmitRunOperator": [[34, "databrickssubmitrunoperator"]], "DatabricksSubmitRunDeferrableOperator": [[34, "databrickssubmitrundeferrableoperator"]], "Releasing security patches": [[35, "releasing-security-patches"]]}, "indexentries": {"cancel_all_runs_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.CANCEL_ALL_RUNS_ENDPOINT"]], "cancel_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.CANCEL_RUN_ENDPOINT"]], "cluster_life_cycle_states (airflow.providers.databricks.hooks.databricks.clusterstate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.CLUSTER_LIFE_CYCLE_STATES"]], "create_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.CREATE_ENDPOINT"]], "clusterstate (class in airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState"]], "delete_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.DELETE_RUN_ENDPOINT"]], "databrickshook (class in airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook"]], "get_cluster_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.GET_CLUSTER_ENDPOINT"]], "get_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.GET_RUN_ENDPOINT"]], "install_libs_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.INSTALL_LIBS_ENDPOINT"]], "list_jobs_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.LIST_JOBS_ENDPOINT"]], "list_pipelines_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.LIST_PIPELINES_ENDPOINT"]], "output_runs_job_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.OUTPUT_RUNS_JOB_ENDPOINT"]], "repair_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.REPAIR_RUN_ENDPOINT"]], "reset_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.RESET_ENDPOINT"]], "restart_cluster_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.RESTART_CLUSTER_ENDPOINT"]], "run_life_cycle_states (airflow.providers.databricks.hooks.databricks.runstate attribute)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.RUN_LIFE_CYCLE_STATES"]], "run_now_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.RUN_NOW_ENDPOINT"]], "runstate (class in airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.RunState"]], "spark_versions_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.SPARK_VERSIONS_ENDPOINT"]], "start_cluster_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.START_CLUSTER_ENDPOINT"]], "submit_run_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.SUBMIT_RUN_ENDPOINT"]], "terminate_cluster_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.TERMINATE_CLUSTER_ENDPOINT"]], "uninstall_libs_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.UNINSTALL_LIBS_ENDPOINT"]], "workspace_get_status_endpoint (in module airflow.providers.databricks.hooks.databricks)": [[0, "airflow.providers.databricks.hooks.databricks.WORKSPACE_GET_STATUS_ENDPOINT"]], "__eq__() (airflow.providers.databricks.hooks.databricks.clusterstate method)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.__eq__"]], "__eq__() (airflow.providers.databricks.hooks.databricks.runstate method)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.__eq__"]], "__repr__() (airflow.providers.databricks.hooks.databricks.clusterstate method)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.__repr__"]], "__repr__() (airflow.providers.databricks.hooks.databricks.runstate method)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.__repr__"]], "a_get_cluster_state() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_cluster_state"]], "a_get_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_run"]], "a_get_run_page_url() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_run_page_url"]], "a_get_run_state() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.a_get_run_state"]], "airflow.providers.databricks.hooks.databricks": [[0, "module-airflow.providers.databricks.hooks.databricks"]], "cancel_all_runs() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.cancel_all_runs"]], "cancel_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.cancel_run"]], "create_job() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.create_job"]], "create_repo() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.create_repo"]], "delete_repo() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.delete_repo"]], "delete_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.delete_run"]], "find_job_id_by_name() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.find_job_id_by_name"]], "find_pipeline_id_by_name() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.find_pipeline_id_by_name"]], "from_json() (airflow.providers.databricks.hooks.databricks.clusterstate class method)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.from_json"]], "from_json() (airflow.providers.databricks.hooks.databricks.runstate class method)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.from_json"]], "get_cluster_state() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_cluster_state"]], "get_job_id() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_job_id"]], "get_repo_by_path() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_repo_by_path"]], "get_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run"]], "get_run_output() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_output"]], "get_run_page_url() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_page_url"]], "get_run_state() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state"]], "get_run_state_lifecycle() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state_lifecycle"]], "get_run_state_message() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state_message"]], "get_run_state_result() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state_result"]], "get_run_state_str() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.get_run_state_str"]], "hook_name (airflow.providers.databricks.hooks.databricks.databrickshook attribute)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.hook_name"]], "install() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.install"]], "is_running (airflow.providers.databricks.hooks.databricks.clusterstate property)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.is_running"]], "is_successful (airflow.providers.databricks.hooks.databricks.runstate property)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.is_successful"]], "is_terminal (airflow.providers.databricks.hooks.databricks.clusterstate property)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.is_terminal"]], "is_terminal (airflow.providers.databricks.hooks.databricks.runstate property)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.is_terminal"]], "list_jobs() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.list_jobs"]], "list_pipelines() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.list_pipelines"]], "module": [[0, "module-airflow.providers.databricks.hooks.databricks"], [1, "module-airflow.providers.databricks.hooks.databricks_base"], [2, "module-airflow.providers.databricks.hooks.databricks_sql"], [3, "module-airflow.providers.databricks.hooks"], [4, "module-airflow.providers.databricks"], [5, "module-airflow.providers.databricks.operators.databricks"], [6, "module-airflow.providers.databricks.operators.databricks_repos"], [7, "module-airflow.providers.databricks.operators.databricks_sql"], [8, "module-airflow.providers.databricks.operators"], [9, "module-airflow.providers.databricks.sensors.databricks_partition"], [10, "module-airflow.providers.databricks.sensors.databricks_sql"], [11, "module-airflow.providers.databricks.sensors"], [12, "module-airflow.providers.databricks.triggers.databricks"], [13, "module-airflow.providers.databricks.triggers"], [14, "module-airflow.providers.databricks.utils.databricks"], [15, "module-airflow.providers.databricks.utils"], [16, "module-tests.system.providers.databricks.example_databricks"], [17, "module-tests.system.providers.databricks.example_databricks_repos"], [18, "module-tests.system.providers.databricks.example_databricks_sensors"], [19, "module-tests.system.providers.databricks.example_databricks_sql"], [20, "module-tests.system.providers.databricks"]], "repair_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.repair_run"]], "reset_job() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.reset_job"]], "restart_cluster() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.restart_cluster"]], "run_now() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.run_now"]], "start_cluster() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.start_cluster"]], "submit_run() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.submit_run"]], "terminate_cluster() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.terminate_cluster"]], "test_connection() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.test_connection"]], "to_json() (airflow.providers.databricks.hooks.databricks.clusterstate method)": [[0, "airflow.providers.databricks.hooks.databricks.ClusterState.to_json"]], "to_json() (airflow.providers.databricks.hooks.databricks.runstate method)": [[0, "airflow.providers.databricks.hooks.databricks.RunState.to_json"]], "uninstall() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.uninstall"]], "update_repo() (airflow.providers.databricks.hooks.databricks.databrickshook method)": [[0, "airflow.providers.databricks.hooks.databricks.DatabricksHook.update_repo"]], "azure_default_ad_endpoint (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.AZURE_DEFAULT_AD_ENDPOINT"]], "azure_management_endpoint (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.AZURE_MANAGEMENT_ENDPOINT"]], "azure_metadata_service_instance_url (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.AZURE_METADATA_SERVICE_INSTANCE_URL"]], "azure_metadata_service_token_url (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.AZURE_METADATA_SERVICE_TOKEN_URL"]], "azure_token_service_url (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.AZURE_TOKEN_SERVICE_URL"]], "basedatabrickshook (class in airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook"]], "bearerauth (class in airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.BearerAuth"]], "default_databricks_scope (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.DEFAULT_DATABRICKS_SCOPE"]], "oidc_token_service_url (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.OIDC_TOKEN_SERVICE_URL"]], "token_refresh_lead_time (in module airflow.providers.databricks.hooks.databricks_base)": [[1, "airflow.providers.databricks.hooks.databricks_base.TOKEN_REFRESH_LEAD_TIME"]], "__aenter__() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.__aenter__"]], "__aexit__() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.__aexit__"]], "airflow.providers.databricks.hooks.databricks_base": [[1, "module-airflow.providers.databricks.hooks.databricks_base"]], "conn_name_attr (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook attribute)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.conn_name_attr"]], "conn_type (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook attribute)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.conn_type"]], "databricks_conn() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.databricks_conn"]], "default_conn_name (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook attribute)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.default_conn_name"]], "encode() (airflow.providers.databricks.hooks.databricks_base.bearerauth method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BearerAuth.encode"]], "extra_parameters (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook attribute)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.extra_parameters"]], "get_conn() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.get_conn"]], "host() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.host"]], "user_agent_header() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.user_agent_header"]], "user_agent_value() (airflow.providers.databricks.hooks.databricks_base.basedatabrickshook method)": [[1, "airflow.providers.databricks.hooks.databricks_base.BaseDatabricksHook.user_agent_value"]], "databrickssqlhook (class in airflow.providers.databricks.hooks.databricks_sql)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook"]], "list_sql_endpoints_endpoint (in module airflow.providers.databricks.hooks.databricks_sql)": [[2, "airflow.providers.databricks.hooks.databricks_sql.LIST_SQL_ENDPOINTS_ENDPOINT"]], "t (in module airflow.providers.databricks.hooks.databricks_sql)": [[2, "airflow.providers.databricks.hooks.databricks_sql.T"]], "airflow.providers.databricks.hooks.databricks_sql": [[2, "module-airflow.providers.databricks.hooks.databricks_sql"]], "bulk_dump() (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook method)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.bulk_dump"]], "bulk_load() (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook method)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.bulk_load"]], "get_conn() (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook method)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.get_conn"]], "hook_name (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook attribute)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.hook_name"]], "run() (airflow.providers.databricks.hooks.databricks_sql.databrickssqlhook method)": [[2, "airflow.providers.databricks.hooks.databricks_sql.DatabricksSqlHook.run"]], "airflow.providers.databricks.hooks": [[3, "module-airflow.providers.databricks.hooks"]], "__version__ (in module airflow.providers.databricks)": [[4, "airflow.providers.databricks.__version__"]], "airflow.providers.databricks": [[4, "module-airflow.providers.databricks"]], "defer_method_name (in module airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DEFER_METHOD_NAME"]], "databrickscreatejobsoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator"]], "databricksjobrunlink (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksJobRunLink"]], "databricksrunnowdeferrableoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowDeferrableOperator"]], "databricksrunnowoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator"]], "databrickssubmitrundeferrableoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunDeferrableOperator"]], "databrickssubmitrunoperator (class in airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"]], "xcom_job_id_key (in module airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.XCOM_JOB_ID_KEY"]], "xcom_run_id_key (in module airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.XCOM_RUN_ID_KEY"]], "xcom_run_page_url_key (in module airflow.providers.databricks.operators.databricks)": [[5, "airflow.providers.databricks.operators.databricks.XCOM_RUN_PAGE_URL_KEY"]], "airflow.providers.databricks.operators.databricks": [[5, "module-airflow.providers.databricks.operators.databricks"]], "execute() (airflow.providers.databricks.operators.databricks.databrickscreatejobsoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks.databricksrunnowoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks.databrickssubmitrundeferrableoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunDeferrableOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.execute"]], "execute_complete() (airflow.providers.databricks.operators.databricks.databricksrunnowoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.execute_complete"]], "execute_complete() (airflow.providers.databricks.operators.databricks.databrickssubmitrundeferrableoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunDeferrableOperator.execute_complete"]], "execute_complete() (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.execute_complete"]], "get_link() (airflow.providers.databricks.operators.databricks.databricksjobrunlink method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksJobRunLink.get_link"]], "name (airflow.providers.databricks.operators.databricks.databricksjobrunlink attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksJobRunLink.name"]], "on_kill() (airflow.providers.databricks.operators.databricks.databricksrunnowoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.on_kill"]], "on_kill() (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator method)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.on_kill"]], "operator_extra_links (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.operator_extra_links"]], "operator_extra_links (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.operator_extra_links"]], "template_ext (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.template_ext"]], "template_ext (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.template_ext"]], "template_fields (airflow.providers.databricks.operators.databricks.databrickscreatejobsoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.template_fields"]], "ui_color (airflow.providers.databricks.operators.databricks.databrickscreatejobsoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator.ui_color"]], "ui_color (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.ui_color"]], "ui_color (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.ui_color"]], "ui_fgcolor (airflow.providers.databricks.operators.databricks.databrickscreatejobsoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksCreateJobsOperator.ui_fgcolor"]], "ui_fgcolor (airflow.providers.databricks.operators.databricks.databricksrunnowoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksRunNowOperator.ui_fgcolor"]], "ui_fgcolor (airflow.providers.databricks.operators.databricks.databrickssubmitrunoperator attribute)": [[5, "airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator.ui_fgcolor"]], "databricksreposcreateoperator (class in airflow.providers.databricks.operators.databricks_repos)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator"]], "databricksreposdeleteoperator (class in airflow.providers.databricks.operators.databricks_repos)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposDeleteOperator"]], "databricksreposupdateoperator (class in airflow.providers.databricks.operators.databricks_repos)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposUpdateOperator"]], "__aws_code_commit_regexp__ (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.__aws_code_commit_regexp__"]], "__detect_repo_provider__() (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator static method)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.__detect_repo_provider__"]], "__git_providers__ (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.__git_providers__"]], "__repos_path_regexp__ (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.__repos_path_regexp__"]], "airflow.providers.databricks.operators.databricks_repos": [[6, "module-airflow.providers.databricks.operators.databricks_repos"]], "execute() (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator method)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks_repos.databricksreposdeleteoperator method)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposDeleteOperator.execute"]], "execute() (airflow.providers.databricks.operators.databricks_repos.databricksreposupdateoperator method)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposUpdateOperator.execute"]], "template_fields (airflow.providers.databricks.operators.databricks_repos.databricksreposcreateoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposCreateOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks_repos.databricksreposdeleteoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposDeleteOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks_repos.databricksreposupdateoperator attribute)": [[6, "airflow.providers.databricks.operators.databricks_repos.DatabricksReposUpdateOperator.template_fields"]], "copy_into_approved_formats (in module airflow.providers.databricks.operators.databricks_sql)": [[7, "airflow.providers.databricks.operators.databricks_sql.COPY_INTO_APPROVED_FORMATS"]], "databrickscopyintooperator (class in airflow.providers.databricks.operators.databricks_sql)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator"]], "databrickssqloperator (class in airflow.providers.databricks.operators.databricks_sql)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator"]], "airflow.providers.databricks.operators.databricks_sql": [[7, "module-airflow.providers.databricks.operators.databricks_sql"]], "conn_id_field (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.conn_id_field"]], "execute() (airflow.providers.databricks.operators.databricks_sql.databrickscopyintooperator method)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator.execute"]], "get_db_hook() (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator method)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.get_db_hook"]], "template_ext (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.template_ext"]], "template_fields (airflow.providers.databricks.operators.databricks_sql.databrickscopyintooperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksCopyIntoOperator.template_fields"]], "template_fields (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.template_fields"]], "template_fields_renderers (airflow.providers.databricks.operators.databricks_sql.databrickssqloperator attribute)": [[7, "airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator.template_fields_renderers"]], "airflow.providers.databricks.operators": [[8, "module-airflow.providers.databricks.operators"]], "databrickspartitionsensor (class in airflow.providers.databricks.sensors.databricks_partition)": [[9, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor"]], "airflow.providers.databricks.sensors.databricks_partition": [[9, "module-airflow.providers.databricks.sensors.databricks_partition"]], "poke() (airflow.providers.databricks.sensors.databricks_partition.databrickspartitionsensor method)": [[9, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor.poke"]], "template_ext (airflow.providers.databricks.sensors.databricks_partition.databrickspartitionsensor attribute)": [[9, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor.template_ext"]], "template_fields (airflow.providers.databricks.sensors.databricks_partition.databrickspartitionsensor attribute)": [[9, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor.template_fields"]], "template_fields_renderers (airflow.providers.databricks.sensors.databricks_partition.databrickspartitionsensor attribute)": [[9, "airflow.providers.databricks.sensors.databricks_partition.DatabricksPartitionSensor.template_fields_renderers"]], "databrickssqlsensor (class in airflow.providers.databricks.sensors.databricks_sql)": [[10, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor"]], "airflow.providers.databricks.sensors.databricks_sql": [[10, "module-airflow.providers.databricks.sensors.databricks_sql"]], "hook() (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor method)": [[10, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.hook"]], "poke() (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor method)": [[10, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.poke"]], "template_ext (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor attribute)": [[10, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.template_ext"]], "template_fields (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor attribute)": [[10, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.template_fields"]], "template_fields_renderers (airflow.providers.databricks.sensors.databricks_sql.databrickssqlsensor attribute)": [[10, "airflow.providers.databricks.sensors.databricks_sql.DatabricksSqlSensor.template_fields_renderers"]], "airflow.providers.databricks.sensors": [[11, "module-airflow.providers.databricks.sensors"]], "databricksexecutiontrigger (class in airflow.providers.databricks.triggers.databricks)": [[12, "airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger"]], "airflow.providers.databricks.triggers.databricks": [[12, "module-airflow.providers.databricks.triggers.databricks"]], "run() (airflow.providers.databricks.triggers.databricks.databricksexecutiontrigger method)": [[12, "airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger.run"]], "serialize() (airflow.providers.databricks.triggers.databricks.databricksexecutiontrigger method)": [[12, "airflow.providers.databricks.triggers.databricks.DatabricksExecutionTrigger.serialize"]], "airflow.providers.databricks.triggers": [[13, "module-airflow.providers.databricks.triggers"]], "airflow.providers.databricks.utils.databricks": [[14, "module-airflow.providers.databricks.utils.databricks"]], "normalise_json_content() (in module airflow.providers.databricks.utils.databricks)": [[14, "airflow.providers.databricks.utils.databricks.normalise_json_content"]], "validate_trigger_event() (in module airflow.providers.databricks.utils.databricks)": [[14, "airflow.providers.databricks.utils.databricks.validate_trigger_event"]], "airflow.providers.databricks.utils": [[15, "module-airflow.providers.databricks.utils"]], "dag_id (in module tests.system.providers.databricks.example_databricks)": [[16, "tests.system.providers.databricks.example_databricks.DAG_ID"]], "env_id (in module tests.system.providers.databricks.example_databricks)": [[16, "tests.system.providers.databricks.example_databricks.ENV_ID"]], "job (in module tests.system.providers.databricks.example_databricks)": [[16, "tests.system.providers.databricks.example_databricks.job"]], "test_run (in module tests.system.providers.databricks.example_databricks)": [[16, "tests.system.providers.databricks.example_databricks.test_run"]], "tests.system.providers.databricks.example_databricks": [[16, "module-tests.system.providers.databricks.example_databricks"]], "dag_id (in module tests.system.providers.databricks.example_databricks_repos)": [[17, "tests.system.providers.databricks.example_databricks_repos.DAG_ID"]], "env_id (in module tests.system.providers.databricks.example_databricks_repos)": [[17, "tests.system.providers.databricks.example_databricks_repos.ENV_ID"]], "default_args (in module tests.system.providers.databricks.example_databricks_repos)": [[17, "tests.system.providers.databricks.example_databricks_repos.default_args"]], "repo_path (in module tests.system.providers.databricks.example_databricks_repos)": [[17, "tests.system.providers.databricks.example_databricks_repos.repo_path"]], "test_run (in module tests.system.providers.databricks.example_databricks_repos)": [[17, "tests.system.providers.databricks.example_databricks_repos.test_run"]], "tests.system.providers.databricks.example_databricks_repos": [[17, "module-tests.system.providers.databricks.example_databricks_repos"]], "dag_id (in module tests.system.providers.databricks.example_databricks_sensors)": [[18, "tests.system.providers.databricks.example_databricks_sensors.DAG_ID"]], "env_id (in module tests.system.providers.databricks.example_databricks_sensors)": [[18, "tests.system.providers.databricks.example_databricks_sensors.ENV_ID"]], "connection_id (in module tests.system.providers.databricks.example_databricks_sensors)": [[18, "tests.system.providers.databricks.example_databricks_sensors.connection_id"]], "test_run (in module tests.system.providers.databricks.example_databricks_sensors)": [[18, "tests.system.providers.databricks.example_databricks_sensors.test_run"]], "tests.system.providers.databricks.example_databricks_sensors": [[18, "module-tests.system.providers.databricks.example_databricks_sensors"]], "dag_id (in module tests.system.providers.databricks.example_databricks_sql)": [[19, "tests.system.providers.databricks.example_databricks_sql.DAG_ID"]], "env_id (in module tests.system.providers.databricks.example_databricks_sql)": [[19, "tests.system.providers.databricks.example_databricks_sql.ENV_ID"]], "connection_id (in module tests.system.providers.databricks.example_databricks_sql)": [[19, "tests.system.providers.databricks.example_databricks_sql.connection_id"]], "test_run (in module tests.system.providers.databricks.example_databricks_sql)": [[19, "tests.system.providers.databricks.example_databricks_sql.test_run"]], "tests.system.providers.databricks.example_databricks_sql": [[19, "module-tests.system.providers.databricks.example_databricks_sql"]], "tests.system.providers.databricks": [[20, "module-tests.system.providers.databricks"]]}})