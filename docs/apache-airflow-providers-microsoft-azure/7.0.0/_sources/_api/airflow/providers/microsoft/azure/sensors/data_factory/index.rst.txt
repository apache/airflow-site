:py:mod:`airflow.providers.microsoft.azure.sensors.data_factory`
================================================================

.. py:module:: airflow.providers.microsoft.azure.sensors.data_factory


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.microsoft.azure.sensors.data_factory.AzureDataFactoryPipelineRunStatusSensor




.. py:class:: AzureDataFactoryPipelineRunStatusSensor(*, run_id, azure_data_factory_conn_id = AzureDataFactoryHook.default_conn_name, resource_group_name = None, factory_name = None, deferrable = conf.getboolean('operators', 'default_deferrable', fallback=False), **kwargs)


   Bases: :py:obj:`airflow.sensors.base.BaseSensorOperator`

   Checks the status of a pipeline run.

   :param azure_data_factory_conn_id: The connection identifier for connecting to Azure Data Factory.
   :param run_id: The pipeline run identifier.
   :param resource_group_name: The resource group name.
   :param factory_name: The data factory name.
   :param deferrable: Run sensor in the deferrable mode.

   .. py:attribute:: template_fields
      :type: Sequence[str]
      :value: ('azure_data_factory_conn_id', 'resource_group_name', 'factory_name', 'run_id')

      

   .. py:attribute:: ui_color
      :value: '#50e6ff'

      

   .. py:method:: hook()

      Create and return an AzureDataFactoryHook (cached).


   .. py:method:: poke(context)

      Override when deriving this class.


   .. py:method:: execute(context)

      Poll for state of the job run.

      In deferrable mode, the polling is deferred to the triggerer. Otherwise
      the sensor waits synchronously.


   .. py:method:: execute_complete(context, event)

      Callback for when the trigger fires - returns immediately.

      Relies on trigger to throw an exception, otherwise it assumes execution was successful.



