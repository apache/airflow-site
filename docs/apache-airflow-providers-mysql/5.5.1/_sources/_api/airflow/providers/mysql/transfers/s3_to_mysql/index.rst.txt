:py:mod:`airflow.providers.mysql.transfers.s3_to_mysql`
=======================================================

.. py:module:: airflow.providers.mysql.transfers.s3_to_mysql


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.providers.mysql.transfers.s3_to_mysql.S3ToMySqlOperator




.. py:class:: S3ToMySqlOperator(*, s3_source_key, mysql_table, mysql_duplicate_key_handling = 'IGNORE', mysql_extra_options = None, aws_conn_id = 'aws_default', mysql_conn_id = 'mysql_default', mysql_local_infile = False, **kwargs)


   Bases: :py:obj:`airflow.models.BaseOperator`

   Loads a file from S3 into a MySQL table.

   :param s3_source_key: The path to the file (S3 key) that will be loaded into MySQL.
   :param mysql_table: The MySQL table into where the data will be sent.
   :param mysql_duplicate_key_handling: Specify what should happen to duplicate data.
       You can choose either `IGNORE` or `REPLACE`.

       .. seealso::
           https://dev.mysql.com/doc/refman/8.0/en/load-data.html#load-data-duplicate-key-handling
   :param mysql_extra_options: MySQL options to specify exactly how to load the data.
   :param aws_conn_id: The S3 connection that contains the credentials to the S3 Bucket.
   :param mysql_conn_id: Reference to :ref:`mysql connection id <howto/connection:mysql>`.
   :param mysql_local_infile: flag to enable local_infile option on the MySQLHook. This
       loads MySQL directly using the LOAD DATA LOCAL INFILE command. Defaults to False.

   .. py:attribute:: template_fields
      :type: Sequence[str]
      :value: ('s3_source_key', 'mysql_table')

      

   .. py:attribute:: template_ext
      :type: Sequence[str]
      :value: ()

      

   .. py:attribute:: ui_color
      :value: '#f4a460'

      

   .. py:method:: execute(context)

      Executes the transfer operation from S3 to MySQL.

      :param context: The context that is being provided when executing.



