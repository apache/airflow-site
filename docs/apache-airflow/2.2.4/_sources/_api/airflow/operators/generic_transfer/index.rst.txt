:py:mod:`airflow.operators.generic_transfer`
============================================

.. py:module:: airflow.operators.generic_transfer


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.operators.generic_transfer.GenericTransfer




.. py:class:: GenericTransfer(*, sql: str, destination_table: str, source_conn_id: str, destination_conn_id: str, preoperator: Optional[Union[str, List[str]]] = None, insert_args: Optional[dict] = None, **kwargs)

   Bases: :py:obj:`airflow.models.BaseOperator`

   Moves data from a connection to another, assuming that they both
   provide the required methods in their respective hooks. The source hook
   needs to expose a `get_records` method, and the destination a
   `insert_rows` method.

   This is meant to be used on small-ish datasets that fit in memory.

   :param sql: SQL query to execute against the source database. (templated)
   :type sql: str
   :param destination_table: target table. (templated)
   :type destination_table: str
   :param source_conn_id: source connection
   :type source_conn_id: str
   :param destination_conn_id: destination connection
   :type destination_conn_id: str
   :param preoperator: sql statement or list of statements to be
       executed prior to loading the data. (templated)
   :type preoperator: str or list[str]
   :param insert_args: extra params for `insert_rows` method.
   :type insert_args: dict

   .. py:attribute:: template_fields
      :annotation: = ['sql', 'destination_table', 'preoperator']

      

   .. py:attribute:: template_ext
      :annotation: = ['.sql', '.hql']

      

   .. py:attribute:: template_fields_renderers
      

      

   .. py:attribute:: ui_color
      :annotation: = #b0f07c

      

   .. py:method:: execute(self, context)

      This is the main method to derive when creating an operator.
      Context is the same dictionary used as when rendering jinja templates.

      Refer to get_template_context for more context.



