:py:mod:`airflow.models.dagpickle`
==================================

.. py:module:: airflow.models.dagpickle


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   airflow.models.dagpickle.DagPickle




.. py:class:: DagPickle(dag)

   Bases: :py:obj:`airflow.models.base.Base`

   Dags can originate from different places (user repos, main repo, ...)
   and also get executed in different places (different executors). This
   object represents a version of a DAG and becomes a source of truth for
   a BackfillJob execution. A pickle is a native python serialized object,
   and in this case gets stored in the database for the duration of the job.

   The executors pick up the DagPickle id and read the dag definition from
   the database.

   .. py:attribute:: id
      

      

   .. py:attribute:: pickle
      

      

   .. py:attribute:: created_dttm
      

      

   .. py:attribute:: pickle_hash
      

      

   .. py:attribute:: __tablename__
      :annotation: = dag_pickle

      


